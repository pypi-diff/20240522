# Comparing `tmp/pyzefir-0.4.1.tar.gz` & `tmp/pyzefir-0.4.22.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "pyzefir-0.4.1.tar", last modified: Thu Mar 21 13:18:05 2024, max compression
+gzip compressed data, was "pyzefir-0.4.22.tar", last modified: Wed May 22 17:05:55 2024, max compression
```

## Comparing `pyzefir-0.4.1.tar` & `pyzefir-0.4.22.tar`

### file list

```diff
@@ -1,189 +1,184 @@
-drwxr-xr-x   0 kruksik   (1000) kruksik   (1000)        0 2024-03-21 13:18:05.570981 pyzefir-0.4.1/
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)    34523 2024-02-05 15:42:18.000000 pyzefir-0.4.1/LICENSE.txt
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)    45993 2024-03-21 13:18:05.570981 pyzefir-0.4.1/PKG-INFO
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     4543 2024-02-16 14:59:55.000000 pyzefir-0.4.1/README.md
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     3274 2024-03-21 13:16:01.000000 pyzefir-0.4.1/pyproject.toml
-drwxr-xr-x   0 kruksik   (1000) kruksik   (1000)        0 2024-03-21 13:18:05.540981 pyzefir-0.4.1/pyzefir/
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)      831 2024-03-21 13:16:01.000000 pyzefir-0.4.1/pyzefir/__init__.py
-drwxr-xr-x   0 kruksik   (1000) kruksik   (1000)        0 2024-03-21 13:18:05.540981 pyzefir-0.4.1/pyzefir/cli/
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)      728 2024-02-05 15:42:18.000000 pyzefir-0.4.1/pyzefir/cli/__init__.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)      811 2024-02-16 14:59:55.000000 pyzefir-0.4.1/pyzefir/cli/__main__.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     2683 2024-03-21 13:16:01.000000 pyzefir-0.4.1/pyzefir/cli/logger.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     6807 2024-03-21 13:16:01.000000 pyzefir-0.4.1/pyzefir/cli/runner.py
-drwxr-xr-x   0 kruksik   (1000) kruksik   (1000)        0 2024-03-21 13:18:05.540981 pyzefir-0.4.1/pyzefir/graph/
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)      728 2024-02-05 15:42:18.000000 pyzefir-0.4.1/pyzefir/graph/__init__.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     1541 2024-02-05 15:42:18.000000 pyzefir-0.4.1/pyzefir/graph/constants.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)    10681 2024-02-05 15:42:18.000000 pyzefir-0.4.1/pyzefir/graph/network_diagram.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     1135 2024-02-05 15:42:18.000000 pyzefir-0.4.1/pyzefir/graph/utils.py
-drwxr-xr-x   0 kruksik   (1000) kruksik   (1000)        0 2024-03-21 13:18:05.540981 pyzefir-0.4.1/pyzefir/model/
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)      728 2024-02-05 15:42:18.000000 pyzefir-0.4.1/pyzefir/model/__init__.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     1823 2024-03-21 13:16:01.000000 pyzefir-0.4.1/pyzefir/model/exception_formatter.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)      875 2024-02-05 15:42:18.000000 pyzefir-0.4.1/pyzefir/model/exceptions.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)    15235 2024-02-16 14:59:55.000000 pyzefir-0.4.1/pyzefir/model/network.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     3463 2024-02-07 16:30:03.000000 pyzefir-0.4.1/pyzefir/model/network_element.py
-drwxr-xr-x   0 kruksik   (1000) kruksik   (1000)        0 2024-03-21 13:18:05.540981 pyzefir-0.4.1/pyzefir/model/network_elements/
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     2428 2024-03-21 13:12:40.000000 pyzefir-0.4.1/pyzefir/model/network_elements/__init__.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)    26394 2024-03-21 13:16:01.000000 pyzefir-0.4.1/pyzefir/model/network_elements/aggregated_consumer.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     6345 2024-03-21 13:16:01.000000 pyzefir-0.4.1/pyzefir/model/network_elements/bus.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     2385 2024-03-21 13:16:01.000000 pyzefir-0.4.1/pyzefir/model/network_elements/capacity_factor.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     6153 2024-03-21 13:16:01.000000 pyzefir-0.4.1/pyzefir/model/network_elements/demand_chunk.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     4028 2024-03-21 13:16:01.000000 pyzefir-0.4.1/pyzefir/model/network_elements/demand_profile.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     3794 2024-03-21 13:16:01.000000 pyzefir-0.4.1/pyzefir/model/network_elements/dsr.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     2752 2024-03-21 13:16:01.000000 pyzefir-0.4.1/pyzefir/model/network_elements/emission_fee.py
-drwxr-xr-x   0 kruksik   (1000) kruksik   (1000)        0 2024-03-21 13:18:05.550981 pyzefir-0.4.1/pyzefir/model/network_elements/energy_source_types/
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)      728 2024-02-05 15:42:18.000000 pyzefir-0.4.1/pyzefir/model/network_elements/energy_source_types/__init__.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     4753 2024-03-21 13:16:01.000000 pyzefir-0.4.1/pyzefir/model/network_elements/energy_source_types/energy_source_type_base.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)    13904 2024-03-21 13:16:01.000000 pyzefir-0.4.1/pyzefir/model/network_elements/energy_source_types/generator_type.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     4580 2024-03-21 13:16:01.000000 pyzefir-0.4.1/pyzefir/model/network_elements/energy_source_types/storage_type.py
-drwxr-xr-x   0 kruksik   (1000) kruksik   (1000)        0 2024-03-21 13:18:05.550981 pyzefir-0.4.1/pyzefir/model/network_elements/energy_sources/
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)      728 2024-02-05 15:42:18.000000 pyzefir-0.4.1/pyzefir/model/network_elements/energy_sources/__init__.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     5798 2024-03-21 13:16:01.000000 pyzefir-0.4.1/pyzefir/model/network_elements/energy_sources/energy_source_base.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)    10435 2024-03-21 13:16:01.000000 pyzefir-0.4.1/pyzefir/model/network_elements/energy_sources/generator.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     4734 2024-03-21 13:16:01.000000 pyzefir-0.4.1/pyzefir/model/network_elements/energy_sources/storage.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     4200 2024-03-21 13:16:01.000000 pyzefir-0.4.1/pyzefir/model/network_elements/fuel.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     7601 2024-03-21 13:16:01.000000 pyzefir-0.4.1/pyzefir/model/network_elements/line.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     8834 2024-03-21 13:16:01.000000 pyzefir-0.4.1/pyzefir/model/network_elements/local_balancing_stack.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     2311 2024-03-21 13:16:01.000000 pyzefir-0.4.1/pyzefir/model/network_elements/transmission_fee.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)    25627 2024-03-21 13:16:01.000000 pyzefir-0.4.1/pyzefir/model/network_validator.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     6519 2024-03-21 13:16:01.000000 pyzefir-0.4.1/pyzefir/model/utils.py
-drwxr-xr-x   0 kruksik   (1000) kruksik   (1000)        0 2024-03-21 13:18:05.550981 pyzefir-0.4.1/pyzefir/optimization/
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)      728 2024-02-05 15:42:18.000000 pyzefir-0.4.1/pyzefir/optimization/__init__.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     2115 2024-02-07 16:30:03.000000 pyzefir-0.4.1/pyzefir/optimization/exportable_results.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     1009 2024-02-05 15:42:18.000000 pyzefir-0.4.1/pyzefir/optimization/input_data.py
-drwxr-xr-x   0 kruksik   (1000) kruksik   (1000)        0 2024-03-21 13:18:05.550981 pyzefir-0.4.1/pyzefir/optimization/linopy/
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)      723 2024-02-16 14:59:55.000000 pyzefir-0.4.1/pyzefir/optimization/linopy/__init__.py
-drwxr-xr-x   0 kruksik   (1000) kruksik   (1000)        0 2024-03-21 13:18:05.550981 pyzefir-0.4.1/pyzefir/optimization/linopy/constraints_builder/
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)      723 2024-02-16 14:59:55.000000 pyzefir-0.4.1/pyzefir/optimization/linopy/constraints_builder/__init__.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     9811 2024-03-21 13:16:01.000000 pyzefir-0.4.1/pyzefir/optimization/linopy/constraints_builder/balancing_constraints_builder.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     1797 2024-02-16 14:59:55.000000 pyzefir-0.4.1/pyzefir/optimization/linopy/constraints_builder/builder.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)    17796 2024-03-21 13:16:01.000000 pyzefir-0.4.1/pyzefir/optimization/linopy/constraints_builder/capacity_evolution_constraints_builder.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     2657 2024-02-16 14:59:55.000000 pyzefir-0.4.1/pyzefir/optimization/linopy/constraints_builder/fraction_constraints_builder.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     5241 2024-02-16 14:59:55.000000 pyzefir-0.4.1/pyzefir/optimization/linopy/constraints_builder/generation_constraints_builder.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     1860 2024-02-16 14:59:55.000000 pyzefir-0.4.1/pyzefir/optimization/linopy/constraints_builder/generation_ramp.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     1437 2024-02-16 14:59:55.000000 pyzefir-0.4.1/pyzefir/optimization/linopy/constraints_builder/line_flow_constraints_builder.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)    21605 2024-03-21 13:16:01.000000 pyzefir-0.4.1/pyzefir/optimization/linopy/constraints_builder/scenario_constraints_builder.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     4668 2024-02-16 14:59:55.000000 pyzefir-0.4.1/pyzefir/optimization/linopy/constraints_builder/storage_constraints_builder.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     5696 2024-03-21 13:16:01.000000 pyzefir-0.4.1/pyzefir/optimization/linopy/expression_handler.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     9399 2024-03-21 13:16:01.000000 pyzefir-0.4.1/pyzefir/optimization/linopy/model.py
-drwxr-xr-x   0 kruksik   (1000) kruksik   (1000)        0 2024-03-21 13:18:05.550981 pyzefir-0.4.1/pyzefir/optimization/linopy/objective_builder/
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     1640 2024-02-16 14:59:55.000000 pyzefir-0.4.1/pyzefir/optimization/linopy/objective_builder/__init__.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     9609 2024-03-21 13:16:01.000000 pyzefir-0.4.1/pyzefir/optimization/linopy/objective_builder/capex_objective_builder.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     1956 2024-02-16 14:59:55.000000 pyzefir-0.4.1/pyzefir/optimization/linopy/objective_builder/curtailed_energy_cost.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     1406 2024-02-16 14:59:55.000000 pyzefir-0.4.1/pyzefir/optimization/linopy/objective_builder/dsr_penalty_objective_builder.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     2616 2024-02-16 14:59:55.000000 pyzefir-0.4.1/pyzefir/optimization/linopy/objective_builder/emission_fee_objective_builder.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     4241 2024-02-16 14:59:55.000000 pyzefir-0.4.1/pyzefir/optimization/linopy/objective_builder/ens_penalty_builder.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     1968 2024-02-16 14:59:55.000000 pyzefir-0.4.1/pyzefir/optimization/linopy/objective_builder/opex_objective_builder.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     1652 2024-02-16 14:59:55.000000 pyzefir-0.4.1/pyzefir/optimization/linopy/objective_builder/transmission_fee_objective_builder.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     1668 2024-02-16 14:59:55.000000 pyzefir-0.4.1/pyzefir/optimization/linopy/objective_builder/var_cost_objective_builder.py
-drwxr-xr-x   0 kruksik   (1000) kruksik   (1000)        0 2024-03-21 13:18:05.550981 pyzefir-0.4.1/pyzefir/optimization/linopy/preprocessing/
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)      723 2024-02-16 14:59:55.000000 pyzefir-0.4.1/pyzefir/optimization/linopy/preprocessing/__init__.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)    10746 2024-03-21 13:16:01.000000 pyzefir-0.4.1/pyzefir/optimization/linopy/preprocessing/indices.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     6107 2024-03-21 13:16:01.000000 pyzefir-0.4.1/pyzefir/optimization/linopy/preprocessing/opt_parameters.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     2656 2024-02-16 14:59:55.000000 pyzefir-0.4.1/pyzefir/optimization/linopy/preprocessing/opt_variables.py
-drwxr-xr-x   0 kruksik   (1000) kruksik   (1000)        0 2024-03-21 13:18:05.560981 pyzefir-0.4.1/pyzefir/optimization/linopy/preprocessing/parameters/
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     5337 2024-02-16 14:59:55.000000 pyzefir-0.4.1/pyzefir/optimization/linopy/preprocessing/parameters/__init__.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     7373 2024-02-16 14:59:55.000000 pyzefir-0.4.1/pyzefir/optimization/linopy/preprocessing/parameters/aggregated_consumer_parameters.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     3121 2024-02-16 14:59:55.000000 pyzefir-0.4.1/pyzefir/optimization/linopy/preprocessing/parameters/bus_parameters.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     1391 2024-02-16 14:59:55.000000 pyzefir-0.4.1/pyzefir/optimization/linopy/preprocessing/parameters/capacity_factor_parameters.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     2342 2024-02-16 14:59:55.000000 pyzefir-0.4.1/pyzefir/optimization/linopy/preprocessing/parameters/demand_chunks_parameters.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     2334 2024-02-16 14:59:55.000000 pyzefir-0.4.1/pyzefir/optimization/linopy/preprocessing/parameters/dsr_parameters.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     1578 2024-02-16 14:59:55.000000 pyzefir-0.4.1/pyzefir/optimization/linopy/preprocessing/parameters/emission_fee_parameters.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     1956 2024-02-16 14:59:55.000000 pyzefir-0.4.1/pyzefir/optimization/linopy/preprocessing/parameters/fuel_parameters.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     5611 2024-02-16 14:59:55.000000 pyzefir-0.4.1/pyzefir/optimization/linopy/preprocessing/parameters/generator_parameters.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     3699 2024-02-16 14:59:55.000000 pyzefir-0.4.1/pyzefir/optimization/linopy/preprocessing/parameters/generator_type_parameters.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     1987 2024-02-16 14:59:55.000000 pyzefir-0.4.1/pyzefir/optimization/linopy/preprocessing/parameters/line_parameters.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     3126 2024-02-16 14:59:55.000000 pyzefir-0.4.1/pyzefir/optimization/linopy/preprocessing/parameters/local_balancing_stack_parameters.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     2813 2024-03-21 13:16:01.000000 pyzefir-0.4.1/pyzefir/optimization/linopy/preprocessing/parameters/scenario_parameters.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     3938 2024-02-16 14:59:55.000000 pyzefir-0.4.1/pyzefir/optimization/linopy/preprocessing/parameters/storage_parameters.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     3396 2024-02-16 14:59:55.000000 pyzefir-0.4.1/pyzefir/optimization/linopy/preprocessing/parameters/storage_type_parameters.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     1477 2024-02-16 14:59:55.000000 pyzefir-0.4.1/pyzefir/optimization/linopy/preprocessing/parameters/transmission_fee_parameters.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     1397 2024-02-16 14:59:55.000000 pyzefir-0.4.1/pyzefir/optimization/linopy/preprocessing/utils.py
-drwxr-xr-x   0 kruksik   (1000) kruksik   (1000)        0 2024-03-21 13:18:05.560981 pyzefir-0.4.1/pyzefir/optimization/linopy/preprocessing/variables/
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)      781 2024-02-16 14:59:55.000000 pyzefir-0.4.1/pyzefir/optimization/linopy/preprocessing/variables/__init__.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     2899 2024-02-16 14:59:55.000000 pyzefir-0.4.1/pyzefir/optimization/linopy/preprocessing/variables/bus_variables.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     1578 2024-02-16 14:59:55.000000 pyzefir-0.4.1/pyzefir/optimization/linopy/preprocessing/variables/fraction_variables.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     3164 2024-02-16 14:59:55.000000 pyzefir-0.4.1/pyzefir/optimization/linopy/preprocessing/variables/generator_type_variables.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     5608 2024-02-16 14:59:55.000000 pyzefir-0.4.1/pyzefir/optimization/linopy/preprocessing/variables/generator_variables.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     1435 2024-02-16 14:59:55.000000 pyzefir-0.4.1/pyzefir/optimization/linopy/preprocessing/variables/line_variables.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     3114 2024-02-16 14:59:55.000000 pyzefir-0.4.1/pyzefir/optimization/linopy/preprocessing/variables/storage_type_variables.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     4724 2024-02-16 14:59:55.000000 pyzefir-0.4.1/pyzefir/optimization/linopy/preprocessing/variables/storage_variables.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     2037 2024-02-16 14:59:55.000000 pyzefir-0.4.1/pyzefir/optimization/model.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     5560 2024-02-16 14:59:55.000000 pyzefir-0.4.1/pyzefir/optimization/opt_config.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)    35110 2024-03-21 13:16:01.000000 pyzefir-0.4.1/pyzefir/optimization/results.py
-drwxr-xr-x   0 kruksik   (1000) kruksik   (1000)        0 2024-03-21 13:18:05.560981 pyzefir-0.4.1/pyzefir/parser/
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)      728 2024-02-05 15:42:18.000000 pyzefir-0.4.1/pyzefir/parser/__init__.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     3691 2024-03-21 13:16:01.000000 pyzefir-0.4.1/pyzefir/parser/csv_parser.py
-drwxr-xr-x   0 kruksik   (1000) kruksik   (1000)        0 2024-03-21 13:18:05.560981 pyzefir-0.4.1/pyzefir/parser/elements_parsers/
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)      728 2024-02-05 15:42:18.000000 pyzefir-0.4.1/pyzefir/parser/elements_parsers/__init__.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     7470 2024-02-16 14:59:55.000000 pyzefir-0.4.1/pyzefir/parser/elements_parsers/aggregated_consumer_parser.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     1360 2024-02-07 16:30:03.000000 pyzefir-0.4.1/pyzefir/parser/elements_parsers/bus_parser.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     1528 2024-02-05 15:42:18.000000 pyzefir-0.4.1/pyzefir/parser/elements_parsers/capacity_factor_parser.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     1995 2024-02-05 15:42:18.000000 pyzefir-0.4.1/pyzefir/parser/elements_parsers/demand_chunk_parser.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     1496 2024-02-05 15:42:18.000000 pyzefir-0.4.1/pyzefir/parser/elements_parsers/demand_profile_parser.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     1794 2024-02-16 14:59:55.000000 pyzefir-0.4.1/pyzefir/parser/elements_parsers/dsr_parser.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)      965 2024-02-05 15:42:18.000000 pyzefir-0.4.1/pyzefir/parser/elements_parsers/element_parser.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     1553 2024-02-05 15:42:18.000000 pyzefir-0.4.1/pyzefir/parser/elements_parsers/emission_fee_parser.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)    10748 2024-02-16 14:59:55.000000 pyzefir-0.4.1/pyzefir/parser/elements_parsers/energy_source_type_parser.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     8683 2024-02-16 14:59:55.000000 pyzefir-0.4.1/pyzefir/parser/elements_parsers/energy_source_unit_parser.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     3253 2024-02-07 16:30:03.000000 pyzefir-0.4.1/pyzefir/parser/elements_parsers/fuel_parser.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     1703 2024-02-16 14:59:55.000000 pyzefir-0.4.1/pyzefir/parser/elements_parsers/line_parser.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     2333 2024-02-05 15:42:18.000000 pyzefir-0.4.1/pyzefir/parser/elements_parsers/local_balancing_stack_parser.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     1354 2024-02-05 15:42:18.000000 pyzefir-0.4.1/pyzefir/parser/elements_parsers/transmission_fee_parser.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     1092 2024-02-05 15:42:18.000000 pyzefir-0.4.1/pyzefir/parser/elements_parsers/utils.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)    18421 2024-02-16 14:59:55.000000 pyzefir-0.4.1/pyzefir/parser/network_creator.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)      929 2024-02-05 15:42:18.000000 pyzefir-0.4.1/pyzefir/parser/utils.py
-drwxr-xr-x   0 kruksik   (1000) kruksik   (1000)        0 2024-03-21 13:18:05.560981 pyzefir-0.4.1/pyzefir/parser/validator/
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)      728 2024-02-05 15:42:18.000000 pyzefir-0.4.1/pyzefir/parser/validator/__init__.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     8587 2024-03-21 13:16:01.000000 pyzefir-0.4.1/pyzefir/parser/validator/dataframe_validator.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)    14211 2024-02-07 16:30:03.000000 pyzefir-0.4.1/pyzefir/parser/validator/valid_structure.py
-drwxr-xr-x   0 kruksik   (1000) kruksik   (1000)        0 2024-03-21 13:18:05.560981 pyzefir-0.4.1/pyzefir/postprocessing/
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)      728 2024-02-05 15:42:18.000000 pyzefir-0.4.1/pyzefir/postprocessing/__init__.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     4895 2024-03-21 13:16:01.000000 pyzefir-0.4.1/pyzefir/postprocessing/results_exporters.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     2247 2024-02-05 15:42:18.000000 pyzefir-0.4.1/pyzefir/postprocessing/results_handler.py
-drwxr-xr-x   0 kruksik   (1000) kruksik   (1000)        0 2024-03-21 13:18:05.560981 pyzefir-0.4.1/pyzefir/structure_creator/
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)      728 2024-02-05 15:42:18.000000 pyzefir-0.4.1/pyzefir/structure_creator/__init__.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)      869 2024-02-05 15:42:18.000000 pyzefir-0.4.1/pyzefir/structure_creator/__main__.py
-drwxr-xr-x   0 kruksik   (1000) kruksik   (1000)        0 2024-03-21 13:18:05.560981 pyzefir-0.4.1/pyzefir/structure_creator/cli/
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)      728 2024-02-05 15:42:18.000000 pyzefir-0.4.1/pyzefir/structure_creator/cli/__init__.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     2843 2024-03-21 13:16:01.000000 pyzefir-0.4.1/pyzefir/structure_creator/cli/cli_wrapper.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     1752 2024-03-21 13:06:04.000000 pyzefir-0.4.1/pyzefir/structure_creator/constants_enums.py
-drwxr-xr-x   0 kruksik   (1000) kruksik   (1000)        0 2024-03-21 13:18:05.560981 pyzefir-0.4.1/pyzefir/structure_creator/data_loader/
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)      723 2024-03-21 13:16:01.000000 pyzefir-0.4.1/pyzefir/structure_creator/data_loader/__init__.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     1360 2024-03-21 13:16:01.000000 pyzefir-0.4.1/pyzefir/structure_creator/data_loader/constants_enums.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     5288 2024-03-21 13:16:01.000000 pyzefir-0.4.1/pyzefir/structure_creator/data_loader/input_data.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     1305 2024-03-21 13:16:01.000000 pyzefir-0.4.1/pyzefir/structure_creator/excel_writer.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     5927 2024-03-21 13:06:04.000000 pyzefir-0.4.1/pyzefir/structure_creator/input_data.py
-drwxr-xr-x   0 kruksik   (1000) kruksik   (1000)        0 2024-03-21 13:18:05.560981 pyzefir-0.4.1/pyzefir/structure_creator/scenario/
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)      728 2024-02-05 15:42:18.000000 pyzefir-0.4.1/pyzefir/structure_creator/scenario/__init__.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     2147 2024-03-21 13:16:01.000000 pyzefir-0.4.1/pyzefir/structure_creator/scenario/constants_enums.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)    10447 2024-03-21 13:16:01.000000 pyzefir-0.4.1/pyzefir/structure_creator/scenario/main.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     1263 2024-03-21 13:16:01.000000 pyzefir-0.4.1/pyzefir/structure_creator/scenario/utils.py
-drwxr-xr-x   0 kruksik   (1000) kruksik   (1000)        0 2024-03-21 13:18:05.570981 pyzefir-0.4.1/pyzefir/structure_creator/structure_and_initial_state/
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)      728 2024-02-05 15:42:18.000000 pyzefir-0.4.1/pyzefir/structure_creator/structure_and_initial_state/__init__.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     3129 2024-03-21 13:06:04.000000 pyzefir-0.4.1/pyzefir/structure_creator/structure_and_initial_state/constants_enums.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     3114 2024-03-21 13:06:04.000000 pyzefir-0.4.1/pyzefir/structure_creator/structure_and_initial_state/create_initial_state_data.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     9889 2024-03-21 13:06:04.000000 pyzefir-0.4.1/pyzefir/structure_creator/structure_and_initial_state/create_structure_data.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)    12104 2024-03-21 13:16:01.000000 pyzefir-0.4.1/pyzefir/structure_creator/structure_and_initial_state/create_structures.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     3252 2024-03-21 13:16:01.000000 pyzefir-0.4.1/pyzefir/structure_creator/structure_and_initial_state/dataclasses.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)    18254 2024-03-21 13:06:04.000000 pyzefir-0.4.1/pyzefir/structure_creator/structure_and_initial_state/main.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     4933 2024-03-21 13:16:01.000000 pyzefir-0.4.1/pyzefir/structure_creator/structure_and_initial_state/preprocess_handlers.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)    12271 2024-03-21 13:16:01.000000 pyzefir-0.4.1/pyzefir/structure_creator/structure_and_initial_state/structure_element_creators.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)      912 2024-03-21 13:16:01.000000 pyzefir-0.4.1/pyzefir/structure_creator/structure_and_initial_state/utils.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     2587 2024-03-21 13:06:04.000000 pyzefir-0.4.1/pyzefir/structure_creator/utils.py
-drwxr-xr-x   0 kruksik   (1000) kruksik   (1000)        0 2024-03-21 13:18:05.570981 pyzefir-0.4.1/pyzefir/utils/
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)      728 2024-02-05 15:42:18.000000 pyzefir-0.4.1/pyzefir/utils/__init__.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)    15283 2024-03-21 13:16:01.000000 pyzefir-0.4.1/pyzefir/utils/config_parser.py
-drwxr-xr-x   0 kruksik   (1000) kruksik   (1000)        0 2024-03-21 13:18:05.570981 pyzefir-0.4.1/pyzefir/utils/converters/
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)      728 2024-02-05 15:42:18.000000 pyzefir-0.4.1/pyzefir/utils/converters/__init__.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     1169 2024-02-05 15:42:18.000000 pyzefir-0.4.1/pyzefir/utils/converters/converter.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     6894 2024-03-21 13:16:01.000000 pyzefir-0.4.1/pyzefir/utils/converters/xlsx_to_csv_converter.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     2995 2024-02-16 14:59:55.000000 pyzefir-0.4.1/pyzefir/utils/functions.py
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)    10368 2024-02-07 16:30:03.000000 pyzefir-0.4.1/pyzefir/utils/path_manager.py
-drwxr-xr-x   0 kruksik   (1000) kruksik   (1000)        0 2024-03-21 13:18:05.570981 pyzefir-0.4.1/pyzefir.egg-info/
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)    45993 2024-03-21 13:18:05.000000 pyzefir-0.4.1/pyzefir.egg-info/PKG-INFO
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)     8442 2024-03-21 13:18:05.000000 pyzefir-0.4.1/pyzefir.egg-info/SOURCES.txt
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)        1 2024-03-21 13:18:05.000000 pyzefir-0.4.1/pyzefir.egg-info/dependency_links.txt
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)      143 2024-03-21 13:18:05.000000 pyzefir-0.4.1/pyzefir.egg-info/entry_points.txt
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)      453 2024-03-21 13:18:05.000000 pyzefir-0.4.1/pyzefir.egg-info/requires.txt
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)        8 2024-03-21 13:18:05.000000 pyzefir-0.4.1/pyzefir.egg-info/top_level.txt
--rw-r--r--   0 kruksik   (1000) kruksik   (1000)       38 2024-03-21 13:18:05.570981 pyzefir-0.4.1/setup.cfg
+drwxr-xr-x   0 akartashov  (1000) akartashov  (1000)        0 2024-05-22 17:05:55.368251 pyzefir-0.4.22/
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)    35184 2024-05-22 17:04:32.000000 pyzefir-0.4.22/LICENSE.txt
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)    49143 2024-05-22 17:05:55.368251 pyzefir-0.4.22/PKG-INFO
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     7940 2024-05-22 17:04:32.000000 pyzefir-0.4.22/README.md
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     3566 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyproject.toml
+drwxr-xr-x   0 akartashov  (1000) akartashov  (1000)        0 2024-05-22 17:05:55.318252 pyzefir-0.4.22/pyzefir/
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)      854 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/__init__.py
+drwxr-xr-x   0 akartashov  (1000) akartashov  (1000)        0 2024-05-22 17:05:55.318252 pyzefir-0.4.22/pyzefir/cli/
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)      743 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/cli/__init__.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)      832 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/cli/__main__.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     2762 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/cli/logger.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     7170 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/cli/runner.py
+drwxr-xr-x   0 akartashov  (1000) akartashov  (1000)        0 2024-05-22 17:05:55.318252 pyzefir-0.4.22/pyzefir/graph/
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)      743 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/graph/__init__.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     1585 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/graph/constants.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)    11942 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/graph/network_diagram.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     1161 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/graph/utils.py
+drwxr-xr-x   0 akartashov  (1000) akartashov  (1000)        0 2024-05-22 17:05:55.328252 pyzefir-0.4.22/pyzefir/model/
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)      743 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/model/__init__.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     1868 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/model/exception_formatter.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)      898 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/model/exceptions.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)    18169 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/model/network.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     3490 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/model/network_element.py
+drwxr-xr-x   0 akartashov  (1000) akartashov  (1000)        0 2024-05-22 17:05:55.328252 pyzefir-0.4.22/pyzefir/model/network_elements/
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     2489 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/model/network_elements/__init__.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)    27679 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/model/network_elements/aggregated_consumer.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     6839 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/model/network_elements/bus.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     2754 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/model/network_elements/capacity_factor.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     6679 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/model/network_elements/demand_chunk.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     4493 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/model/network_elements/demand_profile.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     4168 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/model/network_elements/dsr.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     3145 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/model/network_elements/emission_fee.py
+drwxr-xr-x   0 akartashov  (1000) akartashov  (1000)        0 2024-05-22 17:05:55.328252 pyzefir-0.4.22/pyzefir/model/network_elements/energy_source_types/
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)      743 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/model/network_elements/energy_source_types/__init__.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     4894 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/model/network_elements/energy_source_types/energy_source_type_base.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)    17196 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/model/network_elements/energy_source_types/generator_type.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     5026 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/model/network_elements/energy_source_types/storage_type.py
+drwxr-xr-x   0 akartashov  (1000) akartashov  (1000)        0 2024-05-22 17:05:55.328252 pyzefir-0.4.22/pyzefir/model/network_elements/energy_sources/
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)      743 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/model/network_elements/energy_sources/__init__.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     5961 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/model/network_elements/energy_sources/energy_source_base.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)    11304 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/model/network_elements/energy_sources/generator.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     5193 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/model/network_elements/energy_sources/storage.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     4711 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/model/network_elements/fuel.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     8298 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/model/network_elements/line.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     9550 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/model/network_elements/local_balancing_stack.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     2728 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/model/network_elements/transmission_fee.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)    27486 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/model/network_validator.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     6884 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/model/utils.py
+drwxr-xr-x   0 akartashov  (1000) akartashov  (1000)        0 2024-05-22 17:05:55.328252 pyzefir-0.4.22/pyzefir/optimization/
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)      743 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/optimization/__init__.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     2284 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/optimization/exportable_results.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     1039 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/optimization/input_data.py
+drwxr-xr-x   0 akartashov  (1000) akartashov  (1000)        0 2024-05-22 17:05:55.328252 pyzefir-0.4.22/pyzefir/optimization/linopy/
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)      738 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/optimization/linopy/__init__.py
+drwxr-xr-x   0 akartashov  (1000) akartashov  (1000)        0 2024-05-22 17:05:55.338251 pyzefir-0.4.22/pyzefir/optimization/linopy/constraints_builder/
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)      738 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/optimization/linopy/constraints_builder/__init__.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)    11441 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/optimization/linopy/constraints_builder/balancing_constraints_builder.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     1851 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/optimization/linopy/constraints_builder/builder.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     2070 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/optimization/linopy/constraints_builder/capacity_binding_builder.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)    19983 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/optimization/linopy/constraints_builder/capacity_evolution_constraints_builder.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     3135 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/optimization/linopy/constraints_builder/fraction_constraints_builder.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     6005 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/optimization/linopy/constraints_builder/generation_constraints_builder.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     2146 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/optimization/linopy/constraints_builder/generation_ramp.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     1725 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/optimization/linopy/constraints_builder/line_flow_constraints_builder.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)    23466 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/optimization/linopy/constraints_builder/scenario_constraints_builder.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     5467 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/optimization/linopy/constraints_builder/storage_constraints_builder.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     5865 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/optimization/linopy/expression_handler.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)    10248 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/optimization/linopy/model.py
+drwxr-xr-x   0 akartashov  (1000) akartashov  (1000)        0 2024-05-22 17:05:55.338251 pyzefir-0.4.22/pyzefir/optimization/linopy/objective_builder/
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     1687 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/optimization/linopy/objective_builder/__init__.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)    10106 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/optimization/linopy/objective_builder/capex_objective_builder.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     2193 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/optimization/linopy/objective_builder/curtailed_energy_cost.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     1692 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/optimization/linopy/objective_builder/dsr_penalty_objective_builder.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     2846 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/optimization/linopy/objective_builder/emission_fee_objective_builder.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     5303 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/optimization/linopy/objective_builder/ens_penalty_builder.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     2220 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/optimization/linopy/objective_builder/generation_compensation_objective_builder.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     2347 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/optimization/linopy/objective_builder/opex_objective_builder.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     1873 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/optimization/linopy/objective_builder/transmission_fee_objective_builder.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     1880 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/optimization/linopy/objective_builder/var_cost_objective_builder.py
+drwxr-xr-x   0 akartashov  (1000) akartashov  (1000)        0 2024-05-22 17:05:55.338251 pyzefir-0.4.22/pyzefir/optimization/linopy/preprocessing/
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)      738 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/optimization/linopy/preprocessing/__init__.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)    11069 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/optimization/linopy/preprocessing/indices.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     6337 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/optimization/linopy/preprocessing/opt_parameters.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     2553 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/optimization/linopy/preprocessing/opt_variables.py
+drwxr-xr-x   0 akartashov  (1000) akartashov  (1000)        0 2024-05-22 17:05:55.348251 pyzefir-0.4.22/pyzefir/optimization/linopy/preprocessing/parameters/
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     5489 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/optimization/linopy/preprocessing/parameters/__init__.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     7558 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/optimization/linopy/preprocessing/parameters/aggregated_consumer_parameters.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     3206 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/optimization/linopy/preprocessing/parameters/bus_parameters.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     1423 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/optimization/linopy/preprocessing/parameters/capacity_factor_parameters.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     2406 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/optimization/linopy/preprocessing/parameters/demand_chunks_parameters.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     2460 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/optimization/linopy/preprocessing/parameters/dsr_parameters.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     1620 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/optimization/linopy/preprocessing/parameters/emission_fee_parameters.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     2001 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/optimization/linopy/preprocessing/parameters/fuel_parameters.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     7324 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/optimization/linopy/preprocessing/parameters/generator_parameters.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     4127 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/optimization/linopy/preprocessing/parameters/generator_type_parameters.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     2031 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/optimization/linopy/preprocessing/parameters/line_parameters.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     3207 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/optimization/linopy/preprocessing/parameters/local_balancing_stack_parameters.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     2876 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/optimization/linopy/preprocessing/parameters/scenario_parameters.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     4026 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/optimization/linopy/preprocessing/parameters/storage_parameters.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     3482 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/optimization/linopy/preprocessing/parameters/storage_type_parameters.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     1515 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/optimization/linopy/preprocessing/parameters/transmission_fee_parameters.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     1430 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/optimization/linopy/preprocessing/utils.py
+drwxr-xr-x   0 akartashov  (1000) akartashov  (1000)        0 2024-05-22 17:05:55.348251 pyzefir-0.4.22/pyzefir/optimization/linopy/preprocessing/variables/
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)      802 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/optimization/linopy/preprocessing/variables/__init__.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     2616 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/optimization/linopy/preprocessing/variables/bus_variables.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     1617 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/optimization/linopy/preprocessing/variables/fraction_variables.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     3253 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/optimization/linopy/preprocessing/variables/generator_type_variables.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     5765 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/optimization/linopy/preprocessing/variables/generator_variables.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     1473 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/optimization/linopy/preprocessing/variables/line_variables.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     3202 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/optimization/linopy/preprocessing/variables/storage_type_variables.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     4861 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/optimization/linopy/preprocessing/variables/storage_variables.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     2112 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/optimization/model.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     6242 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/optimization/opt_config.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)    38635 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/optimization/results.py
+drwxr-xr-x   0 akartashov  (1000) akartashov  (1000)        0 2024-05-22 17:05:55.348251 pyzefir-0.4.22/pyzefir/parser/
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)      743 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/parser/__init__.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     4293 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/parser/csv_parser.py
+drwxr-xr-x   0 akartashov  (1000) akartashov  (1000)        0 2024-05-22 17:05:55.358251 pyzefir-0.4.22/pyzefir/parser/elements_parsers/
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)      743 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/parser/elements_parsers/__init__.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     7689 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/parser/elements_parsers/aggregated_consumer_parser.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     1455 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/parser/elements_parsers/bus_parser.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     1572 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/parser/elements_parsers/capacity_factor_parser.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     2059 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/parser/elements_parsers/demand_chunk_parser.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     1540 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/parser/elements_parsers/demand_profile_parser.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     1881 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/parser/elements_parsers/dsr_parser.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)      990 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/parser/elements_parsers/element_parser.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     1603 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/parser/elements_parsers/emission_fee_parser.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)    12346 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/parser/elements_parsers/energy_source_type_parser.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     9291 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/parser/elements_parsers/energy_source_unit_parser.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     3419 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/parser/elements_parsers/fuel_parser.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     1790 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/parser/elements_parsers/line_parser.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     2531 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/parser/elements_parsers/local_balancing_stack_parser.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     1392 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/parser/elements_parsers/transmission_fee_parser.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     1121 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/parser/elements_parsers/utils.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)    20227 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/parser/network_creator.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)      953 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/parser/utils.py
+drwxr-xr-x   0 akartashov  (1000) akartashov  (1000)        0 2024-05-22 17:05:55.358251 pyzefir-0.4.22/pyzefir/parser/validator/
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)      743 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/parser/validator/__init__.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     8798 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/parser/validator/dataframe_validator.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)    15204 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/parser/validator/valid_structure.py
+drwxr-xr-x   0 akartashov  (1000) akartashov  (1000)        0 2024-05-22 17:05:55.358251 pyzefir-0.4.22/pyzefir/postprocessing/
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)      743 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/postprocessing/__init__.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     5171 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/postprocessing/results_exporters.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     2692 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/postprocessing/results_handler.py
+drwxr-xr-x   0 akartashov  (1000) akartashov  (1000)        0 2024-05-22 17:05:55.358251 pyzefir-0.4.22/pyzefir/structure_creator/
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)      743 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/structure_creator/__init__.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)      889 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/structure_creator/__main__.py
+drwxr-xr-x   0 akartashov  (1000) akartashov  (1000)        0 2024-05-22 17:05:55.358251 pyzefir-0.4.22/pyzefir/structure_creator/cli/
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)      743 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/structure_creator/cli/__init__.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     3596 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/structure_creator/cli/cli_wrapper.py
+drwxr-xr-x   0 akartashov  (1000) akartashov  (1000)        0 2024-05-22 17:05:55.358251 pyzefir-0.4.22/pyzefir/structure_creator/data_loader/
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)      738 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/structure_creator/data_loader/__init__.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     1442 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/structure_creator/data_loader/constants_enums.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     8819 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/structure_creator/data_loader/input_data.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     1565 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/structure_creator/excel_writer.py
+drwxr-xr-x   0 akartashov  (1000) akartashov  (1000)        0 2024-05-22 17:05:55.358251 pyzefir-0.4.22/pyzefir/structure_creator/scenario/
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)      743 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/structure_creator/scenario/__init__.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     2269 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/structure_creator/scenario/constants_enums.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)    11370 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/structure_creator/scenario/main.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     1299 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/structure_creator/scenario/utils.py
+drwxr-xr-x   0 akartashov  (1000) akartashov  (1000)        0 2024-05-22 17:05:55.358251 pyzefir-0.4.22/pyzefir/structure_creator/structure_and_initial_state/
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)      743 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/structure_creator/structure_and_initial_state/__init__.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)    14413 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/structure_creator/structure_and_initial_state/create_structures.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     3405 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/structure_creator/structure_and_initial_state/dataclasses.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     5579 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/structure_creator/structure_and_initial_state/preprocess_handlers.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)    14681 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/structure_creator/structure_and_initial_state/structure_element_creators.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)      938 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/structure_creator/structure_and_initial_state/utils.py
+drwxr-xr-x   0 akartashov  (1000) akartashov  (1000)        0 2024-05-22 17:05:55.358251 pyzefir-0.4.22/pyzefir/utils/
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)      743 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/utils/__init__.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)    17201 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/utils/config_parser.py
+drwxr-xr-x   0 akartashov  (1000) akartashov  (1000)        0 2024-05-22 17:05:55.358251 pyzefir-0.4.22/pyzefir/utils/converters/
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)      743 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/utils/converters/__init__.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     1202 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/utils/converters/converter.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     7386 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/utils/converters/xlsx_to_csv_converter.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     3092 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/utils/functions.py
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)    11585 2024-05-22 17:04:32.000000 pyzefir-0.4.22/pyzefir/utils/path_manager.py
+drwxr-xr-x   0 akartashov  (1000) akartashov  (1000)        0 2024-05-22 17:05:55.358251 pyzefir-0.4.22/pyzefir.egg-info/
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)    49143 2024-05-22 17:05:55.000000 pyzefir-0.4.22/pyzefir.egg-info/PKG-INFO
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)     8192 2024-05-22 17:05:55.000000 pyzefir-0.4.22/pyzefir.egg-info/SOURCES.txt
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)        1 2024-05-22 17:05:55.000000 pyzefir-0.4.22/pyzefir.egg-info/dependency_links.txt
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)      143 2024-05-22 17:05:55.000000 pyzefir-0.4.22/pyzefir.egg-info/entry_points.txt
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)      453 2024-05-22 17:05:55.000000 pyzefir-0.4.22/pyzefir.egg-info/requires.txt
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)        8 2024-05-22 17:05:55.000000 pyzefir-0.4.22/pyzefir.egg-info/top_level.txt
+-rw-r--r--   0 akartashov  (1000) akartashov  (1000)       38 2024-05-22 17:05:55.368251 pyzefir-0.4.22/setup.cfg
```

### Comparing `pyzefir-0.4.1/LICENSE.txt` & `pyzefir-0.4.22/LICENSE.txt`

 * *Ordering differences only*

 * *Files 6% similar despite different names*

```diff
@@ -1,661 +1,661 @@
-                    GNU AFFERO GENERAL PUBLIC LICENSE
-                       Version 3, 19 November 2007
-
- Copyright (C) 2007 Free Software Foundation, Inc. <https://fsf.org/>
- Everyone is permitted to copy and distribute verbatim copies
- of this license document, but changing it is not allowed.
-
-                            Preamble
-
-  The GNU Affero General Public License is a free, copyleft license for
-software and other kinds of works, specifically designed to ensure
-cooperation with the community in the case of network server software.
-
-  The licenses for most software and other practical works are designed
-to take away your freedom to share and change the works.  By contrast,
-our General Public Licenses are intended to guarantee your freedom to
-share and change all versions of a program--to make sure it remains free
-software for all its users.
-
-  When we speak of free software, we are referring to freedom, not
-price.  Our General Public Licenses are designed to make sure that you
-have the freedom to distribute copies of free software (and charge for
-them if you wish), that you receive source code or can get it if you
-want it, that you can change the software or use pieces of it in new
-free programs, and that you know you can do these things.
-
-  Developers that use our General Public Licenses protect your rights
-with two steps: (1) assert copyright on the software, and (2) offer
-you this License which gives you legal permission to copy, distribute
-and/or modify the software.
-
-  A secondary benefit of defending all users' freedom is that
-improvements made in alternate versions of the program, if they
-receive widespread use, become available for other developers to
-incorporate.  Many developers of free software are heartened and
-encouraged by the resulting cooperation.  However, in the case of
-software used on network servers, this result may fail to come about.
-The GNU General Public License permits making a modified version and
-letting the public access it on a server without ever releasing its
-source code to the public.
-
-  The GNU Affero General Public License is designed specifically to
-ensure that, in such cases, the modified source code becomes available
-to the community.  It requires the operator of a network server to
-provide the source code of the modified version running there to the
-users of that server.  Therefore, public use of a modified version, on
-a publicly accessible server, gives the public access to the source
-code of the modified version.
-
-  An older license, called the Affero General Public License and
-published by Affero, was designed to accomplish similar goals.  This is
-a different license, not a version of the Affero GPL, but Affero has
-released a new version of the Affero GPL which permits relicensing under
-this license.
-
-  The precise terms and conditions for copying, distribution and
-modification follow.
-
-                       TERMS AND CONDITIONS
-
-  0. Definitions.
-
-  "This License" refers to version 3 of the GNU Affero General Public License.
-
-  "Copyright" also means copyright-like laws that apply to other kinds of
-works, such as semiconductor masks.
-
-  "The Program" refers to any copyrightable work licensed under this
-License.  Each licensee is addressed as "you".  "Licensees" and
-"recipients" may be individuals or organizations.
-
-  To "modify" a work means to copy from or adapt all or part of the work
-in a fashion requiring copyright permission, other than the making of an
-exact copy.  The resulting work is called a "modified version" of the
-earlier work or a work "based on" the earlier work.
-
-  A "covered work" means either the unmodified Program or a work based
-on the Program.
-
-  To "propagate" a work means to do anything with it that, without
-permission, would make you directly or secondarily liable for
-infringement under applicable copyright law, except executing it on a
-computer or modifying a private copy.  Propagation includes copying,
-distribution (with or without modification), making available to the
-public, and in some countries other activities as well.
-
-  To "convey" a work means any kind of propagation that enables other
-parties to make or receive copies.  Mere interaction with a user through
-a computer network, with no transfer of a copy, is not conveying.
-
-  An interactive user interface displays "Appropriate Legal Notices"
-to the extent that it includes a convenient and prominently visible
-feature that (1) displays an appropriate copyright notice, and (2)
-tells the user that there is no warranty for the work (except to the
-extent that warranties are provided), that licensees may convey the
-work under this License, and how to view a copy of this License.  If
-the interface presents a list of user commands or options, such as a
-menu, a prominent item in the list meets this criterion.
-
-  1. Source Code.
-
-  The "source code" for a work means the preferred form of the work
-for making modifications to it.  "Object code" means any non-source
-form of a work.
-
-  A "Standard Interface" means an interface that either is an official
-standard defined by a recognized standards body, or, in the case of
-interfaces specified for a particular programming language, one that
-is widely used among developers working in that language.
-
-  The "System Libraries" of an executable work include anything, other
-than the work as a whole, that (a) is included in the normal form of
-packaging a Major Component, but which is not part of that Major
-Component, and (b) serves only to enable use of the work with that
-Major Component, or to implement a Standard Interface for which an
-implementation is available to the public in source code form.  A
-"Major Component", in this context, means a major essential component
-(kernel, window system, and so on) of the specific operating system
-(if any) on which the executable work runs, or a compiler used to
-produce the work, or an object code interpreter used to run it.
-
-  The "Corresponding Source" for a work in object code form means all
-the source code needed to generate, install, and (for an executable
-work) run the object code and to modify the work, including scripts to
-control those activities.  However, it does not include the work's
-System Libraries, or general-purpose tools or generally available free
-programs which are used unmodified in performing those activities but
-which are not part of the work.  For example, Corresponding Source
-includes interface definition files associated with source files for
-the work, and the source code for shared libraries and dynamically
-linked subprograms that the work is specifically designed to require,
-such as by intimate data communication or control flow between those
-subprograms and other parts of the work.
-
-  The Corresponding Source need not include anything that users
-can regenerate automatically from other parts of the Corresponding
-Source.
-
-  The Corresponding Source for a work in source code form is that
-same work.
-
-  2. Basic Permissions.
-
-  All rights granted under this License are granted for the term of
-copyright on the Program, and are irrevocable provided the stated
-conditions are met.  This License explicitly affirms your unlimited
-permission to run the unmodified Program.  The output from running a
-covered work is covered by this License only if the output, given its
-content, constitutes a covered work.  This License acknowledges your
-rights of fair use or other equivalent, as provided by copyright law.
-
-  You may make, run and propagate covered works that you do not
-convey, without conditions so long as your license otherwise remains
-in force.  You may convey covered works to others for the sole purpose
-of having them make modifications exclusively for you, or provide you
-with facilities for running those works, provided that you comply with
-the terms of this License in conveying all material for which you do
-not control copyright.  Those thus making or running the covered works
-for you must do so exclusively on your behalf, under your direction
-and control, on terms that prohibit them from making any copies of
-your copyrighted material outside their relationship with you.
-
-  Conveying under any other circumstances is permitted solely under
-the conditions stated below.  Sublicensing is not allowed; section 10
-makes it unnecessary.
-
-  3. Protecting Users' Legal Rights From Anti-Circumvention Law.
-
-  No covered work shall be deemed part of an effective technological
-measure under any applicable law fulfilling obligations under article
-11 of the WIPO copyright treaty adopted on 20 December 1996, or
-similar laws prohibiting or restricting circumvention of such
-measures.
-
-  When you convey a covered work, you waive any legal power to forbid
-circumvention of technological measures to the extent such circumvention
-is effected by exercising rights under this License with respect to
-the covered work, and you disclaim any intention to limit operation or
-modification of the work as a means of enforcing, against the work's
-users, your or third parties' legal rights to forbid circumvention of
-technological measures.
-
-  4. Conveying Verbatim Copies.
-
-  You may convey verbatim copies of the Program's source code as you
-receive it, in any medium, provided that you conspicuously and
-appropriately publish on each copy an appropriate copyright notice;
-keep intact all notices stating that this License and any
-non-permissive terms added in accord with section 7 apply to the code;
-keep intact all notices of the absence of any warranty; and give all
-recipients a copy of this License along with the Program.
-
-  You may charge any price or no price for each copy that you convey,
-and you may offer support or warranty protection for a fee.
-
-  5. Conveying Modified Source Versions.
-
-  You may convey a work based on the Program, or the modifications to
-produce it from the Program, in the form of source code under the
-terms of section 4, provided that you also meet all of these conditions:
-
-    a) The work must carry prominent notices stating that you modified
-    it, and giving a relevant date.
-
-    b) The work must carry prominent notices stating that it is
-    released under this License and any conditions added under section
-    7.  This requirement modifies the requirement in section 4 to
-    "keep intact all notices".
-
-    c) You must license the entire work, as a whole, under this
-    License to anyone who comes into possession of a copy.  This
-    License will therefore apply, along with any applicable section 7
-    additional terms, to the whole of the work, and all its parts,
-    regardless of how they are packaged.  This License gives no
-    permission to license the work in any other way, but it does not
-    invalidate such permission if you have separately received it.
-
-    d) If the work has interactive user interfaces, each must display
-    Appropriate Legal Notices; however, if the Program has interactive
-    interfaces that do not display Appropriate Legal Notices, your
-    work need not make them do so.
-
-  A compilation of a covered work with other separate and independent
-works, which are not by their nature extensions of the covered work,
-and which are not combined with it such as to form a larger program,
-in or on a volume of a storage or distribution medium, is called an
-"aggregate" if the compilation and its resulting copyright are not
-used to limit the access or legal rights of the compilation's users
-beyond what the individual works permit.  Inclusion of a covered work
-in an aggregate does not cause this License to apply to the other
-parts of the aggregate.
-
-  6. Conveying Non-Source Forms.
-
-  You may convey a covered work in object code form under the terms
-of sections 4 and 5, provided that you also convey the
-machine-readable Corresponding Source under the terms of this License,
-in one of these ways:
-
-    a) Convey the object code in, or embodied in, a physical product
-    (including a physical distribution medium), accompanied by the
-    Corresponding Source fixed on a durable physical medium
-    customarily used for software interchange.
-
-    b) Convey the object code in, or embodied in, a physical product
-    (including a physical distribution medium), accompanied by a
-    written offer, valid for at least three years and valid for as
-    long as you offer spare parts or customer support for that product
-    model, to give anyone who possesses the object code either (1) a
-    copy of the Corresponding Source for all the software in the
-    product that is covered by this License, on a durable physical
-    medium customarily used for software interchange, for a price no
-    more than your reasonable cost of physically performing this
-    conveying of source, or (2) access to copy the
-    Corresponding Source from a network server at no charge.
-
-    c) Convey individual copies of the object code with a copy of the
-    written offer to provide the Corresponding Source.  This
-    alternative is allowed only occasionally and noncommercially, and
-    only if you received the object code with such an offer, in accord
-    with subsection 6b.
-
-    d) Convey the object code by offering access from a designated
-    place (gratis or for a charge), and offer equivalent access to the
-    Corresponding Source in the same way through the same place at no
-    further charge.  You need not require recipients to copy the
-    Corresponding Source along with the object code.  If the place to
-    copy the object code is a network server, the Corresponding Source
-    may be on a different server (operated by you or a third party)
-    that supports equivalent copying facilities, provided you maintain
-    clear directions next to the object code saying where to find the
-    Corresponding Source.  Regardless of what server hosts the
-    Corresponding Source, you remain obligated to ensure that it is
-    available for as long as needed to satisfy these requirements.
-
-    e) Convey the object code using peer-to-peer transmission, provided
-    you inform other peers where the object code and Corresponding
-    Source of the work are being offered to the general public at no
-    charge under subsection 6d.
-
-  A separable portion of the object code, whose source code is excluded
-from the Corresponding Source as a System Library, need not be
-included in conveying the object code work.
-
-  A "User Product" is either (1) a "consumer product", which means any
-tangible personal property which is normally used for personal, family,
-or household purposes, or (2) anything designed or sold for incorporation
-into a dwelling.  In determining whether a product is a consumer product,
-doubtful cases shall be resolved in favor of coverage.  For a particular
-product received by a particular user, "normally used" refers to a
-typical or common use of that class of product, regardless of the status
-of the particular user or of the way in which the particular user
-actually uses, or expects or is expected to use, the product.  A product
-is a consumer product regardless of whether the product has substantial
-commercial, industrial or non-consumer uses, unless such uses represent
-the only significant mode of use of the product.
-
-  "Installation Information" for a User Product means any methods,
-procedures, authorization keys, or other information required to install
-and execute modified versions of a covered work in that User Product from
-a modified version of its Corresponding Source.  The information must
-suffice to ensure that the continued functioning of the modified object
-code is in no case prevented or interfered with solely because
-modification has been made.
-
-  If you convey an object code work under this section in, or with, or
-specifically for use in, a User Product, and the conveying occurs as
-part of a transaction in which the right of possession and use of the
-User Product is transferred to the recipient in perpetuity or for a
-fixed term (regardless of how the transaction is characterized), the
-Corresponding Source conveyed under this section must be accompanied
-by the Installation Information.  But this requirement does not apply
-if neither you nor any third party retains the ability to install
-modified object code on the User Product (for example, the work has
-been installed in ROM).
-
-  The requirement to provide Installation Information does not include a
-requirement to continue to provide support service, warranty, or updates
-for a work that has been modified or installed by the recipient, or for
-the User Product in which it has been modified or installed.  Access to a
-network may be denied when the modification itself materially and
-adversely affects the operation of the network or violates the rules and
-protocols for communication across the network.
-
-  Corresponding Source conveyed, and Installation Information provided,
-in accord with this section must be in a format that is publicly
-documented (and with an implementation available to the public in
-source code form), and must require no special password or key for
-unpacking, reading or copying.
-
-  7. Additional Terms.
-
-  "Additional permissions" are terms that supplement the terms of this
-License by making exceptions from one or more of its conditions.
-Additional permissions that are applicable to the entire Program shall
-be treated as though they were included in this License, to the extent
-that they are valid under applicable law.  If additional permissions
-apply only to part of the Program, that part may be used separately
-under those permissions, but the entire Program remains governed by
-this License without regard to the additional permissions.
-
-  When you convey a copy of a covered work, you may at your option
-remove any additional permissions from that copy, or from any part of
-it.  (Additional permissions may be written to require their own
-removal in certain cases when you modify the work.)  You may place
-additional permissions on material, added by you to a covered work,
-for which you have or can give appropriate copyright permission.
-
-  Notwithstanding any other provision of this License, for material you
-add to a covered work, you may (if authorized by the copyright holders of
-that material) supplement the terms of this License with terms:
-
-    a) Disclaiming warranty or limiting liability differently from the
-    terms of sections 15 and 16 of this License; or
-
-    b) Requiring preservation of specified reasonable legal notices or
-    author attributions in that material or in the Appropriate Legal
-    Notices displayed by works containing it; or
-
-    c) Prohibiting misrepresentation of the origin of that material, or
-    requiring that modified versions of such material be marked in
-    reasonable ways as different from the original version; or
-
-    d) Limiting the use for publicity purposes of names of licensors or
-    authors of the material; or
-
-    e) Declining to grant rights under trademark law for use of some
-    trade names, trademarks, or service marks; or
-
-    f) Requiring indemnification of licensors and authors of that
-    material by anyone who conveys the material (or modified versions of
-    it) with contractual assumptions of liability to the recipient, for
-    any liability that these contractual assumptions directly impose on
-    those licensors and authors.
-
-  All other non-permissive additional terms are considered "further
-restrictions" within the meaning of section 10.  If the Program as you
-received it, or any part of it, contains a notice stating that it is
-governed by this License along with a term that is a further
-restriction, you may remove that term.  If a license document contains
-a further restriction but permits relicensing or conveying under this
-License, you may add to a covered work material governed by the terms
-of that license document, provided that the further restriction does
-not survive such relicensing or conveying.
-
-  If you add terms to a covered work in accord with this section, you
-must place, in the relevant source files, a statement of the
-additional terms that apply to those files, or a notice indicating
-where to find the applicable terms.
-
-  Additional terms, permissive or non-permissive, may be stated in the
-form of a separately written license, or stated as exceptions;
-the above requirements apply either way.
-
-  8. Termination.
-
-  You may not propagate or modify a covered work except as expressly
-provided under this License.  Any attempt otherwise to propagate or
-modify it is void, and will automatically terminate your rights under
-this License (including any patent licenses granted under the third
-paragraph of section 11).
-
-  However, if you cease all violation of this License, then your
-license from a particular copyright holder is reinstated (a)
-provisionally, unless and until the copyright holder explicitly and
-finally terminates your license, and (b) permanently, if the copyright
-holder fails to notify you of the violation by some reasonable means
-prior to 60 days after the cessation.
-
-  Moreover, your license from a particular copyright holder is
-reinstated permanently if the copyright holder notifies you of the
-violation by some reasonable means, this is the first time you have
-received notice of violation of this License (for any work) from that
-copyright holder, and you cure the violation prior to 30 days after
-your receipt of the notice.
-
-  Termination of your rights under this section does not terminate the
-licenses of parties who have received copies or rights from you under
-this License.  If your rights have been terminated and not permanently
-reinstated, you do not qualify to receive new licenses for the same
-material under section 10.
-
-  9. Acceptance Not Required for Having Copies.
-
-  You are not required to accept this License in order to receive or
-run a copy of the Program.  Ancillary propagation of a covered work
-occurring solely as a consequence of using peer-to-peer transmission
-to receive a copy likewise does not require acceptance.  However,
-nothing other than this License grants you permission to propagate or
-modify any covered work.  These actions infringe copyright if you do
-not accept this License.  Therefore, by modifying or propagating a
-covered work, you indicate your acceptance of this License to do so.
-
-  10. Automatic Licensing of Downstream Recipients.
-
-  Each time you convey a covered work, the recipient automatically
-receives a license from the original licensors, to run, modify and
-propagate that work, subject to this License.  You are not responsible
-for enforcing compliance by third parties with this License.
-
-  An "entity transaction" is a transaction transferring control of an
-organization, or substantially all assets of one, or subdividing an
-organization, or merging organizations.  If propagation of a covered
-work results from an entity transaction, each party to that
-transaction who receives a copy of the work also receives whatever
-licenses to the work the party's predecessor in interest had or could
-give under the previous paragraph, plus a right to possession of the
-Corresponding Source of the work from the predecessor in interest, if
-the predecessor has it or can get it with reasonable efforts.
-
-  You may not impose any further restrictions on the exercise of the
-rights granted or affirmed under this License.  For example, you may
-not impose a license fee, royalty, or other charge for exercise of
-rights granted under this License, and you may not initiate litigation
-(including a cross-claim or counterclaim in a lawsuit) alleging that
-any patent claim is infringed by making, using, selling, offering for
-sale, or importing the Program or any portion of it.
-
-  11. Patents.
-
-  A "contributor" is a copyright holder who authorizes use under this
-License of the Program or a work on which the Program is based.  The
-work thus licensed is called the contributor's "contributor version".
-
-  A contributor's "essential patent claims" are all patent claims
-owned or controlled by the contributor, whether already acquired or
-hereafter acquired, that would be infringed by some manner, permitted
-by this License, of making, using, or selling its contributor version,
-but do not include claims that would be infringed only as a
-consequence of further modification of the contributor version.  For
-purposes of this definition, "control" includes the right to grant
-patent sublicenses in a manner consistent with the requirements of
-this License.
-
-  Each contributor grants you a non-exclusive, worldwide, royalty-free
-patent license under the contributor's essential patent claims, to
-make, use, sell, offer for sale, import and otherwise run, modify and
-propagate the contents of its contributor version.
-
-  In the following three paragraphs, a "patent license" is any express
-agreement or commitment, however denominated, not to enforce a patent
-(such as an express permission to practice a patent or covenant not to
-sue for patent infringement).  To "grant" such a patent license to a
-party means to make such an agreement or commitment not to enforce a
-patent against the party.
-
-  If you convey a covered work, knowingly relying on a patent license,
-and the Corresponding Source of the work is not available for anyone
-to copy, free of charge and under the terms of this License, through a
-publicly available network server or other readily accessible means,
-then you must either (1) cause the Corresponding Source to be so
-available, or (2) arrange to deprive yourself of the benefit of the
-patent license for this particular work, or (3) arrange, in a manner
-consistent with the requirements of this License, to extend the patent
-license to downstream recipients.  "Knowingly relying" means you have
-actual knowledge that, but for the patent license, your conveying the
-covered work in a country, or your recipient's use of the covered work
-in a country, would infringe one or more identifiable patents in that
-country that you have reason to believe are valid.
-
-  If, pursuant to or in connection with a single transaction or
-arrangement, you convey, or propagate by procuring conveyance of, a
-covered work, and grant a patent license to some of the parties
-receiving the covered work authorizing them to use, propagate, modify
-or convey a specific copy of the covered work, then the patent license
-you grant is automatically extended to all recipients of the covered
-work and works based on it.
-
-  A patent license is "discriminatory" if it does not include within
-the scope of its coverage, prohibits the exercise of, or is
-conditioned on the non-exercise of one or more of the rights that are
-specifically granted under this License.  You may not convey a covered
-work if you are a party to an arrangement with a third party that is
-in the business of distributing software, under which you make payment
-to the third party based on the extent of your activity of conveying
-the work, and under which the third party grants, to any of the
-parties who would receive the covered work from you, a discriminatory
-patent license (a) in connection with copies of the covered work
-conveyed by you (or copies made from those copies), or (b) primarily
-for and in connection with specific products or compilations that
-contain the covered work, unless you entered into that arrangement,
-or that patent license was granted, prior to 28 March 2007.
-
-  Nothing in this License shall be construed as excluding or limiting
-any implied license or other defenses to infringement that may
-otherwise be available to you under applicable patent law.
-
-  12. No Surrender of Others' Freedom.
-
-  If conditions are imposed on you (whether by court order, agreement or
-otherwise) that contradict the conditions of this License, they do not
-excuse you from the conditions of this License.  If you cannot convey a
-covered work so as to satisfy simultaneously your obligations under this
-License and any other pertinent obligations, then as a consequence you may
-not convey it at all.  For example, if you agree to terms that obligate you
-to collect a royalty for further conveying from those to whom you convey
-the Program, the only way you could satisfy both those terms and this
-License would be to refrain entirely from conveying the Program.
-
-  13. Remote Network Interaction; Use with the GNU General Public License.
-
-  Notwithstanding any other provision of this License, if you modify the
-Program, your modified version must prominently offer all users
-interacting with it remotely through a computer network (if your version
-supports such interaction) an opportunity to receive the Corresponding
-Source of your version by providing access to the Corresponding Source
-from a network server at no charge, through some standard or customary
-means of facilitating copying of software.  This Corresponding Source
-shall include the Corresponding Source for any work covered by version 3
-of the GNU General Public License that is incorporated pursuant to the
-following paragraph.
-
-  Notwithstanding any other provision of this License, you have
-permission to link or combine any covered work with a work licensed
-under version 3 of the GNU General Public License into a single
-combined work, and to convey the resulting work.  The terms of this
-License will continue to apply to the part which is the covered work,
-but the work with which it is combined will remain governed by version
-3 of the GNU General Public License.
-
-  14. Revised Versions of this License.
-
-  The Free Software Foundation may publish revised and/or new versions of
-the GNU Affero General Public License from time to time.  Such new versions
-will be similar in spirit to the present version, but may differ in detail to
-address new problems or concerns.
-
-  Each version is given a distinguishing version number.  If the
-Program specifies that a certain numbered version of the GNU Affero General
-Public License "or any later version" applies to it, you have the
-option of following the terms and conditions either of that numbered
-version or of any later version published by the Free Software
-Foundation.  If the Program does not specify a version number of the
-GNU Affero General Public License, you may choose any version ever published
-by the Free Software Foundation.
-
-  If the Program specifies that a proxy can decide which future
-versions of the GNU Affero General Public License can be used, that proxy's
-public statement of acceptance of a version permanently authorizes you
-to choose that version for the Program.
-
-  Later license versions may give you additional or different
-permissions.  However, no additional obligations are imposed on any
-author or copyright holder as a result of your choosing to follow a
-later version.
-
-  15. Disclaimer of Warranty.
-
-  THERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY
-APPLICABLE LAW.  EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT
-HOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM "AS IS" WITHOUT WARRANTY
-OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO,
-THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
-PURPOSE.  THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM
-IS WITH YOU.  SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF
-ALL NECESSARY SERVICING, REPAIR OR CORRECTION.
-
-  16. Limitation of Liability.
-
-  IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING
-WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES AND/OR CONVEYS
-THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY
-GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE
-USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF
-DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD
-PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS),
-EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF
-SUCH DAMAGES.
-
-  17. Interpretation of Sections 15 and 16.
-
-  If the disclaimer of warranty and limitation of liability provided
-above cannot be given local legal effect according to their terms,
-reviewing courts shall apply local law that most closely approximates
-an absolute waiver of all civil liability in connection with the
-Program, unless a warranty or assumption of liability accompanies a
-copy of the Program in return for a fee.
-
-                     END OF TERMS AND CONDITIONS
-
-            How to Apply These Terms to Your New Programs
-
-  If you develop a new program, and you want it to be of the greatest
-possible use to the public, the best way to achieve this is to make it
-free software which everyone can redistribute and change under these terms.
-
-  To do so, attach the following notices to the program.  It is safest
-to attach them to the start of each source file to most effectively
-state the exclusion of warranty; and each file should have at least
-the "copyright" line and a pointer to where the full notice is found.
-
-    <one line to give the program's name and a brief idea of what it does.>
-    Copyright (C) <year>  <name of author>
-
-    This program is free software: you can redistribute it and/or modify
-    it under the terms of the GNU Affero General Public License as published
-    by the Free Software Foundation, either version 3 of the License, or
-    (at your option) any later version.
-
-    This program is distributed in the hope that it will be useful,
-    but WITHOUT ANY WARRANTY; without even the implied warranty of
-    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-    GNU Affero General Public License for more details.
-
-    You should have received a copy of the GNU Affero General Public License
-    along with this program.  If not, see <https://www.gnu.org/licenses/>.
-
-Also add information on how to contact you by electronic and paper mail.
-
-  If your software can interact with users remotely through a computer
-network, you should also make sure that it provides a way for users to
-get its source.  For example, if your program is a web application, its
-interface could display a "Source" link that leads users to an archive
-of the code.  There are many ways you could offer source, and different
-solutions will be better for different programs; see section 13 for the
-specific requirements.
-
-  You should also get your employer (if you work as a programmer) or school,
-if any, to sign a "copyright disclaimer" for the program, if necessary.
-For more information on this, and how to apply and follow the GNU AGPL, see
-<https://www.gnu.org/licenses/>.
+                    GNU AFFERO GENERAL PUBLIC LICENSE
+                       Version 3, 19 November 2007
+
+ Copyright (C) 2007 Free Software Foundation, Inc. <https://fsf.org/>
+ Everyone is permitted to copy and distribute verbatim copies
+ of this license document, but changing it is not allowed.
+
+                            Preamble
+
+  The GNU Affero General Public License is a free, copyleft license for
+software and other kinds of works, specifically designed to ensure
+cooperation with the community in the case of network server software.
+
+  The licenses for most software and other practical works are designed
+to take away your freedom to share and change the works.  By contrast,
+our General Public Licenses are intended to guarantee your freedom to
+share and change all versions of a program--to make sure it remains free
+software for all its users.
+
+  When we speak of free software, we are referring to freedom, not
+price.  Our General Public Licenses are designed to make sure that you
+have the freedom to distribute copies of free software (and charge for
+them if you wish), that you receive source code or can get it if you
+want it, that you can change the software or use pieces of it in new
+free programs, and that you know you can do these things.
+
+  Developers that use our General Public Licenses protect your rights
+with two steps: (1) assert copyright on the software, and (2) offer
+you this License which gives you legal permission to copy, distribute
+and/or modify the software.
+
+  A secondary benefit of defending all users' freedom is that
+improvements made in alternate versions of the program, if they
+receive widespread use, become available for other developers to
+incorporate.  Many developers of free software are heartened and
+encouraged by the resulting cooperation.  However, in the case of
+software used on network servers, this result may fail to come about.
+The GNU General Public License permits making a modified version and
+letting the public access it on a server without ever releasing its
+source code to the public.
+
+  The GNU Affero General Public License is designed specifically to
+ensure that, in such cases, the modified source code becomes available
+to the community.  It requires the operator of a network server to
+provide the source code of the modified version running there to the
+users of that server.  Therefore, public use of a modified version, on
+a publicly accessible server, gives the public access to the source
+code of the modified version.
+
+  An older license, called the Affero General Public License and
+published by Affero, was designed to accomplish similar goals.  This is
+a different license, not a version of the Affero GPL, but Affero has
+released a new version of the Affero GPL which permits relicensing under
+this license.
+
+  The precise terms and conditions for copying, distribution and
+modification follow.
+
+                       TERMS AND CONDITIONS
+
+  0. Definitions.
+
+  "This License" refers to version 3 of the GNU Affero General Public License.
+
+  "Copyright" also means copyright-like laws that apply to other kinds of
+works, such as semiconductor masks.
+
+  "The Program" refers to any copyrightable work licensed under this
+License.  Each licensee is addressed as "you".  "Licensees" and
+"recipients" may be individuals or organizations.
+
+  To "modify" a work means to copy from or adapt all or part of the work
+in a fashion requiring copyright permission, other than the making of an
+exact copy.  The resulting work is called a "modified version" of the
+earlier work or a work "based on" the earlier work.
+
+  A "covered work" means either the unmodified Program or a work based
+on the Program.
+
+  To "propagate" a work means to do anything with it that, without
+permission, would make you directly or secondarily liable for
+infringement under applicable copyright law, except executing it on a
+computer or modifying a private copy.  Propagation includes copying,
+distribution (with or without modification), making available to the
+public, and in some countries other activities as well.
+
+  To "convey" a work means any kind of propagation that enables other
+parties to make or receive copies.  Mere interaction with a user through
+a computer network, with no transfer of a copy, is not conveying.
+
+  An interactive user interface displays "Appropriate Legal Notices"
+to the extent that it includes a convenient and prominently visible
+feature that (1) displays an appropriate copyright notice, and (2)
+tells the user that there is no warranty for the work (except to the
+extent that warranties are provided), that licensees may convey the
+work under this License, and how to view a copy of this License.  If
+the interface presents a list of user commands or options, such as a
+menu, a prominent item in the list meets this criterion.
+
+  1. Source Code.
+
+  The "source code" for a work means the preferred form of the work
+for making modifications to it.  "Object code" means any non-source
+form of a work.
+
+  A "Standard Interface" means an interface that either is an official
+standard defined by a recognized standards body, or, in the case of
+interfaces specified for a particular programming language, one that
+is widely used among developers working in that language.
+
+  The "System Libraries" of an executable work include anything, other
+than the work as a whole, that (a) is included in the normal form of
+packaging a Major Component, but which is not part of that Major
+Component, and (b) serves only to enable use of the work with that
+Major Component, or to implement a Standard Interface for which an
+implementation is available to the public in source code form.  A
+"Major Component", in this context, means a major essential component
+(kernel, window system, and so on) of the specific operating system
+(if any) on which the executable work runs, or a compiler used to
+produce the work, or an object code interpreter used to run it.
+
+  The "Corresponding Source" for a work in object code form means all
+the source code needed to generate, install, and (for an executable
+work) run the object code and to modify the work, including scripts to
+control those activities.  However, it does not include the work's
+System Libraries, or general-purpose tools or generally available free
+programs which are used unmodified in performing those activities but
+which are not part of the work.  For example, Corresponding Source
+includes interface definition files associated with source files for
+the work, and the source code for shared libraries and dynamically
+linked subprograms that the work is specifically designed to require,
+such as by intimate data communication or control flow between those
+subprograms and other parts of the work.
+
+  The Corresponding Source need not include anything that users
+can regenerate automatically from other parts of the Corresponding
+Source.
+
+  The Corresponding Source for a work in source code form is that
+same work.
+
+  2. Basic Permissions.
+
+  All rights granted under this License are granted for the term of
+copyright on the Program, and are irrevocable provided the stated
+conditions are met.  This License explicitly affirms your unlimited
+permission to run the unmodified Program.  The output from running a
+covered work is covered by this License only if the output, given its
+content, constitutes a covered work.  This License acknowledges your
+rights of fair use or other equivalent, as provided by copyright law.
+
+  You may make, run and propagate covered works that you do not
+convey, without conditions so long as your license otherwise remains
+in force.  You may convey covered works to others for the sole purpose
+of having them make modifications exclusively for you, or provide you
+with facilities for running those works, provided that you comply with
+the terms of this License in conveying all material for which you do
+not control copyright.  Those thus making or running the covered works
+for you must do so exclusively on your behalf, under your direction
+and control, on terms that prohibit them from making any copies of
+your copyrighted material outside their relationship with you.
+
+  Conveying under any other circumstances is permitted solely under
+the conditions stated below.  Sublicensing is not allowed; section 10
+makes it unnecessary.
+
+  3. Protecting Users' Legal Rights From Anti-Circumvention Law.
+
+  No covered work shall be deemed part of an effective technological
+measure under any applicable law fulfilling obligations under article
+11 of the WIPO copyright treaty adopted on 20 December 1996, or
+similar laws prohibiting or restricting circumvention of such
+measures.
+
+  When you convey a covered work, you waive any legal power to forbid
+circumvention of technological measures to the extent such circumvention
+is effected by exercising rights under this License with respect to
+the covered work, and you disclaim any intention to limit operation or
+modification of the work as a means of enforcing, against the work's
+users, your or third parties' legal rights to forbid circumvention of
+technological measures.
+
+  4. Conveying Verbatim Copies.
+
+  You may convey verbatim copies of the Program's source code as you
+receive it, in any medium, provided that you conspicuously and
+appropriately publish on each copy an appropriate copyright notice;
+keep intact all notices stating that this License and any
+non-permissive terms added in accord with section 7 apply to the code;
+keep intact all notices of the absence of any warranty; and give all
+recipients a copy of this License along with the Program.
+
+  You may charge any price or no price for each copy that you convey,
+and you may offer support or warranty protection for a fee.
+
+  5. Conveying Modified Source Versions.
+
+  You may convey a work based on the Program, or the modifications to
+produce it from the Program, in the form of source code under the
+terms of section 4, provided that you also meet all of these conditions:
+
+    a) The work must carry prominent notices stating that you modified
+    it, and giving a relevant date.
+
+    b) The work must carry prominent notices stating that it is
+    released under this License and any conditions added under section
+    7.  This requirement modifies the requirement in section 4 to
+    "keep intact all notices".
+
+    c) You must license the entire work, as a whole, under this
+    License to anyone who comes into possession of a copy.  This
+    License will therefore apply, along with any applicable section 7
+    additional terms, to the whole of the work, and all its parts,
+    regardless of how they are packaged.  This License gives no
+    permission to license the work in any other way, but it does not
+    invalidate such permission if you have separately received it.
+
+    d) If the work has interactive user interfaces, each must display
+    Appropriate Legal Notices; however, if the Program has interactive
+    interfaces that do not display Appropriate Legal Notices, your
+    work need not make them do so.
+
+  A compilation of a covered work with other separate and independent
+works, which are not by their nature extensions of the covered work,
+and which are not combined with it such as to form a larger program,
+in or on a volume of a storage or distribution medium, is called an
+"aggregate" if the compilation and its resulting copyright are not
+used to limit the access or legal rights of the compilation's users
+beyond what the individual works permit.  Inclusion of a covered work
+in an aggregate does not cause this License to apply to the other
+parts of the aggregate.
+
+  6. Conveying Non-Source Forms.
+
+  You may convey a covered work in object code form under the terms
+of sections 4 and 5, provided that you also convey the
+machine-readable Corresponding Source under the terms of this License,
+in one of these ways:
+
+    a) Convey the object code in, or embodied in, a physical product
+    (including a physical distribution medium), accompanied by the
+    Corresponding Source fixed on a durable physical medium
+    customarily used for software interchange.
+
+    b) Convey the object code in, or embodied in, a physical product
+    (including a physical distribution medium), accompanied by a
+    written offer, valid for at least three years and valid for as
+    long as you offer spare parts or customer support for that product
+    model, to give anyone who possesses the object code either (1) a
+    copy of the Corresponding Source for all the software in the
+    product that is covered by this License, on a durable physical
+    medium customarily used for software interchange, for a price no
+    more than your reasonable cost of physically performing this
+    conveying of source, or (2) access to copy the
+    Corresponding Source from a network server at no charge.
+
+    c) Convey individual copies of the object code with a copy of the
+    written offer to provide the Corresponding Source.  This
+    alternative is allowed only occasionally and noncommercially, and
+    only if you received the object code with such an offer, in accord
+    with subsection 6b.
+
+    d) Convey the object code by offering access from a designated
+    place (gratis or for a charge), and offer equivalent access to the
+    Corresponding Source in the same way through the same place at no
+    further charge.  You need not require recipients to copy the
+    Corresponding Source along with the object code.  If the place to
+    copy the object code is a network server, the Corresponding Source
+    may be on a different server (operated by you or a third party)
+    that supports equivalent copying facilities, provided you maintain
+    clear directions next to the object code saying where to find the
+    Corresponding Source.  Regardless of what server hosts the
+    Corresponding Source, you remain obligated to ensure that it is
+    available for as long as needed to satisfy these requirements.
+
+    e) Convey the object code using peer-to-peer transmission, provided
+    you inform other peers where the object code and Corresponding
+    Source of the work are being offered to the general public at no
+    charge under subsection 6d.
+
+  A separable portion of the object code, whose source code is excluded
+from the Corresponding Source as a System Library, need not be
+included in conveying the object code work.
+
+  A "User Product" is either (1) a "consumer product", which means any
+tangible personal property which is normally used for personal, family,
+or household purposes, or (2) anything designed or sold for incorporation
+into a dwelling.  In determining whether a product is a consumer product,
+doubtful cases shall be resolved in favor of coverage.  For a particular
+product received by a particular user, "normally used" refers to a
+typical or common use of that class of product, regardless of the status
+of the particular user or of the way in which the particular user
+actually uses, or expects or is expected to use, the product.  A product
+is a consumer product regardless of whether the product has substantial
+commercial, industrial or non-consumer uses, unless such uses represent
+the only significant mode of use of the product.
+
+  "Installation Information" for a User Product means any methods,
+procedures, authorization keys, or other information required to install
+and execute modified versions of a covered work in that User Product from
+a modified version of its Corresponding Source.  The information must
+suffice to ensure that the continued functioning of the modified object
+code is in no case prevented or interfered with solely because
+modification has been made.
+
+  If you convey an object code work under this section in, or with, or
+specifically for use in, a User Product, and the conveying occurs as
+part of a transaction in which the right of possession and use of the
+User Product is transferred to the recipient in perpetuity or for a
+fixed term (regardless of how the transaction is characterized), the
+Corresponding Source conveyed under this section must be accompanied
+by the Installation Information.  But this requirement does not apply
+if neither you nor any third party retains the ability to install
+modified object code on the User Product (for example, the work has
+been installed in ROM).
+
+  The requirement to provide Installation Information does not include a
+requirement to continue to provide support service, warranty, or updates
+for a work that has been modified or installed by the recipient, or for
+the User Product in which it has been modified or installed.  Access to a
+network may be denied when the modification itself materially and
+adversely affects the operation of the network or violates the rules and
+protocols for communication across the network.
+
+  Corresponding Source conveyed, and Installation Information provided,
+in accord with this section must be in a format that is publicly
+documented (and with an implementation available to the public in
+source code form), and must require no special password or key for
+unpacking, reading or copying.
+
+  7. Additional Terms.
+
+  "Additional permissions" are terms that supplement the terms of this
+License by making exceptions from one or more of its conditions.
+Additional permissions that are applicable to the entire Program shall
+be treated as though they were included in this License, to the extent
+that they are valid under applicable law.  If additional permissions
+apply only to part of the Program, that part may be used separately
+under those permissions, but the entire Program remains governed by
+this License without regard to the additional permissions.
+
+  When you convey a copy of a covered work, you may at your option
+remove any additional permissions from that copy, or from any part of
+it.  (Additional permissions may be written to require their own
+removal in certain cases when you modify the work.)  You may place
+additional permissions on material, added by you to a covered work,
+for which you have or can give appropriate copyright permission.
+
+  Notwithstanding any other provision of this License, for material you
+add to a covered work, you may (if authorized by the copyright holders of
+that material) supplement the terms of this License with terms:
+
+    a) Disclaiming warranty or limiting liability differently from the
+    terms of sections 15 and 16 of this License; or
+
+    b) Requiring preservation of specified reasonable legal notices or
+    author attributions in that material or in the Appropriate Legal
+    Notices displayed by works containing it; or
+
+    c) Prohibiting misrepresentation of the origin of that material, or
+    requiring that modified versions of such material be marked in
+    reasonable ways as different from the original version; or
+
+    d) Limiting the use for publicity purposes of names of licensors or
+    authors of the material; or
+
+    e) Declining to grant rights under trademark law for use of some
+    trade names, trademarks, or service marks; or
+
+    f) Requiring indemnification of licensors and authors of that
+    material by anyone who conveys the material (or modified versions of
+    it) with contractual assumptions of liability to the recipient, for
+    any liability that these contractual assumptions directly impose on
+    those licensors and authors.
+
+  All other non-permissive additional terms are considered "further
+restrictions" within the meaning of section 10.  If the Program as you
+received it, or any part of it, contains a notice stating that it is
+governed by this License along with a term that is a further
+restriction, you may remove that term.  If a license document contains
+a further restriction but permits relicensing or conveying under this
+License, you may add to a covered work material governed by the terms
+of that license document, provided that the further restriction does
+not survive such relicensing or conveying.
+
+  If you add terms to a covered work in accord with this section, you
+must place, in the relevant source files, a statement of the
+additional terms that apply to those files, or a notice indicating
+where to find the applicable terms.
+
+  Additional terms, permissive or non-permissive, may be stated in the
+form of a separately written license, or stated as exceptions;
+the above requirements apply either way.
+
+  8. Termination.
+
+  You may not propagate or modify a covered work except as expressly
+provided under this License.  Any attempt otherwise to propagate or
+modify it is void, and will automatically terminate your rights under
+this License (including any patent licenses granted under the third
+paragraph of section 11).
+
+  However, if you cease all violation of this License, then your
+license from a particular copyright holder is reinstated (a)
+provisionally, unless and until the copyright holder explicitly and
+finally terminates your license, and (b) permanently, if the copyright
+holder fails to notify you of the violation by some reasonable means
+prior to 60 days after the cessation.
+
+  Moreover, your license from a particular copyright holder is
+reinstated permanently if the copyright holder notifies you of the
+violation by some reasonable means, this is the first time you have
+received notice of violation of this License (for any work) from that
+copyright holder, and you cure the violation prior to 30 days after
+your receipt of the notice.
+
+  Termination of your rights under this section does not terminate the
+licenses of parties who have received copies or rights from you under
+this License.  If your rights have been terminated and not permanently
+reinstated, you do not qualify to receive new licenses for the same
+material under section 10.
+
+  9. Acceptance Not Required for Having Copies.
+
+  You are not required to accept this License in order to receive or
+run a copy of the Program.  Ancillary propagation of a covered work
+occurring solely as a consequence of using peer-to-peer transmission
+to receive a copy likewise does not require acceptance.  However,
+nothing other than this License grants you permission to propagate or
+modify any covered work.  These actions infringe copyright if you do
+not accept this License.  Therefore, by modifying or propagating a
+covered work, you indicate your acceptance of this License to do so.
+
+  10. Automatic Licensing of Downstream Recipients.
+
+  Each time you convey a covered work, the recipient automatically
+receives a license from the original licensors, to run, modify and
+propagate that work, subject to this License.  You are not responsible
+for enforcing compliance by third parties with this License.
+
+  An "entity transaction" is a transaction transferring control of an
+organization, or substantially all assets of one, or subdividing an
+organization, or merging organizations.  If propagation of a covered
+work results from an entity transaction, each party to that
+transaction who receives a copy of the work also receives whatever
+licenses to the work the party's predecessor in interest had or could
+give under the previous paragraph, plus a right to possession of the
+Corresponding Source of the work from the predecessor in interest, if
+the predecessor has it or can get it with reasonable efforts.
+
+  You may not impose any further restrictions on the exercise of the
+rights granted or affirmed under this License.  For example, you may
+not impose a license fee, royalty, or other charge for exercise of
+rights granted under this License, and you may not initiate litigation
+(including a cross-claim or counterclaim in a lawsuit) alleging that
+any patent claim is infringed by making, using, selling, offering for
+sale, or importing the Program or any portion of it.
+
+  11. Patents.
+
+  A "contributor" is a copyright holder who authorizes use under this
+License of the Program or a work on which the Program is based.  The
+work thus licensed is called the contributor's "contributor version".
+
+  A contributor's "essential patent claims" are all patent claims
+owned or controlled by the contributor, whether already acquired or
+hereafter acquired, that would be infringed by some manner, permitted
+by this License, of making, using, or selling its contributor version,
+but do not include claims that would be infringed only as a
+consequence of further modification of the contributor version.  For
+purposes of this definition, "control" includes the right to grant
+patent sublicenses in a manner consistent with the requirements of
+this License.
+
+  Each contributor grants you a non-exclusive, worldwide, royalty-free
+patent license under the contributor's essential patent claims, to
+make, use, sell, offer for sale, import and otherwise run, modify and
+propagate the contents of its contributor version.
+
+  In the following three paragraphs, a "patent license" is any express
+agreement or commitment, however denominated, not to enforce a patent
+(such as an express permission to practice a patent or covenant not to
+sue for patent infringement).  To "grant" such a patent license to a
+party means to make such an agreement or commitment not to enforce a
+patent against the party.
+
+  If you convey a covered work, knowingly relying on a patent license,
+and the Corresponding Source of the work is not available for anyone
+to copy, free of charge and under the terms of this License, through a
+publicly available network server or other readily accessible means,
+then you must either (1) cause the Corresponding Source to be so
+available, or (2) arrange to deprive yourself of the benefit of the
+patent license for this particular work, or (3) arrange, in a manner
+consistent with the requirements of this License, to extend the patent
+license to downstream recipients.  "Knowingly relying" means you have
+actual knowledge that, but for the patent license, your conveying the
+covered work in a country, or your recipient's use of the covered work
+in a country, would infringe one or more identifiable patents in that
+country that you have reason to believe are valid.
+
+  If, pursuant to or in connection with a single transaction or
+arrangement, you convey, or propagate by procuring conveyance of, a
+covered work, and grant a patent license to some of the parties
+receiving the covered work authorizing them to use, propagate, modify
+or convey a specific copy of the covered work, then the patent license
+you grant is automatically extended to all recipients of the covered
+work and works based on it.
+
+  A patent license is "discriminatory" if it does not include within
+the scope of its coverage, prohibits the exercise of, or is
+conditioned on the non-exercise of one or more of the rights that are
+specifically granted under this License.  You may not convey a covered
+work if you are a party to an arrangement with a third party that is
+in the business of distributing software, under which you make payment
+to the third party based on the extent of your activity of conveying
+the work, and under which the third party grants, to any of the
+parties who would receive the covered work from you, a discriminatory
+patent license (a) in connection with copies of the covered work
+conveyed by you (or copies made from those copies), or (b) primarily
+for and in connection with specific products or compilations that
+contain the covered work, unless you entered into that arrangement,
+or that patent license was granted, prior to 28 March 2007.
+
+  Nothing in this License shall be construed as excluding or limiting
+any implied license or other defenses to infringement that may
+otherwise be available to you under applicable patent law.
+
+  12. No Surrender of Others' Freedom.
+
+  If conditions are imposed on you (whether by court order, agreement or
+otherwise) that contradict the conditions of this License, they do not
+excuse you from the conditions of this License.  If you cannot convey a
+covered work so as to satisfy simultaneously your obligations under this
+License and any other pertinent obligations, then as a consequence you may
+not convey it at all.  For example, if you agree to terms that obligate you
+to collect a royalty for further conveying from those to whom you convey
+the Program, the only way you could satisfy both those terms and this
+License would be to refrain entirely from conveying the Program.
+
+  13. Remote Network Interaction; Use with the GNU General Public License.
+
+  Notwithstanding any other provision of this License, if you modify the
+Program, your modified version must prominently offer all users
+interacting with it remotely through a computer network (if your version
+supports such interaction) an opportunity to receive the Corresponding
+Source of your version by providing access to the Corresponding Source
+from a network server at no charge, through some standard or customary
+means of facilitating copying of software.  This Corresponding Source
+shall include the Corresponding Source for any work covered by version 3
+of the GNU General Public License that is incorporated pursuant to the
+following paragraph.
+
+  Notwithstanding any other provision of this License, you have
+permission to link or combine any covered work with a work licensed
+under version 3 of the GNU General Public License into a single
+combined work, and to convey the resulting work.  The terms of this
+License will continue to apply to the part which is the covered work,
+but the work with which it is combined will remain governed by version
+3 of the GNU General Public License.
+
+  14. Revised Versions of this License.
+
+  The Free Software Foundation may publish revised and/or new versions of
+the GNU Affero General Public License from time to time.  Such new versions
+will be similar in spirit to the present version, but may differ in detail to
+address new problems or concerns.
+
+  Each version is given a distinguishing version number.  If the
+Program specifies that a certain numbered version of the GNU Affero General
+Public License "or any later version" applies to it, you have the
+option of following the terms and conditions either of that numbered
+version or of any later version published by the Free Software
+Foundation.  If the Program does not specify a version number of the
+GNU Affero General Public License, you may choose any version ever published
+by the Free Software Foundation.
+
+  If the Program specifies that a proxy can decide which future
+versions of the GNU Affero General Public License can be used, that proxy's
+public statement of acceptance of a version permanently authorizes you
+to choose that version for the Program.
+
+  Later license versions may give you additional or different
+permissions.  However, no additional obligations are imposed on any
+author or copyright holder as a result of your choosing to follow a
+later version.
+
+  15. Disclaimer of Warranty.
+
+  THERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY
+APPLICABLE LAW.  EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT
+HOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM "AS IS" WITHOUT WARRANTY
+OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO,
+THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE.  THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM
+IS WITH YOU.  SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF
+ALL NECESSARY SERVICING, REPAIR OR CORRECTION.
+
+  16. Limitation of Liability.
+
+  IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING
+WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES AND/OR CONVEYS
+THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY
+GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE
+USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF
+DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD
+PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS),
+EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF
+SUCH DAMAGES.
+
+  17. Interpretation of Sections 15 and 16.
+
+  If the disclaimer of warranty and limitation of liability provided
+above cannot be given local legal effect according to their terms,
+reviewing courts shall apply local law that most closely approximates
+an absolute waiver of all civil liability in connection with the
+Program, unless a warranty or assumption of liability accompanies a
+copy of the Program in return for a fee.
+
+                     END OF TERMS AND CONDITIONS
+
+            How to Apply These Terms to Your New Programs
+
+  If you develop a new program, and you want it to be of the greatest
+possible use to the public, the best way to achieve this is to make it
+free software which everyone can redistribute and change under these terms.
+
+  To do so, attach the following notices to the program.  It is safest
+to attach them to the start of each source file to most effectively
+state the exclusion of warranty; and each file should have at least
+the "copyright" line and a pointer to where the full notice is found.
+
+    <one line to give the program's name and a brief idea of what it does.>
+    Copyright (C) <year>  <name of author>
+
+    This program is free software: you can redistribute it and/or modify
+    it under the terms of the GNU Affero General Public License as published
+    by the Free Software Foundation, either version 3 of the License, or
+    (at your option) any later version.
+
+    This program is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+    GNU Affero General Public License for more details.
+
+    You should have received a copy of the GNU Affero General Public License
+    along with this program.  If not, see <https://www.gnu.org/licenses/>.
+
+Also add information on how to contact you by electronic and paper mail.
+
+  If your software can interact with users remotely through a computer
+network, you should also make sure that it provides a way for users to
+get its source.  For example, if your program is a web application, its
+interface could display a "Source" link that leads users to an archive
+of the code.  There are many ways you could offer source, and different
+solutions will be better for different programs; see section 13 for the
+specific requirements.
+
+  You should also get your employer (if you work as a programmer) or school,
+if any, to sign a "copyright disclaimer" for the program, if necessary.
+For more information on this, and how to apply and follow the GNU AGPL, see
+<https://www.gnu.org/licenses/>.
```

### Comparing `pyzefir-0.4.1/PKG-INFO` & `pyzefir-0.4.22/PKG-INFO`

 * *Files 11% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: pyzefir
-Version: 0.4.1
+Version: 0.4.22
 Author-email: Narodowe Centrum Bada Jdrowych <office@idea.edu.pl>
 License:                     GNU AFFERO GENERAL PUBLIC LICENSE
                                Version 3, 19 November 2007
         
          Copyright (C) 2007 Free Software Foundation, Inc. <https://fsf.org/>
          Everyone is permitted to copy and distribute verbatim copies
          of this license document, but changing it is not allowed.
@@ -742,14 +742,22 @@
 
 ## Make stages
 
 Install virtual environment and all dependencies
 ```bash
 make install
 ```
+If you are developing pyZefir it is recommended to use editable mode.
+```bash
+make install EDITABLE=yes
+```
+which  allows you to install a package in such a way that any changes made to
+the source code are immediately reflected in the installed package without the
+need to reinstall it.
+
 Run linters check (black, pylama)
 ```bash
 make lint
 ```
 Run unit and fast integration tests (runs lint stage before)
 ```bash
 Make unit
@@ -805,42 +813,37 @@
 structure-creator -i pyzefir\resources\structure_creator_resources -o pyzefir\results -s base_scenario -h 8760 -y 20
 ```
 
 ### How structure creator resources directory must look like:
 ```markdown
 .
  structure_creator_resources/
-     cap_range/
-        cap_base.xlsx
-        cap_max.xlsx
-        cap_min.xlsx
      lbs/
-        boiler_coal_new_lkt.json
-        boiler_gas_lkt.json
+        boiler_coal_new_lkt.xlsx
+        boiler_gas_lkt.xlsx
         ...
      scenarios/
         base_scenario/
             fractions/
                boiler_coal_new_lkt.xlsx
                boiler_gas_lkt.xlsx
                ...
             cost_parameters.xlsx
             fuel_parameters.xlsx
+            generation_fraction.xlsx
             n_consumers.xlsx
             relative_emission_limits.xlsx
             technology_cap_limits.xlsx
             technology_type_cap_limits.xlsx
             yearly_demand.xlsx
-     subsystems/
-        heating_subsystem.json
-        kse_subsystem.json
-     aggr_types.json
+     aggregates.xlsx
      configuration.xlsx
-     emission_fees.json
-     global_techs.json
+     emissions.xlsx
+     subsystems.xlsx
+     transmission_fees.xlsx
 ```
 
 ## Simulation run
 
 1. Prepare `config.ini` file (look at `config_example.ini` file in project directory)
 
 :information_source: The section `create` of `config.ini` file is used for `structure creator` only, so if you're not going
@@ -857,7 +860,96 @@
 ```
 #### E.g.
 
 ```bash
 pyzefir -c pyzefir/config_basic.ini
 ```
 
+### How pyzefir resources directory must look like:
+```markdown
+
+XLSX input
+.
+ /pyzefir resources/
+     /scenarios/
+        scenario_1.xlsx
+        scenario_2.xlsx
+        ...
+     capacity_factors.xlsx
+     conversion_rate.xlsx
+     demand_chunks.xlsx
+     fuels.xlsx
+     generator_types.xlsx
+     initial_state.xlsx
+     storage_types.xlsx
+     structure.xlsx
+
+CSV input
+
+.
+ /pyzefir resources/
+     /capacity_factors/
+        Profiles.csv
+     /conversion_rate/
+        HEAT_PUMP.csv
+        BOILER_COAL.csv
+        ...
+     /demand_chunks/
+        Demand_Chunks.csv
+        chunk_period_1.csv
+        chunk_period_2.csv
+        ...
+     /demand_types/
+        family.csv
+        multifamily.csv
+        ...
+     /fuels/
+        Emission_Per_Unit.csv
+        Energy_Per_Unit.csv
+     /generator_types/
+        Efficiency.csv
+        Emission_Reduction.csv
+        Generator_Type_Energy_Carrier.csv
+        Generator_Type_Energy_Type.csv
+        Generator_Types.csv
+        Power_Utilization.csv
+     /initial_state/
+        Technology.csv
+        TechnologyStack.csv
+     /storage_types/
+        Parameters.csv
+     /structure/
+        Aggregates.csv
+        Buses.csv
+        DSR.csv
+        Emission_Fees_Emission_Types.csv
+        Emission_Types.csv
+        Energy_Types.csv
+        Generator_Binding.csv
+        Generator_Emission_Fees.csv
+        Generators.csv
+        Lines.csv
+        Power_Reserve.csv
+        Storages.csv
+        Technology_Bus.csv
+        TechnologyStack_Aggregate.csv
+        TechnologyStack_Buses_out.csv
+        TechnologyStack_Buses.csv
+        Transmission_Fees.csv
+     /scenario/
+         /scenario_name/
+            Constants.csv
+            Cost_Parameters.csv
+            Curtailment_Cost.csv
+            Element_Energy_Evolution_Limits.csv
+            Emission_Fees.csv
+            Energy_Source_Evolution_Limits.csv
+            Fractions.csv
+            Fuel_Availability.csv
+            Fuel_Prices.csv
+            Generation_Fraction.csv
+            N_Consumers.csv
+            Relative_Emission_Limits.csv
+            Yearly_Demand.csv
+         /another_scenario_name/
+             ....
+```
```

### Comparing `pyzefir-0.4.1/pyproject.toml` & `pyzefir-0.4.22/pyproject.toml`

 * *Files 23% similar despite different names*

```diff
@@ -1,205 +1,223 @@
-00000000: 5b62 7569 6c64 2d73 7973 7465 6d5d 0a72  [build-system].r
-00000010: 6571 7569 7265 7320 3d20 5b22 7365 7475  equires = ["setu
-00000020: 7074 6f6f 6c73 203d 3d20 3639 2e30 2e33  ptools == 69.0.3
-00000030: 225d 0a62 7569 6c64 2d62 6163 6b65 6e64  "].build-backend
-00000040: 203d 2022 7365 7475 7074 6f6f 6c73 2e62   = "setuptools.b
-00000050: 7569 6c64 5f6d 6574 6122 0a0a 5b70 726f  uild_meta"..[pro
-00000060: 6a65 6374 5d0a 6e61 6d65 203d 2022 7079  ject].name = "py
-00000070: 7a65 6669 7222 0a64 796e 616d 6963 203d  zefir".dynamic =
-00000080: 205b 2276 6572 7369 6f6e 225d 0a61 7574   ["version"].aut
-00000090: 686f 7273 203d 205b 0a20 2020 207b 6e61  hors = [.    {na
-000000a0: 6d65 203d 2022 4e61 726f 646f 7765 2043  me = "Narodowe C
-000000b0: 656e 7472 756d 2042 6164 61c5 8420 4ac4  entrum Bada.. J.
-000000c0: 8564 726f 7779 6368 222c 2065 6d61 696c  .drowych", email
-000000d0: 203d 2022 6f66 6669 6365 4069 6465 612e   = "office@idea.
-000000e0: 6564 752e 706c 227d 2c0a 5d0a 7265 6164  edu.pl"},.].read
-000000f0: 6d65 203d 2022 5245 4144 4d45 2e6d 6422  me = "README.md"
-00000100: 0a6c 6963 656e 7365 203d 207b 6669 6c65  .license = {file
-00000110: 203d 2022 4c49 4345 4e53 452e 7478 7422   = "LICENSE.txt"
-00000120: 7d0a 636c 6173 7369 6669 6572 7320 3d20  }.classifiers = 
-00000130: 5b0a 2020 2022 456e 7669 726f 6e6d 656e  [.   "Environmen
-00000140: 7420 3a3a 2043 6f6e 736f 6c65 222c 0a20  t :: Console",. 
-00000150: 2020 2249 6e74 656e 6465 6420 4175 6469    "Intended Audi
-00000160: 656e 6365 203a 3a20 5363 6965 6e63 652f  ence :: Science/
-00000170: 5265 7365 6172 6368 222c 0a20 2020 224c  Research",.   "L
-00000180: 6963 656e 7365 203a 3a20 4f53 4920 4170  icense :: OSI Ap
-00000190: 7072 6f76 6564 203a 3a20 474e 5520 4166  proved :: GNU Af
-000001a0: 6665 726f 2047 656e 6572 616c 2050 7562  fero General Pub
-000001b0: 6c69 6320 4c69 6365 6e73 6520 7633 206f  lic License v3 o
-000001c0: 7220 6c61 7465 7220 2841 4750 4c76 332b  r later (AGPLv3+
-000001d0: 2922 2c0a 2020 2022 4e61 7475 7261 6c20  )",.   "Natural 
-000001e0: 4c61 6e67 7561 6765 203a 3a20 456e 676c  Language :: Engl
-000001f0: 6973 6822 2c0a 2020 2022 4f70 6572 6174  ish",.   "Operat
-00000200: 696e 6720 5379 7374 656d 203a 3a20 4f53  ing System :: OS
-00000210: 2049 6e64 6570 656e 6465 6e74 222c 0a20   Independent",. 
-00000220: 2020 2250 726f 6772 616d 6d69 6e67 204c    "Programming L
-00000230: 616e 6775 6167 6520 3a3a 2050 7974 686f  anguage :: Pytho
-00000240: 6e20 3a3a 2033 2e31 3122 2c0a 2020 2022  n :: 3.11",.   "
-00000250: 546f 7069 6320 3a3a 2053 6369 656e 7469  Topic :: Scienti
-00000260: 6669 632f 456e 6769 6e65 6572 696e 6722  fic/Engineering"
-00000270: 2c0a 5d0a 0a64 6570 656e 6465 6e63 6965  ,.]..dependencie
-00000280: 7320 3d20 5b0a 2020 2020 226e 756d 7079  s = [.    "numpy
-00000290: 7e3d 312e 3234 2e32 222c 0a20 2020 2022  ~=1.24.2",.    "
-000002a0: 7061 6e64 6173 3d3d 322e 302e 3122 2c0a  pandas==2.0.1",.
-000002b0: 2020 2020 226e 6574 776f 726b 787e 3d33      "networkx~=3
-000002c0: 2e30 222c 0a20 2020 2022 7365 7475 7074  .0",.    "setupt
-000002d0: 6f6f 6c73 3d3d 3637 2e38 2e30 222c 0a20  ools==67.8.0",. 
-000002e0: 2020 2022 6d61 7470 6c6f 746c 6962 7e3d     "matplotlib~=
-000002f0: 332e 372e 3122 2c0a 2020 2020 226f 7065  3.7.1",.    "ope
-00000300: 6e70 7978 6c3d 3d33 2e31 2e32 222c 0a20  npyxl==3.1.2",. 
-00000310: 2020 2022 6775 726f 6269 7079 7e3d 3130     "gurobipy~=10
-00000320: 2e30 2e31 222c 0a20 2020 2022 6269 6469  .0.1",.    "bidi
-00000330: 6374 7e3d 302e 3232 2e31 222c 0a20 2020  ct~=0.22.1",.   
-00000340: 2022 7363 6970 797e 3d31 2e31 312e 3122   "scipy~=1.11.1"
-00000350: 2c0a 2020 2020 2263 6c69 636b 7e3d 382e  ,.    "click~=8.
-00000360: 312e 3622 2c0a 2020 2020 2273 616e 6974  1.6",.    "sanit
-00000370: 697a 652d 6669 6c65 6e61 6d65 7e3d 312e  ize-filename~=1.
-00000380: 322e 3022 2c0a 2020 2020 2258 6c73 7857  2.0",.    "XlsxW
-00000390: 7269 7465 727e 3d33 2e31 2e32 222c 0a20  riter~=3.1.2",. 
-000003a0: 2020 2022 6c69 6e6f 7079 7e3d 302e 332e     "linopy~=0.3.
-000003b0: 3322 2c0a 2020 2020 2278 6172 7261 797e  3",.    "xarray~
-000003c0: 3d32 3032 332e 3132 2e30 222c 0a5d 0a0a  =2023.12.0",.]..
-000003d0: 0a5b 7072 6f6a 6563 742e 6f70 7469 6f6e  .[project.option
-000003e0: 616c 2d64 6570 656e 6465 6e63 6965 735d  al-dependencies]
-000003f0: 0a64 6576 203d 205b 0a20 2020 2022 666c  .dev = [.    "fl
-00000400: 616b 6538 3d3d 372e 302e 3022 2c0a 2020  ake8==7.0.0",.  
-00000410: 2020 2262 6c61 636b 3d3d 3234 2e32 2e30    "black==24.2.0
-00000420: 222c 0a20 2020 2022 7072 652d 636f 6d6d  ",.    "pre-comm
-00000430: 6974 222c 0a20 2020 2022 7079 7465 7374  it",.    "pytest
-00000440: 3d3d 372e 342e 3422 2c0a 2020 2020 2270  ==7.4.4",.    "p
-00000450: 7974 6573 742d 636f 767e 3d34 2e30 2e30  ytest-cov~=4.0.0
-00000460: 222c 0a20 2020 2022 7079 7465 7374 2d6d  ",.    "pytest-m
-00000470: 6f63 6b7e 3d33 2e31 312e 3122 2c0a 2020  ock~=3.11.1",.  
-00000480: 2020 2270 7974 6573 742d 6c61 7a79 2d66    "pytest-lazy-f
-00000490: 6978 7475 7265 7e3d 302e 362e 3322 2c0a  ixture~=0.6.3",.
-000004a0: 2020 2020 2270 7974 6573 742d 7864 6973      "pytest-xdis
-000004b0: 747e 3d33 2e35 2e30 222c 0a20 2020 2022  t~=3.5.0",.    "
-000004c0: 7079 6c61 6d61 5b72 6164 6f6e 2c6d 7970  pylama[radon,myp
-000004d0: 792c 746f 6d6c 5d22 2c0a 2020 2020 2274  y,toml]",.    "t
-000004e0: 6f78 220a 5d0a 6775 726f 6269 203d 205b  ox".].gurobi = [
-000004f0: 0a20 2020 2022 6775 726f 6269 7079 7e3d  .    "gurobipy~=
-00000500: 3130 2e30 2e31 222c 0a5d 0a68 6967 6873  10.0.1",.].highs
-00000510: 203d 205b 0a20 2020 2022 6869 6768 7370   = [.    "highsp
-00000520: 797e 3d31 2e35 2e33 222c 0a5d 0a0a 5b70  y~=1.5.3",.]..[p
-00000530: 726f 6a65 6374 2e73 6372 6970 7473 5d0a  roject.scripts].
-00000540: 7079 7a65 6669 7220 3d20 2270 797a 6566  pyzefir = "pyzef
-00000550: 6972 2e63 6c69 2e72 756e 6e65 723a 636c  ir.cli.runner:cl
-00000560: 695f 7275 6e22 0a73 7472 7563 7475 7265  i_run".structure
-00000570: 2d63 7265 6174 6f72 203d 2022 7079 7a65  -creator = "pyze
-00000580: 6669 722e 7374 7275 6374 7572 655f 6372  fir.structure_cr
-00000590: 6561 746f 722e 636c 692e 636c 695f 7772  eator.cli.cli_wr
-000005a0: 6170 7065 723a 7275 6e5f 7374 7275 6374  apper:run_struct
-000005b0: 7572 655f 6372 6561 746f 725f 636c 6922  ure_creator_cli"
-000005c0: 0a0a 5b74 6f6f 6c2e 7365 7475 7074 6f6f  ..[tool.setuptoo
-000005d0: 6c73 2e64 796e 616d 6963 5d0a 7665 7273  ls.dynamic].vers
-000005e0: 696f 6e20 3d20 7b61 7474 7220 3d20 2270  ion = {attr = "p
-000005f0: 797a 6566 6972 2e5f 5f76 6572 7369 6f6e  yzefir.__version
-00000600: 5f5f 227d 0a0a 5b74 6f6f 6c2e 7365 7475  __"}..[tool.setu
-00000610: 7074 6f6f 6c73 2e70 6163 6b61 6765 732e  ptools.packages.
-00000620: 6669 6e64 5d0a 696e 636c 7564 6520 3d20  find].include = 
-00000630: 5b22 7079 7a65 6669 722a 225d 0a65 7863  ["pyzefir*"].exc
-00000640: 6c75 6465 203d 205b 2264 6f63 732a 222c  lude = ["docs*",
-00000650: 2022 7465 7374 732a 225d 0a0a 5b74 6f6f   "tests*"]..[too
-00000660: 6c2e 6d79 7079 5d0a 6967 6e6f 7265 5f6d  l.mypy].ignore_m
-00000670: 6973 7369 6e67 5f69 6d70 6f72 7473 203d  issing_imports =
-00000680: 2074 7275 650a 6469 7361 6c6c 6f77 5f75   true.disallow_u
-00000690: 6e74 7970 6564 5f64 6566 7320 3d20 7472  ntyped_defs = tr
-000006a0: 7565 0a64 6973 616c 6c6f 775f 696e 636f  ue.disallow_inco
-000006b0: 6d70 6c65 7465 5f64 6566 7320 3d20 7472  mplete_defs = tr
-000006c0: 7565 0a63 6865 636b 5f75 6e74 7970 6564  ue.check_untyped
-000006d0: 5f64 6566 7320 3d20 7472 7565 0a64 6973  _defs = true.dis
-000006e0: 616c 6c6f 775f 756e 7479 7065 645f 6465  allow_untyped_de
-000006f0: 636f 7261 746f 7273 203d 2066 616c 7365  corators = false
-00000700: 0a0a 5b74 6f6f 6c2e 636f 7665 7261 6765  ..[tool.coverage
-00000710: 2e72 6570 6f72 745d 0a65 7863 6c75 6465  .report].exclude
-00000720: 5f6c 696e 6573 203d 205b 0a09 2269 6620  _lines = [.."if 
-00000730: 5f5f 6e61 6d65 5f5f 203d 3d20 2e5f 5f6d  __name__ == .__m
-00000740: 6169 6e5f 5f2e 3a22 2c0a 0922 7261 6973  ain__.:",.."rais
-00000750: 6520 4173 7365 7274 696f 6e45 7272 6f72  e AssertionError
-00000760: 222c 0a09 2269 6620 5459 5045 5f43 4845  ",.."if TYPE_CHE
-00000770: 434b 494e 473a 222c 0a09 2272 6169 7365  CKING:",.."raise
-00000780: 204e 6f74 496d 706c 656d 656e 7465 6445   NotImplementedE
-00000790: 7272 6f72 222c 0a20 2020 5d0a 6f6d 6974  rror",.   ].omit
-000007a0: 203d 205b 0a20 2020 2270 797a 6566 6972   = [.   "pyzefir
-000007b0: 2f67 7261 7068 2f2a 2a22 2c0a 5d0a 0a5b  /graph/**",.]..[
-000007c0: 746f 6f6c 2e70 796c 616d 612e 6c69 6e74  tool.pylama.lint
-000007d0: 6572 2e70 7963 6f64 6573 7479 6c65 5d0a  er.pycodestyle].
-000007e0: 6d61 785f 6c69 6e65 5f6c 656e 6774 6820  max_line_length 
-000007f0: 3d20 3132 300a 5b74 6f6f 6c2e 7079 6c61  = 120.[tool.pyla
-00000800: 6d61 2e6c 696e 7465 722e 7079 6c69 6e74  ma.linter.pylint
-00000810: 5d0a 6d61 785f 6c69 6e65 5f6c 656e 6774  ].max_line_lengt
-00000820: 6820 3d20 3132 300a 5b74 6f6f 6c2e 7079  h = 120.[tool.py
-00000830: 6c61 6d61 2e6c 696e 7465 722e 7261 646f  lama.linter.rado
-00000840: 6e5d 0a6e 6f5f 6173 7365 7274 203d 2074  n].no_assert = t
-00000850: 7275 650a 0a5b 746f 6f6c 2e74 6f78 5d0a  rue..[tool.tox].
-00000860: 6c65 6761 6379 5f74 6f78 5f69 6e69 203d  legacy_tox_ini =
-00000870: 2022 2222 0a20 2020 205b 746f 785d 0a20   """.    [tox]. 
-00000880: 2020 2065 6e76 6c69 7374 203d 2070 7933     envlist = py3
-00000890: 3131 0a20 2020 2069 736f 6c61 7465 645f  11.    isolated_
-000008a0: 6275 696c 6420 3d20 5472 7565 0a0a 2020  build = True..  
-000008b0: 2020 5b74 6573 7465 6e76 5d0a 2020 2020    [testenv].    
-000008c0: 7573 6564 6576 656c 6f70 203d 2054 7275  usedevelop = Tru
-000008d0: 650a 2020 2020 6465 7073 203d 202e 5b64  e.    deps = .[d
-000008e0: 6576 2c67 7572 6f62 692c 6869 6768 735d  ev,gurobi,highs]
-000008f0: 0a0a 2020 2020 5b74 6573 7465 6e76 3a75  ..    [testenv:u
-00000900: 6e69 745d 0a20 2020 2063 6f6d 6d61 6e64  nit].    command
-00000910: 7320 3d0a 2020 2020 2020 2020 2020 2020  s =.            
-00000920: 7079 7468 6f6e 202d 6d20 7079 7465 7374  python -m pytest
-00000930: 202d 7676 7620 2d2d 636f 763d 7079 7a65   -vvv --cov=pyze
-00000940: 6669 7220 2d2d 6a75 6e69 7478 6d6c 3d72  fir --junitxml=r
-00000950: 6570 6f72 742e 786d 6c20 7465 7374 732f  eport.xml tests/
-00000960: 756e 6974 0a0a 2020 2020 5b74 6573 7465  unit..    [teste
-00000970: 6e76 3a66 6173 745f 696e 7465 6772 6174  nv:fast_integrat
-00000980: 696f 6e5d 0a20 2020 2063 6f6d 6d61 6e64  ion].    command
-00000990: 7320 3d0a 2020 2020 2020 2020 2020 2020  s =.            
-000009a0: 7079 7468 6f6e 202d 6d20 7079 7465 7374  python -m pytest
-000009b0: 202d 7676 7620 2d6d 2022 6e6f 7420 6c6f   -vvv -m "not lo
-000009c0: 6e67 5f74 6573 7422 2074 6573 7473 2f69  ng_test" tests/i
-000009d0: 6e74 6567 7261 7469 6f6e 0a0a 2020 2020  ntegration..    
-000009e0: 5b74 6573 7465 6e76 3a69 6e74 6567 7261  [testenv:integra
-000009f0: 7469 6f6e 5d0a 2020 2020 636f 6d6d 616e  tion].    comman
-00000a00: 6473 203d 0a20 2020 2020 2020 2020 2020  ds =.           
-00000a10: 2070 7974 686f 6e20 2d6d 2070 7974 6573   python -m pytes
-00000a20: 7420 2d76 7676 2074 6573 7473 2f69 6e74  t -vvv tests/int
-00000a30: 6567 7261 7469 6f6e 0a0a 2020 2020 5b63  egration..    [c
-00000a40: 6f76 6572 6167 655d 0a20 2020 2078 6d6c  overage].    xml
-00000a50: 5f72 6570 6f72 7420 3d20 7472 7565 0a20  _report = true. 
-00000a60: 2020 2068 746d 6c5f 7265 706f 7274 203d     html_report =
-00000a70: 2074 7275 650a 2222 220a 0a5b 746f 6f6c   true."""..[tool
-00000a80: 2e70 7974 6573 742e 696e 695f 6f70 7469  .pytest.ini_opti
-00000a90: 6f6e 735d 0a61 6464 6f70 7473 203d 2022  ons].addopts = "
-00000aa0: 2d2d 636f 762d 7265 706f 7274 2074 6572  --cov-report ter
-00000ab0: 6d20 2d2d 636f 762d 7265 706f 7274 2078  m --cov-report x
-00000ac0: 6d6c 3a63 6f76 6572 6167 652e 786d 6c20  ml:coverage.xml 
-00000ad0: 2d2d 6e75 6d70 726f 6365 7373 6573 2031  --numprocesses 1
-00000ae0: 3022 0a0a 5b74 6f6f 6c2e 6275 6d70 7665  0"..[tool.bumpve
-00000af0: 7273 696f 6e5d 0a63 7572 7265 6e74 5f76  rsion].current_v
-00000b00: 6572 7369 6f6e 203d 2022 302e 342e 3122  ersion = "0.4.1"
-00000b10: 0a63 6f6d 6d69 7420 3d20 7472 7565 0a74  .commit = true.t
-00000b20: 6167 203d 2074 7275 650a 7061 7273 6520  ag = true.parse 
-00000b30: 3d20 2228 3f50 3c6d 616a 6f72 3e5c 5c64  = "(?P<major>\\d
-00000b40: 2b29 5c5c 2e28 3f50 3c6d 696e 6f72 3e5c  +)\\.(?P<minor>\
-00000b50: 5c64 2b29 5c5c 2e28 3f50 3c70 6174 6368  \d+)\\.(?P<patch
-00000b60: 3e5c 5c64 2b29 285c 5c2d 283f 503c 7265  >\\d+)(\\-(?P<re
-00000b70: 6c65 6173 653e 5b61 2d7a 5d2b 2928 3f50  lease>[a-z]+)(?P
-00000b80: 3c62 7569 6c64 3e5c 5c64 2b29 293f 220a  <build>\\d+))?".
-00000b90: 7365 7269 616c 697a 6520 3d20 5b0a 2020  serialize = [.  
-00000ba0: 2020 227b 6d61 6a6f 727d 2e7b 6d69 6e6f    "{major}.{mino
-00000bb0: 727d 2e7b 7061 7463 687d 222c 0a20 2020  r}.{patch}",.   
-00000bc0: 2027 7b6d 616a 6f72 7d2e 7b6d 696e 6f72   '{major}.{minor
-00000bd0: 7d2e 7b70 6174 6368 7d2d 7b72 656c 6561  }.{patch}-{relea
-00000be0: 7365 7d7b 6275 696c 647d 272c 0a5d 0a0a  se}{build}',.]..
-00000bf0: 5b74 6f6f 6c2e 6275 6d70 7665 7273 696f  [tool.bumpversio
-00000c00: 6e2e 7061 7274 2e72 656c 6561 7365 5d0a  n.part.release].
-00000c10: 7661 6c75 6573 203d 205b 2264 6576 222c  values = ["dev",
-00000c20: 2022 7263 222c 2022 6669 6e61 6c22 5d0a   "rc", "final"].
-00000c30: 6669 7273 745f 7661 6c75 6520 3d20 2264  first_value = "d
-00000c40: 6576 220a 6f70 7469 6f6e 616c 5f76 616c  ev".optional_val
-00000c50: 7565 203d 2022 6669 6e61 6c22 0a0a 5b74  ue = "final"..[t
-00000c60: 6f6f 6c2e 6275 6d70 7665 7273 696f 6e2e  ool.bumpversion.
-00000c70: 7061 7274 2e62 7569 6c64 5d0a 6669 7273  part.build].firs
-00000c80: 745f 7661 6c75 6520 3d20 310a 0a0a 5b5b  t_value = 1...[[
-00000c90: 746f 6f6c 2e62 756d 7076 6572 7369 6f6e  tool.bumpversion
-00000ca0: 2e66 696c 6573 5d5d 0a66 696c 656e 616d  .files]].filenam
-00000cb0: 6520 3d20 2270 797a 6566 6972 2f5f 5f69  e = "pyzefir/__i
-00000cc0: 6e69 745f 5f2e 7079 220a                 nit__.py".
+00000000: 5b62 7569 6c64 2d73 7973 7465 6d5d 0d0a  [build-system]..
+00000010: 7265 7175 6972 6573 203d 205b 2273 6574  requires = ["set
+00000020: 7570 746f 6f6c 7320 3d3d 2036 392e 302e  uptools == 69.0.
+00000030: 3322 5d0d 0a62 7569 6c64 2d62 6163 6b65  3"]..build-backe
+00000040: 6e64 203d 2022 7365 7475 7074 6f6f 6c73  nd = "setuptools
+00000050: 2e62 7569 6c64 5f6d 6574 6122 0d0a 0d0a  .build_meta"....
+00000060: 5b70 726f 6a65 6374 5d0d 0a6e 616d 6520  [project]..name 
+00000070: 3d20 2270 797a 6566 6972 220d 0a64 796e  = "pyzefir"..dyn
+00000080: 616d 6963 203d 205b 2276 6572 7369 6f6e  amic = ["version
+00000090: 225d 0d0a 6175 7468 6f72 7320 3d20 5b0d  "]..authors = [.
+000000a0: 0a20 2020 207b 6e61 6d65 203d 2022 4e61  .    {name = "Na
+000000b0: 726f 646f 7765 2043 656e 7472 756d 2042  rodowe Centrum B
+000000c0: 6164 61c5 8420 4ac4 8564 726f 7779 6368  ada.. J..drowych
+000000d0: 222c 2065 6d61 696c 203d 2022 6f66 6669  ", email = "offi
+000000e0: 6365 4069 6465 612e 6564 752e 706c 227d  ce@idea.edu.pl"}
+000000f0: 2c0d 0a5d 0d0a 7265 6164 6d65 203d 2022  ,..]..readme = "
+00000100: 5245 4144 4d45 2e6d 6422 0d0a 6c69 6365  README.md"..lice
+00000110: 6e73 6520 3d20 7b66 696c 6520 3d20 224c  nse = {file = "L
+00000120: 4943 454e 5345 2e74 7874 227d 0d0a 636c  ICENSE.txt"}..cl
+00000130: 6173 7369 6669 6572 7320 3d20 5b0d 0a20  assifiers = [.. 
+00000140: 2020 2245 6e76 6972 6f6e 6d65 6e74 203a    "Environment :
+00000150: 3a20 436f 6e73 6f6c 6522 2c0d 0a20 2020  : Console",..   
+00000160: 2249 6e74 656e 6465 6420 4175 6469 656e  "Intended Audien
+00000170: 6365 203a 3a20 5363 6965 6e63 652f 5265  ce :: Science/Re
+00000180: 7365 6172 6368 222c 0d0a 2020 2022 4c69  search",..   "Li
+00000190: 6365 6e73 6520 3a3a 204f 5349 2041 7070  cense :: OSI App
+000001a0: 726f 7665 6420 3a3a 2047 4e55 2041 6666  roved :: GNU Aff
+000001b0: 6572 6f20 4765 6e65 7261 6c20 5075 626c  ero General Publ
+000001c0: 6963 204c 6963 656e 7365 2076 3320 6f72  ic License v3 or
+000001d0: 206c 6174 6572 2028 4147 504c 7633 2b29   later (AGPLv3+)
+000001e0: 222c 0d0a 2020 2022 4e61 7475 7261 6c20  ",..   "Natural 
+000001f0: 4c61 6e67 7561 6765 203a 3a20 456e 676c  Language :: Engl
+00000200: 6973 6822 2c0d 0a20 2020 224f 7065 7261  ish",..   "Opera
+00000210: 7469 6e67 2053 7973 7465 6d20 3a3a 204f  ting System :: O
+00000220: 5320 496e 6465 7065 6e64 656e 7422 2c0d  S Independent",.
+00000230: 0a20 2020 2250 726f 6772 616d 6d69 6e67  .   "Programming
+00000240: 204c 616e 6775 6167 6520 3a3a 2050 7974   Language :: Pyt
+00000250: 686f 6e20 3a3a 2033 2e31 3122 2c0d 0a20  hon :: 3.11",.. 
+00000260: 2020 2254 6f70 6963 203a 3a20 5363 6965    "Topic :: Scie
+00000270: 6e74 6966 6963 2f45 6e67 696e 6565 7269  ntific/Engineeri
+00000280: 6e67 222c 0d0a 5d0d 0a0d 0a64 6570 656e  ng",..]....depen
+00000290: 6465 6e63 6965 7320 3d20 5b0d 0a20 2020  dencies = [..   
+000002a0: 2022 6e75 6d70 797e 3d31 2e32 342e 3222   "numpy~=1.24.2"
+000002b0: 2c0d 0a20 2020 2022 7061 6e64 6173 3d3d  ,..    "pandas==
+000002c0: 322e 302e 3122 2c0d 0a20 2020 2022 6e65  2.0.1",..    "ne
+000002d0: 7477 6f72 6b78 7e3d 332e 3022 2c0d 0a20  tworkx~=3.0",.. 
+000002e0: 2020 2022 7365 7475 7074 6f6f 6c73 3d3d     "setuptools==
+000002f0: 3637 2e38 2e30 222c 0d0a 2020 2020 226d  67.8.0",..    "m
+00000300: 6174 706c 6f74 6c69 627e 3d33 2e37 2e31  atplotlib~=3.7.1
+00000310: 222c 0d0a 2020 2020 226f 7065 6e70 7978  ",..    "openpyx
+00000320: 6c3d 3d33 2e31 2e32 222c 0d0a 2020 2020  l==3.1.2",..    
+00000330: 2267 7572 6f62 6970 797e 3d31 302e 302e  "gurobipy~=10.0.
+00000340: 3122 2c0d 0a20 2020 2022 6269 6469 6374  1",..    "bidict
+00000350: 7e3d 302e 3232 2e31 222c 0d0a 2020 2020  ~=0.22.1",..    
+00000360: 2273 6369 7079 7e3d 312e 3131 2e31 222c  "scipy~=1.11.1",
+00000370: 0d0a 2020 2020 2263 6c69 636b 7e3d 382e  ..    "click~=8.
+00000380: 312e 3622 2c0d 0a20 2020 2022 7361 6e69  1.6",..    "sani
+00000390: 7469 7a65 2d66 696c 656e 616d 657e 3d31  tize-filename~=1
+000003a0: 2e32 2e30 222c 0d0a 2020 2020 2258 6c73  .2.0",..    "Xls
+000003b0: 7857 7269 7465 727e 3d33 2e31 2e32 222c  xWriter~=3.1.2",
+000003c0: 0d0a 2020 2020 226c 696e 6f70 797e 3d30  ..    "linopy~=0
+000003d0: 2e33 2e33 222c 0d0a 2020 2020 2278 6172  .3.3",..    "xar
+000003e0: 7261 797e 3d32 3032 332e 3132 2e30 222c  ray~=2023.12.0",
+000003f0: 0d0a 5d0d 0a0d 0a0d 0a5b 7072 6f6a 6563  ..]......[projec
+00000400: 742e 6f70 7469 6f6e 616c 2d64 6570 656e  t.optional-depen
+00000410: 6465 6e63 6965 735d 0d0a 6465 7620 3d20  dencies]..dev = 
+00000420: 5b0d 0a20 2020 2022 666c 616b 6538 3d3d  [..    "flake8==
+00000430: 372e 302e 3022 2c0d 0a20 2020 2022 626c  7.0.0",..    "bl
+00000440: 6163 6b3d 3d32 342e 322e 3022 2c0d 0a20  ack==24.2.0",.. 
+00000450: 2020 2022 7072 652d 636f 6d6d 6974 222c     "pre-commit",
+00000460: 0d0a 2020 2020 2270 7974 6573 743d 3d37  ..    "pytest==7
+00000470: 2e34 2e34 222c 0d0a 2020 2020 2270 7974  .4.4",..    "pyt
+00000480: 6573 742d 636f 767e 3d34 2e30 2e30 222c  est-cov~=4.0.0",
+00000490: 0d0a 2020 2020 2270 7974 6573 742d 6d6f  ..    "pytest-mo
+000004a0: 636b 7e3d 332e 3131 2e31 222c 0d0a 2020  ck~=3.11.1",..  
+000004b0: 2020 2270 7974 6573 742d 6c61 7a79 2d66    "pytest-lazy-f
+000004c0: 6978 7475 7265 7e3d 302e 362e 3322 2c0d  ixture~=0.6.3",.
+000004d0: 0a20 2020 2022 7079 7465 7374 2d78 6469  .    "pytest-xdi
+000004e0: 7374 7e3d 332e 352e 3022 2c0d 0a20 2020  st~=3.5.0",..   
+000004f0: 2022 7079 6c61 6d61 5b72 6164 6f6e 2c6d   "pylama[radon,m
+00000500: 7970 792c 746f 6d6c 5d22 2c0d 0a20 2020  ypy,toml]",..   
+00000510: 2022 746f 7822 0d0a 5d0d 0a67 7572 6f62   "tox"..]..gurob
+00000520: 6920 3d20 5b0d 0a20 2020 2022 6775 726f  i = [..    "guro
+00000530: 6269 7079 7e3d 3130 2e30 2e31 222c 0d0a  bipy~=10.0.1",..
+00000540: 5d0d 0a68 6967 6873 203d 205b 0d0a 2020  ]..highs = [..  
+00000550: 2020 2268 6967 6873 7079 7e3d 312e 352e    "highspy~=1.5.
+00000560: 3322 2c0d 0a5d 0d0a 0d0a 5b70 726f 6a65  3",..]....[proje
+00000570: 6374 2e73 6372 6970 7473 5d0d 0a70 797a  ct.scripts]..pyz
+00000580: 6566 6972 203d 2022 7079 7a65 6669 722e  efir = "pyzefir.
+00000590: 636c 692e 7275 6e6e 6572 3a63 6c69 5f72  cli.runner:cli_r
+000005a0: 756e 220d 0a73 7472 7563 7475 7265 2d63  un"..structure-c
+000005b0: 7265 6174 6f72 203d 2022 7079 7a65 6669  reator = "pyzefi
+000005c0: 722e 7374 7275 6374 7572 655f 6372 6561  r.structure_crea
+000005d0: 746f 722e 636c 692e 636c 695f 7772 6170  tor.cli.cli_wrap
+000005e0: 7065 723a 7275 6e5f 7374 7275 6374 7572  per:run_structur
+000005f0: 655f 6372 6561 746f 725f 636c 6922 0d0a  e_creator_cli"..
+00000600: 0d0a 5b74 6f6f 6c2e 7365 7475 7074 6f6f  ..[tool.setuptoo
+00000610: 6c73 2e64 796e 616d 6963 5d0d 0a76 6572  ls.dynamic]..ver
+00000620: 7369 6f6e 203d 207b 6174 7472 203d 2022  sion = {attr = "
+00000630: 7079 7a65 6669 722e 5f5f 7665 7273 696f  pyzefir.__versio
+00000640: 6e5f 5f22 7d0d 0a0d 0a5b 746f 6f6c 2e73  n__"}....[tool.s
+00000650: 6574 7570 746f 6f6c 732e 7061 636b 6167  etuptools.packag
+00000660: 6573 2e66 696e 645d 0d0a 696e 636c 7564  es.find]..includ
+00000670: 6520 3d20 5b22 7079 7a65 6669 722a 225d  e = ["pyzefir*"]
+00000680: 0d0a 6578 636c 7564 6520 3d20 5b22 646f  ..exclude = ["do
+00000690: 6373 2a22 2c20 2274 6573 7473 2a22 5d0d  cs*", "tests*"].
+000006a0: 0a0d 0a5b 746f 6f6c 2e6d 7970 795d 0d0a  ...[tool.mypy]..
+000006b0: 6967 6e6f 7265 5f6d 6973 7369 6e67 5f69  ignore_missing_i
+000006c0: 6d70 6f72 7473 203d 2074 7275 650d 0a64  mports = true..d
+000006d0: 6973 616c 6c6f 775f 756e 7479 7065 645f  isallow_untyped_
+000006e0: 6465 6673 203d 2074 7275 650d 0a64 6973  defs = true..dis
+000006f0: 616c 6c6f 775f 696e 636f 6d70 6c65 7465  allow_incomplete
+00000700: 5f64 6566 7320 3d20 7472 7565 0d0a 6368  _defs = true..ch
+00000710: 6563 6b5f 756e 7479 7065 645f 6465 6673  eck_untyped_defs
+00000720: 203d 2074 7275 650d 0a64 6973 616c 6c6f   = true..disallo
+00000730: 775f 756e 7479 7065 645f 6465 636f 7261  w_untyped_decora
+00000740: 746f 7273 203d 2066 616c 7365 0d0a 0d0a  tors = false....
+00000750: 5b74 6f6f 6c2e 636f 7665 7261 6765 2e72  [tool.coverage.r
+00000760: 6570 6f72 745d 0d0a 6578 636c 7564 655f  eport]..exclude_
+00000770: 6c69 6e65 7320 3d20 5b0d 0a09 2269 6620  lines = [..."if 
+00000780: 5f5f 6e61 6d65 5f5f 203d 3d20 2e5f 5f6d  __name__ == .__m
+00000790: 6169 6e5f 5f2e 3a22 2c0d 0a09 2272 6169  ain__.:",..."rai
+000007a0: 7365 2041 7373 6572 7469 6f6e 4572 726f  se AssertionErro
+000007b0: 7222 2c0d 0a09 2269 6620 5459 5045 5f43  r",..."if TYPE_C
+000007c0: 4845 434b 494e 473a 222c 0d0a 0922 7261  HECKING:",..."ra
+000007d0: 6973 6520 4e6f 7449 6d70 6c65 6d65 6e74  ise NotImplement
+000007e0: 6564 4572 726f 7222 2c0d 0a20 2020 5d0d  edError",..   ].
+000007f0: 0a6f 6d69 7420 3d20 5b0d 0a20 2020 2270  .omit = [..   "p
+00000800: 797a 6566 6972 2f67 7261 7068 2f2a 2a22  yzefir/graph/**"
+00000810: 2c0d 0a5d 0d0a 0d0a 5b74 6f6f 6c2e 7079  ,..]....[tool.py
+00000820: 6c61 6d61 2e6c 696e 7465 722e 7079 636f  lama.linter.pyco
+00000830: 6465 7374 796c 655d 0d0a 6d61 785f 6c69  destyle]..max_li
+00000840: 6e65 5f6c 656e 6774 6820 3d20 3132 300d  ne_length = 120.
+00000850: 0a5b 746f 6f6c 2e70 796c 616d 612e 6c69  .[tool.pylama.li
+00000860: 6e74 6572 2e70 796c 696e 745d 0d0a 6d61  nter.pylint]..ma
+00000870: 785f 6c69 6e65 5f6c 656e 6774 6820 3d20  x_line_length = 
+00000880: 3132 300d 0a5b 746f 6f6c 2e70 796c 616d  120..[tool.pylam
+00000890: 612e 6c69 6e74 6572 2e72 6164 6f6e 5d0d  a.linter.radon].
+000008a0: 0a6e 6f5f 6173 7365 7274 203d 2074 7275  .no_assert = tru
+000008b0: 650d 0a0d 0a5b 746f 6f6c 2e74 6f78 5d0d  e....[tool.tox].
+000008c0: 0a6c 6567 6163 795f 746f 785f 696e 6920  .legacy_tox_ini 
+000008d0: 3d20 2222 220d 0a20 2020 205b 746f 785d  = """..    [tox]
+000008e0: 0d0a 2020 2020 656e 766c 6973 7420 3d20  ..    envlist = 
+000008f0: 7079 3331 310d 0a20 2020 2069 736f 6c61  py311..    isola
+00000900: 7465 645f 6275 696c 6420 3d20 5472 7565  ted_build = True
+00000910: 0d0a 0d0a 2020 2020 5b74 6573 7465 6e76  ....    [testenv
+00000920: 5d0d 0a20 2020 2075 7365 6465 7665 6c6f  ]..    usedevelo
+00000930: 7020 3d20 5472 7565 0d0a 2020 2020 6465  p = True..    de
+00000940: 7073 203d 202e 5b64 6576 2c67 7572 6f62  ps = .[dev,gurob
+00000950: 692c 6869 6768 735d 0d0a 0d0a 2020 2020  i,highs]....    
+00000960: 5b74 6573 7465 6e76 3a75 6e69 745d 0d0a  [testenv:unit]..
+00000970: 2020 2020 636f 6d6d 616e 6473 203d 0d0a      commands =..
+00000980: 2020 2020 2020 2020 2020 2020 7079 7468              pyth
+00000990: 6f6e 202d 6d20 7079 7465 7374 202d 7676  on -m pytest -vv
+000009a0: 7620 2d2d 636f 763d 7079 7a65 6669 7220  v --cov=pyzefir 
+000009b0: 2d2d 6a75 6e69 7478 6d6c 3d72 6570 6f72  --junitxml=repor
+000009c0: 742e 786d 6c20 7465 7374 732f 756e 6974  t.xml tests/unit
+000009d0: 0d0a 0d0a 2020 2020 5b74 6573 7465 6e76  ....    [testenv
+000009e0: 3a66 6173 745f 696e 7465 6772 6174 696f  :fast_integratio
+000009f0: 6e5d 0d0a 2020 2020 636f 6d6d 616e 6473  n]..    commands
+00000a00: 203d 0d0a 2020 2020 2020 2020 2020 2020   =..            
+00000a10: 7079 7468 6f6e 202d 6d20 7079 7465 7374  python -m pytest
+00000a20: 202d 7676 7620 2d6d 2022 6e6f 7420 6c6f   -vvv -m "not lo
+00000a30: 6e67 5f74 6573 7422 2074 6573 7473 2f69  ng_test" tests/i
+00000a40: 6e74 6567 7261 7469 6f6e 0d0a 0d0a 2020  ntegration....  
+00000a50: 2020 5b74 6573 7465 6e76 3a69 6e74 6567    [testenv:integ
+00000a60: 7261 7469 6f6e 5d0d 0a20 2020 2063 6f6d  ration]..    com
+00000a70: 6d61 6e64 7320 3d0d 0a20 2020 2020 2020  mands =..       
+00000a80: 2020 2020 2070 7974 686f 6e20 2d6d 2070       python -m p
+00000a90: 7974 6573 7420 2d76 7676 2074 6573 7473  ytest -vvv tests
+00000aa0: 2f69 6e74 6567 7261 7469 6f6e 0d0a 0d0a  /integration....
+00000ab0: 2020 2020 5b63 6f76 6572 6167 655d 0d0a      [coverage]..
+00000ac0: 2020 2020 786d 6c5f 7265 706f 7274 203d      xml_report =
+00000ad0: 2074 7275 650d 0a20 2020 2068 746d 6c5f   true..    html_
+00000ae0: 7265 706f 7274 203d 2074 7275 650d 0a22  report = true.."
+00000af0: 2222 0d0a 0d0a 5b74 6f6f 6c2e 7079 7465  ""....[tool.pyte
+00000b00: 7374 2e69 6e69 5f6f 7074 696f 6e73 5d0d  st.ini_options].
+00000b10: 0a61 6464 6f70 7473 203d 2022 2d2d 636f  .addopts = "--co
+00000b20: 762d 7265 706f 7274 2074 6572 6d20 2d2d  v-report term --
+00000b30: 636f 762d 7265 706f 7274 2078 6d6c 3a63  cov-report xml:c
+00000b40: 6f76 6572 6167 652e 786d 6c20 2d2d 6e75  overage.xml --nu
+00000b50: 6d70 726f 6365 7373 6573 2031 3022 0d0a  mprocesses 10"..
+00000b60: 6669 6c74 6572 7761 726e 696e 6773 203d  filterwarnings =
+00000b70: 205b 0d0a 2320 2020 2022 6572 726f 7222   [..#    "error"
+00000b80: 2c0d 0a20 2020 2022 6967 6e6f 7265 3a3a  ,..    "ignore::
+00000b90: 7079 7a65 6669 722e 6d6f 6465 6c2e 6e65  pyzefir.model.ne
+00000ba0: 7477 6f72 6b5f 656c 656d 656e 7473 2e65  twork_elements.e
+00000bb0: 6e65 7267 795f 736f 7572 6365 5f74 7970  nergy_source_typ
+00000bc0: 6573 2e67 656e 6572 6174 6f72 5f74 7970  es.generator_typ
+00000bd0: 652e 5375 6d4e 6f74 4571 7561 6c54 6f4f  e.SumNotEqualToO
+00000be0: 6e65 5761 726e 696e 6722 2c0d 0a5d 0d0a  neWarning",..]..
+00000bf0: 0d0a 5b74 6f6f 6c2e 6275 6d70 7665 7273  ..[tool.bumpvers
+00000c00: 696f 6e5d 0d0a 6375 7272 656e 745f 7665  ion]..current_ve
+00000c10: 7273 696f 6e20 3d20 2230 2e34 2e32 3222  rsion = "0.4.22"
+00000c20: 0d0a 636f 6d6d 6974 203d 2074 7275 650d  ..commit = true.
+00000c30: 0a74 6167 203d 2074 7275 650d 0a70 6172  .tag = true..par
+00000c40: 7365 203d 2022 283f 503c 6d61 6a6f 723e  se = "(?P<major>
+00000c50: 5c5c 642b 295c 5c2e 283f 503c 6d69 6e6f  \\d+)\\.(?P<mino
+00000c60: 723e 5c5c 642b 295c 5c2e 283f 503c 7061  r>\\d+)\\.(?P<pa
+00000c70: 7463 683e 5c5c 642b 2928 5c5c 2d28 3f50  tch>\\d+)(\\-(?P
+00000c80: 3c72 656c 6561 7365 3e5b 612d 7a5d 2b29  <release>[a-z]+)
+00000c90: 283f 503c 6275 696c 643e 5c5c 642b 2929  (?P<build>\\d+))
+00000ca0: 3f22 0d0a 7365 7269 616c 697a 6520 3d20  ?"..serialize = 
+00000cb0: 5b0d 0a20 2020 2022 7b6d 616a 6f72 7d2e  [..    "{major}.
+00000cc0: 7b6d 696e 6f72 7d2e 7b70 6174 6368 7d22  {minor}.{patch}"
+00000cd0: 2c0d 0a20 2020 2027 7b6d 616a 6f72 7d2e  ,..    '{major}.
+00000ce0: 7b6d 696e 6f72 7d2e 7b70 6174 6368 7d2d  {minor}.{patch}-
+00000cf0: 7b72 656c 6561 7365 7d7b 6275 696c 647d  {release}{build}
+00000d00: 272c 0d0a 5d0d 0a0d 0a5b 746f 6f6c 2e62  ',..]....[tool.b
+00000d10: 756d 7076 6572 7369 6f6e 2e70 6172 742e  umpversion.part.
+00000d20: 7265 6c65 6173 655d 0d0a 7661 6c75 6573  release]..values
+00000d30: 203d 205b 2264 6576 222c 2022 7263 222c   = ["dev", "rc",
+00000d40: 2022 6669 6e61 6c22 5d0d 0a66 6972 7374   "final"]..first
+00000d50: 5f76 616c 7565 203d 2022 6465 7622 0d0a  _value = "dev"..
+00000d60: 6f70 7469 6f6e 616c 5f76 616c 7565 203d  optional_value =
+00000d70: 2022 6669 6e61 6c22 0d0a 0d0a 5b74 6f6f   "final"....[too
+00000d80: 6c2e 6275 6d70 7665 7273 696f 6e2e 7061  l.bumpversion.pa
+00000d90: 7274 2e62 7569 6c64 5d0d 0a66 6972 7374  rt.build]..first
+00000da0: 5f76 616c 7565 203d 2031 0d0a 0d0a 0d0a  _value = 1......
+00000db0: 5b5b 746f 6f6c 2e62 756d 7076 6572 7369  [[tool.bumpversi
+00000dc0: 6f6e 2e66 696c 6573 5d5d 0d0a 6669 6c65  on.files]]..file
+00000dd0: 6e61 6d65 203d 2022 7079 7a65 6669 722f  name = "pyzefir/
+00000de0: 5f5f 696e 6974 5f5f 2e70 7922 0d0a       __init__.py"..
```

### Comparing `pyzefir-0.4.1/pyzefir/__init__.py` & `pyzefir-0.4.22/pyzefir/__init__.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,22 +1,22 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-__version__ = "0.4.1"
-
-import os
-from pathlib import Path
-
-ROOT_DIR = Path(os.path.abspath(__file__))
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+__version__ = "0.4.22"
+
+import os
+from pathlib import Path
+
+ROOT_DIR = Path(os.path.abspath(__file__))
```

### Comparing `pyzefir-0.4.1/pyzefir/cli/__init__.py` & `pyzefir-0.4.22/pyzefir/optimization/linopy/__init__.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,15 +1,15 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+# PyZefir
+# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
```

### Comparing `pyzefir-0.4.1/pyzefir/cli/__main__.py` & `pyzefir-0.4.22/pyzefir/cli/__main__.py`

 * *Ordering differences only*

 * *Files 15% similar despite different names*

```diff
@@ -1,21 +1,21 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-
-from pyzefir.cli.runner import cli_run
-
-if __name__ == "__main__":
-    cli_run()
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+
+from pyzefir.cli.runner import cli_run
+
+if __name__ == "__main__":
+    cli_run()
```

### Comparing `pyzefir-0.4.1/pyzefir/cli/logger.py` & `pyzefir-0.4.22/pyzefir/cli/logger.py`

 * *Ordering differences only*

 * *Files 20% similar despite different names*

```diff
@@ -1,79 +1,79 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-import logging
-import sys
-from pathlib import Path
-from typing import Final
-
-LOG_FORMAT: Final[str] = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
-DEFAULT_LOG_LEVEL: Final[int] = logging.INFO
-
-LOG_LEVEL_MAPPING: Final[dict[str, int]] = {
-    "debug": logging.DEBUG,
-    "info": logging.INFO,
-    "warning": logging.WARNING,
-    "error": logging.ERROR,
-    "critical": logging.CRITICAL,
-}
-
-
-def get_root_logger() -> logging.Logger:
-    root_module_name = __name__.split(".")[0]
-    return logging.getLogger(root_module_name)
-
-
-def setup_logging(
-    name: str | None = None,
-    log_file_path: Path | None = None,
-    level: int = DEFAULT_LOG_LEVEL,
-) -> None:
-    """Logger configuration for cli runner."""
-    root_logger = logging.getLogger(name) if name is not None else get_root_logger()
-    root_logger.setLevel(level)
-    setup_console_logging(root_logger, level)
-
-    if log_file_path is not None:
-        setup_file_logging(root_logger, log_file_path, level)
-
-
-def setup_file_logging(
-    logger: logging.Logger, log_file_path: Path, level: int = DEFAULT_LOG_LEVEL
-) -> None:
-    file_handler = logging.FileHandler(log_file_path)
-    file_handler.setLevel(level)
-    formatter = logging.Formatter(LOG_FORMAT)
-    file_handler.setFormatter(formatter)
-    logger.addHandler(file_handler)
-
-
-def setup_console_logging(
-    logger: logging.Logger, level: int = DEFAULT_LOG_LEVEL
-) -> None:
-    console_handler = logging.StreamHandler(sys.stdout)
-    console_handler.setLevel(level)
-    formatter = logging.Formatter(LOG_FORMAT)
-    console_handler.setFormatter(formatter)
-    logger.addHandler(console_handler)
-
-
-def tear_down_logger(name: str | None) -> None:
-    """Shut down logger to release log file handler and close the process."""
-    logger = logging.getLogger(name) if name is not None else get_root_logger()
-    handlers = logger.handlers
-    for handler in handlers:
-        logger.removeHandler(handler)
-        handler.close()
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+import logging
+import sys
+from pathlib import Path
+from typing import Final
+
+LOG_FORMAT: Final[str] = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
+DEFAULT_LOG_LEVEL: Final[int] = logging.INFO
+
+LOG_LEVEL_MAPPING: Final[dict[str, int]] = {
+    "debug": logging.DEBUG,
+    "info": logging.INFO,
+    "warning": logging.WARNING,
+    "error": logging.ERROR,
+    "critical": logging.CRITICAL,
+}
+
+
+def get_root_logger() -> logging.Logger:
+    root_module_name = __name__.split(".")[0]
+    return logging.getLogger(root_module_name)
+
+
+def setup_logging(
+    name: str | None = None,
+    log_file_path: Path | None = None,
+    level: int = DEFAULT_LOG_LEVEL,
+) -> None:
+    """Logger configuration for cli runner."""
+    root_logger = logging.getLogger(name) if name is not None else get_root_logger()
+    root_logger.setLevel(level)
+    setup_console_logging(root_logger, level)
+
+    if log_file_path is not None:
+        setup_file_logging(root_logger, log_file_path, level)
+
+
+def setup_file_logging(
+    logger: logging.Logger, log_file_path: Path, level: int = DEFAULT_LOG_LEVEL
+) -> None:
+    file_handler = logging.FileHandler(log_file_path)
+    file_handler.setLevel(level)
+    formatter = logging.Formatter(LOG_FORMAT)
+    file_handler.setFormatter(formatter)
+    logger.addHandler(file_handler)
+
+
+def setup_console_logging(
+    logger: logging.Logger, level: int = DEFAULT_LOG_LEVEL
+) -> None:
+    console_handler = logging.StreamHandler(sys.stdout)
+    console_handler.setLevel(level)
+    formatter = logging.Formatter(LOG_FORMAT)
+    console_handler.setFormatter(formatter)
+    logger.addHandler(console_handler)
+
+
+def tear_down_logger(name: str | None) -> None:
+    """Shut down logger to release log file handler and close the process."""
+    logger = logging.getLogger(name) if name is not None else get_root_logger()
+    handlers = logger.handlers
+    for handler in handlers:
+        logger.removeHandler(handler)
+        handler.close()
```

### Comparing `pyzefir-0.4.1/pyzefir/cli/runner.py` & `pyzefir-0.4.22/pyzefir/cli/runner.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,168 +1,171 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-import logging
-from pathlib import Path
-
-import click
-
-from pyzefir.cli.logger import setup_logging, tear_down_logger
-from pyzefir.model.exception_formatter import NetworkExceptionFormatter
-from pyzefir.model.network import Network
-from pyzefir.model.network_validator import NetworkValidator
-from pyzefir.optimization.exportable_results import ExportableResults
-from pyzefir.optimization.input_data import OptimizationInputData
-from pyzefir.optimization.linopy.model import LinopyOptimizationModel
-from pyzefir.optimization.opt_config import OptConfig
-from pyzefir.optimization.results import Results
-from pyzefir.parser.csv_parser import CsvParser
-from pyzefir.parser.network_creator import NetworkCreator
-from pyzefir.postprocessing.results_exporters import CsvExporter, XlsxExporter
-from pyzefir.postprocessing.results_handler import ResultsHandler
-from pyzefir.structure_creator.cli.cli_wrapper import create_structure
-from pyzefir.utils.config_parser import ConfigLoader
-from pyzefir.utils.converters.xlsx_to_csv_converter import ExcelToCsvConverter
-from pyzefir.utils.path_manager import CsvPathManager
-
-
-class CliRunner:
-    def __init__(self, config_path: Path) -> None:
-        self.config_params = ConfigLoader(config_path).load()
-        self._logger = logging.getLogger(__name__)
-
-    def run(self) -> None:
-        try:
-            self._run()
-        except Exception as exc:
-            if self.config_params.format_exceptions:
-                NetworkExceptionFormatter(exc).format(self._logger)
-                exit(1)
-            raise
-
-    def _run(self) -> None:
-        setup_logging(
-            log_file_path=self.config_params.output_path / "cli.log",
-            level=self.config_params.log_level,
-        )
-        self._logger.info("Starting CLI Runner...")
-        self._structure_create()
-        self._convert_input_data_to_csv()
-        network = self._create_network_object()
-        opt_config = self._create_opt_config(network)
-        results = self._run_optimization(network, opt_config)
-        self._run_postprocessing(results.to_exportable())
-        tear_down_logger(self._logger.name)
-
-    def _structure_create(self) -> None:
-        if (
-            self.config_params.n_hours is not None
-            and self.config_params.n_years is not None
-        ):
-            self._logger.info("Triggered structure creator to run ... ")
-            create_structure(
-                input_path=self.config_params.structure_creator_input_path,
-                output_path=self.config_params.input_path,
-                scenario_name=self.config_params.scenario,
-                n_hours=self.config_params.n_hours,
-                n_years=self.config_params.n_years,
-            )
-
-    def _convert_input_data_to_csv(self) -> None:
-        if (
-            self.config_params.input_format == "xlsx"
-            and self.config_params.csv_dump_path is not None
-        ):
-            self._logger.info(
-                "Converting xlsx input files from %s to csv files, result will be saved "
-                "to %s...",
-                self.config_params.input_path,
-                self.config_params.csv_dump_path,
-            )
-            ExcelToCsvConverter(
-                input_files_path=self.config_params.input_path,
-                output_files_path=self.config_params.csv_dump_path,
-                scenario_path=self.config_params.input_path
-                / "scenarios"
-                / f"{self.config_params.scenario}.xlsx",
-            ).convert()
-
-    def _create_network_object(self) -> Network:
-        self._logger.info(
-            "Loading csv data from %s...", self.config_params.csv_dump_path
-        )
-        input_csv_path = (
-            self.config_params.csv_dump_path or self.config_params.input_path
-        )
-        loaded_csv_data = CsvParser(
-            path_manager=CsvPathManager(
-                dir_path=input_csv_path,
-                scenario_name=self.config_params.scenario,
-            )
-        ).load_dfs()
-        config_dict = self.config_params.network_config
-        network = NetworkCreator.create(loaded_csv_data, config_dict)
-        NetworkValidator(network).validate()
-
-        return network
-
-    def _create_opt_config(self, network: Network) -> OptConfig:
-        return OptConfig(
-            hours=network.constants.n_hours,
-            years=network.constants.n_years,
-            discount_rate=self.config_params.discount_rate,
-            year_sample=self.config_params.year_sample,
-            hour_sample=self.config_params.hour_sample,
-            sol_dump_path=self.config_params.sol_dump_path,
-            opt_logs_dump_path=self.config_params.opt_logs_path,
-            money_scale=self.config_params.money_scale,
-            ens=self.config_params.ens,
-            use_hourly_scale=self.config_params.use_hourly_scale,
-            solver_name=self.config_params.solver,
-        )
-
-    def _run_optimization(self, network: Network, opt_config: OptConfig) -> Results:
-        engine = LinopyOptimizationModel()
-        self._logger.info("Building optimization model...")
-        engine.build(OptimizationInputData(network, opt_config))
-        self._logger.info("Running optimization...")
-        engine.optimize()
-        return engine.results
-
-    def _run_postprocessing(self, results: ExportableResults) -> None:
-        handler = ResultsHandler(CsvExporter())
-        self._logger.info(
-            "Saving *.csv results to %s...",
-            self.config_params.output_path,
-        )
-        handler.export_results(self.config_params.output_path / "csv", results)
-        self._logger.info(
-            "Saving *.xlsx results to %s...", self.config_params.output_path
-        )
-        handler.exporter = XlsxExporter()
-        handler.export_results(self.config_params.output_path / "xlsx", results)
-        self._logger.info("Xlsx results saved.")
-
-
-@click.command()
-@click.option(
-    "-c",
-    "--config",
-    type=click.Path(exists=True),
-    required=True,
-    help="Path to *.ini file.",
-)
-def cli_run(config: str) -> None:
-    CliRunner(Path(config)).run()
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+import logging
+from pathlib import Path
+
+import click
+
+from pyzefir.cli.logger import setup_logging, tear_down_logger
+from pyzefir.model.exception_formatter import NetworkExceptionFormatter
+from pyzefir.model.network import Network
+from pyzefir.model.network_validator import NetworkValidator
+from pyzefir.optimization.exportable_results import ExportableResults
+from pyzefir.optimization.input_data import OptimizationInputData
+from pyzefir.optimization.linopy.model import LinopyOptimizationModel
+from pyzefir.optimization.opt_config import OptConfig
+from pyzefir.optimization.results import Results
+from pyzefir.parser.csv_parser import CsvParser
+from pyzefir.parser.network_creator import NetworkCreator
+from pyzefir.postprocessing.results_exporters import CsvExporter, XlsxExporter
+from pyzefir.postprocessing.results_handler import ResultsHandler
+from pyzefir.structure_creator.cli.cli_wrapper import create_structure
+from pyzefir.utils.config_parser import ConfigLoader
+from pyzefir.utils.converters.xlsx_to_csv_converter import ExcelToCsvConverter
+from pyzefir.utils.path_manager import CsvPathManager
+
+
+class CliRunner:
+    def __init__(self, config_path: Path) -> None:
+        self.config_params = ConfigLoader(config_path).load()
+        self._logger = logging.getLogger(__name__)
+
+    def run(self) -> None:
+        try:
+            self._run()
+        except Exception as exc:
+            if self.config_params.format_exceptions:
+                NetworkExceptionFormatter(exc).format(self._logger)
+                exit(1)
+            raise
+
+    def _run(self) -> None:
+        setup_logging(
+            log_file_path=self.config_params.output_path / "cli.log",
+            level=self.config_params.log_level,
+        )
+        self._logger.info("Starting CLI Runner...")
+        self._structure_create()
+        self._convert_input_data_to_csv()
+        network = self._create_network_object()
+        opt_config = self._create_opt_config(network)
+        results = self._run_optimization(network, opt_config)
+        self._run_postprocessing(results.to_exportable())
+        tear_down_logger(self._logger.name)
+
+    def _structure_create(self) -> None:
+        if (
+            self.config_params.n_hours is not None
+            and self.config_params.n_years is not None
+        ):
+            self._logger.info("Triggered structure creator to run ... ")
+            create_structure(
+                input_path=self.config_params.structure_creator_input_path,
+                output_path=self.config_params.input_path,
+                scenario_name=self.config_params.scenario,
+                n_hours=self.config_params.n_hours,
+                n_years=self.config_params.n_years,
+            )
+
+    def _convert_input_data_to_csv(self) -> None:
+        if (
+            self.config_params.input_format == "xlsx"
+            and self.config_params.csv_dump_path is not None
+        ):
+            self._logger.info(
+                "Converting xlsx input files from %s to csv files, result will be saved "
+                "to %s...",
+                self.config_params.input_path,
+                self.config_params.csv_dump_path,
+            )
+            ExcelToCsvConverter(
+                input_files_path=self.config_params.input_path,
+                output_files_path=self.config_params.csv_dump_path,
+                scenario_path=self.config_params.input_path
+                / "scenarios"
+                / f"{self.config_params.scenario}.xlsx",
+            ).convert()
+
+    def _create_network_object(self) -> Network:
+        self._logger.info(
+            "Loading csv data from %s...", self.config_params.csv_dump_path
+        )
+        input_csv_path = (
+            self.config_params.csv_dump_path or self.config_params.input_path
+        )
+        loaded_csv_data = CsvParser(
+            path_manager=CsvPathManager(
+                dir_path=input_csv_path,
+                scenario_name=self.config_params.scenario,
+            )
+        ).load_dfs()
+        config_dict = self.config_params.network_config
+        network = NetworkCreator.create(loaded_csv_data, config_dict)
+        NetworkValidator(network).validate()
+
+        return network
+
+    def _create_opt_config(self, network: Network) -> OptConfig:
+        return OptConfig(
+            hours=network.constants.n_hours,
+            years=network.constants.n_years,
+            discount_rate=self.config_params.discount_rate,
+            year_sample=self.config_params.year_sample,
+            hour_sample=self.config_params.hour_sample,
+            sol_dump_path=self.config_params.sol_dump_path,
+            opt_logs_dump_path=self.config_params.opt_logs_path,
+            money_scale=self.config_params.money_scale,
+            ens=network.constants.ens_penalty_cost,
+            use_hourly_scale=self.config_params.use_hourly_scale,
+            solver_name=self.config_params.solver,
+            solver_settings=self.config_params.solver_settings,
+        )
+
+    def _run_optimization(self, network: Network, opt_config: OptConfig) -> Results:
+        engine = LinopyOptimizationModel()
+        self._logger.info("Building optimization model...")
+        engine.build(OptimizationInputData(network, opt_config))
+        self._logger.info("Running optimization...")
+        engine.optimize()
+        return engine.results
+
+    def _run_postprocessing(self, results: ExportableResults) -> None:
+        handler = ResultsHandler(CsvExporter())
+        self._logger.info(
+            "Saving *.csv results to %s...",
+            self.config_params.output_path,
+        )
+        handler.export_results(self.config_params.output_path / "csv", results)
+        self._logger.info("Csv results saved.")
+        if self.config_params.xlsx_results:
+            self._logger.info(
+                "Saving *.xlsx results to %s...", self.config_params.output_path
+            )
+            handler.exporter = XlsxExporter()
+            handler.export_results(self.config_params.output_path / "xlsx", results)
+            self._logger.info("Xlsx results saved.")
+
+
+@click.command()
+@click.option(
+    "-c",
+    "--config",
+    type=click.Path(exists=True),
+    required=True,
+    help="Path to *.ini file.",
+)
+def cli_run(config: str) -> None:
+    CliRunner(Path(config)).run()
```

### Comparing `pyzefir-0.4.1/pyzefir/graph/__init__.py` & `pyzefir-0.4.22/pyzefir/optimization/linopy/constraints_builder/__init__.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,15 +1,15 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+# PyZefir
+# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
```

### Comparing `pyzefir-0.4.1/pyzefir/graph/constants.py` & `pyzefir-0.4.22/pyzefir/graph/constants.py`

 * *Ordering differences only*

 * *Files 18% similar despite different names*

```diff
@@ -1,44 +1,44 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-from dataclasses import dataclass
-
-
-@dataclass(frozen=True)
-class NodeType:
-    BUS: str = "bus"
-    STORAGE: str = "storage"
-    GENERATOR: str = "generator"
-    LOCAL_BALANCING_STACK: str = "local_balancing_stack"
-    AGGREGATED_CONSUMER: str = "aggregated_consumer"
-
-
-@dataclass(frozen=True)
-class NodeConfig:
-    node_shape: str
-    node_size: int
-    fill: bool = True
-
-
-default_color: str = "grey"
-
-node_config: dict[str, NodeConfig] = {
-    NodeType.BUS: NodeConfig(node_shape="s", node_size=4000),
-    NodeType.STORAGE: NodeConfig(node_shape="o", node_size=2000, fill=False),
-    NodeType.GENERATOR: NodeConfig(node_shape="o", node_size=2000),
-    NodeType.LOCAL_BALANCING_STACK: NodeConfig(node_shape="v", node_size=2000),
-    NodeType.AGGREGATED_CONSUMER: NodeConfig(node_shape="^", node_size=2000),
-}
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+from dataclasses import dataclass
+
+
+@dataclass(frozen=True)
+class NodeType:
+    BUS: str = "bus"
+    STORAGE: str = "storage"
+    GENERATOR: str = "generator"
+    LOCAL_BALANCING_STACK: str = "local_balancing_stack"
+    AGGREGATED_CONSUMER: str = "aggregated_consumer"
+
+
+@dataclass(frozen=True)
+class NodeConfig:
+    node_shape: str
+    node_size: int
+    fill: bool = True
+
+
+default_color: str = "grey"
+
+node_config: dict[str, NodeConfig] = {
+    NodeType.BUS: NodeConfig(node_shape="s", node_size=4000),
+    NodeType.STORAGE: NodeConfig(node_shape="o", node_size=2000, fill=False),
+    NodeType.GENERATOR: NodeConfig(node_shape="o", node_size=2000),
+    NodeType.LOCAL_BALANCING_STACK: NodeConfig(node_shape="v", node_size=2000),
+    NodeType.AGGREGATED_CONSUMER: NodeConfig(node_shape="^", node_size=2000),
+}
```

### Comparing `pyzefir-0.4.1/pyzefir/graph/utils.py` & `pyzefir-0.4.22/pyzefir/graph/utils.py`

 * *Ordering differences only*

 * *Files 12% similar despite different names*

```diff
@@ -1,26 +1,26 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-from pyzefir.graph.network_diagram import NetworkGraph, NetworkGraphArtist
-from pyzefir.model.network import Network
-
-
-def draw_network(
-    network: Network, show: bool = True, savefile: str | None = None
-) -> None:
-    network_graph = NetworkGraph(network).build_graph()
-    graph_artist = NetworkGraphArtist(network_graph, network.energy_types)
-    graph_artist.draw_graph(show=show, filename=savefile)
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+from pyzefir.graph.network_diagram import NetworkGraph, NetworkGraphArtist
+from pyzefir.model.network import Network
+
+
+def draw_network(
+    network: Network, show: bool = True, savefile: str | None = None
+) -> None:
+    network_graph = NetworkGraph(network).build_graph()
+    graph_artist = NetworkGraphArtist(network_graph, network.energy_types)
+    graph_artist.draw_graph(show=show, filename=savefile)
```

### Comparing `pyzefir-0.4.1/pyzefir/model/__init__.py` & `pyzefir-0.4.22/pyzefir/optimization/linopy/preprocessing/__init__.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,15 +1,15 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+# PyZefir
+# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
```

### Comparing `pyzefir-0.4.1/pyzefir/model/exception_formatter.py` & `pyzefir-0.4.22/pyzefir/model/exception_formatter.py`

 * *Ordering differences only*

 * *Files 14% similar despite different names*

```diff
@@ -1,45 +1,45 @@
-# PyZefir
-# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-from collections import defaultdict
-from logging import Logger
-
-
-class NetworkExceptionFormatter:
-    def __init__(self, exc: Exception) -> None:
-        self.exc, self.msg = self.sort_exceptions(exc)
-
-    @staticmethod
-    def sort_exceptions(exc: Exception) -> tuple[dict[str, list[Exception]], str]:
-        if not isinstance(exc, ExceptionGroup):
-            return {exc.__class__.__name__: [exc]}, exc.args[0]
-
-        exceptions_dict = defaultdict(list)
-        for e in exc.exceptions:
-            exceptions_dict[e.__class__.__name__].append(e)
-        return dict(exceptions_dict), exc.message
-
-    def format(self, logger: Logger) -> None:
-        logger.error(self.msg)
-        for exc_class, exc_list in self.exc.items():
-            logger.error(f"{exc_class:#^100}")
-            for exc in exc_list:
-                if not isinstance(exc, ExceptionGroup):
-                    logger.error(f"{exc.args[0]}")
-                    continue
-                logger.error(f"{exc.message}")
-                for e_sub in exc.exceptions:
-                    logger.error(f"\t\t{e_sub.args[0]}")
+# PyZefir
+# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+from collections import defaultdict
+from logging import Logger
+
+
+class NetworkExceptionFormatter:
+    def __init__(self, exc: Exception) -> None:
+        self.exc, self.msg = self.sort_exceptions(exc)
+
+    @staticmethod
+    def sort_exceptions(exc: Exception) -> tuple[dict[str, list[Exception]], str]:
+        if not isinstance(exc, ExceptionGroup):
+            return {exc.__class__.__name__: [exc]}, exc.args[0]
+
+        exceptions_dict = defaultdict(list)
+        for e in exc.exceptions:
+            exceptions_dict[e.__class__.__name__].append(e)
+        return dict(exceptions_dict), exc.message
+
+    def format(self, logger: Logger) -> None:
+        logger.error(self.msg)
+        for exc_class, exc_list in self.exc.items():
+            logger.error(f"{exc_class:#^100}")
+            for exc in exc_list:
+                if not isinstance(exc, ExceptionGroup):
+                    logger.error(f"{exc.args[0]}")
+                    continue
+                logger.error(f"{exc.message}")
+                for e_sub in exc.exceptions:
+                    logger.error(f"\t\t{e_sub.args[0]}")
```

### Comparing `pyzefir-0.4.1/pyzefir/model/exceptions.py` & `pyzefir-0.4.22/pyzefir/model/exceptions.py`

 * *Ordering differences only*

 * *Files 18% similar despite different names*

```diff
@@ -1,23 +1,23 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-
-class NetworkValidatorException(Exception):
-    pass
-
-
-class NetworkValidatorExceptionGroup(NetworkValidatorException, ExceptionGroup):
-    pass
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+
+class NetworkValidatorException(Exception):
+    pass
+
+
+class NetworkValidatorExceptionGroup(NetworkValidatorException, ExceptionGroup):
+    pass
```

### Comparing `pyzefir-0.4.1/pyzefir/model/network.py` & `pyzefir-0.4.22/pyzefir/model/network_elements/energy_source_types/generator_type.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,450 +1,457 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-from collections.abc import MutableMapping
-from typing import Generic, Iterator, TypeVar
-
-from pyzefir.model.exceptions import NetworkValidatorException
-from pyzefir.model.network_elements import (
-    DSR,
-    AggregatedConsumer,
-    Bus,
-    CapacityFactor,
-    DemandChunk,
-    DemandProfile,
-    EmissionFee,
-    EnergySourceType,
-    Fuel,
-    Generator,
-    GeneratorType,
-    Line,
-    LocalBalancingStack,
-    NetworkElement,
-    Storage,
-    StorageType,
-    TransmissionFee,
-)
-from pyzefir.model.utils import NetworkConstants
-
-TNetworkDictElement = TypeVar(
-    "TNetworkDictElement", bound=NetworkElement | EnergySourceType | DemandProfile
-)
-
-
-class NetworkElementsDict(MutableMapping, Generic[TNetworkDictElement]):
-    """
-    A dictionary-like collection class for managing network elements.
-    """
-
-    def __init__(
-        self, initial_dict: dict[str, TNetworkDictElement] | None = None
-    ) -> None:
-        """
-        Initializes a new instance of the NetworkElementsDict class.
-
-        Args:
-            initial_dict (dict[str, TNetworkDictElement] | None): Optional initial dictionary to populate
-            the network elements. Defaults to None.
-        """
-        self.elements_dict: dict[str, TNetworkDictElement] = (
-            initial_dict if initial_dict else dict()
-        )
-
-    def __setitem__(self, __k: str, __v: TNetworkDictElement) -> None:
-        """
-        Sets a network element with the specified key and value.
-
-        Raises:
-            NetworkValidatorException: If a network element with the same key already exists.
-
-        Args:
-            __k (str): The key of the network element.
-            __v (TNetworkDictElement): The value of the network element.
-        """
-        if __k in self.elements_dict:
-            raise NetworkValidatorException(
-                f"Network element {type(self.elements_dict[__k]).__name__} with name {__k} has been already added"
-            )
-        self.elements_dict.__setitem__(__k, __v)
-
-    def __getitem__(self, __k: str) -> TNetworkDictElement:
-        """
-        Gets the value of the network element with the specified key.
-
-        Args:
-            __k (str): The key of the network element.
-
-        Returns:
-            TNetworkDictElement: The value of the network element.
-        """
-        return self.elements_dict.__getitem__(__k)
-
-    def __len__(self) -> int:
-        """
-        Returns the number of network elements in the collection.
-
-        Returns:
-            int: The number of network elements.
-        """
-        return self.elements_dict.__len__()
-
-    def __iter__(self) -> Iterator[str]:
-        """
-        Returns an iterator over the keys of the network elements.
-
-        Returns:
-            Iterator[str]: An iterator over the keys.
-        """
-        return self.elements_dict.__iter__()
-
-    def __delitem__(self, __v: str) -> None:
-        """
-        Removes the network element with the specified key.
-
-        Args:
-            __v (str): The key of the network element to remove.
-        """
-        self.elements_dict.__delitem__(__v)
-
-    def __repr__(self) -> str:
-        return repr(self.elements_dict)
-
-    def add_element(self, element: TNetworkDictElement) -> None:
-        """
-        Adds a network element to the collection.
-
-        Args:
-            element (TNetworkDictElement): The network element to add.
-        """
-        self.__setitem__(element.name, element)
-
-
-class Network:
-    """
-    A class representing a network.
-    """
-
-    def __init__(
-        self,
-        network_constants: NetworkConstants,
-        energy_types: list[str],
-        emission_types: list[str] | None = None,
-    ) -> None:
-        """
-        Initializes a new instance of the Network class.
-
-        Args:
-            energy_types (set[str]): Set of energy types associated with the network.
-            emission_types (set[str] | None): Set of emission types associated with the network. Defaults to None.
-        """
-        self._energy_types: list[str] = energy_types
-        self._emission_types: list[str] = (
-            emission_types if emission_types is not None else list()
-        )
-
-        self.buses: NetworkElementsDict[Bus] = NetworkElementsDict()
-        self.generators: NetworkElementsDict[Generator] = NetworkElementsDict()
-        self.storages: NetworkElementsDict[Storage] = NetworkElementsDict()
-        self.lines: NetworkElementsDict[Line] = NetworkElementsDict()
-        self.transmission_fees: NetworkElementsDict[TransmissionFee] = (
-            NetworkElementsDict()
-        )
-        self.emission_fees: NetworkElementsDict[EmissionFee] = NetworkElementsDict()
-        self.local_balancing_stacks: NetworkElementsDict[LocalBalancingStack] = (
-            NetworkElementsDict()
-        )
-        self.aggregated_consumers: NetworkElementsDict[AggregatedConsumer] = (
-            NetworkElementsDict()
-        )
-        self.fuels: NetworkElementsDict[Fuel] = NetworkElementsDict()
-        self.capacity_factors: NetworkElementsDict[CapacityFactor] = (
-            NetworkElementsDict()
-        )
-
-        self.generator_types: NetworkElementsDict[GeneratorType] = NetworkElementsDict()
-        self.storage_types: NetworkElementsDict[StorageType] = NetworkElementsDict()
-        self.demand_profiles: NetworkElementsDict[DemandProfile] = NetworkElementsDict()
-        self.demand_chunks: NetworkElementsDict[DemandChunk] = NetworkElementsDict()
-        self.dsr: NetworkElementsDict[DSR] = NetworkElementsDict()
-
-        self.constants = network_constants
-
-    @property
-    def energy_types(self) -> list[str]:
-        """
-        Gets the set of energy types supported by the network.
-
-        Returns:
-            set[str]: Set of energy types.
-        """
-        return self._energy_types
-
-    @property
-    def emission_types(self) -> list[str]:
-        """
-        Gets the set of emission types supported by the network.
-
-        Returns:
-            set[str]: Set of emission types.
-        """
-        return self._emission_types
-
-    def add_generator_type(self, gen_type: GeneratorType) -> None:
-        """
-        Adds a GeneratorType to the network.
-
-        Raises:
-            NetworkValidatorException: If the gen_type is None or not of type
-            GeneratorType or on validation error.
-
-        Args:
-            gen_type (GeneratorType): The GeneratorType to add.
-        """
-        if not isinstance(gen_type, GeneratorType):
-            raise NetworkValidatorException(
-                f"Incorrect type. Should be GeneratorType, but it is {type(gen_type)} instead"
-            )
-        gen_type.validate(self)
-        self.generator_types[gen_type.name] = gen_type
-
-    def add_storage_type(self, stor_type: StorageType) -> None:
-        """
-        Adds a StorageType to the network.
-
-        Raises:
-            NetworkValidatorException: If the stor_type is None or not of type
-            StorageType or on validation error.
-
-        Args:
-            stor_type (StorageType): The StorageType to add.
-        """
-        if stor_type is None:
-            raise NetworkValidatorException("Energy Source Type cannot be None")
-        if not isinstance(stor_type, StorageType):
-            raise NetworkValidatorException(
-                f"Incorrect type. Should be StorageType, but it is {type(stor_type)} instead"
-            )
-        stor_type.validate(self)
-        self.storage_types[stor_type.name] = stor_type
-
-    def add_demand_profile(self, demand: DemandProfile) -> None:
-        """
-        Adds a DemandProfile to the network.
-
-        Raises:
-            NetworkValidatorException: If the demand is None or not of type
-            DemandProfile or on validation error.
-
-        Args:
-            demand (DemandProfile): The DemandProfile to add.
-        """
-        if demand is None:
-            raise NetworkValidatorException("Demand Profile cannot be None")
-        if not isinstance(demand, DemandProfile):
-            raise NetworkValidatorException(
-                f"Incorrect type. Should be DemandProfile, but it is {type(demand)} instead"
-            )
-        demand.validate(self)
-        self.demand_profiles[demand.name] = demand
-
-    def add_bus(self, bus: Bus) -> None:
-        """
-        Adds a Bus to the network.
-
-        Raises:
-            NetworkValidatorException: If the bus is None or on validation error.
-
-        Args:
-            bus (Bus): The Bus to add.
-        """
-        if bus is None:
-            raise NetworkValidatorException("Bus cannot be None")
-        bus.validate(self)
-        self.buses[bus.name] = bus
-
-    def add_storage(self, storage: Storage) -> None:
-        """
-        Adds a Storage to the network.
-
-        Raises:
-            NetworkValidatorException: If the storage is None or on validation error.
-
-        Args:
-            storage (Storage): The Storage to add.
-
-        """
-        if storage is None:
-            raise NetworkValidatorException("Storage cannot be None")
-        storage.validate(self)
-        self.storages[storage.name] = storage
-        self.buses[storage.bus].attach_storage(storage.name)
-
-    def add_generator(self, gen: Generator) -> None:
-        """
-        Adds a Generator to the network.
-
-        Raises:
-            NetworkValidatorException: If the gen is not an instance of Generator class
-             or on validation error.
-
-        Args:
-            gen (Generator): The Generator to add.
-        """
-        if not isinstance(gen, Generator):
-            raise NetworkValidatorException(
-                f"Generator must be an instance of Generator class, but it is {type(gen)} instead."
-            )
-        gen.validate(self)
-        self.generators[gen.name] = gen
-        for bus_name in gen.buses:
-            self.buses[bus_name].attach_generator(gen.name)
-
-    def add_line(self, line: Line) -> None:
-        """
-        Adds a Line to the network.
-
-        Raises:
-            NetworkValidatorException: If the line is None or on validation error.
-
-        Args:
-            line (Line): The Line to add.
-        """
-        if line is None:
-            raise NetworkValidatorException("Line cannot be None")
-        line.validate(self)
-        self.lines[line.name] = line
-        self.buses[line.fr].attach_from_line(line.name)
-        self.buses[line.to].attach_to_line(line.name)
-
-    def add_transmission_fee(self, transmission_fee: TransmissionFee) -> None:
-        """
-        Adds a TransmissionFee to the network.
-
-        Raises:
-            NetworkValidatorException: If the transmission_fee is None or on validation error.
-
-        Args:
-            transmission_fee (TransmissionFee): The TransmissionFee to add.
-        """
-        if transmission_fee is None:
-            raise NetworkValidatorException("TransmissionFee cannot be None")
-        transmission_fee.validate(self)
-        self.transmission_fees[transmission_fee.name] = transmission_fee
-
-    def add_local_balancing_stack(self, local_bl_st: LocalBalancingStack) -> None:
-        """
-        Adds a LocalBalancingStack to the network.
-
-        Raises:
-            NetworkValidatorException: If the local_bl_st is None or on validation error.
-
-        Args:
-            local_bl_st (LocalBalancingStack): The LocalBalancingStack to add.
-        """
-        if local_bl_st is None:
-            raise NetworkValidatorException("Local Balancing Stack cannot be None")
-        local_bl_st.validate(self)
-        self.local_balancing_stacks[local_bl_st.name] = local_bl_st
-
-    def add_aggregated_consumer(self, aggregated_consumer: AggregatedConsumer) -> None:
-        """
-        Adds an AggregatedConsumer to the network.
-
-        Raises:
-            NetworkValidatorException: If the aggregated_consumer is None or on validation error.
-
-        Args:
-            aggregated_consumer (AggregatedConsumer): The AggregatedConsumer to add.
-        """
-        if aggregated_consumer is None:
-            raise NetworkValidatorException("AggregatedConsumer cannot be None")
-        aggregated_consumer.validate(self)
-        self.aggregated_consumers[aggregated_consumer.name] = aggregated_consumer
-
-    def add_fuel(self, fuel: Fuel) -> None:
-        """
-        Adds a Fuel to the network.
-
-        Raises:
-            NetworkValidatorException: If the fuel is None or on validation error.
-
-        Args:
-        fuel (Fuel): The Fuel to add.
-        """
-        if fuel is None:
-            raise NetworkValidatorException("Fuel cannot be None")
-        fuel.validate(self)
-        self.fuels[fuel.name] = fuel
-
-    def add_capacity_factor(self, capacity_factor: CapacityFactor) -> None:
-        """
-        Adds a CapacityFactor to the network.
-
-        Raises:
-            NetworkValidatorException: If the capacity_factor is None or on validation error.
-
-        Args:
-            capacity_factor (CapacityFactor): The CapacityFactor to add.
-        """
-        if capacity_factor is None:
-            raise NetworkValidatorException("Capacity factor cannot be none")
-        capacity_factor.validate(self)
-        self.capacity_factors[capacity_factor.name] = capacity_factor
-
-    def add_emission_fee(self, emission_fee: EmissionFee) -> None:
-        """
-        Adds a EmissionFee to the network.
-
-        Raises:
-            NetworkValidatorException: If the emission_fee is None or on validation error.
-
-        Args:
-            emission_fee (EmissionFee): The EmissionFee to add.
-        """
-        if emission_fee is None:
-            raise NetworkValidatorException("EmissionFee cannot be None")
-        emission_fee.validate(self)
-        self.emission_fees[emission_fee.name] = emission_fee
-
-    def add_demand_chunk(self, demand_chunk: DemandChunk) -> None:
-        """
-        Adds a DemandChunk to the network.
-
-        Raises:
-            NetworkValidatorException: If the demand_chunk is None or on validation error.
-
-        Args:
-            demand_chunk (DemandChunk): The DemandChunk to add.
-        """
-        if demand_chunk is None:
-            raise NetworkValidatorException("DemandChunk cannot be None")
-        demand_chunk.validate(self)
-        self.demand_chunks[demand_chunk.name] = demand_chunk
-
-    def add_dsr(self, dsr: DSR) -> None:
-        """
-        Adds DSR to the network.
-
-        Raises:
-            NetworkValidatorException:
-
-        Args:
-            dsr (DSR): The DSR to add.
-        """
-        if dsr is None:
-            raise NetworkValidatorException("DSR cannot be None")
-        dsr.validate(self)
-        self.dsr[dsr.name] = dsr
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+from __future__ import annotations
+
+import logging
+import warnings
+from dataclasses import dataclass, field
+from typing import TYPE_CHECKING
+
+import numpy as np
+import pandas as pd
+
+from pyzefir.model.exceptions import (
+    NetworkValidatorException,
+    NetworkValidatorExceptionGroup,
+)
+from pyzefir.model.network_elements import EnergySourceType
+from pyzefir.model.utils import validate_series
+from pyzefir.utils.functions import is_flow_int
+
+_logger = logging.getLogger(__name__)
+
+
+if TYPE_CHECKING:
+    from pyzefir.model.network import Network
+
+
+class SumNotEqualToOneWarning(Warning):
+    pass
+
+
+class GeneratorTypeValidatorExceptionGroup(NetworkValidatorExceptionGroup):
+    pass
+
+
+@dataclass(kw_only=True)
+class GeneratorType(EnergySourceType):
+    """
+    A class that represents the GeneratorType in the network structure which stores parameters
+    defined for a given type of generators
+    """
+
+    efficiency: pd.DataFrame
+    """
+    Efficiency defined for every energy type that is produced by the generator
+    """
+    energy_types: set[str]
+    """
+    Names of energy types produced by the GeneratorType
+    """
+    emission_reduction: dict[str, float]
+    """
+    Reduction of emission for specific emission type applied by the generator.
+    """
+    power_utilization: pd.Series
+    """
+    Determines the percentage of the installed generator's rated power that
+    can be used
+    """
+    conversion_rate: dict[str, pd.Series] = field(default_factory=dict)
+    """
+    Conversion rate describes amount of produced energy from 1 unit of given energy type
+    """
+    fuel: str | None = field(default=None)
+    """
+    Name of the fuel that can be used by the generator (for dispatchable generators)
+    """
+    capacity_factor: str | None = field(default=None)
+    """
+    Name of the generator capacity factor (for non-dispatchable generators)
+    """
+    ramp: float = np.nan
+    """Percentage difference between generations
+    in relation to the installed capacity subsequent hours"""
+    energy_curtailment_cost: dict[str, pd.Series] = field(default_factory=dict)
+    """ energy curtailment for generator """
+    generation_compensation: pd.Series | None = None
+    """generation compensation parameters used to decrease objective
+    pd.DataFrame with hours (rows) and years (columns)"""
+
+    def validate(self, network: Network) -> None:
+        """
+        Validation procedure checking:
+        - Validates whether at least one of capacity factor or fuel is not None
+
+        Method validate runs following validate methods:
+        - _validate_fuels
+        - _validate_capacity_factor
+        - _validate_efficiency
+        - _validate_emission_reduction
+        - _validate_conversion_rate
+
+        Args:
+            network (Network): network to which self is to be added
+
+        Returns:
+            None
+
+        Raises:
+            NetworkValidatorExceptionGroup: If exception_list contains exception.
+        """
+        _logger.debug("Validating generator type object: %s...", self.name)
+        exception_list: list[NetworkValidatorException] = []
+        self._validate_energy_source_type_base(network, exception_list)
+        if self.capacity_factor is not None and self.fuel is not None:
+            exception_list.append(
+                NetworkValidatorException(
+                    "Generator type can have either capacity "
+                    "factor or fuel at the same time"
+                )
+            )
+
+        for name, gen_type in network.generator_types.items():
+            curtailment_cost = gen_type.energy_curtailment_cost
+            if len(curtailment_cost):
+                self.validate_curtailment_cost(
+                    network, name, curtailment_cost, exception_list
+                )
+        self._validate_fuels(exception_list, network)
+        self._validate_capacity_factor(exception_list, network)
+        self._validate_efficiency(exception_list, network)
+        self._validate_emission_reduction(exception_list, network)
+        self._validate_conversion_rate(exception_list, network)
+        self._validate_power_utilization(network, exception_list)
+        self._validate_generation_compensation(exception_list)
+
+        if not isinstance(self.ramp, float | int):
+            exception_list.append(
+                NetworkValidatorException("Ramp value must be float or empty.")
+            )
+
+        elif not np.isnan(self.ramp) and not 0 < self.ramp < 1:
+            exception_list.append(
+                NetworkValidatorException(
+                    f"Ramp value must be "
+                    f"greater than 0 and less than 1, but it is {self.ramp}"
+                )
+            )
+
+        if exception_list:
+            _logger.debug("Got error validating network: %s", exception_list)
+            raise GeneratorTypeValidatorExceptionGroup(
+                f"While adding GeneratorType {self.name} following "
+                f"errors occurred: ",
+                exception_list,
+            )
+        _logger.debug("Generator type %s validation: Done", self.name)
+
+    @property
+    def inbound_energy_type(self) -> set[str]:
+        """
+        Gets set of energy types needed by the generator
+        Returns:
+            set[str]: Set of energy types.
+        """
+        return set(self.conversion_rate) if self.conversion_rate else set()
+
+    def _validate_generation_compensation(
+        self, exception_list: list[NetworkValidatorException]
+    ) -> None:
+        """
+        Validation procedure checking:
+        - Validates generation compensation type
+        - Validates generation compensation data type
+
+        Args:
+            exception_list (NetworkValidatorException) - list of raised exceptions.
+
+        Returns:
+            None
+        """
+        if not isinstance(self.generation_compensation, pd.Series | None):
+            exception_list.append(
+                NetworkValidatorException(
+                    f"Generation compensation of generator type {self.name} "
+                    "must be type of pandas Series or None."
+                )
+            )
+        elif (
+            self.generation_compensation is not None
+            and not pd.api.types.is_numeric_dtype(self.generation_compensation)
+        ):
+            exception_list.append(
+                NetworkValidatorException(
+                    f"Generation compensation of generator type {self.name} "
+                    f"must contain float or int values only."
+                )
+            )
+
+    def _validate_fuels(
+        self, exception_list: list[NetworkValidatorException], network: Network
+    ) -> None:
+        """
+        Validation procedure checking:
+        - Validates fuel type
+        - Fuel reference validation
+
+        Args:
+            exception_list (NetworkValidatorException) - list of raised exceptions.
+            network (Network): network to which self is to be added.
+
+        Returns:
+            None
+        """
+        if self.fuel is not None and not isinstance(self.fuel, str):
+            exception_list.append(
+                NetworkValidatorException(
+                    "None or str type for fuel expected but type:"
+                    f" {type(self.fuel)} given"
+                )
+            )
+        if self.fuel is not None and self.fuel not in network.fuels:
+            exception_list.append(
+                NetworkValidatorException(
+                    f"Fuel {self.fuel} has not been added to the network"
+                )
+            )
+        _logger.debug("Validate fuels: OK")
+
+    def _validate_capacity_factor(
+        self, exception_list: list[NetworkValidatorException], network: Network
+    ) -> None:
+        """
+        Validation procedure checking:
+        - Validates if capacity_factor not string type or None
+        - Validates if capacity_factor is not None and not exists in network.capacity_factors
+
+        Args:
+            exception_list (NetworkValidatorException) - list of raised exceptions.
+            network (Network): network to which self is to be added.
+
+        Returns:
+            None
+        """
+        if (
+            not isinstance(self.capacity_factor, str)
+            and self.capacity_factor is not None
+        ):
+            exception_list.append(
+                NetworkValidatorException(
+                    f"None or str type for capacity factor expected but type: "
+                    f"{type(self.capacity_factor)} given"
+                )
+            )
+        if (
+            self.capacity_factor is not None
+            and self.capacity_factor not in network.capacity_factors
+        ):
+            exception_list.append(
+                NetworkValidatorException(
+                    f"Capacity factor "
+                    f"'{self.capacity_factor}' has not been added to the network"
+                )
+            )
+        _logger.debug("Validate capacity factor: OK")
+
+    def _validate_conversion_rate(
+        self,
+        exception_list: list[NetworkValidatorException],
+        network: Network,
+    ) -> None:
+        """
+        Validation procedure checking:
+        - Validates whether conversion rate is not None and conversion rate energy types exist
+        in network.energy_types
+
+        Args:
+            exception_list (NetworkValidatorException) - list of raised exceptions.
+            network (Network): network to which self is to be added.
+
+        Returns:
+            None
+        """
+        if self.conversion_rate is None:
+            exception_list.append(
+                NetworkValidatorException("Conversion rate cannot be None.")
+            )
+            return
+        if not set(self.conversion_rate.keys()).issubset(network.energy_types):
+            exception_list.append(
+                NetworkValidatorException(
+                    f"Conversion rate energy types do not exist "
+                    f"in network energy types: {sorted(network.energy_types)}"
+                )
+            )
+        _logger.debug("Validate conversion rate: OK")
+
+    def _validate_efficiency(
+        self, exception_list: list[NetworkValidatorException], network: Network
+    ) -> None:
+        """
+        Validation procedure checking:
+        - Validates if efficiency of generator type is not None
+        - Validates whether efficiency energy types exist in network.energy_types
+        - Validates if sum per each year is >= 1.0
+
+        Args:
+            exception_list (NetworkValidatorException) - list of raised exceptions.
+            network (Network): network to which self is to be added.
+
+        Returns:
+            None
+        """
+        if self.efficiency is None:
+            exception_list.append(
+                NetworkValidatorException("Efficiency cannot be None.")
+            )
+            return
+        if not set(self.efficiency.columns.to_list()).issubset(network.energy_types):
+            exception_list.append(
+                NetworkValidatorException(
+                    f"Efficiency energy types do not exist "
+                    f"in network energy types: {sorted(network.energy_types)}"
+                )
+            )
+        is_sum_greater_than_or_1 = self.efficiency.sum(axis=1) - 1e-6 > 1
+        hours_not_satisfying_condition = self.efficiency.index[
+            is_sum_greater_than_or_1
+        ].tolist()
+        if hours_not_satisfying_condition:
+            _logger.warning(
+                "Generator type %s efficiency contains hours: %s which sum for each energy type is above 1",
+                self.name,
+                hours_not_satisfying_condition,
+            )
+            warnings.warn(
+                f"Generator type {self.name} efficiency contains hours: {hours_not_satisfying_condition} "
+                "which sum for each energy type is above 1",
+                SumNotEqualToOneWarning,
+            )
+
+        _logger.debug("Validate efficiency: OK")
+
+    def _validate_emission_reduction(
+        self, exception_list: list[NetworkValidatorException], network: Network
+    ) -> None:
+        """
+        Validation procedure checking:
+        - Validates if emission reduction of generator type is not None
+        - Validates whether emission reduction energy types exist in network.emission_types
+
+        Args:
+            exception_list (NetworkValidatorException) - list of raised exceptions.
+            network (Network): network to which self is to be added.
+
+        Returns:
+            None
+        """
+        if self.emission_reduction is None:
+            exception_list.append(
+                NetworkValidatorException("Emission reduction cannot be None.")
+            )
+            return
+        if emission_diff := set(self.emission_reduction.keys()).difference(
+            network.emission_types
+        ):
+            exception_list.append(
+                NetworkValidatorException(
+                    f"Emission reduction emission types {emission_diff} do not exist "
+                    f"in network emission types: {sorted(network.emission_types)}"
+                )
+            )
+        _logger.debug("Validate emission reduction: OK")
+
+    @staticmethod
+    def _validate_curtailment_idx(
+        network: Network,
+        name: GeneratorType,
+        curtailment_cost: pd.Series,
+        exception_list: list[NetworkValidatorException],
+    ) -> None:
+        if (
+            len(curtailment_cost)
+            and len(set(curtailment_cost.index)) != network.constants.n_years
+        ):
+            exception_list.append(
+                NetworkValidatorException(
+                    f"Incorrect year indices for energy curtailment cost of generator type "
+                    f"<{str(name)}> The number of indexes should match the number of years"
+                )
+            )
+
+    @staticmethod
+    def _validate_curtailment_val(
+        network: Network,
+        name: GeneratorType,
+        curtailment_cost: pd.Series,
+        exception_list: list[NetworkValidatorException],
+    ) -> None:
+        curtailment_cost_vals = curtailment_cost.values if len(curtailment_cost) else []
+        vals = [el for el in curtailment_cost_vals if is_flow_int(el)]
+        if len(vals) > 0 and len(vals) != network.constants.n_years:
+            exception_list.append(
+                NetworkValidatorException(
+                    f"Incorrect values for energy curtailment cost of generator type <{str(name)}>"
+                )
+            )
+
+    def validate_curtailment_cost(
+        self,
+        network: Network,
+        name: GeneratorType,
+        curtailment_cost: pd.Series,
+        exception_list: list[NetworkValidatorException],
+    ) -> None:
+        GeneratorType._validate_curtailment_idx(
+            network, name, curtailment_cost, exception_list
+        )
+        GeneratorType._validate_curtailment_val(
+            network, name, curtailment_cost, exception_list
+        )
+
+    def _validate_power_utilization(
+        self,
+        network: Network,
+        exception_list: list[NetworkValidatorException],
+    ) -> None:
+        """
+        Validation procedure checking:
+        - Validates if power utilization is instance of pd.Series
+        - Validates if power utilization values range
+
+        Args:
+            exception_list (NetworkValidatorException) - list of raised exceptions.
+
+        Returns:
+            None
+        """
+        if validate_series(
+            name="power_utilization",
+            series=self.power_utilization,
+            length=network.constants.n_hours,
+            exception_list=exception_list,
+        ):
+            if not (incorrect_rows := self.power_utilization >= 0).all():
+                incorrect_hours = incorrect_rows.index[~incorrect_rows].to_list()
+                exception_list.append(
+                    NetworkValidatorException(
+                        f"Power utilization values must be greater "
+                        f"or equal 0, but for hours: {incorrect_hours} it is not"
+                    )
+                )
+        _logger.debug("Validate power utilization: OK")
```

### Comparing `pyzefir-0.4.1/pyzefir/model/network_element.py` & `pyzefir-0.4.22/pyzefir/model/network_element.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,104 +1,102 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-from __future__ import annotations
-
-from abc import ABC, abstractmethod
-from dataclasses import dataclass
-from typing import TYPE_CHECKING, Any
-
-from pyzefir.model.exceptions import NetworkValidatorException
-
-if TYPE_CHECKING:
-    from pyzefir.model.network import Network
-
-
-@dataclass
-class NetworkElement(ABC):
-    """
-    Interface for Network element implementation.
-    """
-
-    name: str
-    """
-    Unique element name
-    """
-
-    def _validate_name_type(
-        self, exception_list: list[NetworkValidatorException]
-    ) -> None:
-        """
-        Validation procedure checking:
-        - if name is type string
-
-        Args:
-            exception_list (list[NetworkValidatorException]): List of exceptions to which new exceptions are added
-
-        """
-        if not isinstance(self.name, str):
-            exception_list.append(
-                NetworkValidatorException(
-                    f"Network element name must be of type string, but it is {type(self.name)} instead."
-                )
-            )
-
-    @abstractmethod
-    def validate(self, network: Network) -> None:
-        """
-        Validation procedure triggered every time when NetworkElement instance is added to the given network. In case of
-        inconsistencies or errors, appropriate exception should be raised.
-
-        :param network: Network - network to which self is to be added
-        :return: None
-        """
-        raise NotImplementedError
-
-    def _validate_attribute_type(
-        self,
-        attr: str,
-        attr_type: Any,
-        exception_list: list[NetworkValidatorException],
-        raise_error: bool = False,
-    ) -> None:
-        """
-        Validates if given attribute is instance of given type.
-
-        Note:
-            Works only for basic build-in types.
-
-        Args:
-            attr (str): attribute to validate.
-            attr_type (Any): expected type.
-
-        Returns:
-            None.
-
-        Raises:
-            NetworkValidatorException: If attr is not an instance of given class.
-        """
-        if not isinstance(getattr(self, attr), attr_type):
-            if raise_error:
-                raise NetworkValidatorException(
-                    f"{self.__class__.__name__} attribute '{attr}' for {self.name} must be an instance of "
-                    f"{attr_type}, but it is an instance of {type(getattr(self, attr))} instead"
-                )
-            exception_list.append(
-                NetworkValidatorException(
-                    f"{self.__class__.__name__} attribute '{attr}' for {self.name} "
-                    "must be an instance of "
-                    f"{attr_type}, but it is an instance of {type(getattr(self, attr))} instead"
-                )
-            )
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+from __future__ import annotations
+
+import logging
+from abc import ABC, abstractmethod
+from dataclasses import dataclass
+from typing import TYPE_CHECKING, Any
+
+from pyzefir.model.exceptions import NetworkValidatorException
+
+_logger = logging.getLogger(__name__)
+
+if TYPE_CHECKING:
+    from pyzefir.model.network import Network
+
+
+@dataclass
+class NetworkElement(ABC):
+    """
+    Interface for Network element implementation.
+    """
+
+    name: str
+    """
+    Unique element name
+    """
+
+    def _validate_name_type(
+        self, exception_list: list[NetworkValidatorException]
+    ) -> None:
+        """
+        Validation procedure checking:
+        - if name is type string
+
+        Args:
+            exception_list (list[NetworkValidatorException]): List of exceptions to which new exceptions are added
+
+        """
+        if not isinstance(self.name, str):
+            exception_str = f"Network element name must be of type string, but it is {type(self.name)} instead."
+            _logger.debug(exception_str)
+            exception_list.append(NetworkValidatorException(exception_str))
+
+    @abstractmethod
+    def validate(self, network: Network) -> None:
+        """
+        Validation procedure triggered every time when NetworkElement instance is added to the given network. In case of
+        inconsistencies or errors, appropriate exception should be raised.
+
+        :param network: Network - network to which self is to be added
+        :return: None
+        """
+        raise NotImplementedError
+
+    def _validate_attribute_type(
+        self,
+        attr: str,
+        attr_type: Any,
+        exception_list: list[NetworkValidatorException],
+        raise_error: bool = False,
+    ) -> None:
+        """
+        Validates if given attribute is instance of given type.
+
+        Note:
+            Works only for basic build-in types.
+
+        Args:
+            attr (str): attribute to validate.
+            attr_type (Any): expected type.
+
+        Returns:
+            None.
+
+        Raises:
+            NetworkValidatorException: If attr is not an instance of given class.
+        """
+        if not isinstance(getattr(self, attr), attr_type):
+            exception_str = (
+                f"{self.__class__.__name__} attribute '{attr}' for {self.name} must be an instance of"
+                f" {attr_type}, but it is an instance of {type(getattr(self, attr))} instead"
+            )
+            if raise_error:
+                _logger.debug(exception_str)
+                raise NetworkValidatorException(exception_str)
+            _logger.debug(exception_str)
+            exception_list.append(NetworkValidatorException(exception_str))
```

### Comparing `pyzefir-0.4.1/pyzefir/model/network_elements/__init__.py` & `pyzefir-0.4.22/pyzefir/model/network_elements/__init__.py`

 * *Ordering differences only*

 * *Files 15% similar despite different names*

```diff
@@ -1,61 +1,61 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-from pyzefir.model.network_element import NetworkElement
-from pyzefir.model.network_elements.aggregated_consumer import AggregatedConsumer
-from pyzefir.model.network_elements.bus import Bus
-from pyzefir.model.network_elements.capacity_factor import CapacityFactor
-from pyzefir.model.network_elements.demand_chunk import DemandChunk
-from pyzefir.model.network_elements.demand_profile import DemandProfile
-from pyzefir.model.network_elements.dsr import DSR
-from pyzefir.model.network_elements.emission_fee import EmissionFee
-from pyzefir.model.network_elements.energy_source_types.energy_source_type_base import (
-    EnergySourceType,
-)
-from pyzefir.model.network_elements.energy_source_types.generator_type import (
-    GeneratorType,
-)
-from pyzefir.model.network_elements.energy_source_types.storage_type import StorageType
-from pyzefir.model.network_elements.energy_sources.energy_source_base import (
-    EnergySource,
-)
-from pyzefir.model.network_elements.energy_sources.generator import Generator
-from pyzefir.model.network_elements.energy_sources.storage import Storage
-from pyzefir.model.network_elements.fuel import Fuel
-from pyzefir.model.network_elements.line import Line
-from pyzefir.model.network_elements.local_balancing_stack import LocalBalancingStack
-from pyzefir.model.network_elements.transmission_fee import TransmissionFee
-
-__all__ = [
-    "NetworkElement",
-    "AggregatedConsumer",
-    "Bus",
-    "CapacityFactor",
-    "Fuel",
-    "Line",
-    "LocalBalancingStack",
-    "EnergySource",
-    "Generator",
-    "Storage",
-    "EnergySourceType",
-    "GeneratorType",
-    "StorageType",
-    "DemandProfile",
-    "TransmissionFee",
-    "EmissionFee",
-    "DemandChunk",
-    "DSR",
-]
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+from pyzefir.model.network_element import NetworkElement
+from pyzefir.model.network_elements.aggregated_consumer import AggregatedConsumer
+from pyzefir.model.network_elements.bus import Bus
+from pyzefir.model.network_elements.capacity_factor import CapacityFactor
+from pyzefir.model.network_elements.demand_chunk import DemandChunk
+from pyzefir.model.network_elements.demand_profile import DemandProfile
+from pyzefir.model.network_elements.dsr import DSR
+from pyzefir.model.network_elements.emission_fee import EmissionFee
+from pyzefir.model.network_elements.energy_source_types.energy_source_type_base import (
+    EnergySourceType,
+)
+from pyzefir.model.network_elements.energy_source_types.generator_type import (
+    GeneratorType,
+)
+from pyzefir.model.network_elements.energy_source_types.storage_type import StorageType
+from pyzefir.model.network_elements.energy_sources.energy_source_base import (
+    EnergySource,
+)
+from pyzefir.model.network_elements.energy_sources.generator import Generator
+from pyzefir.model.network_elements.energy_sources.storage import Storage
+from pyzefir.model.network_elements.fuel import Fuel
+from pyzefir.model.network_elements.line import Line
+from pyzefir.model.network_elements.local_balancing_stack import LocalBalancingStack
+from pyzefir.model.network_elements.transmission_fee import TransmissionFee
+
+__all__ = [
+    "NetworkElement",
+    "AggregatedConsumer",
+    "Bus",
+    "CapacityFactor",
+    "Fuel",
+    "Line",
+    "LocalBalancingStack",
+    "EnergySource",
+    "Generator",
+    "Storage",
+    "EnergySourceType",
+    "GeneratorType",
+    "StorageType",
+    "DemandProfile",
+    "TransmissionFee",
+    "EmissionFee",
+    "DemandChunk",
+    "DSR",
+]
```

### Comparing `pyzefir-0.4.1/pyzefir/model/network_elements/aggregated_consumer.py` & `pyzefir-0.4.22/pyzefir/model/network_elements/aggregated_consumer.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,669 +1,682 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-from __future__ import annotations
-
-import math
-from dataclasses import dataclass
-from typing import TYPE_CHECKING
-
-import numpy as np
-import pandas as pd
-
-from pyzefir.model.exceptions import (
-    NetworkValidatorException,
-    NetworkValidatorExceptionGroup,
-)
-from pyzefir.model.network_element import NetworkElement
-from pyzefir.model.utils import check_interval, validate_dict_type, validate_series
-
-if TYPE_CHECKING:
-    from pyzefir.model.network import Network
-
-
-class AggregatedConsumerValidatorExceptionGroup(NetworkValidatorExceptionGroup):
-    pass
-
-
-@dataclass
-class AggregatedConsumer(NetworkElement):
-    """
-    A class that represents the AggregatedConsumer element in the
-    network structure which aggregate LocalBalancingStack
-    """
-
-    demand_profile: str
-    """
-    Unique name of DemandProfile which holds normalized demand profile pd.Series
-    """
-    stack_base_fraction: dict[str, float]
-    """
-    Dictionary mapping LocalBalancingStack.name to float representing fraction
-    of aggregated consumer in 0 year for each technology.
-    """
-    yearly_energy_usage: dict[str, pd.Series]
-    """
-    Total amount of energy (all types) that needs to be provided to the given
-    aggregate in a given year
-    """
-    min_fraction: dict[str, pd.Series]
-    """
-    Dictionary mapping LocalBalancingStack.name to float representing minimal fraction
-    of aggregated consumer using energy from corresponding LocalBalancingStack.
-    Fraction value must be in range <0;1> and sum to 1 for specific aggregate.
-    """
-    max_fraction: dict[str, pd.Series]
-    """
-    Dictionary mapping LocalBalancingStack.name to float representing maximal fraction
-    of aggregated consumer using energy from corresponding LocalBalancingStack.
-    Fraction value must be in range <0;1> and sum to 1 for specific aggregate.
-    """
-    max_fraction_decrease: dict[str, pd.Series]
-    """
-    Dictionary mapping LocalBalancingStack.name to float representing maximal fraction decrease
-    of aggregated consumer using energy from corresponding LocalBalancingStack.
-    Fraction value must be in range <0;1> and sum to 1 for specific aggregate.
-    """
-    max_fraction_increase: dict[str, pd.Series]
-    """
-    Dictionary mapping LocalBalancingStack.name to float representing maximal fraction increase
-    of aggregated consumer using energy from corresponding LocalBalancingStack.
-    Fraction value must be in range <0;1> and sum to 1 for specific aggregate.
-    """
-    n_consumers: pd.Series
-    """
-    Number of consumers represented by the aggregate
-    """
-    average_area: float | None
-    """
-    Average area of this aggregate
-    """
-
-    @property
-    def available_stacks(self) -> list[str]:
-        """
-        Get a unique list of all LocalBalancingStack object names mapped to the
-        object via stack_base_fraction parameter
-
-        Returns:
-            list[str]: List of LocalBalancingStack names.
-        """
-        return list(self.stack_base_fraction.keys())
-
-    def _validate_demand_profile(
-        self, network: Network, exception_list: list[NetworkValidatorException]
-    ) -> None:
-        """
-        Validate demand profile of AggregatedConsumer.
-            - Validates if demand profile is a string
-            - Validates if demand profile is defined in the network
-
-        Args:
-            network (Network): Network to which AggregatedConsumer is
-                to be added.
-            exception_list (list[NetworkValidatorException]): List of
-                exceptions to be raised.
-        """
-        if not isinstance(self.demand_profile, str):
-            exception_list.append(
-                NetworkValidatorException("Demand must be given as a string")
-            )
-            return  # do not need to validate if demand_profile is not str
-        if network.demand_profiles.get(self.demand_profile) is None:
-            exception_list.append(
-                NetworkValidatorException(
-                    f"Demand {self.demand_profile} must be defined in the network"
-                )
-            )
-        else:
-            demand_profile_energy_types = [
-                *network.demand_profiles[self.demand_profile].normalized_profile.keys()
-            ]
-
-            for stack_name in self.available_stacks:
-                stack = network.local_balancing_stacks.get(stack_name)
-                if stack is None:
-                    continue
-                stack_energy_types = set(stack.buses_out.keys())
-                if diff := set(stack_energy_types).symmetric_difference(
-                    demand_profile_energy_types
-                ):
-                    exception_list.append(
-                        NetworkValidatorException(
-                            f"Energy types of demand profile "
-                            f"are different than energy types defined in the connected stack {stack_name}. "
-                            f"Difference: {diff}"
-                        )
-                    )
-
-    def _validate_stack_base_fraction_type(
-        self, exception_list: list[NetworkValidatorException]
-    ) -> bool:
-        """
-        Validate type of stack_base_fraction parameter.
-            - Validates if stack_base_fraction is a dictionary
-
-        Args:
-            exception_list (list[NetworkValidatorException]): List of
-                exceptions to be raised.
-
-        Returns:
-            bool: Returns True if the validation is successful, indicating that the
-            stack_base_fraction parameter has the correct type and format.
-            Returns False if validation fails.
-        """
-
-        if not isinstance(self.stack_base_fraction, dict):
-            exception_list.append(
-                NetworkValidatorException(
-                    "Stack base fractions must be given as a dictionary"
-                )
-            )
-            return False
-
-        is_validation_ok = True
-
-        if not all(
-            isinstance(fraction, (int, float))
-            for fraction in self.stack_base_fraction.values()
-        ):
-            exception_list.append(
-                NetworkValidatorException(
-                    "Stack base fractions must be given as a dictionary with values of type float"
-                )
-            )
-            is_validation_ok = False
-
-        if not all(isinstance(key, str) for key in self.stack_base_fraction.keys()):
-            exception_list.append(
-                NetworkValidatorException(
-                    "Stack base fractions must be given as a dictionary with keys of type str"
-                )
-            )
-            is_validation_ok = False
-
-        return is_validation_ok
-
-    def _validate_stack_base_fraction(
-        self, network: Network, exception_list: list[NetworkValidatorException]
-    ) -> None:
-        """
-        Validate LocalBalancingStacks in aggregated consumer.
-            - Validate type
-            - Validates if LocalBalancingStacks are defined in the network
-            - Validates if sum of fractions is equal to 1
-            - Validates if fractions are in range <0;1>
-
-        Args:
-            network (Network): Network to which AggregatedConsumer is to
-                be added.
-            exception_list (list[NetworkValidatorException]): List of exceptions
-                to be raised.
-        """
-        if not self._validate_stack_base_fraction_type(exception_list):
-            return  # skip validation if incorrect types
-
-        if not math.isclose(1, fraction_sum := sum(self.stack_base_fraction.values())):
-            exception_list.append(
-                NetworkValidatorException(
-                    "Local balancing stack fractions do not sum to 1, "
-                    f"but to {fraction_sum} instead"
-                )
-            )
-
-        for stack, fraction in self.stack_base_fraction.items():
-            if not check_interval(lower_bound=0, upper_bound=1, value=fraction):
-                exception_list.append(
-                    NetworkValidatorException(
-                        f"The value of the {stack} is inconsistent with th expected bounds of "
-                        f"the interval: 0 <= {fraction} <= 1"
-                    )
-                )
-
-            if stack not in network.local_balancing_stacks:
-                exception_list.append(
-                    NetworkValidatorException(
-                        f"Local balancing stack {stack} does not exist in the network"
-                    )
-                )
-            if network.constants.binary_fraction and fraction not in [0, 1]:
-                exception_list.append(
-                    NetworkValidatorException(
-                        f"For binary fraction setting, stack base fraction must contain only values 0 and 1. "
-                        f"Found value: {fraction}"
-                    )
-                )
-
-    def _validate_yearly_energy_usage_types(
-        self, exception_list: list[NetworkValidatorException]
-    ) -> bool:
-        """
-        Validate types of yearly_energy_usage parameter.
-
-        Args:
-            exception_list (list[NetworkValidatorException]): List of exceptions
-                to be raised.
-
-        Returns:
-            bool: Returns True if the validation is successful, indicating that the
-            yearly_energy_usage parameter has the correct type and format.
-            Returns False if validation fails.
-        """
-        if not isinstance(self.yearly_energy_usage, dict):
-            exception_list.append(
-                NetworkValidatorException("Yearly energy usage must be of dict type")
-            )
-            return False
-
-        is_validation_ok = True
-        if not all(
-            isinstance(energy_source, str)
-            for energy_source in self.yearly_energy_usage.keys()
-        ):
-            exception_list.append(
-                NetworkValidatorException("Energy type must be of str type")
-            )
-            is_validation_ok = False
-
-        if not all(
-            isinstance(energy_usage, pd.Series)
-            for energy_usage in self.yearly_energy_usage.values()
-        ):
-            exception_list.append(
-                NetworkValidatorException("Energy usage must be of pd.Series type")
-            )
-            is_validation_ok = False
-
-        return is_validation_ok
-
-    def _validate_yearly_energy_usage(
-        self,
-        network: Network,
-        exception_list: list[NetworkValidatorException],
-    ) -> None:
-        """
-        Validate yearly energy usage series of AggregatedConsumer element.
-            - Validate type
-            - Validate that all energy types have same index
-            - Validate that all energy types are defined in the network
-
-        Args:
-            exception_list (list[NetworkValidatorException]): List of exceptions
-                to be raised.
-        """
-
-        if not self._validate_yearly_energy_usage_types(exception_list):
-            return  # Do not validate further if types are invalid
-
-        if len(self.yearly_energy_usage) == 0:
-            exception_list.append(
-                NetworkValidatorException(
-                    "Yearly energy usage must contain at least one energy type"
-                )
-            )
-            return
-
-        keys = set(self.yearly_energy_usage.keys())
-        index = self.yearly_energy_usage[next(iter(keys))].index
-
-        if not all(self.yearly_energy_usage[key].index.equals(index) for key in keys):
-            exception_list.append(
-                NetworkValidatorException(
-                    "Yearly energy usage series must have the same index"
-                )
-            )
-
-        for stack_name in self.available_stacks:
-            stack = network.local_balancing_stacks.get(stack_name)
-            if stack is None:
-                continue
-            stack_energy_types = set(stack.buses_out.keys())
-            if diff := set(stack_energy_types).symmetric_difference(keys):
-                exception_list.append(
-                    NetworkValidatorException(
-                        f"Energy types are different than energy types defined in the connected stack {stack_name}. "
-                        f"Difference: {diff}"
-                    )
-                )
-
-    def _validate_fraction_types(
-        self,
-        number_of_years: int,
-        exception_list: list[NetworkValidatorException],
-        fraction_name: str,
-    ) -> bool:
-        """
-        Validate type of fraction parameter.
-            - Validates if fraction is a dictionary
-            - Values of dictionary is pd.Series
-            - pd.Series index: int and values: float
-
-        Args:
-            exception_list (list[NetworkValidatorException]): List of
-                exceptions to be raised.
-            number_of_years (int): The length of the simulation period
-
-        Returns:
-            bool: Returns True if the validation is successful, indicating that the
-            fraction parameter has the correct type and format.
-            Returns False if validation fails.
-        """
-        if validate_dict_type(
-            dict_to_validate=getattr(self, fraction_name),
-            key_type=str,
-            value_type=pd.Series,
-            parameter_name=f"fraction {fraction_name}",
-            key_parameter_name="aggregate",
-            value_parameter_name="fraction_series",
-            exception_list=exception_list,
-        ):
-            return self._validate_series_types(
-                number_of_years, exception_list, fraction_name
-            )
-        else:
-            return False
-
-    def _validate_series_types(
-        self,
-        number_of_years: int,
-        exception_list: list[NetworkValidatorException],
-        fraction_name: str,
-    ) -> bool:
-        """
-        Validate fraction series structure types.
-            - series index are int type
-            - series values are float type (float or np.nan)
-        Args:
-            exception_list (list[NetworkValidatorException]): List of
-                exceptions to be raised.
-            number_of_years (int): The length of the simulation period
-        Returns:
-            bool: Returns True if the validation is successful, indicating that the
-            fraction parameter has the correct type and format.
-            Returns False if validation fails.
-        """
-        is_validation_ok = True
-        for stack, series in getattr(self, fraction_name).items():
-            if validate_series(
-                name=f"Local balancing stack {stack} fraction {fraction_name} series",
-                series=series,
-                length=number_of_years,
-                exception_list=exception_list,
-                index_type=np.integer,
-                values_type=np.floating,
-            ):
-                values_outside_range = series.loc[~series.between(0, 1)].dropna()
-                if not values_outside_range.empty:
-                    exception_list.append(
-                        NetworkValidatorException(
-                            f"Fraction {fraction_name} in LBS {stack} values must be given in range"
-                            f" <0:1> but {values_outside_range.tolist()} given instead"
-                        )
-                    )
-                    is_validation_ok = False
-            else:
-                is_validation_ok = False
-        return is_validation_ok
-
-    def _validate_fraction(
-        self,
-        fraction_name: str,
-        network: Network,
-        exception_list: list[NetworkValidatorException],
-    ) -> bool:
-        is_fraction_ok = True
-        fraction = getattr(self, fraction_name)
-        if not self._validate_fraction_types(
-            network.constants.n_years, exception_list, fraction_name
-        ):
-            return False
-        for stack, fraction_series in fraction.items():
-            if stack not in self.available_stacks:
-                exception_list.append(
-                    NetworkValidatorException(
-                        f"Local balancing stack {stack} given for fraction "
-                        f"{fraction_name} is not defined in base_fractions"
-                    )
-                )
-                is_fraction_ok = False
-            if not pd.isna(fraction_series.iloc[0]):
-                exception_list.append(
-                    NetworkValidatorException(
-                        f"Local balancing stack {stack} in fraction attribute {fraction_name} "
-                        "detected value for base year. This attribute could be provided "
-                        "for every year except the base year."
-                    )
-                )
-                is_fraction_ok = False
-            if network.constants.binary_fraction:
-                wrong_indices = fraction_series[
-                    (~fraction_series.isin([0, 1, np.nan]))
-                ].index.to_list()
-                if wrong_indices:
-                    exception_list.append(
-                        NetworkValidatorException(
-                            f"For binary fraction setting, {fraction_name} in stack {stack} must contain "
-                            f"only values 0 or 1 for all years. "
-                            f"Detected incorrect values for years: {wrong_indices}. "
-                            f"Values: {fraction_series[wrong_indices].to_list()}"
-                        )
-                    )
-                    is_fraction_ok = False
-        return is_fraction_ok
-
-    def _validate_fractions(
-        self, network: Network, exception_list: list[NetworkValidatorException]
-    ) -> None:
-        """
-        Validates the fraction data for the aggregated consumer in the network
-        - Validates fraction types
-        - Checks if local balancing stacks exist in the network
-        - Compares the length of fraction series with the number of years in the model
-        - Validates summed series
-
-        Args:
-            network (Network): The network containing the consumer and its related data.
-            exception_list (list[NetworkValidatorException]): A list to collect validation exceptions.
-        """
-        all_fractions_ok = True
-        fraction_attr_names = [
-            "min_fraction",
-            "max_fraction",
-            "max_fraction_decrease",
-            "max_fraction_increase",
-        ]
-        for fraction_name in fraction_attr_names:
-            all_fractions_ok = (
-                self._validate_fraction(fraction_name, network, exception_list)
-                and all_fractions_ok
-            )
-
-        if all_fractions_ok:
-            self._validate_fraction_values(exception_list)
-
-    def _validate_fraction_aggregated_values(
-        self,
-        min_df: pd.DataFrame,
-        max_df: pd.DataFrame,
-        exception_list: list[NetworkValidatorException],
-    ) -> None:
-        min_sum = min_df.sum(axis=1, skipna=False)
-        max_sum = max_df.sum(axis=1, skipna=False)
-        if (min_df > 1).any().any():
-            exception_list.append(
-                NetworkValidatorException(
-                    f"Minimal fraction must be lower or equal to 1 for each year. "
-                    f"Detected values greater than 1 for years: {min_df.index[(min_df > 1).any(axis=1)].to_list()}"
-                )
-            )
-
-        if (series := ((min_sum > 1) & (~min_sum.isna()))).any():
-            exception_list.append(
-                NetworkValidatorException(
-                    f"Minimal fraction sum must be lower than 1. "
-                    f"Detected values greater than 1 for years: {min_df.index[series].to_list()}"
-                )
-            )
-        if (
-            set(self.available_stacks) == set(max_df.columns)
-            and (series := ((max_sum < 1) & (~max_sum.isna()))).any()
-        ):
-            exception_list.append(
-                NetworkValidatorException(
-                    f"If maximal fraction is defined for every available stack in this aggregate consumer, "
-                    f"then sum of these fractions must not be lower than 1. "
-                    f"Detected incorrect values for years: {max_df.index[series].to_list()}"
-                )
-            )
-
-    def _validate_fraction_values(
-        self,
-        exception_list: list[NetworkValidatorException],
-    ) -> None:
-        min_df = pd.DataFrame(self.min_fraction)
-        max_df = pd.DataFrame(self.max_fraction)
-        self._validate_fraction_aggregated_values(min_df, max_df, exception_list)
-        self._validate_stack_fractions(exception_list)
-
-    def _validate_stack_fractions(
-        self,
-        exception_list: list[NetworkValidatorException],
-    ) -> None:
-        for stack in self.available_stacks:
-            min_fraction = self.min_fraction.get(stack)
-            max_fraction = self.max_fraction.get(stack)
-            max_fraction_increase = self.max_fraction_increase.get(stack)
-            max_fraction_decrease = self.max_fraction_decrease.get(stack)
-            self._validate_fraction_per_stack(
-                min_fraction,
-                max_fraction,
-                max_fraction_increase,
-                max_fraction_decrease,
-                exception_list,
-            )
-
-    @staticmethod
-    def _validate_fraction_per_stack(
-        min_fraction: pd.Series | None,
-        max_fraction: pd.Series | None,
-        max_fraction_increase: pd.Series | None,
-        max_fraction_decrease: pd.Series | None,
-        exception_list: list[NetworkValidatorException],
-    ) -> None:
-        if min_fraction is None or max_fraction is None:
-            return
-        if (series := (min_fraction > max_fraction)).any():
-            exception_list.append(
-                NetworkValidatorException(
-                    f"Maximal fraction must be greater or equal than minimal fraction value. "
-                    f"Detected incorrect values for years: {min_fraction.index[series].to_list()}"
-                )
-            )
-        if max_fraction_increase is not None:
-            increase = min_fraction.shift(-1) - max_fraction
-            if not (
-                series := (
-                    (increase <= max_fraction_increase)
-                    | increase.isnull()
-                    | max_fraction_increase.isnull()
-                )
-            ).all():
-                exception_list.append(
-                    NetworkValidatorException(
-                        f"In every year minimal fraction in the next year must be "
-                        f"lower than maximal fraction plus maximal fraction increase. "
-                        f"Detected incorrect values for years: {max_fraction_increase.index[~series].to_list()}"
-                    )
-                )
-        if max_fraction_decrease is not None:
-            decrease = min_fraction - max_fraction.shift(-1)
-            if not (
-                series := (
-                    (decrease <= max_fraction_decrease)
-                    | decrease.isnull()
-                    | max_fraction_decrease.isnull()
-                )
-            ).all():
-                exception_list.append(
-                    NetworkValidatorException(
-                        f"In every year maximal fraction in the next year must be "
-                        f"lower than minimal fraction plus maximal fraction decrease. "
-                        f"Detected incorrect values for years: {max_fraction_decrease.index[~series].to_list()}"
-                    )
-                )
-
-    def _validate_n_consumers(
-        self,
-        n_years: int,
-        exception_list: list[NetworkValidatorException],
-    ) -> None:
-        validate_series(
-            name="N_consumer series",
-            series=self.n_consumers,
-            length=n_years,
-            exception_list=exception_list,
-            index_type=np.integer,
-            values_type=np.integer,
-            allow_null=False,
-        )
-        if (self.n_consumers <= 0).any():
-            exception_list.append(
-                NetworkValidatorException(
-                    "For n_consumers series all values must be positive and given for each year in simulation."
-                )
-            )
-
-    def validate(self, network: Network) -> None:
-        """
-        Validate AggregatedConsumer element.
-            - Validate demand profile
-            - Validate stack base fraction
-            - Validate yearly energy usage
-            - Validate fraction
-
-        Args:
-            network (Network): Network to which AggregatedConsumer is
-                to be added.
-
-        Raises:
-            NetworkValidatorExceptionGroup: If AggregatedConsumer is invalid.
-        """
-        exception_list: list[NetworkValidatorException] = []
-
-        self._validate_name_type(exception_list=exception_list)
-        self._validate_demand_profile(network=network, exception_list=exception_list)
-        self._validate_yearly_energy_usage(
-            network=network, exception_list=exception_list
-        )
-        self._validate_n_consumers(
-            n_years=network.constants.n_years, exception_list=exception_list
-        )
-
-        self._validate_stack_base_fraction(
-            network=network, exception_list=exception_list
-        )
-        self._validate_fractions(network=network, exception_list=exception_list)
-        if self.average_area is not None:
-            if not isinstance(self.average_area, float):
-                exception_list.append(
-                    NetworkValidatorException("Average area must be given as float")
-                )
-
-        if exception_list:
-            raise AggregatedConsumerValidatorExceptionGroup(
-                f"While adding AggregatedConsumer {self.name} following errors occurred: ",
-                exception_list,
-            )
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+from __future__ import annotations
+
+import logging
+import math
+from dataclasses import dataclass
+from typing import TYPE_CHECKING
+
+import numpy as np
+import pandas as pd
+
+from pyzefir.model.exceptions import (
+    NetworkValidatorException,
+    NetworkValidatorExceptionGroup,
+)
+from pyzefir.model.network_element import NetworkElement
+from pyzefir.model.utils import check_interval, validate_dict_type, validate_series
+
+if TYPE_CHECKING:
+    from pyzefir.model.network import Network
+
+_logger = logging.getLogger(name=__name__)
+
+
+class AggregatedConsumerValidatorExceptionGroup(NetworkValidatorExceptionGroup):
+    pass
+
+
+@dataclass
+class AggregatedConsumer(NetworkElement):
+    """
+    A class that represents the AggregatedConsumer element in the
+    network structure which aggregate LocalBalancingStack
+    """
+
+    demand_profile: str
+    """
+    Unique name of DemandProfile which holds normalized demand profile pd.Series
+    """
+    stack_base_fraction: dict[str, float]
+    """
+    Dictionary mapping LocalBalancingStack.name to float representing fraction
+    of aggregated consumer in 0 year for each technology.
+    """
+    yearly_energy_usage: dict[str, pd.Series]
+    """
+    Total amount of energy (all types) that needs to be provided to the given
+    aggregate in a given year
+    """
+    min_fraction: dict[str, pd.Series]
+    """
+    Dictionary mapping LocalBalancingStack.name to float representing minimal fraction
+    of aggregated consumer using energy from corresponding LocalBalancingStack.
+    Fraction value must be in range <0;1> and sum to 1 for specific aggregate.
+    """
+    max_fraction: dict[str, pd.Series]
+    """
+    Dictionary mapping LocalBalancingStack.name to float representing maximal fraction
+    of aggregated consumer using energy from corresponding LocalBalancingStack.
+    Fraction value must be in range <0;1> and sum to 1 for specific aggregate.
+    """
+    max_fraction_decrease: dict[str, pd.Series]
+    """
+    Dictionary mapping LocalBalancingStack.name to float representing maximal fraction decrease
+    of aggregated consumer using energy from corresponding LocalBalancingStack.
+    Fraction value must be in range <0;1> and sum to 1 for specific aggregate.
+    """
+    max_fraction_increase: dict[str, pd.Series]
+    """
+    Dictionary mapping LocalBalancingStack.name to float representing maximal fraction increase
+    of aggregated consumer using energy from corresponding LocalBalancingStack.
+    Fraction value must be in range <0;1> and sum to 1 for specific aggregate.
+    """
+    n_consumers: pd.Series
+    """
+    Number of consumers represented by the aggregate
+    """
+    average_area: float | None
+    """
+    Average area of this aggregate
+    """
+
+    @property
+    def available_stacks(self) -> list[str]:
+        """
+        Get a unique list of all LocalBalancingStack object names mapped to the
+        object via stack_base_fraction parameter
+
+        Returns:
+            list[str]: List of LocalBalancingStack names.
+        """
+        return list(self.stack_base_fraction.keys())
+
+    def _validate_demand_profile(
+        self, network: Network, exception_list: list[NetworkValidatorException]
+    ) -> None:
+        """
+        Validate demand profile of AggregatedConsumer.
+            - Validates if demand profile is a string
+            - Validates if demand profile is defined in the network
+
+        Args:
+            network (Network): Network to which AggregatedConsumer is
+                to be added.
+            exception_list (list[NetworkValidatorException]): List of
+                exceptions to be raised.
+        """
+        if not isinstance(self.demand_profile, str):
+            exception_list.append(
+                NetworkValidatorException("Demand must be given as a string")
+            )
+            return  # do not need to validate if demand_profile is not str
+        if network.demand_profiles.get(self.demand_profile) is None:
+            exception_list.append(
+                NetworkValidatorException(
+                    f"Demand {self.demand_profile} must be defined in the network"
+                )
+            )
+        else:
+            demand_profile_energy_types = [
+                *network.demand_profiles[self.demand_profile].normalized_profile.keys()
+            ]
+
+            for stack_name in self.available_stacks:
+                stack = network.local_balancing_stacks.get(stack_name)
+                if stack is None:
+                    continue
+                stack_energy_types = set(stack.buses_out.keys())
+                if diff := set(stack_energy_types).symmetric_difference(
+                    demand_profile_energy_types
+                ):
+                    exception_list.append(
+                        NetworkValidatorException(
+                            f"Energy types of demand profile "
+                            f"are different than energy types defined in the connected stack {stack_name}. "
+                            f"Difference: {diff}"
+                        )
+                    )
+        _logger.debug("Validate demand profile: OK")
+
+    def _validate_stack_base_fraction_type(
+        self, exception_list: list[NetworkValidatorException]
+    ) -> bool:
+        """
+        Validate type of stack_base_fraction parameter.
+            - Validates if stack_base_fraction is a dictionary
+
+        Args:
+            exception_list (list[NetworkValidatorException]): List of
+                exceptions to be raised.
+
+        Returns:
+            bool: Returns True if the validation is successful, indicating that the
+            stack_base_fraction parameter has the correct type and format.
+            Returns False if validation fails.
+        """
+
+        if not isinstance(self.stack_base_fraction, dict):
+            exception_list.append(
+                NetworkValidatorException(
+                    "Stack base fractions must be given as a dictionary"
+                )
+            )
+            return False
+
+        is_validation_ok = True
+
+        if not all(
+            isinstance(fraction, (int, float))
+            for fraction in self.stack_base_fraction.values()
+        ):
+            exception_list.append(
+                NetworkValidatorException(
+                    "Stack base fractions must be given as a dictionary with values of type float"
+                )
+            )
+            is_validation_ok = False
+
+        if not all(isinstance(key, str) for key in self.stack_base_fraction.keys()):
+            exception_list.append(
+                NetworkValidatorException(
+                    "Stack base fractions must be given as a dictionary with keys of type str"
+                )
+            )
+            is_validation_ok = False
+
+        return is_validation_ok
+
+    def _validate_stack_base_fraction(
+        self, network: Network, exception_list: list[NetworkValidatorException]
+    ) -> None:
+        """
+        Validate LocalBalancingStacks in aggregated consumer.
+            - Validate type
+            - Validates if LocalBalancingStacks are defined in the network
+            - Validates if sum of fractions is equal to 1
+            - Validates if fractions are in range <0;1>
+
+        Args:
+            network (Network): Network to which AggregatedConsumer is to
+                be added.
+            exception_list (list[NetworkValidatorException]): List of exceptions
+                to be raised.
+        """
+        if not self._validate_stack_base_fraction_type(exception_list):
+            return  # skip validation if incorrect types
+
+        if not math.isclose(1, fraction_sum := sum(self.stack_base_fraction.values())):
+            exception_list.append(
+                NetworkValidatorException(
+                    "Local balancing stack fractions do not sum to 1, "
+                    f"but to {fraction_sum} instead"
+                )
+            )
+
+        for stack, fraction in self.stack_base_fraction.items():
+            if not check_interval(lower_bound=0, upper_bound=1, value=fraction):
+                exception_list.append(
+                    NetworkValidatorException(
+                        f"The value of the {stack} is inconsistent with th expected bounds of "
+                        f"the interval: 0 <= {fraction} <= 1"
+                    )
+                )
+
+            if stack not in network.local_balancing_stacks:
+                exception_list.append(
+                    NetworkValidatorException(
+                        f"Local balancing stack {stack} does not exist in the network"
+                    )
+                )
+            if network.constants.binary_fraction and fraction not in [0, 1]:
+                exception_list.append(
+                    NetworkValidatorException(
+                        f"For binary fraction setting, stack base fraction must contain only values 0 and 1. "
+                        f"Found value: {fraction}"
+                    )
+                )
+        _logger.debug("Validate stack base fraction: OK")
+
+    def _validate_yearly_energy_usage_types(
+        self, exception_list: list[NetworkValidatorException]
+    ) -> bool:
+        """
+        Validate types of yearly_energy_usage parameter.
+
+        Args:
+            exception_list (list[NetworkValidatorException]): List of exceptions
+                to be raised.
+
+        Returns:
+            bool: Returns True if the validation is successful, indicating that the
+            yearly_energy_usage parameter has the correct type and format.
+            Returns False if validation fails.
+        """
+        if not isinstance(self.yearly_energy_usage, dict):
+            exception_list.append(
+                NetworkValidatorException("Yearly energy usage must be of dict type")
+            )
+            return False
+
+        is_validation_ok = True
+        if not all(
+            isinstance(energy_source, str)
+            for energy_source in self.yearly_energy_usage.keys()
+        ):
+            exception_list.append(
+                NetworkValidatorException("Energy type must be of str type")
+            )
+            is_validation_ok = False
+
+        if not all(
+            isinstance(energy_usage, pd.Series)
+            for energy_usage in self.yearly_energy_usage.values()
+        ):
+            exception_list.append(
+                NetworkValidatorException("Energy usage must be of pd.Series type")
+            )
+            is_validation_ok = False
+
+        return is_validation_ok
+
+    def _validate_yearly_energy_usage(
+        self,
+        network: Network,
+        exception_list: list[NetworkValidatorException],
+    ) -> None:
+        """
+        Validate yearly energy usage series of AggregatedConsumer element.
+            - Validate type
+            - Validate that all energy types have same index
+            - Validate that all energy types are defined in the network
+
+        Args:
+            exception_list (list[NetworkValidatorException]): List of exceptions
+                to be raised.
+        """
+
+        if not self._validate_yearly_energy_usage_types(exception_list):
+            return  # Do not validate further if types are invalid
+
+        if len(self.yearly_energy_usage) == 0:
+            exception_list.append(
+                NetworkValidatorException(
+                    "Yearly energy usage must contain at least one energy type"
+                )
+            )
+            return
+
+        keys = set(self.yearly_energy_usage.keys())
+        index = self.yearly_energy_usage[next(iter(keys))].index
+
+        if not all(self.yearly_energy_usage[key].index.equals(index) for key in keys):
+            exception_list.append(
+                NetworkValidatorException(
+                    "Yearly energy usage series must have the same index"
+                )
+            )
+
+        for stack_name in self.available_stacks:
+            stack = network.local_balancing_stacks.get(stack_name)
+            if stack is None:
+                continue
+            stack_energy_types = set(stack.buses_out.keys())
+            if diff := set(stack_energy_types).symmetric_difference(keys):
+                exception_list.append(
+                    NetworkValidatorException(
+                        f"Energy types are different than energy types defined in the connected stack {stack_name}. "
+                        f"Difference: {diff}"
+                    )
+                )
+        _logger.debug("Validate yearly energy usage: OK")
+
+    def _validate_fraction_types(
+        self,
+        number_of_years: int,
+        exception_list: list[NetworkValidatorException],
+        fraction_name: str,
+    ) -> bool:
+        """
+        Validate type of fraction parameter.
+            - Validates if fraction is a dictionary
+            - Values of dictionary is pd.Series
+            - pd.Series index: int and values: float
+
+        Args:
+            exception_list (list[NetworkValidatorException]): List of
+                exceptions to be raised.
+            number_of_years (int): The length of the simulation period
+
+        Returns:
+            bool: Returns True if the validation is successful, indicating that the
+            fraction parameter has the correct type and format.
+            Returns False if validation fails.
+        """
+        if validate_dict_type(
+            dict_to_validate=getattr(self, fraction_name),
+            key_type=str,
+            value_type=pd.Series,
+            parameter_name=f"fraction {fraction_name}",
+            key_parameter_name="aggregate",
+            value_parameter_name="fraction_series",
+            exception_list=exception_list,
+        ):
+            return self._validate_series_types(
+                number_of_years, exception_list, fraction_name
+            )
+        else:
+            return False
+
+    def _validate_series_types(
+        self,
+        number_of_years: int,
+        exception_list: list[NetworkValidatorException],
+        fraction_name: str,
+    ) -> bool:
+        """
+        Validate fraction series structure types.
+            - series index are int type
+            - series values are float type (float or np.nan)
+        Args:
+            exception_list (list[NetworkValidatorException]): List of
+                exceptions to be raised.
+            number_of_years (int): The length of the simulation period
+        Returns:
+            bool: Returns True if the validation is successful, indicating that the
+            fraction parameter has the correct type and format.
+            Returns False if validation fails.
+        """
+        is_validation_ok = True
+        for stack, series in getattr(self, fraction_name).items():
+            if validate_series(
+                name=f"Local balancing stack {stack} fraction {fraction_name} series",
+                series=series,
+                length=number_of_years,
+                exception_list=exception_list,
+                index_type=np.integer,
+                values_type=np.floating,
+            ):
+                values_outside_range = series.loc[~series.between(0, 1)].dropna()
+                if not values_outside_range.empty:
+                    exception_list.append(
+                        NetworkValidatorException(
+                            f"Fraction {fraction_name} in LBS {stack} values must be given in range"
+                            f" <0:1> but {values_outside_range.tolist()} given instead"
+                        )
+                    )
+                    is_validation_ok = False
+            else:
+                is_validation_ok = False
+        return is_validation_ok
+
+    def _validate_fraction(
+        self,
+        fraction_name: str,
+        network: Network,
+        exception_list: list[NetworkValidatorException],
+    ) -> bool:
+        is_fraction_ok = True
+        fraction = getattr(self, fraction_name)
+        if not self._validate_fraction_types(
+            network.constants.n_years, exception_list, fraction_name
+        ):
+            return False
+        for stack, fraction_series in fraction.items():
+            if stack not in self.available_stacks:
+                exception_list.append(
+                    NetworkValidatorException(
+                        f"Local balancing stack {stack} given for fraction "
+                        f"{fraction_name} is not defined in base_fractions"
+                    )
+                )
+                is_fraction_ok = False
+            if not pd.isna(fraction_series.iloc[0]):
+                exception_list.append(
+                    NetworkValidatorException(
+                        f"Local balancing stack {stack} in fraction attribute {fraction_name} "
+                        "detected value for base year. This attribute could be provided "
+                        "for every year except the base year."
+                    )
+                )
+                is_fraction_ok = False
+            if network.constants.binary_fraction:
+                wrong_indices = fraction_series[
+                    (~fraction_series.isin([0, 1, np.nan]))
+                ].index.to_list()
+                if wrong_indices:
+                    exception_list.append(
+                        NetworkValidatorException(
+                            f"For binary fraction setting, {fraction_name} in stack {stack} must contain "
+                            f"only values 0 or 1 for all years. "
+                            f"Detected incorrect values for years: {wrong_indices}. "
+                            f"Values: {fraction_series[wrong_indices].to_list()}"
+                        )
+                    )
+                    is_fraction_ok = False
+        return is_fraction_ok
+
+    def _validate_fractions(
+        self, network: Network, exception_list: list[NetworkValidatorException]
+    ) -> None:
+        """
+        Validates the fraction data for the aggregated consumer in the network
+        - Validates fraction types
+        - Checks if local balancing stacks exist in the network
+        - Compares the length of fraction series with the number of years in the model
+        - Validates summed series
+
+        Args:
+            network (Network): The network containing the consumer and its related data.
+            exception_list (list[NetworkValidatorException]): A list to collect validation exceptions.
+        """
+        all_fractions_ok = True
+        fraction_attr_names = [
+            "min_fraction",
+            "max_fraction",
+            "max_fraction_decrease",
+            "max_fraction_increase",
+        ]
+        for fraction_name in fraction_attr_names:
+            all_fractions_ok = (
+                self._validate_fraction(fraction_name, network, exception_list)
+                and all_fractions_ok
+            )
+
+        if all_fractions_ok:
+            self._validate_fraction_values(exception_list)
+        _logger.debug("Validate fractions: OK")
+
+    def _validate_fraction_aggregated_values(
+        self,
+        min_df: pd.DataFrame,
+        max_df: pd.DataFrame,
+        exception_list: list[NetworkValidatorException],
+    ) -> None:
+        min_sum = min_df.sum(axis=1, skipna=False)
+        max_sum = max_df.sum(axis=1, skipna=False)
+        if (min_df > 1).any().any():
+            exception_list.append(
+                NetworkValidatorException(
+                    f"Minimal fraction must be lower or equal to 1 for each year. "
+                    f"Detected values greater than 1 for years: {min_df.index[(min_df > 1).any(axis=1)].to_list()}"
+                )
+            )
+
+        if (series := ((min_sum > 1) & (~min_sum.isna()))).any():
+            exception_list.append(
+                NetworkValidatorException(
+                    f"Minimal fraction sum must be lower than 1. "
+                    f"Detected values greater than 1 for years: {min_df.index[series].to_list()}"
+                )
+            )
+        if (
+            set(self.available_stacks) == set(max_df.columns)
+            and (series := ((max_sum < 1) & (~max_sum.isna()))).any()
+        ):
+            exception_list.append(
+                NetworkValidatorException(
+                    f"If maximal fraction is defined for every available stack in this aggregate consumer, "
+                    f"then sum of these fractions must not be lower than 1. "
+                    f"Detected incorrect values for years: {max_df.index[series].to_list()}"
+                )
+            )
+
+    def _validate_fraction_values(
+        self,
+        exception_list: list[NetworkValidatorException],
+    ) -> None:
+        min_df = pd.DataFrame(self.min_fraction)
+        max_df = pd.DataFrame(self.max_fraction)
+        self._validate_fraction_aggregated_values(min_df, max_df, exception_list)
+        self._validate_stack_fractions(exception_list)
+
+    def _validate_stack_fractions(
+        self,
+        exception_list: list[NetworkValidatorException],
+    ) -> None:
+        for stack in self.available_stacks:
+            min_fraction = self.min_fraction.get(stack)
+            max_fraction = self.max_fraction.get(stack)
+            max_fraction_increase = self.max_fraction_increase.get(stack)
+            max_fraction_decrease = self.max_fraction_decrease.get(stack)
+            self._validate_fraction_per_stack(
+                min_fraction,
+                max_fraction,
+                max_fraction_increase,
+                max_fraction_decrease,
+                exception_list,
+            )
+
+    @staticmethod
+    def _validate_fraction_per_stack(
+        min_fraction: pd.Series | None,
+        max_fraction: pd.Series | None,
+        max_fraction_increase: pd.Series | None,
+        max_fraction_decrease: pd.Series | None,
+        exception_list: list[NetworkValidatorException],
+    ) -> None:
+        if min_fraction is None or max_fraction is None:
+            return
+        if (series := (min_fraction > max_fraction)).any():
+            exception_list.append(
+                NetworkValidatorException(
+                    f"Maximal fraction must be greater or equal than minimal fraction value. "
+                    f"Detected incorrect values for years: {min_fraction.index[series].to_list()}"
+                )
+            )
+        if max_fraction_increase is not None:
+            increase = min_fraction.shift(-1) - max_fraction
+            if not (
+                series := (
+                    (increase <= max_fraction_increase)
+                    | increase.isnull()
+                    | max_fraction_increase.isnull()
+                )
+            ).all():
+                exception_list.append(
+                    NetworkValidatorException(
+                        f"In every year minimal fraction in the next year must be "
+                        f"lower than maximal fraction plus maximal fraction increase. "
+                        f"Detected incorrect values for years: {max_fraction_increase.index[~series].to_list()}"
+                    )
+                )
+        if max_fraction_decrease is not None:
+            decrease = min_fraction - max_fraction.shift(-1)
+            if not (
+                series := (
+                    (decrease <= max_fraction_decrease)
+                    | decrease.isnull()
+                    | max_fraction_decrease.isnull()
+                )
+            ).all():
+                exception_list.append(
+                    NetworkValidatorException(
+                        f"In every year maximal fraction in the next year must be "
+                        f"lower than minimal fraction plus maximal fraction decrease. "
+                        f"Detected incorrect values for years: {max_fraction_decrease.index[~series].to_list()}"
+                    )
+                )
+
+    def _validate_n_consumers(
+        self,
+        n_years: int,
+        exception_list: list[NetworkValidatorException],
+    ) -> None:
+        validate_series(
+            name="N_consumer series",
+            series=self.n_consumers,
+            length=n_years,
+            exception_list=exception_list,
+            index_type=np.integer,
+            values_type=np.integer,
+            allow_null=False,
+        )
+        if (self.n_consumers <= 0).any():
+            exception_list.append(
+                NetworkValidatorException(
+                    "For n_consumers series all values must be positive and given for each year in simulation."
+                )
+            )
+        _logger.debug("Validate n consumers: OK")
+
+    def validate(self, network: Network) -> None:
+        """
+        Validate AggregatedConsumer element.
+            - Validate demand profile
+            - Validate stack base fraction
+            - Validate yearly energy usage
+            - Validate fraction
+
+        Args:
+            network (Network): Network to which AggregatedConsumer is
+                to be added.
+
+        Raises:
+            NetworkValidatorExceptionGroup: If AggregatedConsumer is invalid.
+        """
+        _logger.debug("Validating aggregated consumer object: %s...", self.name)
+        exception_list: list[NetworkValidatorException] = []
+
+        self._validate_name_type(exception_list=exception_list)
+        self._validate_demand_profile(network=network, exception_list=exception_list)
+        self._validate_yearly_energy_usage(
+            network=network, exception_list=exception_list
+        )
+        self._validate_n_consumers(
+            n_years=network.constants.n_years, exception_list=exception_list
+        )
+
+        self._validate_stack_base_fraction(
+            network=network, exception_list=exception_list
+        )
+        self._validate_fractions(network=network, exception_list=exception_list)
+        if self.average_area is not None:
+            if not isinstance(self.average_area, float):
+                exception_list.append(
+                    NetworkValidatorException("Average area must be given as float")
+                )
+
+        if exception_list:
+            _logger.debug(
+                "Got error validating aggregated consumer: %s", exception_list
+            )
+            raise AggregatedConsumerValidatorExceptionGroup(
+                f"While adding AggregatedConsumer {self.name} following errors occurred: ",
+                exception_list,
+            )
+        _logger.debug("Aggregated consumer %s validation: Done", self.name)
```

### Comparing `pyzefir-0.4.1/pyzefir/model/network_elements/bus.py` & `pyzefir-0.4.22/pyzefir/model/network_elements/bus.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,190 +1,195 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-from __future__ import annotations
-
-import logging
-from dataclasses import dataclass, field
-from typing import TYPE_CHECKING
-
-from pyzefir.model.exceptions import (
-    NetworkValidatorException,
-    NetworkValidatorExceptionGroup,
-)
-from pyzefir.model.network_element import NetworkElement
-
-if TYPE_CHECKING:
-    from pyzefir.model.network import Network
-
-_logger = logging.getLogger(__name__)
-
-
-class BusValidatorExceptionGroup(NetworkValidatorExceptionGroup):
-    pass
-
-
-@dataclass
-class Bus(NetworkElement):
-    """
-    A class that represents the Bus element in the network structure
-    """
-
-    energy_type: str
-    """
-    Name of the bus energy type
-    """
-    generators: set[str] = field(default_factory=set, init=False)
-    """
-    Set of generators attached to the bus
-    """
-    storages: set[str] = field(default_factory=set, init=False)
-    """
-    Set of storages attached to the bus
-    """
-    lines_in: set[str] = field(default_factory=set, init=False)
-    """
-    Set of lines oriented positive (inflow orientation)
-    """
-    lines_out: set[str] = field(default_factory=set, init=False)
-    """
-    Set of lines oriented negative (outflow orientation)
-    """
-    dsr_type: str | None = None
-    """
-    Name of DSR type
-    """
-
-    def _validate_energy_type(
-        self,
-        network: Network,
-        exception_list: list[NetworkValidatorException],
-    ) -> None:
-        if not isinstance(self.energy_type, str):
-            exception_list.append(
-                NetworkValidatorException(
-                    f"Energy Type must be a string, but given {type(self.energy_type)} instead"
-                )
-            )
-        elif self.energy_type not in network.energy_types:
-            exception_list.append(
-                NetworkValidatorException(
-                    f"Energy type {self.energy_type} "
-                    "is not compliant with the network "
-                    f"energy types: {sorted(network.energy_types)}"
-                )
-            )
-
-    def validate(self, network: Network) -> None:
-        """
-        Validation procedure checking:
-        - whether the Bus energy_type is in the energy_type of the Network
-        - type of bus name
-        - whether the Bus dsr_type exists in the Network DSR
-
-        Args:
-            network (Network): Network object to which this object belongs
-
-        Raises:
-            NetworkValidatorExceptionGroup: If any of the validation fails
-
-        """
-        exception_list: list[NetworkValidatorException] = []
-        self._validate_name_type(exception_list)
-        self._validate_energy_type(network, exception_list)
-        self._validate_dsr_mapping(network, exception_list)
-        if exception_list:
-            raise BusValidatorExceptionGroup(
-                f"While adding Bus {self.name} following errors occurred: ",
-                exception_list,
-            )
-
-    def attach_generator(self, generator_name: str) -> None:
-        """
-        Adds given generator name to this Bus generator set.
-
-        Args:
-            generator_name (str): Generator name to attach
-        """
-        if generator_name in self.generators:
-            _logger.debug(
-                f"Generator name: {generator_name} already in {self.name} generators"
-            )
-            return None
-        self.generators.add(generator_name)
-        _logger.debug(
-            f"Generator name: {generator_name} added to {self.name} generators"
-        )
-
-    def attach_storage(self, storage_name: str) -> None:
-        """
-        Adds given storage name to this Bus storage set.
-
-        Args:
-            storage_name (str): Storage name to attach
-        """
-
-        if storage_name in self.storages:
-            _logger.debug(
-                f"Storage name: {storage_name} already in {self.name} storages"
-            )
-            return None
-        self.storages.add(storage_name)
-        _logger.debug(f"Storage name: {storage_name} added to {self.name} storages")
-
-    def attach_from_line(self, line_name: str) -> None:
-        """
-        Adds given line name to this Bus line "from" set.
-
-        Args:
-            line_name (str): Line name to attach
-        """
-
-        if line_name in self.lines_out:
-            _logger.debug(f"Line name: {line_name} already in {self.name} line_out")
-            return None
-        self.lines_out.add(line_name)
-        _logger.debug(f"Line name: {line_name} added to {self.name} line_out")
-
-    def attach_to_line(self, line_name: str) -> None:
-        """
-        Adds given line name to this Bus line "to" set.
-
-        Args:
-            line_name (str): Line name to attach
-        """
-
-        if line_name in self.lines_in:
-            _logger.debug(f"Line name: {line_name} already in {self.name} line_in")
-            return None
-        self.lines_in.add(line_name)
-        _logger.debug(f"Line name: {line_name} added to {self.name} line_in")
-
-    def _validate_dsr_mapping(
-        self, network: Network, exception_list: list[NetworkValidatorException]
-    ) -> None:
-        if self.dsr_type is not None:
-            if not isinstance(self.dsr_type, str):
-                exception_list.append(
-                    NetworkValidatorException(
-                        f"DSR type must be type of str, not type {type(self.dsr_type).__name__}"
-                    )
-                )
-            elif self.dsr_type not in network.dsr:
-                exception_list.append(
-                    NetworkValidatorException(
-                        f"DSR type {self.dsr_type} does not exist in Network DSR"
-                    )
-                )
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+from __future__ import annotations
+
+import logging
+from dataclasses import dataclass, field
+from typing import TYPE_CHECKING
+
+from pyzefir.model.exceptions import (
+    NetworkValidatorException,
+    NetworkValidatorExceptionGroup,
+)
+from pyzefir.model.network_element import NetworkElement
+
+if TYPE_CHECKING:
+    from pyzefir.model.network import Network
+
+_logger = logging.getLogger(__name__)
+
+
+class BusValidatorExceptionGroup(NetworkValidatorExceptionGroup):
+    pass
+
+
+@dataclass
+class Bus(NetworkElement):
+    """
+    A class that represents the Bus element in the network structure
+    """
+
+    energy_type: str
+    """
+    Name of the bus energy type
+    """
+    generators: set[str] = field(default_factory=set, init=False)
+    """
+    Set of generators attached to the bus
+    """
+    storages: set[str] = field(default_factory=set, init=False)
+    """
+    Set of storages attached to the bus
+    """
+    lines_in: set[str] = field(default_factory=set, init=False)
+    """
+    Set of lines oriented positive (inflow orientation)
+    """
+    lines_out: set[str] = field(default_factory=set, init=False)
+    """
+    Set of lines oriented negative (outflow orientation)
+    """
+    dsr_type: str | None = None
+    """
+    Name of DSR type
+    """
+
+    def _validate_energy_type(
+        self,
+        network: Network,
+        exception_list: list[NetworkValidatorException],
+    ) -> None:
+        if not isinstance(self.energy_type, str):
+            exception_list.append(
+                NetworkValidatorException(
+                    f"Energy Type must be a string, but given {type(self.energy_type)} instead"
+                )
+            )
+        elif self.energy_type not in network.energy_types:
+            exception_list.append(
+                NetworkValidatorException(
+                    f"Energy type {self.energy_type} "
+                    "is not compliant with the network "
+                    f"energy types: {sorted(network.energy_types)}"
+                )
+            )
+        _logger.debug("Validate energy type: OK")
+
+    def validate(self, network: Network) -> None:
+        """
+        Validation procedure checking:
+        - whether the Bus energy_type is in the energy_type of the Network
+        - type of bus name
+        - whether the Bus dsr_type exists in the Network DSR
+
+        Args:
+            network (Network): Network object to which this object belongs
+
+        Raises:
+            NetworkValidatorExceptionGroup: If any of the validation fails
+
+        """
+        _logger.debug("Validating bus object: %s...", self.name)
+        exception_list: list[NetworkValidatorException] = []
+        self._validate_name_type(exception_list)
+        self._validate_energy_type(network, exception_list)
+        self._validate_dsr_mapping(network, exception_list)
+        if exception_list:
+            _logger.debug("Got error validating bus: %s", exception_list)
+            raise BusValidatorExceptionGroup(
+                f"While adding Bus {self.name} following errors occurred: ",
+                exception_list,
+            )
+        _logger.debug("Bus %s validation: Done", self.name)
+
+    def attach_generator(self, generator_name: str) -> None:
+        """
+        Adds given generator name to this Bus generator set.
+
+        Args:
+            generator_name (str): Generator name to attach
+        """
+        if generator_name in self.generators:
+            _logger.debug(
+                f"Generator name: {generator_name} already in {self.name} generators"
+            )
+            return None
+        self.generators.add(generator_name)
+        _logger.debug(
+            f"Generator name: {generator_name} added to {self.name} generators"
+        )
+
+    def attach_storage(self, storage_name: str) -> None:
+        """
+        Adds given storage name to this Bus storage set.
+
+        Args:
+            storage_name (str): Storage name to attach
+        """
+
+        if storage_name in self.storages:
+            _logger.debug(
+                f"Storage name: {storage_name} already in {self.name} storages"
+            )
+            return None
+        self.storages.add(storage_name)
+        _logger.debug(f"Storage name: {storage_name} added to {self.name} storages")
+
+    def attach_from_line(self, line_name: str) -> None:
+        """
+        Adds given line name to this Bus line "from" set.
+
+        Args:
+            line_name (str): Line name to attach
+        """
+
+        if line_name in self.lines_out:
+            _logger.debug(f"Line name: {line_name} already in {self.name} line_out")
+            return None
+        self.lines_out.add(line_name)
+        _logger.debug(f"Line name: {line_name} added to {self.name} line_out")
+
+    def attach_to_line(self, line_name: str) -> None:
+        """
+        Adds given line name to this Bus line "to" set.
+
+        Args:
+            line_name (str): Line name to attach
+        """
+
+        if line_name in self.lines_in:
+            _logger.debug(f"Line name: {line_name} already in {self.name} line_in")
+            return None
+        self.lines_in.add(line_name)
+        _logger.debug(f"Line name: {line_name} added to {self.name} line_in")
+
+    def _validate_dsr_mapping(
+        self, network: Network, exception_list: list[NetworkValidatorException]
+    ) -> None:
+        if self.dsr_type is not None:
+            if not isinstance(self.dsr_type, str):
+                exception_list.append(
+                    NetworkValidatorException(
+                        f"DSR type must be type of str, not type {type(self.dsr_type).__name__}"
+                    )
+                )
+            elif self.dsr_type not in network.dsr:
+                exception_list.append(
+                    NetworkValidatorException(
+                        f"DSR type {self.dsr_type} does not exist in Network DSR"
+                    )
+                )
+        _logger.debug("Validate dsr mapping: OK")
```

### Comparing `pyzefir-0.4.1/pyzefir/model/network_elements/capacity_factor.py` & `pyzefir-0.4.22/pyzefir/model/network_elements/capacity_factor.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,74 +1,80 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-from __future__ import annotations
-
-from dataclasses import dataclass
-from typing import TYPE_CHECKING
-
-import pandas as pd
-
-from pyzefir.model.exceptions import (
-    NetworkValidatorException,
-    NetworkValidatorExceptionGroup,
-)
-from pyzefir.model.network_element import NetworkElement
-from pyzefir.model.utils import validate_series
-
-if TYPE_CHECKING:
-    from pyzefir.model.network import Network
-
-
-class CapacityFactorValidatorExceptionGroup(NetworkValidatorExceptionGroup):
-    pass
-
-
-@dataclass
-class CapacityFactor(NetworkElement):
-    """
-    A class that represents the CapacityFactor in the network structureCapacity which defines generation profile
-    from 1 unit of power for various non-dispatchable generators (i.e. pv, wind, ...).
-    """
-
-    profile: pd.Series
-    """
-    An hourly data series representing capacity factor
-    """
-
-    def validate(self, network: Network) -> None:
-        """
-        Validation procedure checking:
-        - if profile is not none and is correct type
-
-        Args:
-            network (Network): network to which the CapacityFactor belongs
-        """
-        exception_list: list[NetworkValidatorException] = []
-
-        self._validate_name_type(exception_list)
-        validate_series(
-            name="Profile",
-            series=self.profile,
-            length=network.constants.n_hours,
-            exception_list=exception_list,
-            allow_null=False,
-        )
-
-        if exception_list:
-            raise CapacityFactorValidatorExceptionGroup(
-                f"While adding Capacity Factor {self.name} following errors occurred: ",
-                exception_list,
-            )
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+from __future__ import annotations
+
+import logging
+from dataclasses import dataclass
+from typing import TYPE_CHECKING
+
+import pandas as pd
+
+from pyzefir.model.exceptions import (
+    NetworkValidatorException,
+    NetworkValidatorExceptionGroup,
+)
+from pyzefir.model.network_element import NetworkElement
+from pyzefir.model.utils import validate_series
+
+_logger = logging.getLogger(__name__)
+
+if TYPE_CHECKING:
+    from pyzefir.model.network import Network
+
+
+class CapacityFactorValidatorExceptionGroup(NetworkValidatorExceptionGroup):
+    pass
+
+
+@dataclass
+class CapacityFactor(NetworkElement):
+    """
+    A class that represents the CapacityFactor in the network structureCapacity which defines generation profile
+    from 1 unit of power for various non-dispatchable generators (i.e. pv, wind, ...).
+    """
+
+    profile: pd.Series
+    """
+    An hourly data series representing capacity factor
+    """
+
+    def validate(self, network: Network) -> None:
+        """
+        Validation procedure checking:
+        - if profile is not none and is correct type
+
+        Args:
+            network (Network): network to which the CapacityFactor belongs
+        """
+        _logger.debug("Validating capacity factor object: %s...", self.name)
+        exception_list: list[NetworkValidatorException] = []
+
+        self._validate_name_type(exception_list)
+        validate_series(
+            name="Profile",
+            series=self.profile,
+            length=network.constants.n_hours,
+            exception_list=exception_list,
+            allow_null=False,
+        )
+
+        if exception_list:
+            _logger.debug("Got error validating capacity factor: %s", exception_list)
+            raise CapacityFactorValidatorExceptionGroup(
+                f"While adding Capacity Factor {self.name} following errors occurred: ",
+                exception_list,
+            )
+        _logger.debug("Capacity factor %s validation: Done", self.name)
```

### Comparing `pyzefir-0.4.1/pyzefir/model/network_elements/demand_chunk.py` & `pyzefir-0.4.22/pyzefir/model/network_elements/demand_chunk.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,176 +1,183 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-from __future__ import annotations
-
-from dataclasses import dataclass
-from typing import TYPE_CHECKING
-
-import numpy as np
-
-from pyzefir.model.exceptions import (
-    NetworkValidatorException,
-    NetworkValidatorExceptionGroup,
-)
-from pyzefir.model.network_element import NetworkElement
-
-if TYPE_CHECKING:
-    from pyzefir.model.network import Network
-
-
-class DemandChunkValidatorExceptionGroup(NetworkValidatorExceptionGroup):
-    pass
-
-
-@dataclass
-class DemandChunk(NetworkElement):
-    """
-    Demand chunk parameters
-    """
-
-    tag: str
-    """
-    Demand chunk tag
-    """
-    energy_type: str
-    """
-    Demand chunk energy type
-    """
-    periods: np.ndarray
-    """
-    Periods array with shape (n_periods, 2) where each row contains hour index of period_start and period_end
-    """
-    demand: np.ndarray
-    """
-    2D matrix with shape (n_periods, n_years), indicates energy demand for every period in every year
-    """
-
-    def _validate_periods_and_demand(
-        self,
-        exception_list: list[NetworkValidatorException],
-        network: Network,
-    ) -> None:
-        """
-        Validate periods and demand parameters
-            - check if periods and demand have the same length
-            - check if periods have 2 columns
-            - check if periods are in the format (start, end)
-            - check if demand has n_years columns
-            - check if periods are type of int
-            - check if demand is type of float
-
-        Args:
-            exception_list (list[NetworkValidatorException]): List of exceptions
-                to which new exceptions will be added
-            network (Network): Network object to which this object belongs
-        """
-        if len(self.periods) != len(self.demand):
-            exception_list.append(
-                NetworkValidatorException(
-                    f"Length of periods ({len(self.periods)}) and demand ({len(self.demand)}) should be the same"
-                )
-            )
-
-        if self.periods.shape[1] != 2:
-            exception_list.append(
-                NetworkValidatorException(
-                    f"Periods should have 2 columns, not {self.periods.shape[1]}"
-                )
-            )
-        elif not np.array(self.periods[:, 0] < self.periods[:, 1]).all():
-            exception_list.append(
-                NetworkValidatorException(
-                    "Periods should be in the format (start, end), not (end, start)"
-                )
-            )
-
-        if self.demand.shape[1] != network.constants.n_years:
-            exception_list.append(
-                NetworkValidatorException(
-                    f"Demand should have {network.constants.n_years} columns, not {self.demand.shape[1]}"
-                )
-            )
-
-        if not np.issubdtype(self.periods.dtype, np.integer):
-            exception_list.append(
-                NetworkValidatorException(
-                    f"Periods should be type of int, not {self.periods.dtype}"
-                )
-            )
-
-        if not np.issubdtype(self.demand.dtype, np.floating) and not np.issubdtype(
-            self.demand.dtype, np.integer
-        ):
-            exception_list.append(
-                NetworkValidatorException(
-                    f"Demand should be type of float, not {self.demand.dtype}"
-                )
-            )
-
-    def validate(self, network: Network) -> None:
-        """
-        Validate DemandChunk.
-            - validates if tag is correct type and present in network
-            - validates if energy type is correct type and present in network
-            - validates periods attribute
-            - validates demand attribute
-
-        Args:
-            network (Network): Network object to which this object belongs
-
-        Raises:
-            NetworkValidatorExceptionGroup: If any of the validation fails
-        """
-        exception_list: list[NetworkValidatorException] = []
-
-        if isinstance(self.tag, str):
-            if self.tag not in {
-                *[tag for gen in network.generators.values() for tag in gen.tags],
-                *[tag for stor in network.storages.values() for tag in stor.tags],
-            }:
-                exception_list.append(
-                    NetworkValidatorException(
-                        f"Tag {self.tag} is not defined in the network"
-                    )
-                )
-        else:
-            exception_list.append(
-                NetworkValidatorException(
-                    f"Tag {self.tag} should be type of str, not {type(self.tag).__name__}"
-                )
-            )
-
-        if isinstance(self.energy_type, str):
-            if self.energy_type not in network.energy_types:
-                exception_list.append(
-                    NetworkValidatorException(
-                        f"Energy type {self.energy_type} is not defined in the network"
-                    )
-                )
-        else:
-            exception_list.append(
-                NetworkValidatorException(
-                    f"Energy type {self.energy_type} should be type of str, not {type(self.energy_type).__name__}"
-                )
-            )
-
-        self._validate_periods_and_demand(exception_list, network)
-
-        if exception_list:
-            raise DemandChunkValidatorExceptionGroup(
-                f"While adding DemandChunk {self.name} " "following errors occurred: ",
-                exception_list,
-            )
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+from __future__ import annotations
+
+import logging
+from dataclasses import dataclass
+from typing import TYPE_CHECKING
+
+import numpy as np
+
+from pyzefir.model.exceptions import (
+    NetworkValidatorException,
+    NetworkValidatorExceptionGroup,
+)
+from pyzefir.model.network_element import NetworkElement
+
+_logger = logging.getLogger(name=__name__)
+
+if TYPE_CHECKING:
+    from pyzefir.model.network import Network
+
+
+class DemandChunkValidatorExceptionGroup(NetworkValidatorExceptionGroup):
+    pass
+
+
+@dataclass
+class DemandChunk(NetworkElement):
+    """
+    Demand chunk parameters
+    """
+
+    tag: str
+    """
+    Demand chunk tag
+    """
+    energy_type: str
+    """
+    Demand chunk energy type
+    """
+    periods: np.ndarray
+    """
+    Periods array with shape (n_periods, 2) where each row contains hour index of period_start and period_end
+    """
+    demand: np.ndarray
+    """
+    2D matrix with shape (n_periods, n_years), indicates energy demand for every period in every year
+    """
+
+    def _validate_periods_and_demand(
+        self,
+        exception_list: list[NetworkValidatorException],
+        network: Network,
+    ) -> None:
+        """
+        Validate periods and demand parameters
+            - check if periods and demand have the same length
+            - check if periods have 2 columns
+            - check if periods are in the format (start, end)
+            - check if demand has n_years columns
+            - check if periods are type of int
+            - check if demand is type of float
+
+        Args:
+            exception_list (list[NetworkValidatorException]): List of exceptions
+                to which new exceptions will be added
+            network (Network): Network object to which this object belongs
+        """
+        if len(self.periods) != len(self.demand):
+            exception_list.append(
+                NetworkValidatorException(
+                    f"Length of periods ({len(self.periods)}) and demand ({len(self.demand)}) should be the same"
+                )
+            )
+
+        if self.periods.shape[1] != 2:
+            exception_list.append(
+                NetworkValidatorException(
+                    f"Periods should have 2 columns, not {self.periods.shape[1]}"
+                )
+            )
+        elif not np.array(self.periods[:, 0] < self.periods[:, 1]).all():
+            exception_list.append(
+                NetworkValidatorException(
+                    "Periods should be in the format (start, end), not (end, start)"
+                )
+            )
+
+        if self.demand.shape[1] != network.constants.n_years:
+            exception_list.append(
+                NetworkValidatorException(
+                    f"Demand should have {network.constants.n_years} columns, not {self.demand.shape[1]}"
+                )
+            )
+
+        if not np.issubdtype(self.periods.dtype, np.integer):
+            exception_list.append(
+                NetworkValidatorException(
+                    f"Periods should be type of int, not {self.periods.dtype}"
+                )
+            )
+
+        if not np.issubdtype(self.demand.dtype, np.floating) and not np.issubdtype(
+            self.demand.dtype, np.integer
+        ):
+            exception_list.append(
+                NetworkValidatorException(
+                    f"Demand should be type of float, not {self.demand.dtype}"
+                )
+            )
+        _logger.debug("Validate periods and demands: OK")
+
+    def validate(self, network: Network) -> None:
+        """
+        Validate DemandChunk.
+            - validates if tag is correct type and present in network
+            - validates if energy type is correct type and present in network
+            - validates periods attribute
+            - validates demand attribute
+
+        Args:
+            network (Network): Network object to which this object belongs
+
+        Raises:
+            NetworkValidatorExceptionGroup: If any of the validation fails
+        """
+        _logger.debug("Validating demand chunk object: %s...", self.name)
+        exception_list: list[NetworkValidatorException] = []
+
+        if isinstance(self.tag, str):
+            if self.tag not in {
+                *[tag for gen in network.generators.values() for tag in gen.tags],
+                *[tag for stor in network.storages.values() for tag in stor.tags],
+            }:
+                exception_list.append(
+                    NetworkValidatorException(
+                        f"Tag {self.tag} is not defined in the network"
+                    )
+                )
+        else:
+            exception_list.append(
+                NetworkValidatorException(
+                    f"Tag {self.tag} should be type of str, not {type(self.tag).__name__}"
+                )
+            )
+
+        if isinstance(self.energy_type, str):
+            if self.energy_type not in network.energy_types:
+                exception_list.append(
+                    NetworkValidatorException(
+                        f"Energy type {self.energy_type} is not defined in the network"
+                    )
+                )
+        else:
+            exception_list.append(
+                NetworkValidatorException(
+                    f"Energy type {self.energy_type} should be type of str, not {type(self.energy_type).__name__}"
+                )
+            )
+
+        self._validate_periods_and_demand(exception_list, network)
+
+        if exception_list:
+            _logger.debug("Got error validating demand chunk: %s", exception_list)
+            raise DemandChunkValidatorExceptionGroup(
+                f"While adding DemandChunk {self.name} " "following errors occurred: ",
+                exception_list,
+            )
+        _logger.debug("Demand chunk %s validation: Done", self.name)
```

### Comparing `pyzefir-0.4.1/pyzefir/model/network_elements/demand_profile.py` & `pyzefir-0.4.22/pyzefir/model/network_elements/demand_profile.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,115 +1,122 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-from __future__ import annotations
-
-import math
-from dataclasses import dataclass
-from typing import TYPE_CHECKING
-
-import pandas as pd
-
-from pyzefir.model.exceptions import (
-    NetworkValidatorException,
-    NetworkValidatorExceptionGroup,
-)
-from pyzefir.model.network_element import NetworkElement
-from pyzefir.model.utils import validate_dict_type
-
-if TYPE_CHECKING:
-    from pyzefir.model.network import Network
-
-
-class DemandProfileValidatorExceptionGroup(NetworkValidatorExceptionGroup):
-    pass
-
-
-@dataclass
-class DemandProfile(NetworkElement):
-    """
-    Energy demand profile parameters
-    """
-
-    normalized_profile: dict[str, pd.Series]
-    """
-    Parameter that represents an hourly data series for a given type of energy,
-    each series should be normalized and sum up to 1
-    """
-
-    def _validate_normalized_profile(
-        self, network: Network, exception_list: list[NetworkValidatorException]
-    ) -> None:
-        """
-        Validate normalized_profile parameter
-            - check if demand has the same length for every energy type in the network,
-            - check if demand is normalized
-        Args:
-            network (Network): Network object to which this object belongs
-            exception_list (list[NetworkValidatorException]): List of exceptions
-                to which new exceptions will be added
-        """
-        for energy_type, profile in self.normalized_profile.items():
-            # check if demand is normalized
-            if not (
-                profile.between(0, 1).all()
-                and math.isclose(profile.sum(), 1, rel_tol=1e-5)
-            ):
-                exception_list.append(
-                    NetworkValidatorException(
-                        f"Energy type {energy_type} is not normalized"
-                    )
-                )
-
-        # check if all demands are same length
-        if len({len(profile) for profile in self.normalized_profile.values()}) > 1:
-            exception_list.append(
-                NetworkValidatorException(
-                    "Normalized profile has different length for different energy types"
-                )
-            )
-
-    def validate(self, network: Network) -> None:
-        """
-        Validate AggregatedConsumer.
-            - validate normalized_profile
-
-        Args:
-            network (Network): Network object to which this object belongs
-
-        Raises:
-            NetworkValidatorExceptionGroup: If any of the validation fails
-        """
-        exception_list: list[NetworkValidatorException] = []
-        self._validate_name_type(exception_list)
-        if validate_dict_type(
-            dict_to_validate=self.normalized_profile,
-            key_type=str,
-            value_type=pd.Series,
-            parameter_name="Normalized profile",
-            key_parameter_name="Energy type",
-            value_parameter_name="Demand series",
-            exception_list=exception_list,
-        ):
-            self._validate_normalized_profile(
-                network=network, exception_list=exception_list
-            )
-
-        if exception_list:
-            raise DemandProfileValidatorExceptionGroup(
-                f"While adding DemandProfile {self.name} "
-                "following errors occurred: ",
-                exception_list,
-            )
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+from __future__ import annotations
+
+import logging
+import math
+from dataclasses import dataclass
+from typing import TYPE_CHECKING
+
+import pandas as pd
+
+from pyzefir.model.exceptions import (
+    NetworkValidatorException,
+    NetworkValidatorExceptionGroup,
+)
+from pyzefir.model.network_element import NetworkElement
+from pyzefir.model.utils import validate_dict_type
+
+_logger = logging.getLogger(__name__)
+
+if TYPE_CHECKING:
+    from pyzefir.model.network import Network
+
+
+class DemandProfileValidatorExceptionGroup(NetworkValidatorExceptionGroup):
+    pass
+
+
+@dataclass
+class DemandProfile(NetworkElement):
+    """
+    Energy demand profile parameters
+    """
+
+    normalized_profile: dict[str, pd.Series]
+    """
+    Parameter that represents an hourly data series for a given type of energy,
+    each series should be normalized and sum up to 1
+    """
+
+    def _validate_normalized_profile(
+        self, network: Network, exception_list: list[NetworkValidatorException]
+    ) -> None:
+        """
+        Validate normalized_profile parameter
+            - check if demand has the same length for every energy type in the network,
+            - check if demand is normalized
+        Args:
+            network (Network): Network object to which this object belongs
+            exception_list (list[NetworkValidatorException]): List of exceptions
+                to which new exceptions will be added
+        """
+        for energy_type, profile in self.normalized_profile.items():
+            # check if demand is normalized
+            if not (
+                profile.between(0, 1).all()
+                and math.isclose(profile.sum(), 1, rel_tol=1e-5)
+            ):
+                exception_list.append(
+                    NetworkValidatorException(
+                        f"Energy type {energy_type} is not normalized"
+                    )
+                )
+
+        # check if all demands are same length
+        if len({len(profile) for profile in self.normalized_profile.values()}) > 1:
+            exception_list.append(
+                NetworkValidatorException(
+                    "Normalized profile has different length for different energy types"
+                )
+            )
+        _logger.debug("Validate normalized profile: OK")
+
+    def validate(self, network: Network) -> None:
+        """
+        Validate AggregatedConsumer.
+            - validate normalized_profile
+
+        Args:
+            network (Network): Network object to which this object belongs
+
+        Raises:
+            NetworkValidatorExceptionGroup: If any of the validation fails
+        """
+        _logger.debug("Validating demand profile object: %s...", self.name)
+        exception_list: list[NetworkValidatorException] = []
+        self._validate_name_type(exception_list)
+        if validate_dict_type(
+            dict_to_validate=self.normalized_profile,
+            key_type=str,
+            value_type=pd.Series,
+            parameter_name="Normalized profile",
+            key_parameter_name="Energy type",
+            value_parameter_name="Demand series",
+            exception_list=exception_list,
+        ):
+            self._validate_normalized_profile(
+                network=network, exception_list=exception_list
+            )
+
+        if exception_list:
+            _logger.debug("Got error validating demand profile: %s", exception_list)
+            raise DemandProfileValidatorExceptionGroup(
+                f"While adding DemandProfile {self.name} "
+                "following errors occurred: ",
+                exception_list,
+            )
+        _logger.debug("Demand profile %s validation: Done", self.name)
```

### Comparing `pyzefir-0.4.1/pyzefir/model/network_elements/dsr.py` & `pyzefir-0.4.22/pyzefir/model/network_elements/dsr.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,115 +1,121 @@
-# PyZefir
-# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-from __future__ import annotations
-
-from typing import TYPE_CHECKING
-
-from pyzefir.model.utils import check_interval
-
-if TYPE_CHECKING:
-    from pyzefir.model.network import Network
-
-from dataclasses import dataclass, fields
-
-from pyzefir.model.exceptions import (
-    NetworkValidatorException,
-    NetworkValidatorExceptionGroup,
-)
-from pyzefir.model.network_element import NetworkElement
-
-
-class DSRValidatorExceptionGroup(NetworkValidatorExceptionGroup):
-    pass
-
-
-@dataclass
-class DSR(NetworkElement):
-    name: str
-    """
-    Names of individual DSR
-    """
-    compensation_factor: float
-    """
-    Compensation factor in the both closed range [0,1]
-    """
-    balancing_period_len: int
-    """
-    Number of hours determining the length of the balancing period of DSR
-    """
-    penalization: float
-    """
-    Penalization of demand shift per unit of energy [PLN / xWh]
-    """
-    relative_shift_limit: float | None = None
-    """
-    Maximum total shift against total net injection at a node during this period,
-    in the both opened range (0,1)
-    """
-    abs_shift_limit: float | None = None
-    """
-    Maximum total shift per period
-    """
-
-    def validate(self, network: Network) -> None:
-        """
-        Validation procedure checking:
-        - All attributes have correct types
-        - Compensation factor value in the both closed range [0,1]
-        - Relative shift limit value in the both opened range (0,1)
-
-        Args:
-            network (Network): Network object to which this object belongs
-
-        Raises:
-            NetworkValidatorExceptionGroup: If any of the validation fails
-
-        """
-        exception_list: list[NetworkValidatorException] = []
-
-        self._validate(exception_list)
-
-        if exception_list:
-            raise DSRValidatorExceptionGroup(
-                f"While adding DSR {self.name} following errors occurred: ",
-                exception_list,
-            )
-
-    def _validate(self, exception_list: list[NetworkValidatorException]) -> None:
-        for field in fields(self):
-            self._validate_attribute_type(
-                field.name, eval(str(field.type)), exception_list
-            )
-
-        if self.compensation_factor is not None and not check_interval(
-            lower_bound=0, upper_bound=1, value=self.compensation_factor
-        ):
-            exception_list.append(
-                NetworkValidatorException(
-                    f"The value of the compensation_factor is inconsistent with th expected bounds of "
-                    f"the interval: 0 <= {self.compensation_factor} <= 1"
-                )
-            )
-
-        if self.relative_shift_limit is not None and not check_interval(
-            lower_bound=0, upper_bound=1, value=self.relative_shift_limit
-        ):
-            exception_list.append(
-                NetworkValidatorException(
-                    f"The value of the relative_shift_limit is inconsistent with th expected bounds of "
-                    f"the interval: 0 < {self.relative_shift_limit} < 1"
-                )
-            )
+# PyZefir
+# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+from __future__ import annotations
+
+import logging
+from typing import TYPE_CHECKING
+
+from pyzefir.model.utils import check_interval
+
+if TYPE_CHECKING:
+    from pyzefir.model.network import Network
+
+from dataclasses import dataclass, fields
+
+from pyzefir.model.exceptions import (
+    NetworkValidatorException,
+    NetworkValidatorExceptionGroup,
+)
+from pyzefir.model.network_element import NetworkElement
+
+_logger = logging.getLogger(__name__)
+
+
+class DSRValidatorExceptionGroup(NetworkValidatorExceptionGroup):
+    pass
+
+
+@dataclass
+class DSR(NetworkElement):
+    name: str
+    """
+    Names of individual DSR
+    """
+    compensation_factor: float
+    """
+    Compensation factor in the both closed range [0,1]
+    """
+    balancing_period_len: int
+    """
+    Number of hours determining the length of the balancing period of DSR
+    """
+    penalization: float
+    """
+    Penalization of demand shift per unit of energy [PLN / xWh]
+    """
+    relative_shift_limit: float | None = None
+    """
+    Maximum total shift against total net injection at a node during this period,
+    in the both opened range (0,1)
+    """
+    abs_shift_limit: float | None = None
+    """
+    Maximum total shift per period
+    """
+
+    def validate(self, network: Network) -> None:
+        """
+        Validation procedure checking:
+        - All attributes have correct types
+        - Compensation factor value in the both closed range [0,1]
+        - Relative shift limit value in the both opened range (0,1)
+
+        Args:
+            network (Network): Network object to which this object belongs
+
+        Raises:
+            NetworkValidatorExceptionGroup: If any of the validation fails
+
+        """
+        _logger.debug("Validating DSR object: %s...", self.name)
+        exception_list: list[NetworkValidatorException] = []
+
+        self._validate(exception_list)
+
+        if exception_list:
+            _logger.debug("Got error validating DSR: %s", exception_list)
+            raise DSRValidatorExceptionGroup(
+                f"While adding DSR {self.name} following errors occurred: ",
+                exception_list,
+            )
+        _logger.debug("DSR %s validation: Done", self.name)
+
+    def _validate(self, exception_list: list[NetworkValidatorException]) -> None:
+        for field in fields(self):
+            self._validate_attribute_type(
+                field.name, eval(str(field.type)), exception_list
+            )
+
+        if self.compensation_factor is not None and not check_interval(
+            lower_bound=0, upper_bound=1, value=self.compensation_factor
+        ):
+            exception_list.append(
+                NetworkValidatorException(
+                    f"The value of the compensation_factor is inconsistent with th expected bounds of "
+                    f"the interval: 0 <= {self.compensation_factor} <= 1"
+                )
+            )
+
+        if self.relative_shift_limit is not None and not check_interval(
+            lower_bound=0, upper_bound=1, value=self.relative_shift_limit
+        ):
+            exception_list.append(
+                NetworkValidatorException(
+                    f"The value of the relative_shift_limit is inconsistent with th expected bounds of "
+                    f"the interval: 0 < {self.relative_shift_limit} < 1"
+                )
+            )
```

### Comparing `pyzefir-0.4.1/pyzefir/model/network_elements/emission_fee.py` & `pyzefir-0.4.22/pyzefir/model/network_elements/emission_fee.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,86 +1,92 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-from __future__ import annotations
-
-from dataclasses import dataclass
-from typing import TYPE_CHECKING
-
-import numpy as np
-import pandas as pd
-
-from pyzefir.model.exceptions import (
-    NetworkValidatorException,
-    NetworkValidatorExceptionGroup,
-)
-from pyzefir.model.network_element import NetworkElement
-from pyzefir.model.utils import validate_series
-
-if TYPE_CHECKING:
-    from pyzefir.model.network import Network
-
-
-class EmissionFeeValidatorExceptionGroup(NetworkValidatorExceptionGroup):
-    pass
-
-
-@dataclass(kw_only=True)
-class EmissionFee(NetworkElement):
-    """
-    A class that represents the Emission Fee element in the network structure
-    """
-
-    emission_type: str
-    """ Name of the emission type """
-    price: pd.Series
-    """ Amount of a given emission fee in particular years"""
-
-    def validate(self, network: Network) -> None:
-        """
-        Validation procedure checking:
-        - if emission_type is in the network
-        - if the price is a correct pd.Series
-
-        Args:
-            network (Network): Network to which EmissionFee is to be added.
-
-        Raises:
-            NetworkValidatorExceptionGroup: If any of the validations fails.
-        """
-        exception_list: list[NetworkValidatorException] = []
-
-        if self.emission_type not in network.emission_types:
-            exception_list.append(
-                NetworkValidatorException(
-                    f"Emission type: {self.emission_type} does not exist in the network"
-                )
-            )
-
-        validate_series(
-            name="EmissionFee",
-            series=self.price,
-            length=network.constants.n_years,
-            exception_list=exception_list,
-            index_type=np.integer,
-            values_type=np.floating,
-            allow_null=False,
-        )
-
-        if exception_list:
-            raise EmissionFeeValidatorExceptionGroup(
-                f"While adding EmissionFee {self.name} following errors occurred: ",
-                exception_list,
-            )
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+from __future__ import annotations
+
+import logging
+from dataclasses import dataclass
+from typing import TYPE_CHECKING
+
+import numpy as np
+import pandas as pd
+
+from pyzefir.model.exceptions import (
+    NetworkValidatorException,
+    NetworkValidatorExceptionGroup,
+)
+from pyzefir.model.network_element import NetworkElement
+from pyzefir.model.utils import validate_series
+
+if TYPE_CHECKING:
+    from pyzefir.model.network import Network
+
+_logger = logging.getLogger(name=__name__)
+
+
+class EmissionFeeValidatorExceptionGroup(NetworkValidatorExceptionGroup):
+    pass
+
+
+@dataclass(kw_only=True)
+class EmissionFee(NetworkElement):
+    """
+    A class that represents the Emission Fee element in the network structure
+    """
+
+    emission_type: str
+    """ Name of the emission type """
+    price: pd.Series
+    """ Amount of a given emission fee in particular years"""
+
+    def validate(self, network: Network) -> None:
+        """
+        Validation procedure checking:
+        - if emission_type is in the network
+        - if the price is a correct pd.Series
+
+        Args:
+            network (Network): Network to which EmissionFee is to be added.
+
+        Raises:
+            NetworkValidatorExceptionGroup: If any of the validations fails.
+        """
+        _logger.debug("Validating emission fee element object: %s...", self.name)
+        exception_list: list[NetworkValidatorException] = []
+
+        if self.emission_type not in network.emission_types:
+            exception_list.append(
+                NetworkValidatorException(
+                    f"Emission type: {self.emission_type} does not exist in the network"
+                )
+            )
+
+        validate_series(
+            name="EmissionFee",
+            series=self.price,
+            length=network.constants.n_years,
+            exception_list=exception_list,
+            index_type=np.integer,
+            values_type=np.floating,
+            allow_null=False,
+        )
+
+        if exception_list:
+            _logger.debug("Got error validating emission fee: %s", exception_list)
+            raise EmissionFeeValidatorExceptionGroup(
+                f"While adding EmissionFee {self.name} following errors occurred: ",
+                exception_list,
+            )
+        _logger.debug("Emission fee element %s validation: Done", self.name)
```

### Comparing `pyzefir-0.4.1/pyzefir/model/network_elements/energy_source_types/__init__.py` & `pyzefir-0.4.22/pyzefir/structure_creator/data_loader/__init__.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,15 +1,15 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+# PyZefir
+# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
```

### Comparing `pyzefir-0.4.1/pyzefir/model/network_elements/energy_source_types/energy_source_type_base.py` & `pyzefir-0.4.22/pyzefir/model/network_elements/energy_source_types/energy_source_type_base.py`

 * *Ordering differences only*

 * *Files 20% similar despite different names*

```diff
@@ -1,141 +1,141 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-from __future__ import annotations
-
-from abc import ABC
-from dataclasses import dataclass, field
-from typing import TYPE_CHECKING
-
-import pandas as pd
-
-from pyzefir.model.exceptions import NetworkValidatorException
-from pyzefir.model.network_element import NetworkElement
-from pyzefir.model.utils import validate_series
-
-if TYPE_CHECKING:
-    from pyzefir.model.network import Network
-
-
-@dataclass(kw_only=True)
-class EnergySourceType(NetworkElement, ABC):
-    """
-    An abstract class that defines the core attributes for each energy source type
-    """
-
-    name: str
-    """
-    Unique type name
-    """
-    life_time: int
-    """
-    Life time of added/installed capacity
-    """
-    build_time: int
-    """
-    Number of years needed to build new capacity
-    """
-    capex: pd.Series
-    """
-    Investment cost [$/1 unit of added capacity]
-    """
-    opex: pd.Series
-    """
-    Maintenance cost [$/1 unit of installed capacity]
-    """
-    min_capacity: pd.Series
-    """
-    Minimal amount of installed capacity of all units with this energy source type unit for a given year
-    """
-    max_capacity: pd.Series
-    """
-    Maximal amount of installed capacity of all units with this energy source type unit for a given year
-    """
-    min_capacity_increase: pd.Series
-    """
-    Maximal decrease of installed capacity of all units with this energy source type unit for a given year
-    """
-    max_capacity_increase: pd.Series
-    """
-    Minimal decrease of installed capacity of all units with this energy source type unit for a given year
-    """
-    tags: list[str] = field(default_factory=list)
-    """
-    Optional tag name list to group generator and storage types
-    """
-
-    def _validate_energy_source_type_base(
-        self,
-        network: Network,
-        exception_list: list[NetworkValidatorException],
-    ) -> None:
-        """
-        Validates base energy source type parameters:
-        - if attributes have proper type
-        - if series attributes have defined data rows for every year in a simulation
-        - if tags attribute is list of strings
-
-        Args:
-            exception_list (list[NetworkValidatorException]): list of exceptions to be raised
-        """
-        self._validate_name_type(exception_list)
-        self._validate_tags(exception_list)
-
-        for attr in ["life_time", "build_time"]:
-            if not isinstance(getattr(self, attr), int):
-                exception_list.append(
-                    NetworkValidatorException(
-                        f"Invalid {attr}."
-                        f" {attr.capitalize()} must be an integer, "
-                        f"not {type(getattr(self, attr)).__name__}"
-                    )
-                )
-
-        for attr in ["capex", "opex"]:
-            validate_series(
-                name=f"Energy source {attr}",
-                series=getattr(self, attr),
-                length=network.constants.n_years,
-                exception_list=exception_list,
-            )
-
-        for attr in [
-            "min_capacity",
-            "max_capacity",
-            "min_capacity_increase",
-            "max_capacity_increase",
-        ]:
-            series = getattr(self, attr)
-            if validate_series(
-                name=f"Energy source type {attr}",
-                series=series,
-                length=network.constants.n_years,
-                exception_list=exception_list,
-                is_numeric=True,
-            ) and not pd.isnull(series.iloc[0]):
-                exception_list.append(
-                    NetworkValidatorException(
-                        f"{attr.capitalize()} must have a NaN value for the base year"
-                    )
-                )
-
-    def _validate_tags(self, exception_list: list[NetworkValidatorException]) -> None:
-        if not isinstance(self.tags, list) or any(
-            not isinstance(t, str) for t in self.tags
-        ):
-            exception_list.append(
-                NetworkValidatorException(f"Invalid tags: {self.tags}. ")
-            )
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+from __future__ import annotations
+
+from abc import ABC
+from dataclasses import dataclass, field
+from typing import TYPE_CHECKING
+
+import pandas as pd
+
+from pyzefir.model.exceptions import NetworkValidatorException
+from pyzefir.model.network_element import NetworkElement
+from pyzefir.model.utils import validate_series
+
+if TYPE_CHECKING:
+    from pyzefir.model.network import Network
+
+
+@dataclass(kw_only=True)
+class EnergySourceType(NetworkElement, ABC):
+    """
+    An abstract class that defines the core attributes for each energy source type
+    """
+
+    name: str
+    """
+    Unique type name
+    """
+    life_time: int
+    """
+    Life time of added/installed capacity
+    """
+    build_time: int
+    """
+    Number of years needed to build new capacity
+    """
+    capex: pd.Series
+    """
+    Investment cost [$/1 unit of added capacity]
+    """
+    opex: pd.Series
+    """
+    Maintenance cost [$/1 unit of installed capacity]
+    """
+    min_capacity: pd.Series
+    """
+    Minimal amount of installed capacity of all units with this energy source type unit for a given year
+    """
+    max_capacity: pd.Series
+    """
+    Maximal amount of installed capacity of all units with this energy source type unit for a given year
+    """
+    min_capacity_increase: pd.Series
+    """
+    Maximal decrease of installed capacity of all units with this energy source type unit for a given year
+    """
+    max_capacity_increase: pd.Series
+    """
+    Minimal decrease of installed capacity of all units with this energy source type unit for a given year
+    """
+    tags: list[str] = field(default_factory=list)
+    """
+    Optional tag name list to group generator and storage types
+    """
+
+    def _validate_energy_source_type_base(
+        self,
+        network: Network,
+        exception_list: list[NetworkValidatorException],
+    ) -> None:
+        """
+        Validates base energy source type parameters:
+        - if attributes have proper type
+        - if series attributes have defined data rows for every year in a simulation
+        - if tags attribute is list of strings
+
+        Args:
+            exception_list (list[NetworkValidatorException]): list of exceptions to be raised
+        """
+        self._validate_name_type(exception_list)
+        self._validate_tags(exception_list)
+
+        for attr in ["life_time", "build_time"]:
+            if not isinstance(getattr(self, attr), int):
+                exception_list.append(
+                    NetworkValidatorException(
+                        f"Invalid {attr}."
+                        f" {attr.capitalize()} must be an integer, "
+                        f"not {type(getattr(self, attr)).__name__}"
+                    )
+                )
+
+        for attr in ["capex", "opex"]:
+            validate_series(
+                name=f"Energy source {attr}",
+                series=getattr(self, attr),
+                length=network.constants.n_years,
+                exception_list=exception_list,
+            )
+
+        for attr in [
+            "min_capacity",
+            "max_capacity",
+            "min_capacity_increase",
+            "max_capacity_increase",
+        ]:
+            series = getattr(self, attr)
+            if validate_series(
+                name=f"Energy source type {attr}",
+                series=series,
+                length=network.constants.n_years,
+                exception_list=exception_list,
+                is_numeric=True,
+            ) and not pd.isnull(series.iloc[0]):
+                exception_list.append(
+                    NetworkValidatorException(
+                        f"{attr.capitalize()} must have a NaN value for the base year"
+                    )
+                )
+
+    def _validate_tags(self, exception_list: list[NetworkValidatorException]) -> None:
+        if not isinstance(self.tags, list) or any(
+            not isinstance(t, str) for t in self.tags
+        ):
+            exception_list.append(
+                NetworkValidatorException(f"Invalid tags: {self.tags}. ")
+            )
```

### Comparing `pyzefir-0.4.1/pyzefir/model/network_elements/energy_sources/__init__.py` & `pyzefir-0.4.22/pyzefir/cli/__init__.py`

 * *Ordering differences only*

 * *Files 23% similar despite different names*

```diff
@@ -1,15 +1,15 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
```

### Comparing `pyzefir-0.4.1/pyzefir/model/network_elements/energy_sources/energy_source_base.py` & `pyzefir-0.4.22/pyzefir/model/network_elements/energy_sources/energy_source_base.py`

 * *Ordering differences only*

 * *Files 23% similar despite different names*

```diff
@@ -1,163 +1,163 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-from __future__ import annotations
-
-from abc import ABC
-from dataclasses import dataclass, field
-from typing import TYPE_CHECKING
-
-import pandas as pd
-
-from pyzefir.model.exceptions import NetworkValidatorException
-from pyzefir.model.network_element import NetworkElement
-from pyzefir.model.utils import validate_series
-
-if TYPE_CHECKING:
-    from pyzefir.model.network import Network
-
-
-@dataclass(kw_only=True)
-class EnergySource(NetworkElement, ABC):
-    """
-    A class holding individual parameters for a given element
-    """
-
-    energy_source_type: str
-    """
-    Unique name of energy source element type
-    """
-    unit_base_cap: float
-    """
-    Installed capacity of a given energy source in the initial year (starting condition of the optimization)
-    """
-    unit_min_capacity: pd.Series
-    """
-    Minimal amount of installed capacity of given energy source for a given year
-    """
-    unit_max_capacity: pd.Series
-    """
-    Maximal amount of installed capacity of given energy source for a given year
-    """
-    unit_min_capacity_increase: pd.Series
-    """
-    Maximal decrease of installed capacity of given energy source for a given year
-    """
-    unit_max_capacity_increase: pd.Series
-    """
-    Minimal decrease of installed capacity of given energy source for a given year
-    """
-    min_device_nom_power: float | None = None
-    """
-    Minimal device nominal power for single device
-    """
-    max_device_nom_power: float | None = None
-    """
-    Maximum device nominal power for single device
-    """
-    tags: list[str] = field(default_factory=list)
-    """
-    Optional tag name list to group generators and storages
-    """
-
-    def _validate_device_nominal_power(
-        self,
-        nom_power_name: str,
-        exception_list: list[NetworkValidatorException],
-    ) -> None:
-        nom_power = getattr(self, nom_power_name)
-        if not isinstance(nom_power, int | float | None):
-            exception_list.append(
-                NetworkValidatorException(
-                    f"Invalid {nom_power_name}. "
-                    f"{nom_power_name} must be an instance of one of the types: float, int or None, "
-                    f"not {type(nom_power).__name__}"
-                )
-            )
-        elif nom_power is not None and not nom_power >= 0:
-            exception_list.append(
-                NetworkValidatorException(
-                    f"{nom_power_name.capitalize()} has invalid value. "
-                    f"It must be greater or equal to zero, but it is: {nom_power}"
-                )
-            )
-
-    def _validate_base_energy_source(
-        self, network: Network, exception_list: list[NetworkValidatorException]
-    ) -> None:
-        """
-        Validates base energy source parameters:
-        - if energy_source_type is proper string
-        - if unit_base_cap is numeric
-        - if tags attribute is list of strings
-
-        Method validate runs following validate methods:
-        - _validate_device_nominal_power
-
-        Args:
-            network (Network): network to which self is to be added
-
-        Raises:
-            NetworkValidatorExceptionGroup: If exception_list contains exception.
-        """
-        self._validate_name_type(exception_list)
-        if not isinstance(self.energy_source_type, str):
-            exception_list.append(
-                NetworkValidatorException(
-                    f"Invalid energy source type."
-                    " Energy source type must be a string, "
-                    f"not {type(self.energy_source_type).__name__}"
-                )
-            )
-
-        if not isinstance(self.unit_base_cap, (int, float)):
-            exception_list.append(
-                NetworkValidatorException(
-                    f"Invalid unit base capacity. "
-                    "Unit base capacity must be numeric, "
-                    f"not {type(self.unit_base_cap).__name__}"
-                )
-            )
-
-        if not isinstance(self.tags, list) or any(
-            not isinstance(t, str) for t in self.tags
-        ):
-            exception_list.append(
-                NetworkValidatorException(f"Invalid tags: {self.tags}. ")
-            )
-
-        for attr in [
-            "unit_min_capacity",
-            "unit_max_capacity",
-            "unit_min_capacity_increase",
-            "unit_max_capacity_increase",
-        ]:
-            series = getattr(self, attr)
-            if validate_series(
-                name=f"{attr.capitalize()}",
-                series=series,
-                length=network.constants.n_years,
-                exception_list=exception_list,
-                is_numeric=True,
-            ) and not pd.isnull(series.iloc[0]):
-                exception_list.append(
-                    NetworkValidatorException(
-                        f"{attr.capitalize()} must have a NaN value for the base year"
-                    )
-                )
-
-        self._validate_device_nominal_power("min_device_nom_power", exception_list)
-        self._validate_device_nominal_power("max_device_nom_power", exception_list)
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+from __future__ import annotations
+
+from abc import ABC
+from dataclasses import dataclass, field
+from typing import TYPE_CHECKING
+
+import pandas as pd
+
+from pyzefir.model.exceptions import NetworkValidatorException
+from pyzefir.model.network_element import NetworkElement
+from pyzefir.model.utils import validate_series
+
+if TYPE_CHECKING:
+    from pyzefir.model.network import Network
+
+
+@dataclass(kw_only=True)
+class EnergySource(NetworkElement, ABC):
+    """
+    A class holding individual parameters for a given element
+    """
+
+    energy_source_type: str
+    """
+    Unique name of energy source element type
+    """
+    unit_base_cap: float
+    """
+    Installed capacity of a given energy source in the initial year (starting condition of the optimization)
+    """
+    unit_min_capacity: pd.Series
+    """
+    Minimal amount of installed capacity of given energy source for a given year
+    """
+    unit_max_capacity: pd.Series
+    """
+    Maximal amount of installed capacity of given energy source for a given year
+    """
+    unit_min_capacity_increase: pd.Series
+    """
+    Maximal decrease of installed capacity of given energy source for a given year
+    """
+    unit_max_capacity_increase: pd.Series
+    """
+    Minimal decrease of installed capacity of given energy source for a given year
+    """
+    min_device_nom_power: float | None = None
+    """
+    Minimal device nominal power for single device
+    """
+    max_device_nom_power: float | None = None
+    """
+    Maximum device nominal power for single device
+    """
+    tags: list[str] = field(default_factory=list)
+    """
+    Optional tag name list to group generators and storages
+    """
+
+    def _validate_device_nominal_power(
+        self,
+        nom_power_name: str,
+        exception_list: list[NetworkValidatorException],
+    ) -> None:
+        nom_power = getattr(self, nom_power_name)
+        if not isinstance(nom_power, int | float | None):
+            exception_list.append(
+                NetworkValidatorException(
+                    f"Invalid {nom_power_name}. "
+                    f"{nom_power_name} must be an instance of one of the types: float, int or None, "
+                    f"not {type(nom_power).__name__}"
+                )
+            )
+        elif nom_power is not None and not nom_power >= 0:
+            exception_list.append(
+                NetworkValidatorException(
+                    f"{nom_power_name.capitalize()} has invalid value. "
+                    f"It must be greater or equal to zero, but it is: {nom_power}"
+                )
+            )
+
+    def _validate_base_energy_source(
+        self, network: Network, exception_list: list[NetworkValidatorException]
+    ) -> None:
+        """
+        Validates base energy source parameters:
+        - if energy_source_type is proper string
+        - if unit_base_cap is numeric
+        - if tags attribute is list of strings
+
+        Method validate runs following validate methods:
+        - _validate_device_nominal_power
+
+        Args:
+            network (Network): network to which self is to be added
+
+        Raises:
+            NetworkValidatorExceptionGroup: If exception_list contains exception.
+        """
+        self._validate_name_type(exception_list)
+        if not isinstance(self.energy_source_type, str):
+            exception_list.append(
+                NetworkValidatorException(
+                    f"Invalid energy source type."
+                    " Energy source type must be a string, "
+                    f"not {type(self.energy_source_type).__name__}"
+                )
+            )
+
+        if not isinstance(self.unit_base_cap, (int, float)):
+            exception_list.append(
+                NetworkValidatorException(
+                    f"Invalid unit base capacity. "
+                    "Unit base capacity must be numeric, "
+                    f"not {type(self.unit_base_cap).__name__}"
+                )
+            )
+
+        if not isinstance(self.tags, list) or any(
+            not isinstance(t, str) for t in self.tags
+        ):
+            exception_list.append(
+                NetworkValidatorException(f"Invalid tags: {self.tags}. ")
+            )
+
+        for attr in [
+            "unit_min_capacity",
+            "unit_max_capacity",
+            "unit_min_capacity_increase",
+            "unit_max_capacity_increase",
+        ]:
+            series = getattr(self, attr)
+            if validate_series(
+                name=f"{attr.capitalize()}",
+                series=series,
+                length=network.constants.n_years,
+                exception_list=exception_list,
+                is_numeric=True,
+            ) and not pd.isnull(series.iloc[0]):
+                exception_list.append(
+                    NetworkValidatorException(
+                        f"{attr.capitalize()} must have a NaN value for the base year"
+                    )
+                )
+
+        self._validate_device_nominal_power("min_device_nom_power", exception_list)
+        self._validate_device_nominal_power("max_device_nom_power", exception_list)
```

### Comparing `pyzefir-0.4.1/pyzefir/model/network_elements/energy_sources/generator.py` & `pyzefir-0.4.22/pyzefir/model/network_elements/energy_sources/generator.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,265 +1,281 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-from __future__ import annotations
-
-from collections import defaultdict
-from dataclasses import InitVar, dataclass, field
-from typing import TYPE_CHECKING
-
-from pyzefir.model.exceptions import (
-    NetworkValidatorException,
-    NetworkValidatorExceptionGroup,
-)
-from pyzefir.model.network_elements import EnergySource, GeneratorType
-
-if TYPE_CHECKING:
-    from pyzefir.model.network import Network
-
-
-class GeneratorValidatorExceptionGroup(NetworkValidatorExceptionGroup):
-    pass
-
-
-@dataclass(kw_only=True)
-class Generator(EnergySource):
-    """
-    A class that represents the Generator element in the network structure
-    """
-
-    emission_fee: set[str] = field(default_factory=set)
-    """
-    Emission fee assigned to a given generator.
-    """
-    bus: InitVar[str | set[str]] = None
-    """
-    Bus name to which the Generator is attached. One generator may be attached to multiple buses.
-    """
-    buses: set[str] = field(init=False)
-
-    def _validate_buses_energy_types(
-        self, exception_list: list[NetworkValidatorException], network: Network
-    ) -> None:
-        bus_energy_type_dict = defaultdict(list)
-        for bus_name in self.buses:
-            if (bus := network.buses.get(bus_name)) is not None:
-                bus_energy_type_dict[bus.energy_type].append(bus.name)
-        for et, et_buses in bus_energy_type_dict.items():
-            if len(et_buses) > 1:
-                exception_list.append(
-                    NetworkValidatorException(
-                        f"Buses {sorted(et_buses)} have the same energy_type {et} which is not allowed"
-                    )
-                )
-
-    def _validate_buses(
-        self,
-        exception_list: list[NetworkValidatorException],
-        network: Network,
-        generator_type: GeneratorType,
-    ) -> None:
-        """
-        Validation procedure checking:
-        - Validates if bus name existing in network
-        - Validates if bus.energy_type match with generator energy types and inbound energy type
-        - Validates if buses attr of Generator is set or contains strings
-        - Validates if generator has conversion_rate for energy types
-
-        Args:
-            exception_list (NetworkValidatorException): list of raised exceptions.
-            network (Network): network to which self is to be added.
-            generator_type (GeneratorType): GeneratorType object
-        """
-        should_check_conversion_rate = True
-        if not all(isinstance(item, str) for item in self.buses):
-            exception_list.append(
-                NetworkValidatorException(
-                    "Generator attribute 'buses' must contain only strings"
-                )
-            )
-        self._validate_attribute_type(
-            attr="buses", attr_type=set, exception_list=exception_list
-        )
-
-        self._validate_buses_energy_types(
-            exception_list=exception_list, network=network
-        )
-        for bus_name in self.buses:
-            if bus_name not in network.buses:
-                exception_list.append(
-                    NetworkValidatorException(
-                        f"Cannot attach generator to a bus {bus_name} - bus does not exist in the network"
-                    )
-                )
-                should_check_conversion_rate = False
-            elif (
-                network.buses[bus_name].energy_type
-                not in generator_type.energy_types | generator_type.inbound_energy_type
-            ):
-                gen_en_types = sorted(
-                    list(
-                        generator_type.energy_types | generator_type.inbound_energy_type
-                    )
-                )
-                exception_list.append(
-                    NetworkValidatorException(
-                        f"Unable to attach generator to a bus {bus_name}. "
-                        f"Bus energy type ({network.buses[bus_name].energy_type}) "
-                        f"and generator energy types ({gen_en_types}) do not match"
-                    )
-                )
-                should_check_conversion_rate = False
-
-        if should_check_conversion_rate and (
-            diff := (
-                set(generator_type.conversion_rate.keys())
-                - set([network.buses.get(bus).energy_type for bus in self.buses])
-            )
-        ):
-            exception_list.append(
-                NetworkValidatorException(
-                    f"Conversion_rate for energy types: "
-                    f"{sorted(list(diff))} which are not in connected buses energy types"
-                )
-            )
-
-    def _validate_generator_type(
-        self,
-        exception_list: list[NetworkValidatorException],
-        network: Network,
-        generator_type: GeneratorType,
-    ) -> None:
-        """
-        Validate GeneratorType.
-            - Validates if generator_type is type of GeneratorType
-            - Validates if generator_type energy types are compliant with the network
-
-        Args:
-            exception_list (list[NetworkValidatorException]): List of exceptions
-                to which new exceptions will be added
-            network (Network): Network object to which this object belongs
-            generator_type (GeneratorType): GeneratorType object associated with this Generator
-        """
-        if generator_type is None:
-            exception_list.append(
-                NetworkValidatorException("Network does not contain generator type")
-            )
-            return
-        if not isinstance(generator_type, GeneratorType):
-            exception_list.append(
-                NetworkValidatorException(
-                    f"Generator type must be of type GeneratorType, but it is {type(generator_type)} instead."
-                )
-            )
-            return
-        gen_energy_types = [en_t for en_t in generator_type.energy_types]
-        if not generator_type.energy_types.issubset(network.energy_types):
-            exception_list.append(
-                NetworkValidatorException(
-                    f"Gen energy types: {gen_energy_types}"
-                    " are not compliant with the network"
-                    f" energy types: {sorted(network.energy_types)}"
-                )
-            )
-
-    def _validate_emission_fee(
-        self, network: Network, exception_list: list[NetworkValidatorException]
-    ) -> None:
-        """
-        Validation procedure checking:
-        - Validates emission_fee in network
-        - Validates emission_fee.emission_type are unique for given gen
-
-        Args:
-            exception_list (NetworkValidatorException): list of raised exceptions.
-            network (Network): network to which self is to be added.
-        """
-        emission_fee_types: set[str] = set()
-        network_emissions = network.emission_fees
-        for fee in self.emission_fee:
-            if fee not in network_emissions:
-                exception_list.append(
-                    NetworkValidatorException(
-                        f"Network does not contain Emission Fee: {fee} in its structure"
-                    )
-                )
-                continue
-            emission_type = network_emissions[fee].emission_type
-            if (
-                emission_type not in emission_fee_types
-                and len(
-                    duplicated_fees := {
-                        em
-                        for em in self.emission_fee
-                        if network_emissions[em].emission_type == emission_type
-                    }
-                )
-                > 1
-            ):
-                exception_list.append(
-                    NetworkValidatorException(
-                        f"There are fees: {sorted(list(duplicated_fees))} which"
-                        f" apply to the same type of emission: {emission_type}"
-                    )
-                )
-                emission_fee_types.add(emission_type)
-
-    def validate(self, network: Network) -> None:
-        """
-        Validation procedure checking:
-        - if network doesn't contain any generator type and generator type is None
-        - correctness of Generator object
-        - whether the Generator energy_type is in the energy_type of the network
-
-        Method validate runs following validate methods:
-        - _validate_base_energy_source
-        - _validate_generator_type
-        - _validate_buses
-
-        Args:
-            network (Network): Network to which Generator is to be added.
-
-        Raises:
-            NetworkValidatorExceptionGroup: If Generator is invalid.
-        """
-        exception_list: list[NetworkValidatorException] = []
-        self._validate_base_energy_source(
-            network=network, exception_list=exception_list
-        )
-        generator_type = network.generator_types.get(self.energy_source_type)
-        self._validate_generator_type(
-            exception_list=exception_list,
-            network=network,
-            generator_type=generator_type,
-        )
-        if isinstance(generator_type, GeneratorType):
-            self._validate_buses(
-                exception_list=exception_list,
-                network=network,
-                generator_type=generator_type,
-            )
-        self._validate_emission_fee(network=network, exception_list=exception_list)
-        if exception_list:
-            raise GeneratorValidatorExceptionGroup(
-                f"While adding Generator {self.name} with type {self.energy_source_type} following errors occurred: ",
-                exception_list,
-            )
-
-    def __post_init__(self, bus: str | set[str]) -> None:
-        if bus is None:
-            self.buses = set()
-        else:
-            self.buses = {bus} if isinstance(bus, str) else bus
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+from __future__ import annotations
+
+import logging
+from collections import defaultdict
+from dataclasses import InitVar, dataclass, field
+from typing import TYPE_CHECKING
+
+from pyzefir.model.exceptions import (
+    NetworkValidatorException,
+    NetworkValidatorExceptionGroup,
+)
+from pyzefir.model.network_elements import EnergySource, GeneratorType
+
+if TYPE_CHECKING:
+    from pyzefir.model.network import Network
+
+_logger = logging.getLogger(__name__)
+
+
+class GeneratorValidatorExceptionGroup(NetworkValidatorExceptionGroup):
+    pass
+
+
+@dataclass(kw_only=True)
+class Generator(EnergySource):
+    """
+    A class that represents the Generator element in the network structure
+    """
+
+    emission_fee: set[str] = field(default_factory=set)
+    """
+    Emission fee assigned to a given generator.
+    """
+    bus: InitVar[str | set[str]] = None
+    """
+    Bus name to which the Generator is attached. One generator may be attached to multiple buses.
+    """
+    buses: set[str] = field(init=False)
+    """
+    Collection of all buses attached to the generator.
+    """
+    generator_binding: str | None = None
+    """
+    Identifier of the generator binding.
+    """
+
+    def _validate_buses_energy_types(
+        self, exception_list: list[NetworkValidatorException], network: Network
+    ) -> None:
+        bus_energy_type_dict = defaultdict(list)
+        for bus_name in self.buses:
+            if (bus := network.buses.get(bus_name)) is not None:
+                bus_energy_type_dict[bus.energy_type].append(bus.name)
+        for et, et_buses in bus_energy_type_dict.items():
+            if len(et_buses) > 1:
+                exception_list.append(
+                    NetworkValidatorException(
+                        f"Buses {sorted(et_buses)} have the same energy_type {et} which is not allowed"
+                    )
+                )
+
+    def _validate_buses(
+        self,
+        exception_list: list[NetworkValidatorException],
+        network: Network,
+        generator_type: GeneratorType,
+    ) -> None:
+        """
+        Validation procedure checking:
+        - Validates if bus name existing in network
+        - Validates if bus.energy_type match with generator energy types and inbound energy type
+        - Validates if buses attr of Generator is set or contains strings
+        - Validates if generator has conversion_rate for energy types
+
+        Args:
+            exception_list (NetworkValidatorException): list of raised exceptions.
+            network (Network): network to which self is to be added.
+            generator_type (GeneratorType): GeneratorType object
+        """
+        should_check_conversion_rate = True
+        if not all(isinstance(item, str) for item in self.buses):
+            exception_list.append(
+                NetworkValidatorException(
+                    "Generator attribute 'buses' must contain only strings"
+                )
+            )
+        self._validate_attribute_type(
+            attr="buses", attr_type=set, exception_list=exception_list
+        )
+
+        self._validate_buses_energy_types(
+            exception_list=exception_list, network=network
+        )
+        for bus_name in self.buses:
+            if bus_name not in network.buses:
+                exception_list.append(
+                    NetworkValidatorException(
+                        f"Cannot attach generator to a bus {bus_name} - bus does not exist in the network"
+                    )
+                )
+                should_check_conversion_rate = False
+            elif (
+                network.buses[bus_name].energy_type
+                not in generator_type.energy_types | generator_type.inbound_energy_type
+            ):
+                gen_en_types = sorted(
+                    list(
+                        generator_type.energy_types | generator_type.inbound_energy_type
+                    )
+                )
+                exception_list.append(
+                    NetworkValidatorException(
+                        f"Unable to attach generator to a bus {bus_name}. "
+                        f"Bus energy type ({network.buses[bus_name].energy_type}) "
+                        f"and generator energy types ({gen_en_types}) do not match"
+                    )
+                )
+                should_check_conversion_rate = False
+
+        if should_check_conversion_rate and (
+            diff := (
+                set(generator_type.conversion_rate.keys())
+                - set([network.buses.get(bus).energy_type for bus in self.buses])
+            )
+        ):
+            exception_list.append(
+                NetworkValidatorException(
+                    f"Conversion_rate for energy types: "
+                    f"{sorted(list(diff))} which are not in connected buses energy types"
+                )
+            )
+        _logger.debug("Validate buses: OK")
+
+    def _validate_generator_type(
+        self,
+        exception_list: list[NetworkValidatorException],
+        network: Network,
+        generator_type: GeneratorType,
+    ) -> None:
+        """
+        Validate GeneratorType.
+            - Validates if generator_type is type of GeneratorType
+            - Validates if generator_type energy types are compliant with the network
+
+        Args:
+            exception_list (list[NetworkValidatorException]): List of exceptions
+                to which new exceptions will be added
+            network (Network): Network object to which this object belongs
+            generator_type (GeneratorType): GeneratorType object associated with this Generator
+        """
+        if generator_type is None:
+            exception_list.append(
+                NetworkValidatorException("Network does not contain generator type")
+            )
+            return
+        if not isinstance(generator_type, GeneratorType):
+            exception_list.append(
+                NetworkValidatorException(
+                    f"Generator type must be of type GeneratorType, but it is {type(generator_type)} instead."
+                )
+            )
+            return
+        gen_energy_types = [en_t for en_t in generator_type.energy_types]
+        if not generator_type.energy_types.issubset(network.energy_types):
+            exception_list.append(
+                NetworkValidatorException(
+                    f"Gen energy types: {gen_energy_types}"
+                    " are not compliant with the network"
+                    f" energy types: {sorted(network.energy_types)}"
+                )
+            )
+        _logger.debug("Validate generator type: OK")
+
+    def _validate_emission_fee(
+        self, network: Network, exception_list: list[NetworkValidatorException]
+    ) -> None:
+        """
+        Validation procedure checking:
+        - Validates emission_fee in network
+        - Validates emission_fee.emission_type are unique for given gen
+
+        Args:
+            exception_list (NetworkValidatorException): list of raised exceptions.
+            network (Network): network to which self is to be added.
+        """
+        emission_fee_types: set[str] = set()
+        network_emissions = network.emission_fees
+        for fee in self.emission_fee:
+            if fee not in network_emissions:
+                exception_list.append(
+                    NetworkValidatorException(
+                        f"Network does not contain Emission Fee: {fee} in its structure"
+                    )
+                )
+                continue
+            emission_type = network_emissions[fee].emission_type
+            if (
+                emission_type not in emission_fee_types
+                and len(
+                    duplicated_fees := {
+                        em
+                        for em in self.emission_fee
+                        if network_emissions[em].emission_type == emission_type
+                    }
+                )
+                > 1
+            ):
+                exception_list.append(
+                    NetworkValidatorException(
+                        f"There are fees: {sorted(list(duplicated_fees))} which"
+                        f" apply to the same type of emission: {emission_type}"
+                    )
+                )
+                emission_fee_types.add(emission_type)
+        _logger.debug("Validate emission fee: OK")
+
+    def validate(self, network: Network) -> None:
+        """
+        Validation procedure checking:
+        - if network doesn't contain any generator type and generator type is None
+        - correctness of Generator object
+        - whether the Generator energy_type is in the energy_type of the network
+
+        Method validate runs following validate methods:
+        - _validate_base_energy_source
+        - _validate_generator_type
+        - _validate_buses
+
+        Args:
+            network (Network): Network to which Generator is to be added.
+
+        Raises:
+            NetworkValidatorExceptionGroup: If Generator is invalid.
+        """
+        _logger.debug("Validating generator object: %s...", self.name)
+        exception_list: list[NetworkValidatorException] = []
+        self._validate_base_energy_source(
+            network=network, exception_list=exception_list
+        )
+        generator_type = network.generator_types.get(self.energy_source_type)
+        self._validate_generator_type(
+            exception_list=exception_list,
+            network=network,
+            generator_type=generator_type,
+        )
+        if isinstance(generator_type, GeneratorType):
+            self._validate_buses(
+                exception_list=exception_list,
+                network=network,
+                generator_type=generator_type,
+            )
+        self._validate_emission_fee(network=network, exception_list=exception_list)
+        if exception_list:
+            _logger.debug("Got error validating generator: %s", exception_list)
+            raise GeneratorValidatorExceptionGroup(
+                f"While adding Generator {self.name} with type {self.energy_source_type} following errors occurred: ",
+                exception_list,
+            )
+        _logger.debug("Generator %s validation: Done", self.name)
+
+    def __post_init__(self, bus: str | set[str]) -> None:
+        if bus is None:
+            self.buses = set()
+        else:
+            self.buses = {bus} if isinstance(bus, str) else bus
```

### Comparing `pyzefir-0.4.1/pyzefir/model/network_elements/energy_sources/storage.py` & `pyzefir-0.4.22/pyzefir/model/network_elements/energy_sources/storage.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,136 +1,143 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-from __future__ import annotations
-
-from dataclasses import dataclass
-from typing import TYPE_CHECKING
-
-from pyzefir.model.exceptions import (
-    NetworkValidatorException,
-    NetworkValidatorExceptionGroup,
-)
-from pyzefir.model.network_elements import EnergySource, StorageType
-
-if TYPE_CHECKING:
-    from pyzefir.model.network import Network
-
-
-class StorageValidatorExceptionGroup(NetworkValidatorExceptionGroup):
-    pass
-
-
-@dataclass(kw_only=True)
-class Storage(EnergySource):
-    """
-    A class that represents the Generator in the network structure
-    """
-
-    bus: str
-    """
-    Bus name to which the Storage element is attached
-    """
-
-    def validate(self, network: Network) -> None:
-        """
-        Validation procedure checking:
-        - correctness of StorageType
-        - Validates if bus attribute of Storage obj exists in network.buses,
-        - Validates if bus energy type same as storage energy type
-        Method validate runs following validate methods:
-        - _validate_base_energy_source
-        - _validate_storage_type
-
-        Args:
-            network (Network): network to which self is to be added.
-
-        Returns:
-            None.
-
-        Raises:
-            NetworkValidatorExceptionGroup: If exception_list contains exception.
-        """
-        exception_list: list[NetworkValidatorException] = []
-        self._validate_base_energy_source(
-            network=network, exception_list=exception_list
-        )
-        storage_type = network.storage_types.get(self.energy_source_type)
-        validate_energy_type_flag = self._validate_storage_type(
-            storage_type, exception_list
-        )
-        if self.bus not in network.buses:
-            validate_energy_type_flag = False
-            exception_list.append(
-                NetworkValidatorException(
-                    f"Bus {self.bus} does not exist in the network"
-                )
-            )
-        if (
-            validate_energy_type_flag
-            and network.buses[self.bus].energy_type != storage_type.energy_type
-        ):
-            exception_list.append(
-                NetworkValidatorException(
-                    f"Bus {self.bus} energy type "
-                    f"({network.buses[self.bus].energy_type}) is different, "
-                    f"than energy type "
-                    f"({storage_type.energy_type}) attached to this bus"
-                )
-            )
-        if exception_list:
-            raise StorageValidatorExceptionGroup(
-                f"While adding Storage {self.name} with type {self.energy_source_type} following errors occurred: ",
-                exception_list,
-            )
-
-    def _validate_storage_type(
-        self,
-        storage_type: StorageType,
-        exception_list: list[NetworkValidatorException],
-    ) -> bool:
-        """
-        Validation procedure checking:
-        - Validates storage_type type
-
-        Args:
-            storage_type (StorageType): StorageType object.
-            exception_list (NetworkValidatorException): list of raised exceptions.
-
-        Returns:
-            True (flag) if assigned StorageType is correct, otherwise False.
-
-        Raises:
-            NetworkValidatorException: If storage_type is None.
-            NetworkValidatorException: If storage_type is not an instance of StorageType.
-        """
-
-        is_storage_type_correct = True
-        if storage_type is None:
-            exception_list.append(
-                NetworkValidatorException(
-                    f"Storage type {self.energy_source_type} not found in the network"
-                )
-            )
-            is_storage_type_correct = False
-        elif not isinstance(storage_type, StorageType):
-            exception_list.append(
-                NetworkValidatorException(
-                    f"Storage type must be of type StorageType, but it is {type(storage_type)} instead."
-                )
-            )
-            is_storage_type_correct = False
-
-        return is_storage_type_correct
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+from __future__ import annotations
+
+import logging
+from dataclasses import dataclass
+from typing import TYPE_CHECKING
+
+from pyzefir.model.exceptions import (
+    NetworkValidatorException,
+    NetworkValidatorExceptionGroup,
+)
+from pyzefir.model.network_elements import EnergySource, StorageType
+
+if TYPE_CHECKING:
+    from pyzefir.model.network import Network
+
+_logger = logging.getLogger(__name__)
+
+
+class StorageValidatorExceptionGroup(NetworkValidatorExceptionGroup):
+    pass
+
+
+@dataclass(kw_only=True)
+class Storage(EnergySource):
+    """
+    A class that represents the Generator in the network structure
+    """
+
+    bus: str
+    """
+    Bus name to which the Storage element is attached
+    """
+
+    def validate(self, network: Network) -> None:
+        """
+        Validation procedure checking:
+        - correctness of StorageType
+        - Validates if bus attribute of Storage obj exists in network.buses,
+        - Validates if bus energy type same as storage energy type
+        Method validate runs following validate methods:
+        - _validate_base_energy_source
+        - _validate_storage_type
+
+        Args:
+            network (Network): network to which self is to be added.
+
+        Returns:
+            None.
+
+        Raises:
+            NetworkValidatorExceptionGroup: If exception_list contains exception.
+        """
+        _logger.debug("Validating storage object: %s...", self.name)
+        exception_list: list[NetworkValidatorException] = []
+        self._validate_base_energy_source(
+            network=network, exception_list=exception_list
+        )
+        storage_type = network.storage_types.get(self.energy_source_type)
+        validate_energy_type_flag = self._validate_storage_type(
+            storage_type, exception_list
+        )
+        if self.bus not in network.buses:
+            validate_energy_type_flag = False
+            exception_list.append(
+                NetworkValidatorException(
+                    f"Bus {self.bus} does not exist in the network"
+                )
+            )
+        if (
+            validate_energy_type_flag
+            and network.buses[self.bus].energy_type != storage_type.energy_type
+        ):
+            exception_list.append(
+                NetworkValidatorException(
+                    f"Bus {self.bus} energy type "
+                    f"({network.buses[self.bus].energy_type}) is different, "
+                    f"than energy type "
+                    f"({storage_type.energy_type}) attached to this bus"
+                )
+            )
+        if exception_list:
+            _logger.debug("Got error validating storage: %s", exception_list)
+            raise StorageValidatorExceptionGroup(
+                f"While adding Storage {self.name} with type {self.energy_source_type} following errors occurred: ",
+                exception_list,
+            )
+        _logger.debug("Storage %s validation: Done", self.name)
+
+    def _validate_storage_type(
+        self,
+        storage_type: StorageType,
+        exception_list: list[NetworkValidatorException],
+    ) -> bool:
+        """
+        Validation procedure checking:
+        - Validates storage_type type
+
+        Args:
+            storage_type (StorageType): StorageType object.
+            exception_list (NetworkValidatorException): list of raised exceptions.
+
+        Returns:
+            True (flag) if assigned StorageType is correct, otherwise False.
+
+        Raises:
+            NetworkValidatorException: If storage_type is None.
+            NetworkValidatorException: If storage_type is not an instance of StorageType.
+        """
+
+        is_storage_type_correct = True
+        if storage_type is None:
+            exception_list.append(
+                NetworkValidatorException(
+                    f"Storage type {self.energy_source_type} not found in the network"
+                )
+            )
+            is_storage_type_correct = False
+        elif not isinstance(storage_type, StorageType):
+            exception_list.append(
+                NetworkValidatorException(
+                    f"Storage type must be of type StorageType, but it is {type(storage_type)} instead."
+                )
+            )
+            is_storage_type_correct = False
+        _logger.debug("Validate storage type: OK")
+
+        return is_storage_type_correct
```

### Comparing `pyzefir-0.4.1/pyzefir/model/network_elements/line.py` & `pyzefir-0.4.22/pyzefir/model/network_elements/line.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,213 +1,224 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-from __future__ import annotations
-
-from dataclasses import dataclass
-from typing import TYPE_CHECKING
-
-from pyzefir.model.exceptions import (
-    NetworkValidatorException,
-    NetworkValidatorExceptionGroup,
-)
-from pyzefir.model.network_element import NetworkElement
-from pyzefir.model.utils import check_interval
-
-if TYPE_CHECKING:
-    from pyzefir.model.network import Network
-
-
-class LineValidatorExceptionGroup(NetworkValidatorExceptionGroup):
-    pass
-
-
-@dataclass(kw_only=True)
-class Line(NetworkElement):
-    """
-    A class that represents the Line element in the network structure
-    """
-
-    energy_type: str
-    """
-    Unique name of Line's energy type
-    """
-    fr: str
-    """
-    Unique name of Bus from which this line departs
-    """
-    to: str
-    """
-    Unique name of Bus this line enters
-    """
-    transmission_loss: float
-    """
-    Losses of energy on a line parameter from [0,1]
-    """
-    max_capacity: float
-    """
-    Maximal amount of energy, that can flow through the line in one hour
-    """
-    transmission_fee: str | None = None
-    """
-    Name of the TransmissionFee element that defines the fee for transmission of energy
-    """
-
-    def _validate_energy_type(
-        self,
-        network: Network,
-        exception_list: list[NetworkValidatorException],
-    ) -> None:
-        if self.energy_type not in network.energy_types:
-            exception_list.append(
-                NetworkValidatorException(
-                    f"Energy type of line {self.energy_type} not found in the "
-                    f"Network energy types: {sorted([e for e in network.energy_types])}"
-                )
-            )
-
-    def _validate_line_connections(
-        self,
-        network: Network,
-        exception_list: list[NetworkValidatorException],
-    ) -> None:
-        def _validate_line_connection(
-            connected_bus_name: str,
-            line_type_name: str,
-        ) -> bool:
-            """
-
-            Returns: True if line bus is in Network buses
-
-            """
-            if not isinstance(connected_bus_name, str):
-                exception_list.append(
-                    NetworkValidatorException(
-                        f"Line {line_type_name.capitalize()} must be of type string"
-                    )
-                )
-                return False
-            if connected_bus_name not in network.buses:
-                exception_list.append(
-                    NetworkValidatorException(
-                        f"Cannot set the {line_type_name} of the line to bus "
-                        f"{connected_bus_name}. Bus {connected_bus_name} "
-                        f"does not exist in the network"
-                    )
-                )
-                return False
-            if network.buses[connected_bus_name].energy_type != self.energy_type:
-                exception_list.append(
-                    NetworkValidatorException(
-                        f"Cannot set {line_type_name} of the line to bus {connected_bus_name}. "
-                        f"Bus {connected_bus_name} energy type is "
-                        f"{network.buses[connected_bus_name].energy_type}, "
-                        f"which is different from the line energy type: {self.energy_type}."
-                    )
-                )
-
-            return True
-
-        is_line_fr_connected = _validate_line_connection(self.fr, "beginning")
-        is_line_to_connected = _validate_line_connection(self.to, "end")
-
-        if (
-            is_line_fr_connected
-            and is_line_to_connected
-            and network.buses[self.fr].energy_type != network.buses[self.to].energy_type
-        ):
-            exception_list.append(
-                NetworkValidatorException(
-                    f"Cannot add a line between buses {self.fr} and "
-                    f"{self.to} with different energy types "
-                    f"{network.buses[self.fr].energy_type} != "
-                    f"{network.buses[self.to].energy_type}"
-                )
-            )
-
-    def _validate_transmission_loss(
-        self,
-        exception_list: list[NetworkValidatorException],
-    ) -> None:
-        if not isinstance(self.transmission_loss, float | int):
-            exception_list.append(
-                NetworkValidatorException(
-                    f"Transmission loss must be of type float, but is {type(self.transmission_loss)} instead"
-                )
-            )
-            return None
-
-        if not check_interval(
-            lower_bound=0, upper_bound=1, value=self.transmission_loss
-        ):
-            exception_list.append(
-                NetworkValidatorException(
-                    f"The value of the transmission_loss is inconsistent with th expected bounds of "
-                    f"the interval: 0 <= {self.transmission_loss} <= 1"
-                )
-            )
-
-    def _validate_max_capacity(
-        self,
-        exception_list: list[NetworkValidatorException],
-    ) -> None:
-        if not isinstance(self.max_capacity, float | int):
-            exception_list.append(
-                NetworkValidatorException(
-                    f"Max capacity must be of type float, but is {type(self.max_capacity)} instead"
-                )
-            )
-
-    def validate(self, network: Network) -> None:
-        """
-        Validate Line element.
-            - if attributes have correct types
-            - if energy type is in network's energy types
-            - if line has proper fr and to connections:
-                - connected bus is in the network
-                - bus energy type is compliant with line energy type
-            - if transmission loss has value between 0 and 1
-            - if transmission fee is in network's transmission fees
-
-        Args:
-            network (Network): Network to which Line is to be added.
-
-        Raises:
-            NetworkValidatorExceptionGroup: If Line is invalid.
-        """
-        exception_list: list[NetworkValidatorException] = []
-
-        self._validate_name_type(exception_list)
-        self._validate_energy_type(network, exception_list)
-        self._validate_line_connections(network, exception_list)
-        self._validate_transmission_loss(exception_list)
-        self._validate_max_capacity(exception_list)
-
-        if (
-            self.transmission_fee is not None
-            and self.transmission_fee not in network.transmission_fees
-        ):
-            exception_list.append(
-                NetworkValidatorException(
-                    f"Cannot set a transmission fee for the line. "
-                    f"Transmission fee {self.transmission_fee} does not exist in the network"
-                )
-            )
-
-        if exception_list:
-            raise LineValidatorExceptionGroup(
-                f"While adding Line {self.name} following errors occurred: ",
-                exception_list,
-            )
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+from __future__ import annotations
+
+import logging
+from dataclasses import dataclass
+from typing import TYPE_CHECKING
+
+from pyzefir.model.exceptions import (
+    NetworkValidatorException,
+    NetworkValidatorExceptionGroup,
+)
+from pyzefir.model.network_element import NetworkElement
+from pyzefir.model.utils import check_interval
+
+if TYPE_CHECKING:
+    from pyzefir.model.network import Network
+
+_logger = logging.getLogger(__name__)
+
+
+class LineValidatorExceptionGroup(NetworkValidatorExceptionGroup):
+    pass
+
+
+@dataclass(kw_only=True)
+class Line(NetworkElement):
+    """
+    A class that represents the Line element in the network structure
+    """
+
+    energy_type: str
+    """
+    Unique name of Line's energy type
+    """
+    fr: str
+    """
+    Unique name of Bus from which this line departs
+    """
+    to: str
+    """
+    Unique name of Bus this line enters
+    """
+    transmission_loss: float
+    """
+    Losses of energy on a line parameter from [0,1]
+    """
+    max_capacity: float
+    """
+    Maximal amount of energy, that can flow through the line in one hour
+    """
+    transmission_fee: str | None = None
+    """
+    Name of the TransmissionFee element that defines the fee for transmission of energy
+    """
+
+    def _validate_energy_type(
+        self,
+        network: Network,
+        exception_list: list[NetworkValidatorException],
+    ) -> None:
+        if self.energy_type not in network.energy_types:
+            exception_list.append(
+                NetworkValidatorException(
+                    f"Energy type of line {self.energy_type} not found in the "
+                    f"Network energy types: {sorted([e for e in network.energy_types])}"
+                )
+            )
+        _logger.debug("Validate energy type: OK")
+
+    def _validate_line_connections(
+        self,
+        network: Network,
+        exception_list: list[NetworkValidatorException],
+    ) -> None:
+        def _validate_line_connection(
+            connected_bus_name: str,
+            line_type_name: str,
+        ) -> bool:
+            """
+
+            Returns: True if line bus is in Network buses
+
+            """
+            if not isinstance(connected_bus_name, str):
+                exception_list.append(
+                    NetworkValidatorException(
+                        f"Line {line_type_name.capitalize()} must be of type string"
+                    )
+                )
+                return False
+            if connected_bus_name not in network.buses:
+                exception_list.append(
+                    NetworkValidatorException(
+                        f"Cannot set the {line_type_name} of the line to bus "
+                        f"{connected_bus_name}. Bus {connected_bus_name} "
+                        f"does not exist in the network"
+                    )
+                )
+                return False
+            if network.buses[connected_bus_name].energy_type != self.energy_type:
+                exception_list.append(
+                    NetworkValidatorException(
+                        f"Cannot set {line_type_name} of the line to bus {connected_bus_name}. "
+                        f"Bus {connected_bus_name} energy type is "
+                        f"{network.buses[connected_bus_name].energy_type}, "
+                        f"which is different from the line energy type: {self.energy_type}."
+                    )
+                )
+
+            return True
+
+        is_line_fr_connected = _validate_line_connection(self.fr, "beginning")
+        is_line_to_connected = _validate_line_connection(self.to, "end")
+
+        if (
+            is_line_fr_connected
+            and is_line_to_connected
+            and network.buses[self.fr].energy_type != network.buses[self.to].energy_type
+        ):
+            exception_list.append(
+                NetworkValidatorException(
+                    f"Cannot add a line between buses {self.fr} and "
+                    f"{self.to} with different energy types "
+                    f"{network.buses[self.fr].energy_type} != "
+                    f"{network.buses[self.to].energy_type}"
+                )
+            )
+        _logger.debug("Validate line connections: OK")
+
+    def _validate_transmission_loss(
+        self,
+        exception_list: list[NetworkValidatorException],
+    ) -> None:
+        if not isinstance(self.transmission_loss, float | int):
+            exception_list.append(
+                NetworkValidatorException(
+                    f"Transmission loss must be of type float, but is {type(self.transmission_loss)} instead"
+                )
+            )
+            return None
+
+        if not check_interval(
+            lower_bound=0, upper_bound=1, value=self.transmission_loss
+        ):
+            exception_list.append(
+                NetworkValidatorException(
+                    f"The value of the transmission_loss is inconsistent with th expected bounds of "
+                    f"the interval: 0 <= {self.transmission_loss} <= 1"
+                )
+            )
+        _logger.debug("Validate transmission loss: OK")
+
+    def _validate_max_capacity(
+        self,
+        exception_list: list[NetworkValidatorException],
+    ) -> None:
+        if not isinstance(self.max_capacity, float | int):
+            exception_list.append(
+                NetworkValidatorException(
+                    f"Max capacity must be of type float, but is {type(self.max_capacity)} instead"
+                )
+            )
+        _logger.debug("Validate max capacity: OK")
+
+    def validate(self, network: Network) -> None:
+        """
+        Validate Line element.
+            - if attributes have correct types
+            - if energy type is in network's energy types
+            - if line has proper fr and to connections:
+                - connected bus is in the network
+                - bus energy type is compliant with line energy type
+            - if transmission loss has value between 0 and 1
+            - if transmission fee is in network's transmission fees
+
+        Args:
+            network (Network): Network to which Line is to be added.
+
+        Raises:
+            NetworkValidatorExceptionGroup: If Line is invalid.
+        """
+        _logger.debug("Validating line object: %s...", self.name)
+
+        exception_list: list[NetworkValidatorException] = []
+
+        self._validate_name_type(exception_list)
+        self._validate_energy_type(network, exception_list)
+        self._validate_line_connections(network, exception_list)
+        self._validate_transmission_loss(exception_list)
+        self._validate_max_capacity(exception_list)
+
+        if (
+            self.transmission_fee is not None
+            and self.transmission_fee not in network.transmission_fees
+        ):
+            exception_list.append(
+                NetworkValidatorException(
+                    f"Cannot set a transmission fee for the line. "
+                    f"Transmission fee {self.transmission_fee} does not exist in the network"
+                )
+            )
+
+        if exception_list:
+            _logger.exception("Got error validating line: %s", exception_list)
+            raise LineValidatorExceptionGroup(
+                f"While adding Line {self.name} following errors occurred: ",
+                exception_list,
+            )
+        _logger.debug("Line %s validation: Done", self.name)
```

### Comparing `pyzefir-0.4.1/pyzefir/model/network_elements/local_balancing_stack.py` & `pyzefir-0.4.22/pyzefir/model/network_elements/local_balancing_stack.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,223 +1,234 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-from __future__ import annotations
-
-from dataclasses import dataclass, field
-from typing import TYPE_CHECKING
-
-from pyzefir.model.exceptions import (
-    NetworkValidatorException,
-    NetworkValidatorExceptionGroup,
-)
-from pyzefir.model.network_element import NetworkElement
-
-if TYPE_CHECKING:
-    from pyzefir.model.network import Network
-
-
-class LocalBalancingStackValidatorExceptionGroup(NetworkValidatorExceptionGroup):
-    pass
-
-
-@dataclass
-class LocalBalancingStack(NetworkElement):
-    """
-    A class that represents the LocalBalancingStack element in the network structure.
-    It consists of a set of buses, that are locally balancing together.
-    There must be at least one bus for every energy type defined in the network.
-    """
-
-    buses_out: dict[str, str] = field(default_factory=dict)
-    """
-    Dictionary mapping energy type to bus to which Aggregated load is attached.
-    For every energy type there must be at least one bus in LocalBalancingStack,
-    which servers as outlet.
-    """
-    buses: dict[str, set[str]] = field(default_factory=dict)
-    """
-    Dictionary mapping energy type to set of all buses of given energy type contained in self.
-    Not every bus have to be in buses_out.
-    """
-
-    def _validate_buses_out(
-        self, network: Network, exception_list: list[NetworkValidatorException]
-    ) -> None:
-        """
-        Validation procedure checking:
-        - if buses_out is a correct type
-        - if all buses_out are in the network
-        - if all buses_out have correct energy type
-
-        Args:
-            network (Network): Network to which self is to be added
-            exception_list (list[NetworkValidatorException]): List of exceptions to which new exceptions are added
-
-        """
-        if not isinstance(self.buses_out, dict):
-            exception_list.append(
-                NetworkValidatorException(
-                    f"Outlet buses must be a dict, " f"not {type(self.buses_out)}."
-                )
-            )
-            return
-
-        for energy_type, bus_name in self.buses_out.items():
-            if not isinstance(bus_name, str):
-                exception_list.append(
-                    NetworkValidatorException(
-                        f"Outlet bus name for energy type {energy_type} "
-                        f"must be a string, not {type(bus_name)}."
-                    )
-                )
-                return
-            if not isinstance(energy_type, str):
-                exception_list.append(
-                    NetworkValidatorException(
-                        f"Energy type for outlet bus {bus_name} "
-                        f"must be a string, not {type(energy_type)}."
-                    )
-                )
-                return
-
-            if bus_name not in network.buses:
-                exception_list.append(
-                    NetworkValidatorException(
-                        f"Bus {bus_name} which is declared as an outlet bus "
-                        f"does not exist "
-                        "in the network."
-                    )
-                )
-            elif network.buses[bus_name].energy_type != energy_type:
-                exception_list.append(
-                    NetworkValidatorException(
-                        f"Bus {bus_name} can not be declared as an outlet bus "
-                        f"for energy "
-                        f"{energy_type}, since its energy type is "
-                        f"{network.buses[bus_name].energy_type}."
-                    )
-                )
-
-    def _validate_buses_type(
-        self, exception_list: list[NetworkValidatorException]
-    ) -> None:
-        """
-        Validation procedure checking:
-            - validates if self.buses is a dict
-            - validates energy types' type
-            - validates if buses names collection is set
-            - validates buses names type
-
-        Args:
-            exception_list (list[NetworkValidatorException]): List of exceptions to which new exceptions are added
-
-        """
-        self._validate_attribute_type(
-            attr="buses",
-            attr_type=dict,
-            exception_list=exception_list,
-            raise_error=True,
-        )
-        if not all(isinstance(energy_types, str) for energy_types in self.buses.keys()):
-            exception_list.append(
-                NetworkValidatorException(
-                    f"All the energy types (keys of buses dict) must be a string, "
-                    f"but following types are found: {[type(x).__name__ for x in self.buses.keys()]}"
-                )
-            )
-
-        if not all(
-            isinstance(buses_name_set, set) for buses_name_set in self.buses.values()
-        ):
-            exception_list.append(
-                NetworkValidatorException(
-                    f"Buses names collection type (values of buses dict) "
-                    f"must be a set of strings, but following types are found: "
-                    f"{[type(x).__name__ for x in self.buses.values()]}"
-                )
-            )
-
-        if not all(
-            all(isinstance(bus_names, str) for bus_names in bus_names_collection)
-            for bus_names_collection in self.buses.values()
-        ):
-            exception_list.append(
-                NetworkValidatorException(
-                    "Buses names collection type (values of buses dict) must contain strings only"
-                )
-            )
-
-    def _validate_buses(
-        self, network: Network, exception_list: list[NetworkValidatorException]
-    ) -> None:
-        """
-        Validation procedure checking:
-            - validates if buses energy types exist in the network
-            - validates if buses exist in the network.buses
-            - validates if bus' energy type match with the bus' energy type in network
-
-        Args:
-            network (Network): Network to which self is to be added
-            exception_list (list[NetworkValidatorException]): List of exceptions to which new exceptions are added
-
-        Raises:
-            NetworkValidatorException: If buses attribute has not been set for LocalBalancingStack object
-        """
-        self._validate_buses_type(exception_list)
-        for energy_type in self.buses.keys():
-            if energy_type not in network.energy_types:
-                exception_list.append(
-                    NetworkValidatorException(
-                        f"Buses energy type {energy_type} is not defined in the Network"
-                    )
-                )
-        for energy_type, buses in self.buses.items():
-            for bus_name in buses:
-                if bus_name not in network.buses:
-                    exception_list.append(
-                        NetworkValidatorException(
-                            f"Bus name '{bus_name}' must exist in the Network"
-                        )
-                    )
-                elif not energy_type == network.buses[bus_name].energy_type:
-                    exception_list.append(
-                        NetworkValidatorException(
-                            f"Energy type for {bus_name} must match "
-                            f"with energy type for the same bus in Network"
-                        )
-                    )
-
-    def validate(self, network: Network) -> None:
-        """
-        Validate LocalBalancingStack element.
-            - Validate buses out mapping
-
-        Args:
-            network (Network): Network to which LocalBalancingStack is
-                to be added.
-
-        Raises:
-            NetworkValidatorExceptionGroup: If LocalBalancingStack is invalid.
-        """
-        exception_list: list[NetworkValidatorException] = []
-        self._validate_name_type(exception_list)
-        self._validate_buses_out(network=network, exception_list=exception_list)
-        self._validate_buses(network=network, exception_list=exception_list)
-        if exception_list:
-            raise LocalBalancingStackValidatorExceptionGroup(
-                f"While adding Local Balancing Stack {self.name} following errors occurred: ",
-                exception_list,
-            )
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+from __future__ import annotations
+
+import logging
+from dataclasses import dataclass, field
+from typing import TYPE_CHECKING
+
+from pyzefir.model.exceptions import (
+    NetworkValidatorException,
+    NetworkValidatorExceptionGroup,
+)
+from pyzefir.model.network_element import NetworkElement
+
+if TYPE_CHECKING:
+    from pyzefir.model.network import Network
+
+_logger = logging.getLogger(__name__)
+
+
+class LocalBalancingStackValidatorExceptionGroup(NetworkValidatorExceptionGroup):
+    pass
+
+
+@dataclass
+class LocalBalancingStack(NetworkElement):
+    """
+    A class that represents the LocalBalancingStack element in the network structure.
+    It consists of a set of buses, that are locally balancing together.
+    There must be at least one bus for every energy type defined in the network.
+    """
+
+    buses_out: dict[str, str] = field(default_factory=dict)
+    """
+    Dictionary mapping energy type to bus to which Aggregated load is attached.
+    For every energy type there must be at least one bus in LocalBalancingStack,
+    which servers as outlet.
+    """
+    buses: dict[str, set[str]] = field(default_factory=dict)
+    """
+    Dictionary mapping energy type to set of all buses of given energy type contained in self.
+    Not every bus have to be in buses_out.
+    """
+
+    def _validate_buses_out(
+        self, network: Network, exception_list: list[NetworkValidatorException]
+    ) -> None:
+        """
+        Validation procedure checking:
+        - if buses_out is a correct type
+        - if all buses_out are in the network
+        - if all buses_out have correct energy type
+
+        Args:
+            network (Network): Network to which self is to be added
+            exception_list (list[NetworkValidatorException]): List of exceptions to which new exceptions are added
+
+        """
+        if not isinstance(self.buses_out, dict):
+            exception_list.append(
+                NetworkValidatorException(
+                    f"Outlet buses must be a dict, " f"not {type(self.buses_out)}."
+                )
+            )
+            return
+
+        for energy_type, bus_name in self.buses_out.items():
+            if not isinstance(bus_name, str):
+                exception_list.append(
+                    NetworkValidatorException(
+                        f"Outlet bus name for energy type {energy_type} "
+                        f"must be a string, not {type(bus_name)}."
+                    )
+                )
+                return
+            if not isinstance(energy_type, str):
+                exception_list.append(
+                    NetworkValidatorException(
+                        f"Energy type for outlet bus {bus_name} "
+                        f"must be a string, not {type(energy_type)}."
+                    )
+                )
+                return
+
+            if bus_name not in network.buses:
+                exception_list.append(
+                    NetworkValidatorException(
+                        f"Bus {bus_name} which is declared as an outlet bus "
+                        f"does not exist "
+                        "in the network."
+                    )
+                )
+            elif network.buses[bus_name].energy_type != energy_type:
+                exception_list.append(
+                    NetworkValidatorException(
+                        f"Bus {bus_name} can not be declared as an outlet bus "
+                        f"for energy "
+                        f"{energy_type}, since its energy type is "
+                        f"{network.buses[bus_name].energy_type}."
+                    )
+                )
+        _logger.debug("Validate buses_out: OK")
+
+    def _validate_buses_type(
+        self, exception_list: list[NetworkValidatorException]
+    ) -> None:
+        """
+        Validation procedure checking:
+            - validates if self.buses is a dict
+            - validates energy types' type
+            - validates if buses names collection is set
+            - validates buses names type
+
+        Args:
+            exception_list (list[NetworkValidatorException]): List of exceptions to which new exceptions are added
+
+        """
+        self._validate_attribute_type(
+            attr="buses",
+            attr_type=dict,
+            exception_list=exception_list,
+            raise_error=True,
+        )
+        if not all(isinstance(energy_types, str) for energy_types in self.buses.keys()):
+            exception_list.append(
+                NetworkValidatorException(
+                    f"All the energy types (keys of buses dict) must be a string, "
+                    f"but following types are found: {[type(x).__name__ for x in self.buses.keys()]}"
+                )
+            )
+
+        if not all(
+            isinstance(buses_name_set, set) for buses_name_set in self.buses.values()
+        ):
+            exception_list.append(
+                NetworkValidatorException(
+                    f"Buses names collection type (values of buses dict) "
+                    f"must be a set of strings, but following types are found: "
+                    f"{[type(x).__name__ for x in self.buses.values()]}"
+                )
+            )
+
+        if not all(
+            all(isinstance(bus_names, str) for bus_names in bus_names_collection)
+            for bus_names_collection in self.buses.values()
+        ):
+            exception_list.append(
+                NetworkValidatorException(
+                    "Buses names collection type (values of buses dict) must contain strings only"
+                )
+            )
+        _logger.debug("Validate buses type: OK")
+
+    def _validate_buses(
+        self, network: Network, exception_list: list[NetworkValidatorException]
+    ) -> None:
+        """
+        Validation procedure checking:
+            - validates if buses energy types exist in the network
+            - validates if buses exist in the network.buses
+            - validates if bus' energy type match with the bus' energy type in network
+
+        Args:
+            network (Network): Network to which self is to be added
+            exception_list (list[NetworkValidatorException]): List of exceptions to which new exceptions are added
+
+        Raises:
+            NetworkValidatorException: If buses attribute has not been set for LocalBalancingStack object
+        """
+        self._validate_buses_type(exception_list)
+        for energy_type in self.buses.keys():
+            if energy_type not in network.energy_types:
+                exception_list.append(
+                    NetworkValidatorException(
+                        f"Buses energy type {energy_type} is not defined in the Network"
+                    )
+                )
+        for energy_type, buses in self.buses.items():
+            for bus_name in buses:
+                if bus_name not in network.buses:
+                    exception_list.append(
+                        NetworkValidatorException(
+                            f"Bus name '{bus_name}' must exist in the Network"
+                        )
+                    )
+                elif not energy_type == network.buses[bus_name].energy_type:
+                    exception_list.append(
+                        NetworkValidatorException(
+                            f"Energy type for {bus_name} must match "
+                            f"with energy type for the same bus in Network"
+                        )
+                    )
+        _logger.debug("Validate buses: OK")
+
+    def validate(self, network: Network) -> None:
+        """
+        Validate LocalBalancingStack element.
+            - Validate buses out mapping
+
+        Args:
+            network (Network): Network to which LocalBalancingStack is
+                to be added.
+
+        Raises:
+            NetworkValidatorExceptionGroup: If LocalBalancingStack is invalid.
+        """
+        _logger.debug("Validating local balancing stack object: %s...", self.name)
+        exception_list: list[NetworkValidatorException] = []
+        self._validate_name_type(exception_list)
+        self._validate_buses_out(network=network, exception_list=exception_list)
+        self._validate_buses(network=network, exception_list=exception_list)
+        if exception_list:
+            _logger.exception(
+                "Got error validating local balancing stack: %s", exception_list
+            )
+            raise LocalBalancingStackValidatorExceptionGroup(
+                f"While adding Local Balancing Stack {self.name} following errors occurred: ",
+                exception_list,
+            )
+        _logger.debug("Local balancing stack %s validation: Done", self.name)
```

### Comparing `pyzefir-0.4.1/pyzefir/model/network_elements/transmission_fee.py` & `pyzefir-0.4.22/pyzefir/model/network_elements/transmission_fee.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,75 +1,83 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-from __future__ import annotations
-
-from dataclasses import dataclass
-from typing import TYPE_CHECKING
-
-import pandas as pd
-
-from pyzefir.model.exceptions import (
-    NetworkValidatorException,
-    NetworkValidatorExceptionGroup,
-)
-from pyzefir.model.network_element import NetworkElement
-from pyzefir.model.utils import validate_series
-
-if TYPE_CHECKING:
-    from pyzefir.model.network import Network
-
-
-class TransmissionFeeValidatorExceptionGroup(NetworkValidatorExceptionGroup):
-    pass
-
-
-@dataclass(kw_only=True)
-class TransmissionFee(NetworkElement):
-    """
-    A class that represents the TransmissionFee element in the network structure
-    """
-
-    fee: pd.Series
-    """
-    Hourly fee for transmission of energy
-    """
-
-    def validate(self, network: Network) -> None:
-        """
-        Validates the TransmissionFee element
-            - if the fee is a correct pd.Series
-
-        Args:
-            network (Network): Network to which Line is to be added.
-
-        Raises:
-            NetworkValidatorExceptionGroup: If any of the validations fails.
-        """
-        exception_list: list[NetworkValidatorException] = []
-
-        validate_series(
-            name="TransmissionFee",
-            series=self.fee,
-            length=network.constants.n_hours,
-            exception_list=exception_list,
-            allow_null=False,
-        )
-
-        if exception_list:
-            raise TransmissionFeeValidatorExceptionGroup(
-                f"While adding TransmissionFee {self.name} following errors occurred: ",
-                exception_list,
-            )
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+from __future__ import annotations
+
+import logging
+from dataclasses import dataclass
+from typing import TYPE_CHECKING
+
+import pandas as pd
+
+from pyzefir.model.exceptions import (
+    NetworkValidatorException,
+    NetworkValidatorExceptionGroup,
+)
+from pyzefir.model.network_element import NetworkElement
+from pyzefir.model.utils import validate_series
+
+if TYPE_CHECKING:
+    from pyzefir.model.network import Network
+
+_logger = logging.getLogger(__name__)
+
+
+class TransmissionFeeValidatorExceptionGroup(NetworkValidatorExceptionGroup):
+    pass
+
+
+@dataclass(kw_only=True)
+class TransmissionFee(NetworkElement):
+    """
+    A class that represents the TransmissionFee element in the network structure
+    """
+
+    fee: pd.Series
+    """
+    Hourly fee for transmission of energy
+    """
+
+    def validate(self, network: Network) -> None:
+        """
+        Validates the TransmissionFee element
+            - if the fee is a correct pd.Series
+
+        Args:
+            network (Network): Network to which Line is to be added.
+
+        Raises:
+            NetworkValidatorExceptionGroup: If any of the validations fails.
+        """
+        _logger.debug("Validating transmission fee element object: %s...", self.name)
+        exception_list: list[NetworkValidatorException] = []
+
+        validate_series(
+            name="TransmissionFee",
+            series=self.fee,
+            length=network.constants.n_hours,
+            exception_list=exception_list,
+            allow_null=False,
+        )
+
+        if exception_list:
+            _logger.exception(
+                "Got error validating transmission fee: %s", exception_list
+            )
+            raise TransmissionFeeValidatorExceptionGroup(
+                f"While adding TransmissionFee {self.name} following errors occurred: ",
+                exception_list,
+            )
+        _logger.debug("Transmission fee %s validation: Done", self.name)
```

### Comparing `pyzefir-0.4.1/pyzefir/model/utils.py` & `pyzefir-0.4.22/pyzefir/model/utils.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,194 +1,197 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-from dataclasses import dataclass
-from types import UnionType
-
-import numpy as np
-import pandas as pd
-
-from pyzefir.model.exceptions import NetworkValidatorException
-
-
-@dataclass(frozen=True)
-class NetworkConstants:
-    n_years: int
-    n_hours: int
-    relative_emission_limits: dict[str, pd.Series]
-    base_total_emission: dict[str, float | int]
-    power_reserves: dict[str, dict[str, float | int]]
-    min_generation_fraction: dict[str, dict[tuple[str, str], float]] | None = None
-    max_generation_fraction: dict[str, dict[tuple[str, str], float]] | None = None
-    binary_fraction: bool = False
-    numeric_tolerance: float = 1e-6
-
-
-def _check_if_series_has_numeric_values(series: pd.Series) -> bool:
-    return not pd.api.types.is_numeric_dtype(series) and not pd.isnull(series).all()
-
-
-def _validate_series(
-    name: str,
-    series: pd.Series,
-    length: int,
-    exception_list: list[NetworkValidatorException],
-    is_numeric: bool = True,
-    index_type: type | None = None,
-    values_type: type | None = None,
-    allow_null: bool = True,
-) -> bool:
-    is_validation_ok = True
-    if is_numeric and _check_if_series_has_numeric_values(series):
-        exception_list.append(
-            NetworkValidatorException(f"{name} must have only numeric values")
-        )
-        is_validation_ok = False
-    if len(series) != length:
-        exception_list.append(
-            NetworkValidatorException(f"{name} must have {length} values")
-        )
-        is_validation_ok = False
-    if index_type and not np.issubdtype(series.index.dtype, index_type):
-        exception_list.append(
-            NetworkValidatorException(
-                f"{name} index type is {series.index.dtype} but should be {index_type.__name__}"
-            )
-        )
-        is_validation_ok = False
-    if values_type and not np.issubdtype(series.dtype, values_type):
-        exception_list.append(
-            NetworkValidatorException(
-                f"{name} type is {series.dtype} but should be {values_type.__name__}"
-            )
-        )
-        is_validation_ok = False
-    if not allow_null and pd.isnull(series).any():
-        exception_list.append(
-            NetworkValidatorException(f"{name} must not contain null values")
-        )
-        is_validation_ok = False
-    return is_validation_ok
-
-
-def validate_series(
-    name: str,
-    series: pd.Series,
-    length: int,
-    exception_list: list[NetworkValidatorException],
-    is_numeric: bool = True,
-    index_type: type | None = None,
-    values_type: type | None = None,
-    allow_null: bool = True,
-) -> bool:
-    """
-    Validation procedure checking:
-    - if series is a pandas series
-    - if series has only numeric values
-    - if series has correct length
-
-    (Optional) Validation procedure also checking:
-    - if series.index has provided type
-    - if series has provided type
-    - if series has null values
-    """
-    if isinstance(series, pd.Series):
-        is_validation_ok = _validate_series(
-            name=name,
-            series=series,
-            length=length,
-            exception_list=exception_list,
-            is_numeric=is_numeric,
-            index_type=index_type,
-            values_type=values_type,
-            allow_null=allow_null,
-        )
-    else:
-        exception_list.append(
-            NetworkValidatorException(
-                f"{name} must be a pandas Series, but {type(series).__name__} given"
-            )
-        )
-        is_validation_ok = False
-    return is_validation_ok
-
-
-def validate_dict_type(
-    dict_to_validate: dict,
-    key_type: type | UnionType,
-    value_type: type | UnionType,
-    parameter_name: str,
-    key_parameter_name: str,
-    value_parameter_name: str,
-    exception_list: list[NetworkValidatorException],
-) -> bool:
-    if not isinstance(dict_to_validate, dict):
-        exception_list.append(
-            NetworkValidatorException(
-                f"{parameter_name.capitalize()} must be of dict type"
-            )
-        )
-        return False
-
-    is_validation_ok = True
-    if not all(isinstance(key, key_type) for key in dict_to_validate.keys()):
-        exception_list.append(
-            NetworkValidatorException(
-                f"{key_parameter_name.capitalize()} in {parameter_name} must be of "
-                f"{key_type} type"
-            )
-        )
-        is_validation_ok = False
-
-    if not all(isinstance(value, value_type) for value in dict_to_validate.values()):
-        exception_list.append(
-            NetworkValidatorException(
-                f"{value_parameter_name.capitalize()} in {parameter_name} must be "
-                f"of {value_type} type"
-            )
-        )
-        is_validation_ok = False
-
-    return is_validation_ok
-
-
-def check_interval(
-    lower_bound: int | float,
-    upper_bound: int | float,
-    value: int | float,
-    is_lower_bound_closed: bool = True,
-    is_upper_bound_closed: bool = True,
-) -> bool:
-    """
-    Checks if the given value falls within the specified interval defined by the lower and upper bounds.
-
-    Args:
-        lower_bound (int or float): The lower bound of the interval.
-        upper_bound (int or float): The upper bound of the interval.
-        value (int or float): The value to be checked against the interval.
-        is_lower_bound_closed (bool, optional): Whether the lower bound is closed (inclusive). Default is True.
-        is_upper_bound_closed (bool, optional): Whether the upper bound is closed (inclusive). Default is True.
-
-    Returns:
-        bool
-    """
-
-    return (
-        (is_lower_bound_closed and lower_bound <= value)
-        or (not is_lower_bound_closed and lower_bound < value)
-    ) and (
-        (is_upper_bound_closed and value <= upper_bound)
-        or (not is_upper_bound_closed and value < upper_bound)
-    )
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+import logging
+from dataclasses import dataclass
+from types import UnionType
+
+import numpy as np
+import pandas as pd
+
+from pyzefir.model.exceptions import NetworkValidatorException
+
+_logger = logging.getLogger(__name__)
+
+
+@dataclass(frozen=True)
+class NetworkConstants:
+    n_years: int
+    n_hours: int
+    relative_emission_limits: dict[str, pd.Series]
+    base_total_emission: dict[str, float | int]
+    power_reserves: dict[str, dict[str, float | int]]
+    min_generation_fraction: dict[str, dict[tuple[str, str], float]] | None = None
+    max_generation_fraction: dict[str, dict[tuple[str, str], float]] | None = None
+    binary_fraction: bool = False
+    ens_penalty_cost: float = 100
+
+
+def _check_if_series_has_numeric_values(series: pd.Series) -> bool:
+    return not pd.api.types.is_numeric_dtype(series) and not pd.isnull(series).all()
+
+
+def _validate_series(
+    name: str,
+    series: pd.Series,
+    length: int,
+    exception_list: list[NetworkValidatorException],
+    is_numeric: bool = True,
+    index_type: type | None = None,
+    values_type: type | None = None,
+    allow_null: bool = True,
+) -> bool:
+    is_validation_ok = True
+    if is_numeric and _check_if_series_has_numeric_values(series):
+        exception_list.append(
+            NetworkValidatorException(f"{name} must have only numeric values")
+        )
+        is_validation_ok = False
+    if len(series) != length:
+        exception_list.append(
+            NetworkValidatorException(f"{name} must have {length} values")
+        )
+        is_validation_ok = False
+    if index_type and not np.issubdtype(series.index.dtype, index_type):
+        exception_list.append(
+            NetworkValidatorException(
+                f"{name} index type is {series.index.dtype} but should be {index_type.__name__}"
+            )
+        )
+        is_validation_ok = False
+    if values_type and not np.issubdtype(series.dtype, values_type):
+        exception_list.append(
+            NetworkValidatorException(
+                f"{name} type is {series.dtype} but should be {values_type.__name__}"
+            )
+        )
+        is_validation_ok = False
+    if not allow_null and pd.isnull(series).any():
+        exception_list.append(
+            NetworkValidatorException(f"{name} must not contain null values")
+        )
+        is_validation_ok = False
+    return is_validation_ok
+
+
+def validate_series(
+    name: str,
+    series: pd.Series,
+    length: int,
+    exception_list: list[NetworkValidatorException],
+    is_numeric: bool = True,
+    index_type: type | None = None,
+    values_type: type | None = None,
+    allow_null: bool = True,
+) -> bool:
+    """
+    Validation procedure checking:
+    - if series is a pandas series
+    - if series has only numeric values
+    - if series has correct length
+
+    (Optional) Validation procedure also checking:
+    - if series.index has provided type
+    - if series has provided type
+    - if series has null values
+    """
+    if isinstance(series, pd.Series):
+        is_validation_ok = _validate_series(
+            name=name,
+            series=series,
+            length=length,
+            exception_list=exception_list,
+            is_numeric=is_numeric,
+            index_type=index_type,
+            values_type=values_type,
+            allow_null=allow_null,
+        )
+    else:
+        exception_list.append(
+            NetworkValidatorException(
+                f"{name} must be a pandas Series, but {type(series).__name__} given"
+            )
+        )
+        is_validation_ok = False
+    return is_validation_ok
+
+
+def validate_dict_type(
+    dict_to_validate: dict,
+    key_type: type | UnionType,
+    value_type: type | UnionType,
+    parameter_name: str,
+    key_parameter_name: str,
+    value_parameter_name: str,
+    exception_list: list[NetworkValidatorException],
+) -> bool:
+    if not isinstance(dict_to_validate, dict):
+        exception_list.append(
+            NetworkValidatorException(
+                f"{parameter_name.capitalize()} must be of dict type"
+            )
+        )
+        return False
+
+    is_validation_ok = True
+    if not all(isinstance(key, key_type) for key in dict_to_validate.keys()):
+        exception_list.append(
+            NetworkValidatorException(
+                f"{key_parameter_name.capitalize()} in {parameter_name} must be of "
+                f"{key_type} type"
+            )
+        )
+        is_validation_ok = False
+
+    if not all(isinstance(value, value_type) for value in dict_to_validate.values()):
+        exception_list.append(
+            NetworkValidatorException(
+                f"{value_parameter_name.capitalize()} in {parameter_name} must be "
+                f"of {value_type} type"
+            )
+        )
+        is_validation_ok = False
+    if not is_validation_ok:
+        _logger.exception("There is a problem validating dict type: %s", exception_list)
+    return is_validation_ok
+
+
+def check_interval(
+    lower_bound: int | float,
+    upper_bound: int | float,
+    value: int | float,
+    is_lower_bound_closed: bool = True,
+    is_upper_bound_closed: bool = True,
+) -> bool:
+    """
+    Checks if the given value falls within the specified interval defined by the lower and upper bounds.
+
+    Args:
+        lower_bound (int or float): The lower bound of the interval.
+        upper_bound (int or float): The upper bound of the interval.
+        value (int or float): The value to be checked against the interval.
+        is_lower_bound_closed (bool, optional): Whether the lower bound is closed (inclusive). Default is True.
+        is_upper_bound_closed (bool, optional): Whether the upper bound is closed (inclusive). Default is True.
+
+    Returns:
+        bool
+    """
+
+    return (
+        (is_lower_bound_closed and lower_bound <= value)
+        or (not is_lower_bound_closed and lower_bound < value)
+    ) and (
+        (is_upper_bound_closed and value <= upper_bound)
+        or (not is_upper_bound_closed and value < upper_bound)
+    )
```

### Comparing `pyzefir-0.4.1/pyzefir/optimization/__init__.py` & `pyzefir-0.4.22/pyzefir/graph/__init__.py`

 * *Ordering differences only*

 * *Files 23% similar despite different names*

```diff
@@ -1,15 +1,15 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
```

### Comparing `pyzefir-0.4.1/pyzefir/optimization/exportable_results.py` & `pyzefir-0.4.22/pyzefir/optimization/exportable_results.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,71 +1,73 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-from abc import ABC
-from dataclasses import dataclass
-
-import pandas as pd
-
-
-@dataclass
-class ExportableResultsGroup(ABC):
-    pass
-
-
-@dataclass
-class ExportableGeneratorsResults(ExportableResultsGroup):
-    generation: dict[str, pd.DataFrame]
-    dump_energy: dict[str, pd.DataFrame]
-    capacity: pd.DataFrame
-    generation_per_energy_type: dict[str, pd.DataFrame]
-    dump_energy_per_energy_type: dict[str, pd.DataFrame]
-    capex: pd.DataFrame
-
-
-@dataclass
-class ExportableStorageResults(ExportableResultsGroup):
-    generation: dict[str, pd.DataFrame]
-    load: dict[str, pd.DataFrame]
-    state_of_charge: dict[str, pd.DataFrame]
-    capacity: pd.DataFrame
-    capex: pd.DataFrame
-
-
-@dataclass
-class ExportableLinesResults(ExportableResultsGroup):
-    flow: dict[str, pd.DataFrame]
-
-
-@dataclass
-class ExportableFractionsResults(ExportableResultsGroup):
-    fraction: dict[str, pd.DataFrame]
-
-
-@dataclass
-class ExportableBusResults(ExportableResultsGroup):
-    generation_ens: dict[str, pd.DataFrame]
-    shift_minus: dict[str, pd.DataFrame]
-    shift_plus: dict[str, pd.DataFrame]
-
-
-@dataclass
-class ExportableResults:
-    objective_value: pd.Series
-    generators_results: ExportableGeneratorsResults
-    storages_results: ExportableStorageResults
-    lines_results: ExportableLinesResults
-    fractions_results: ExportableFractionsResults
-    bus_results: ExportableBusResults
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+from abc import ABC
+from dataclasses import dataclass
+
+import pandas as pd
+
+
+@dataclass
+class ExportableResultsGroup(ABC):
+    pass
+
+
+@dataclass
+class ExportableGeneratorsResults(ExportableResultsGroup):
+    generation: dict[str, pd.DataFrame]
+    dump_energy: dict[str, pd.DataFrame]
+    capacity: pd.DataFrame
+    generation_per_energy_type: dict[str, pd.DataFrame]
+    dump_energy_per_energy_type: dict[str, pd.DataFrame]
+    global_capex: pd.DataFrame
+    local_capex: dict[str, pd.DataFrame]
+
+
+@dataclass
+class ExportableStorageResults(ExportableResultsGroup):
+    generation: dict[str, pd.DataFrame]
+    load: dict[str, pd.DataFrame]
+    state_of_charge: dict[str, pd.DataFrame]
+    capacity: pd.DataFrame
+    global_capex: pd.DataFrame
+    local_capex: dict[str, pd.DataFrame]
+
+
+@dataclass
+class ExportableLinesResults(ExportableResultsGroup):
+    flow: dict[str, pd.DataFrame]
+
+
+@dataclass
+class ExportableFractionsResults(ExportableResultsGroup):
+    fraction: dict[str, pd.DataFrame]
+
+
+@dataclass
+class ExportableBusResults(ExportableResultsGroup):
+    generation_ens: dict[str, pd.DataFrame]
+    shift_minus: dict[str, pd.DataFrame]
+    shift_plus: dict[str, pd.DataFrame]
+
+
+@dataclass
+class ExportableResults:
+    objective_value: pd.Series
+    generators_results: ExportableGeneratorsResults
+    storages_results: ExportableStorageResults
+    lines_results: ExportableLinesResults
+    fractions_results: ExportableFractionsResults
+    bus_results: ExportableBusResults
```

### Comparing `pyzefir-0.4.1/pyzefir/optimization/input_data.py` & `pyzefir-0.4.22/pyzefir/optimization/input_data.py`

 * *Ordering differences only*

 * *Files 14% similar despite different names*

```diff
@@ -1,30 +1,30 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-from dataclasses import dataclass
-
-from pyzefir.model.network import Network
-from pyzefir.optimization.opt_config import OptConfig
-
-
-@dataclass
-class OptimizationInputData:
-    """
-    All necessary data to run an optimization.
-    """
-
-    network: Network
-    config: OptConfig
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+from dataclasses import dataclass
+
+from pyzefir.model.network import Network
+from pyzefir.optimization.opt_config import OptConfig
+
+
+@dataclass
+class OptimizationInputData:
+    """
+    All necessary data to run an optimization.
+    """
+
+    network: Network
+    config: OptConfig
```

### Comparing `pyzefir-0.4.1/pyzefir/optimization/linopy/__init__.py` & `pyzefir-0.4.22/pyzefir/model/__init__.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,15 +1,15 @@
-# PyZefir
-# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
```

### Comparing `pyzefir-0.4.1/pyzefir/optimization/linopy/constraints_builder/__init__.py` & `pyzefir-0.4.22/pyzefir/model/network_elements/energy_source_types/__init__.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,15 +1,15 @@
-# PyZefir
-# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
```

### Comparing `pyzefir-0.4.1/pyzefir/optimization/linopy/constraints_builder/builder.py` & `pyzefir-0.4.22/pyzefir/optimization/linopy/objective_builder/__init__.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,54 +1,47 @@
-# PyZefir
-# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-import abc
-
-from linopy import Model
-
-from pyzefir.optimization.linopy.expression_handler import ExpressionHandler
-from pyzefir.optimization.linopy.preprocessing.indices import Indices
-from pyzefir.optimization.linopy.preprocessing.opt_parameters import (
-    OptimizationParameters,
-)
-from pyzefir.optimization.linopy.preprocessing.opt_variables import (
-    OptimizationVariables,
-)
-
-
-class PartialConstraintsBuilder(metaclass=abc.ABCMeta):
-    """
-    An abstract class to represent build of some constraints set
-    """
-
-    def __init__(
-        self,
-        indices: Indices,
-        parameters: OptimizationParameters,
-        variables: OptimizationVariables,
-        model: Model,
-    ) -> None:
-        self.indices = indices
-        self.parameters = parameters
-        self.variables = variables
-        self.model = model
-        self.expr = ExpressionHandler(indices, variables, parameters)
-
-    @abc.abstractmethod
-    def build_constraints(self) -> None:
-        """
-        Creating optimization constraints.
-        """
-        raise NotImplementedError
+# PyZefir
+# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+from abc import abstractmethod
+
+from linopy import LinearExpression, Model
+
+from pyzefir.optimization.linopy.expression_handler import ExpressionHandler
+from pyzefir.optimization.linopy.preprocessing.indices import Indices
+from pyzefir.optimization.linopy.preprocessing.opt_parameters import (
+    OptimizationParameters,
+)
+from pyzefir.optimization.linopy.preprocessing.opt_variables import (
+    OptimizationVariables,
+)
+
+
+class ObjectiveBuilder:
+    def __init__(
+        self,
+        indices: Indices,
+        parameters: OptimizationParameters,
+        variables: OptimizationVariables,
+        model: Model,
+    ) -> None:
+        self.indices = indices
+        self.parameters = parameters
+        self.variables = variables
+        self.model = model
+        self.expr = ExpressionHandler(indices, variables, parameters)
+
+    @abstractmethod
+    def build_expression(self) -> LinearExpression:
+        pass
```

### Comparing `pyzefir-0.4.1/pyzefir/optimization/linopy/constraints_builder/capacity_evolution_constraints_builder.py` & `pyzefir-0.4.22/pyzefir/optimization/linopy/constraints_builder/capacity_evolution_constraints_builder.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,413 +1,448 @@
-# PyZefir
-# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-import numpy as np
-
-from pyzefir.optimization.linopy.constraints_builder.builder import (
-    PartialConstraintsBuilder,
-)
-from pyzefir.optimization.linopy.preprocessing.indices import IndexingSet
-from pyzefir.optimization.linopy.preprocessing.parameters.generator_parameters import (
-    GeneratorParameters,
-)
-from pyzefir.optimization.linopy.preprocessing.parameters.generator_type_parameters import (
-    GeneratorTypeParameters,
-)
-from pyzefir.optimization.linopy.preprocessing.parameters.storage_parameters import (
-    StorageParameters,
-)
-from pyzefir.optimization.linopy.preprocessing.parameters.storage_type_parameters import (
-    StorageTypeParameters,
-)
-from pyzefir.optimization.linopy.preprocessing.variables.generator_type_variables import (
-    GeneratorTypeVariables,
-)
-from pyzefir.optimization.linopy.preprocessing.variables.generator_variables import (
-    GeneratorVariables,
-)
-from pyzefir.optimization.linopy.preprocessing.variables.storage_type_variables import (
-    StorageTypeVariables,
-)
-from pyzefir.optimization.linopy.preprocessing.variables.storage_variables import (
-    StorageVariables,
-)
-from pyzefir.utils.functions import get_dict_vals
-
-
-class CapacityEvolutionConstrBuilder(PartialConstraintsBuilder):
-    def build_constraints(self) -> None:
-        self.capacity_evolution_constraints()
-        self.supplementary_evolution_constraints()
-        self.base_capacity_constraints()
-        self.generator_n_min_max_power_constraints()
-
-    def generator_n_min_max_power_constraints(self) -> None:
-        self._build_n_min_max_power_constraints(
-            self.indices.GEN, self.parameters.gen, self.variables.gen
-        )
-        self._build_n_min_max_power_constraints(
-            self.indices.STOR, self.parameters.stor, self.variables.stor
-        )
-
-    def capacity_evolution_constraints(self) -> None:
-        self._build_capacity_evolution_constraints_gen_stor()
-        self._build_local_capacity_evolution_constraints_gen_stor()
-
-    def _build_capacity_evolution_constraints_gen_stor(self) -> None:
-        self._build_capacity_evolution_constraints(
-            unit_ii=self.indices.GEN,
-            unit_par=self.parameters.gen,
-            unit_tpar=self.parameters.tgen,
-            unit_tidx=self.parameters.gen.tgen,
-            unit_var=self.variables.gen,
-            unit_aggr_map=self.indices.aggr_gen_map,
-        )
-        self._build_capacity_evolution_constraints(
-            unit_ii=self.indices.STOR,
-            unit_par=self.parameters.stor,
-            unit_tpar=self.parameters.tstor,
-            unit_tidx=self.parameters.stor.tstor,
-            unit_var=self.variables.stor,
-            unit_aggr_map=self.indices.aggr_stor_map,
-        )
-
-    def _build_local_capacity_evolution_constraints_gen_stor(self) -> None:
-        self._build_local_capacity_evolution_constraints(
-            unit_par=self.parameters.gen,
-            unit_tpar=self.parameters.tgen,
-            unit_tidx=self.parameters.gen.tgen,
-            unit_tvar=self.variables.tgen,
-            unit_aggr_map=self.indices.aggr_gen_map,
-            unit_aggr_tmap=self.indices.aggr_tgen_map,
-            unit_type="GEN",
-        )
-        self._build_local_capacity_evolution_constraints(
-            unit_par=self.parameters.stor,
-            unit_tpar=self.parameters.tstor,
-            unit_tidx=self.parameters.stor.tstor,
-            unit_tvar=self.variables.tstor,
-            unit_aggr_map=self.indices.aggr_stor_map,
-            unit_aggr_tmap=self.indices.aggr_tstor_map,
-            unit_type="STOR",
-        )
-
-    def supplementary_evolution_constraints(self) -> None:
-        self._build_reduced_capacity_upper_bound_constraints_gen_stor()
-        self._build_local_supplementary_capacity_upper_bound_constraints_gen_stor()
-
-    def _build_reduced_capacity_upper_bound_constraints_gen_stor(self) -> None:
-        self._build_reduced_capacity_upper_bound_constraints(
-            unit_ii=self.indices.GEN,
-            unit_tpar=self.parameters.tgen,
-            unit_tidx=self.parameters.gen.tgen,
-            unit_var=self.variables.gen,
-            unit_aggr_map=self.indices.aggr_gen_map,
-        )
-        self._build_reduced_capacity_upper_bound_constraints(
-            unit_ii=self.indices.STOR,
-            unit_tpar=self.parameters.tstor,
-            unit_tidx=self.parameters.stor.tstor,
-            unit_var=self.variables.stor,
-            unit_aggr_map=self.indices.aggr_stor_map,
-        )
-
-    def _build_local_supplementary_capacity_upper_bound_constraints_gen_stor(
-        self,
-    ) -> None:
-        """Supplementary constraints specifying the cap <-> tcap relation
-        and equivalent of reduced_capacity_upper_bound_constraints for local technologies
-        The constraints separately for generators and storages
-        """
-        self._build_local_supplementary_capacity_upper_bound_constraints(
-            unit_tpar=self.parameters.tgen,
-            unit_tidx=self.parameters.gen.tgen,
-            unit_var=self.variables.gen,
-            unit_tvar=self.variables.tgen,
-            unit_aggr_tmap=self.indices.aggr_tgen_map,
-        )
-        self._build_local_supplementary_capacity_upper_bound_constraints(
-            unit_tpar=self.parameters.tstor,
-            unit_tidx=self.parameters.stor.tstor,
-            unit_var=self.variables.stor,
-            unit_tvar=self.variables.tstor,
-            unit_aggr_tmap=self.indices.aggr_tstor_map,
-        )
-
-    def base_capacity_constraints(self) -> None:
-        for idx, val in self.parameters.gen.base_cap.items():
-            self.model.add_constraints(
-                self.variables.gen.cap.isel(gen=idx, year=0) == val,
-                name=f"GEN_{idx}_Y0_CAP_CONSTRAINT",
-            )
-
-        for idx, val in self.parameters.stor.base_cap.items():
-            self.model.add_constraints(
-                self.variables.stor.cap.isel(stor=idx, year=0) == val,
-                name=f"STOR_{idx}_Y0_CAP_CONSTRAINT",
-            )
-
-    def _build_capacity_evolution_constraints(
-        self,
-        unit_ii: IndexingSet,
-        unit_par: GeneratorParameters | StorageParameters,
-        unit_tpar: GeneratorTypeParameters | StorageTypeParameters,
-        unit_tidx: dict[int, int],
-        unit_var: GeneratorVariables | StorageVariables,
-        unit_aggr_map: dict[int, set],
-    ) -> None:
-        cap, cap_base_minus = unit_var.cap, unit_var.cap_base_minus
-        cap_plus, cap_minus = unit_var.cap_plus, unit_var.cap_minus
-        lbs_unit_idx = get_dict_vals(unit_aggr_map)
-        for u_idx, u_name in unit_ii.mapping.items():
-            if u_idx in lbs_unit_idx:  # if u_idx in any lbs then skipped
-                continue
-            base_cap = unit_par.base_cap[u_idx]
-            lt = unit_tpar.lt[unit_tidx[u_idx]]
-            bt = unit_tpar.bt[unit_tidx[u_idx]]
-            for y in self.indices.Y.ord:
-                initial_cap = (
-                    -cap_base_minus.sel(
-                        index=[(u_idx, s) for s in range(1, y + 1)]
-                    ).sum()
-                    + base_cap
-                    if y < lt
-                    else 0
-                )
-                incr_cap = cap_plus.sel(
-                    index=[(u_idx, s) for s in self._s_range(y, lt, bt)]
-                ).sum()
-                decr_cap = cap_minus.sel(
-                    index=[
-                        (u_idx, s, t)
-                        for s in self._s_range(y, lt, bt)
-                        for t in self._t_range(y, s, lt, bt)
-                    ]
-                ).sum()
-                self.model.add_constraints(
-                    cap.isel(**{cap.dims[0]: u_idx, "year": y})
-                    == initial_cap + incr_cap - decr_cap,
-                    name=f"{unit_ii.name}_{u_name}_Y_{y}_CAPACITY_EVOLUTION_CONSTRAINT",
-                )
-
-    def _build_local_capacity_evolution_constraints(
-        self,
-        unit_par: GeneratorParameters | StorageParameters,
-        unit_tpar: GeneratorTypeParameters | StorageTypeParameters,
-        unit_tidx: dict[int, int],
-        unit_tvar: GeneratorTypeVariables | StorageTypeVariables,
-        unit_aggr_map: dict[int, set],
-        unit_aggr_tmap: dict[int, set],
-        unit_type: str,
-    ) -> None:
-        tcap, tcap_base_minus = unit_tvar.tcap, unit_tvar.tcap_base_minus
-        tcap_plus, tcap_minus = unit_tvar.tcap_plus, unit_tvar.tcap_minus
-        for aggr_idx in unit_aggr_map.keys():
-            for t_idx in unit_aggr_tmap[aggr_idx]:
-                u_idxs = self._get_unit_idx_from_type(unit_tidx, t_idx)
-                base_cap: np.ndarray = np.sum(
-                    [unit_par.base_cap[u_idx] for u_idx in u_idxs],
-                )
-                lt = unit_tpar.lt[t_idx]
-                bt = unit_tpar.bt[t_idx]
-                for y in self.indices.Y.ord:
-                    initial_cap = (
-                        -tcap_base_minus.sel(
-                            index=[(aggr_idx, t_idx, s) for s in range(1, y + 1)]
-                        ).sum()
-                        + base_cap
-                        if y < lt
-                        else 0
-                    )
-                    incr_cap = tcap_plus.sel(
-                        index=[(aggr_idx, t_idx, s) for s in self._s_range(y, lt, bt)]
-                    ).sum()
-                    decr_cap = tcap_minus.sel(
-                        index=[
-                            (aggr_idx, t_idx, s, t)
-                            for s in self._s_range(y, lt, bt)
-                            for t in self._t_range(y, s, lt, bt)
-                        ]
-                    ).sum()
-                    self.model.add_constraints(
-                        tcap.sel(index=[(aggr_idx, t_idx, y)])
-                        == initial_cap + incr_cap - decr_cap,
-                        name=f"aggr_{aggr_idx}_{unit_type}_type_{t_idx}_Y_{y}_LOCAL_CAPACITY_EVOLUTION_CONSTRAINT",
-                    )
-
-    def _build_reduced_capacity_upper_bound_constraints(
-        self,
-        unit_ii: IndexingSet,
-        unit_tpar: GeneratorTypeParameters | StorageTypeParameters,
-        unit_tidx: dict[int, int],
-        unit_var: GeneratorVariables | StorageVariables,
-        unit_aggr_map: dict[int, set],
-    ) -> None:
-        cap_plus, cap_minus = unit_var.cap_plus, unit_var.cap_minus
-        lbs_unit_idx = get_dict_vals(unit_aggr_map)
-        for u_idx, u_name in unit_ii.mapping.items():
-            if u_idx in lbs_unit_idx:
-                continue
-            lt, bt = unit_tpar.lt[unit_tidx[u_idx]], unit_tpar.bt[unit_tidx[u_idx]]
-            for y in self.indices.Y.ord:
-                zero_cap_minus_sum = cap_minus.sel(
-                    index=[(u_idx, y, s) for s in self._t_range(y, y, lt, bt)]
-                ).sum()
-                self.model.add_constraints(
-                    zero_cap_minus_sum == 0,
-                    name=f"{unit_ii.name}_{u_name}_Y_{y}_ZERO_REDUCED_CAPACITY_CONSTRAINT",
-                )
-                all_cap_minus_sum = cap_minus.sel(
-                    index=[(u_idx, y, s) for s in self.indices.Y.ord]
-                ).sum()
-                self.model.add_constraints(
-                    all_cap_minus_sum <= cap_plus.sel(index=[(u_idx, y)]),
-                    name=f"{unit_ii.name}_{u_name}_Y_{y}_REDUCED_CAPACITY_UB_CONSTRAINT",
-                )
-
-    def _build_local_supplementary_capacity_upper_bound_constraints(
-        self,
-        unit_tpar: GeneratorTypeParameters | StorageTypeParameters,
-        unit_tidx: dict[int, int],
-        unit_var: GeneratorVariables | StorageVariables,
-        unit_tvar: GeneratorTypeVariables | StorageTypeVariables,
-        unit_aggr_tmap: dict[int, set],
-    ) -> None:
-        cap = unit_var.cap
-        tcap, tcap_plus, tcap_minus = (
-            unit_tvar.tcap,
-            unit_tvar.tcap_plus,
-            unit_tvar.tcap_minus,
-        )
-        for aggr_idx in unit_aggr_tmap.keys():
-            for type_idx in unit_aggr_tmap[aggr_idx]:
-                lt, bt = (
-                    unit_tpar.lt[type_idx],
-                    unit_tpar.bt[type_idx],
-                )
-                u_idxs = self._get_unit_idx_from_type(unit_tidx, type_idx)
-
-                for y in self.indices.Y.ord:
-                    zero_cap_minus_sum = tcap_minus.sel(
-                        index=[
-                            (aggr_idx, type_idx, y, s)
-                            for s in self._t_range(y, y, lt, bt)
-                        ]
-                    )
-                    self.model.add_constraints(
-                        zero_cap_minus_sum == 0,
-                        name=f"aggr_idx_{aggr_idx}_{cap.dims[0]}_t_idx_{type_idx}_Y_{y}"
-                        "_LOCAL_ZERO_REDUCED_CAPACITY_CONSTRAINT",
-                    )
-                    t_all_cap_minus_sum = tcap_minus.sel(
-                        index=[(aggr_idx, type_idx, y, s) for s in self.indices.Y.ord]
-                    ).sum()
-                    self.model.add_constraints(
-                        t_all_cap_minus_sum
-                        <= tcap_plus.sel(index=[(aggr_idx, type_idx, y)]),
-                        name=f"aggr_idx_{aggr_idx}_{cap.dims[0]}_t_idx_{type_idx}_Y_{y}"
-                        "_LOCAL_REDUCED_CAPACITY_UB_CONSTRAINT",
-                    )
-
-                    # definitions of t_cap in evolution equations:
-
-                    self.model.add_constraints(
-                        tcap.sel(index=[(aggr_idx, type_idx, y)])
-                        == cap.isel(**{cap.dims[0]: list(u_idxs), "year": y}).sum(),
-                        name=f"cap_{aggr_idx}_{cap.dims[0]}_t_idx_{type_idx}_Y_{y}_CAP_LOCAL_SUM_CONSTRAINT",
-                    )
-
-    def _build_n_min_max_power_constraints(
-        self,
-        unit_ii: IndexingSet,
-        unit_par: GeneratorParameters | StorageParameters,
-        unit_var: GeneratorVariables | StorageVariables,
-    ) -> None:
-        """Slavkov problem"""
-        for u_idx, u_name in unit_ii.mapping.items():
-            for lbs_idx in self.parameters.lbs.buses.keys():
-                lbs_buses = set().union(
-                    *list(self.parameters.lbs.buses[lbs_idx].values())
-                )
-                unit_buses = (
-                    {unit_par.bus[u_idx]}
-                    if isinstance(unit_par, StorageParameters)
-                    else unit_par.buses[u_idx]
-                )
-                if not unit_buses.isdisjoint(lbs_buses):
-                    self._build_n_min_max_power_for_aggr_constraints(
-                        lbs_idx,
-                        u_idx,
-                        u_name,
-                        unit_par,
-                        unit_var,
-                    )
-
-    def _build_n_min_max_power_for_aggr_constraints(
-        self,
-        lbs_idx: int,
-        u_idx: int,
-        u_name: str,
-        unit_par: GeneratorParameters | StorageParameters,
-        unit_var: GeneratorVariables | StorageVariables,
-    ) -> None:
-        aggr_idx = [
-            ii
-            for ii in self.indices.AGGR.ord
-            if self.parameters.aggr.lbs_indicator[ii, lbs_idx] == 1
-        ].pop()
-        for y in self.indices.Y.ord[1:]:
-            if u_idx in unit_par.min_device_nom_power:
-                min_aggregated_power = (
-                    self.parameters.aggr.n_consumers[aggr_idx][y]
-                    * unit_par.min_device_nom_power[u_idx]
-                    * self.variables.frac.fraction.isel(
-                        aggr=aggr_idx, lbs=lbs_idx, year=y
-                    )
-                )
-                self.model.add_constraints(
-                    min_aggregated_power
-                    <= unit_var.cap.isel(**{unit_var.cap.dims[0]: u_idx, "year": y})
-                    + self.parameters.scenario_parameters.numeric_tolerance,
-                    name=f"{aggr_idx}_{u_name}_{y}_DEVICE_MIN_POWER_CONSTRAINT",
-                )
-            if u_idx in unit_par.max_device_nom_power:
-                max_aggregated_power = (
-                    self.parameters.aggr.n_consumers[aggr_idx][y]
-                    * unit_par.max_device_nom_power[u_idx]
-                    * self.variables.frac.fraction.isel(
-                        aggr=aggr_idx, lbs=lbs_idx, year=y
-                    )
-                )
-                self.model.add_constraints(
-                    max_aggregated_power
-                    + self.parameters.scenario_parameters.numeric_tolerance
-                    >= unit_var.cap.isel(**{unit_var.cap.dims[0]: u_idx, "year": y}),
-                    name=f"{aggr_idx}_{u_name}_{y}_DEVICE_MAX_POWER_CONSTRAIN",
-                )
-
-    @staticmethod
-    def _get_unit_idx_from_type(unit_t_idx: dict[int, int], type_idx: int) -> set[int]:
-        return {
-            u_idx for u_idx, u_type_idx in unit_t_idx.items() if u_type_idx == type_idx
-        }
-
-    @staticmethod
-    def _s_range(y: int, lt: int, bt: int) -> range:
-        return range(max(0, y - lt - bt + 1), y - bt + 1)
-
-    @staticmethod
-    def _t_range(y: int, s: int, lt: int, bt: int) -> range:
-        return range(s + bt, min(y, s + bt + lt - 1) + 1)
+# PyZefir
+# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+import logging
+
+import numpy as np
+
+from pyzefir.optimization.linopy.constraints_builder.builder import (
+    PartialConstraintsBuilder,
+)
+from pyzefir.optimization.linopy.preprocessing.indices import IndexingSet
+from pyzefir.optimization.linopy.preprocessing.parameters.generator_parameters import (
+    GeneratorParameters,
+)
+from pyzefir.optimization.linopy.preprocessing.parameters.generator_type_parameters import (
+    GeneratorTypeParameters,
+)
+from pyzefir.optimization.linopy.preprocessing.parameters.storage_parameters import (
+    StorageParameters,
+)
+from pyzefir.optimization.linopy.preprocessing.parameters.storage_type_parameters import (
+    StorageTypeParameters,
+)
+from pyzefir.optimization.linopy.preprocessing.variables.generator_type_variables import (
+    GeneratorTypeVariables,
+)
+from pyzefir.optimization.linopy.preprocessing.variables.generator_variables import (
+    GeneratorVariables,
+)
+from pyzefir.optimization.linopy.preprocessing.variables.storage_type_variables import (
+    StorageTypeVariables,
+)
+from pyzefir.optimization.linopy.preprocessing.variables.storage_variables import (
+    StorageVariables,
+)
+from pyzefir.utils.functions import get_dict_vals
+
+_logger = logging.getLogger(__name__)
+
+
+class CapacityEvolutionConstrBuilder(PartialConstraintsBuilder):
+    def build_constraints(self) -> None:
+        _logger.info("Capacity evolution constraints builder is working...")
+        self.capacity_evolution_constraints()
+        self.supplementary_evolution_constraints()
+        self.base_capacity_constraints()
+        self.generator_n_min_max_power_constraints()
+        _logger.info("Capacity evolution constraints builder is finished!")
+
+    def generator_n_min_max_power_constraints(self) -> None:
+        _logger.debug("Building power constraints...")
+        self._build_n_min_max_power_constraints(
+            self.indices.GEN, self.parameters.gen, self.variables.gen
+        )
+        _logger.debug("Building generator power constraints: Done")
+        self._build_n_min_max_power_constraints(
+            self.indices.STOR, self.parameters.stor, self.variables.stor
+        )
+        _logger.debug("Building storage power constraints: Done")
+        _logger.debug("Build power constraints: Done")
+
+    def capacity_evolution_constraints(self) -> None:
+        _logger.debug("Building capacity evolution constraints...")
+        self._build_capacity_evolution_constraints_gen_stor()
+        self._build_local_capacity_evolution_constraints_gen_stor()
+        _logger.debug("Build capacity evolution constraints: Done")
+
+    def _build_capacity_evolution_constraints_gen_stor(self) -> None:
+        self._build_capacity_evolution_constraints(
+            unit_ii=self.indices.GEN,
+            unit_par=self.parameters.gen,
+            unit_tpar=self.parameters.tgen,
+            unit_tidx=self.parameters.gen.tgen,
+            unit_var=self.variables.gen,
+            unit_aggr_map=self.indices.aggr_gen_map,
+        )
+        _logger.debug("Build generation capacity evolution constraints: Done")
+        self._build_capacity_evolution_constraints(
+            unit_ii=self.indices.STOR,
+            unit_par=self.parameters.stor,
+            unit_tpar=self.parameters.tstor,
+            unit_tidx=self.parameters.stor.tstor,
+            unit_var=self.variables.stor,
+            unit_aggr_map=self.indices.aggr_stor_map,
+        )
+        _logger.debug("Build storage capacity evolution constraints: Done")
+
+    def _build_local_capacity_evolution_constraints_gen_stor(self) -> None:
+        self._build_local_capacity_evolution_constraints(
+            unit_par=self.parameters.gen,
+            unit_tpar=self.parameters.tgen,
+            unit_tidx=self.parameters.gen.tgen,
+            unit_tvar=self.variables.tgen,
+            unit_aggr_map=self.indices.aggr_gen_map,
+            unit_aggr_tmap=self.indices.aggr_tgen_map,
+            unit_type="GEN",
+        )
+        _logger.debug("Build local generation capacity evolution constraints: Done")
+        self._build_local_capacity_evolution_constraints(
+            unit_par=self.parameters.stor,
+            unit_tpar=self.parameters.tstor,
+            unit_tidx=self.parameters.stor.tstor,
+            unit_tvar=self.variables.tstor,
+            unit_aggr_map=self.indices.aggr_stor_map,
+            unit_aggr_tmap=self.indices.aggr_tstor_map,
+            unit_type="STOR",
+        )
+        _logger.debug("Build local storage capacity evolution constraints: Done")
+
+    def supplementary_evolution_constraints(self) -> None:
+        _logger.debug("Building supplementary evolution constraints...")
+        self._build_reduced_capacity_upper_bound_constraints_gen_stor()
+        self._build_local_supplementary_capacity_upper_bound_constraints_gen_stor()
+        _logger.debug("Build supplementary evolution constraints: Done")
+
+    def _build_reduced_capacity_upper_bound_constraints_gen_stor(self) -> None:
+        self._build_reduced_capacity_upper_bound_constraints(
+            unit_ii=self.indices.GEN,
+            unit_tpar=self.parameters.tgen,
+            unit_tidx=self.parameters.gen.tgen,
+            unit_var=self.variables.gen,
+            unit_aggr_map=self.indices.aggr_gen_map,
+        )
+        _logger.debug("Build generation reduced capacity upper bound constraints: Done")
+        self._build_reduced_capacity_upper_bound_constraints(
+            unit_ii=self.indices.STOR,
+            unit_tpar=self.parameters.tstor,
+            unit_tidx=self.parameters.stor.tstor,
+            unit_var=self.variables.stor,
+            unit_aggr_map=self.indices.aggr_stor_map,
+        )
+        _logger.debug("Build storage reduced capacity upper bound constraints: Done")
+
+    def _build_local_supplementary_capacity_upper_bound_constraints_gen_stor(
+        self,
+    ) -> None:
+        """Supplementary constraints specifying the cap <-> tcap relation
+        and equivalent of reduced_capacity_upper_bound_constraints for local technologies
+        The constraints separately for generators and storages
+        """
+        self._build_local_supplementary_capacity_upper_bound_constraints(
+            unit_tpar=self.parameters.tgen,
+            unit_tidx=self.parameters.gen.tgen,
+            unit_var=self.variables.gen,
+            unit_tvar=self.variables.tgen,
+            unit_aggr_tmap=self.indices.aggr_tgen_map,
+            unit_aggr_map=self.indices.aggr_gen_map,
+        )
+        _logger.debug(
+            "Build generation local supplementary capacity upper bound constraints: Done"
+        )
+        self._build_local_supplementary_capacity_upper_bound_constraints(
+            unit_tpar=self.parameters.tstor,
+            unit_tidx=self.parameters.stor.tstor,
+            unit_var=self.variables.stor,
+            unit_tvar=self.variables.tstor,
+            unit_aggr_tmap=self.indices.aggr_tstor_map,
+            unit_aggr_map=self.indices.aggr_stor_map,
+        )
+        _logger.debug(
+            "Build storage local supplementary capacity upper bound constraints: Done"
+        )
+
+    def base_capacity_constraints(self) -> None:
+        for idx, val in self.parameters.gen.base_cap.items():
+            self.model.add_constraints(
+                self.variables.gen.cap.isel(gen=idx, year=0) == val,
+                name=f"GEN_{idx}_Y0_CAP_CONSTRAINT",
+            )
+
+        for idx, val in self.parameters.stor.base_cap.items():
+            self.model.add_constraints(
+                self.variables.stor.cap.isel(stor=idx, year=0) == val,
+                name=f"STOR_{idx}_Y0_CAP_CONSTRAINT",
+            )
+        _logger.debug("Build base capacity constraints: Done")
+
+    def _build_capacity_evolution_constraints(
+        self,
+        unit_ii: IndexingSet,
+        unit_par: GeneratorParameters | StorageParameters,
+        unit_tpar: GeneratorTypeParameters | StorageTypeParameters,
+        unit_tidx: dict[int, int],
+        unit_var: GeneratorVariables | StorageVariables,
+        unit_aggr_map: dict[int, set],
+    ) -> None:
+        cap, cap_base_minus = unit_var.cap, unit_var.cap_base_minus
+        cap_plus, cap_minus = unit_var.cap_plus, unit_var.cap_minus
+        lbs_unit_idx = get_dict_vals(unit_aggr_map)
+        for u_idx, u_name in unit_ii.mapping.items():
+            if u_idx in lbs_unit_idx:  # if u_idx in any lbs then skipped
+                continue
+            base_cap = unit_par.base_cap[u_idx]
+            lt = unit_tpar.lt[unit_tidx[u_idx]]
+            bt = unit_tpar.bt[unit_tidx[u_idx]]
+            for y in self.indices.Y.ord:
+                initial_cap = (
+                    -cap_base_minus.sel(
+                        index=[(u_idx, s) for s in range(1, y + 1)]
+                    ).sum()
+                    + base_cap
+                    if y < lt
+                    else 0
+                )
+                incr_cap = cap_plus.sel(
+                    index=[(u_idx, s) for s in self._s_range(y, lt, bt)]
+                ).sum()
+                decr_cap = cap_minus.sel(
+                    index=[
+                        (u_idx, s, t)
+                        for s in self._s_range(y, lt, bt)
+                        for t in self._t_range(y, s, lt, bt)
+                    ]
+                ).sum()
+                self.model.add_constraints(
+                    cap.isel(**{cap.dims[0]: u_idx, "year": y})
+                    == initial_cap + incr_cap - decr_cap,
+                    name=f"{unit_ii.name}_{u_name}_Y_{y}_CAPACITY_EVOLUTION_CONSTRAINT",
+                )
+
+    def _build_local_capacity_evolution_constraints(
+        self,
+        unit_par: GeneratorParameters | StorageParameters,
+        unit_tpar: GeneratorTypeParameters | StorageTypeParameters,
+        unit_tidx: dict[int, int],
+        unit_tvar: GeneratorTypeVariables | StorageTypeVariables,
+        unit_aggr_map: dict[int, set],
+        unit_aggr_tmap: dict[int, set],
+        unit_type: str,
+    ) -> None:
+        tcap, tcap_base_minus = unit_tvar.tcap, unit_tvar.tcap_base_minus
+        tcap_plus, tcap_minus = unit_tvar.tcap_plus, unit_tvar.tcap_minus
+        for aggr_idx in unit_aggr_map.keys():
+            for t_idx in unit_aggr_tmap[aggr_idx]:
+                u_idxs = self._get_unit_idx_from_type(
+                    unit_tidx, t_idx, unit_aggr_map[aggr_idx]
+                )
+                base_cap: np.ndarray = np.sum(
+                    [unit_par.base_cap[u_idx] for u_idx in u_idxs],
+                )
+                lt = unit_tpar.lt[t_idx]
+                bt = unit_tpar.bt[t_idx]
+                for y in self.indices.Y.ord:
+                    initial_cap = (
+                        -tcap_base_minus.sel(
+                            index=[(aggr_idx, t_idx, s) for s in range(1, y + 1)]
+                        ).sum()
+                        + base_cap
+                        if y < lt
+                        else 0
+                    )
+                    incr_cap = tcap_plus.sel(
+                        index=[(aggr_idx, t_idx, s) for s in self._s_range(y, lt, bt)]
+                    ).sum()
+                    decr_cap = tcap_minus.sel(
+                        index=[
+                            (aggr_idx, t_idx, s, t)
+                            for s in self._s_range(y, lt, bt)
+                            for t in self._t_range(y, s, lt, bt)
+                        ]
+                    ).sum()
+                    self.model.add_constraints(
+                        tcap.sel(index=[(aggr_idx, t_idx, y)])
+                        == initial_cap + incr_cap - decr_cap,
+                        name=f"aggr_{aggr_idx}_{unit_type}_type_{t_idx}_Y_{y}_LOCAL_CAPACITY_EVOLUTION_CONSTRAINT",
+                    )
+
+    def _build_reduced_capacity_upper_bound_constraints(
+        self,
+        unit_ii: IndexingSet,
+        unit_tpar: GeneratorTypeParameters | StorageTypeParameters,
+        unit_tidx: dict[int, int],
+        unit_var: GeneratorVariables | StorageVariables,
+        unit_aggr_map: dict[int, set],
+    ) -> None:
+        cap_plus, cap_minus = unit_var.cap_plus, unit_var.cap_minus
+        lbs_unit_idx = get_dict_vals(unit_aggr_map)
+        for u_idx, u_name in unit_ii.mapping.items():
+            if u_idx in lbs_unit_idx:
+                continue
+            lt, bt = unit_tpar.lt[unit_tidx[u_idx]], unit_tpar.bt[unit_tidx[u_idx]]
+            for y in self.indices.Y.ord:
+                zero_cap_minus_sum = cap_minus.sel(
+                    index=[(u_idx, y, s) for s in self._t_range(y, y, lt, bt)]
+                ).sum()
+                self.model.add_constraints(
+                    zero_cap_minus_sum == 0,
+                    name=f"{unit_ii.name}_{u_name}_Y_{y}_ZERO_REDUCED_CAPACITY_CONSTRAINT",
+                )
+                all_cap_minus_sum = cap_minus.sel(
+                    index=[(u_idx, y, s) for s in self.indices.Y.ord]
+                ).sum()
+                self.model.add_constraints(
+                    all_cap_minus_sum <= cap_plus.sel(index=[(u_idx, y)]),
+                    name=f"{unit_ii.name}_{u_name}_Y_{y}_REDUCED_CAPACITY_UB_CONSTRAINT",
+                )
+
+    def _build_local_supplementary_capacity_upper_bound_constraints(
+        self,
+        unit_tpar: GeneratorTypeParameters | StorageTypeParameters,
+        unit_tidx: dict[int, int],
+        unit_var: GeneratorVariables | StorageVariables,
+        unit_tvar: GeneratorTypeVariables | StorageTypeVariables,
+        unit_aggr_tmap: dict[int, set],
+        unit_aggr_map: dict[int, set],
+    ) -> None:
+        cap = unit_var.cap
+        tcap, tcap_plus, tcap_minus = (
+            unit_tvar.tcap,
+            unit_tvar.tcap_plus,
+            unit_tvar.tcap_minus,
+        )
+        for aggr_idx in unit_aggr_tmap.keys():
+            for type_idx in unit_aggr_tmap[aggr_idx]:
+                lt, bt = (
+                    unit_tpar.lt[type_idx],
+                    unit_tpar.bt[type_idx],
+                )
+                u_idxs = self._get_unit_idx_from_type(
+                    unit_tidx, type_idx, unit_aggr_map[aggr_idx]
+                )
+
+                for y in self.indices.Y.ord:
+                    zero_cap_minus_sum = tcap_minus.sel(
+                        index=[
+                            (aggr_idx, type_idx, y, s)
+                            for s in self._t_range(y, y, lt, bt)
+                        ]
+                    )
+                    self.model.add_constraints(
+                        zero_cap_minus_sum == 0,
+                        name=f"aggr_idx_{aggr_idx}_{cap.dims[0]}_t_idx_{type_idx}_Y_{y}"
+                        "_LOCAL_ZERO_REDUCED_CAPACITY_CONSTRAINT",
+                    )
+                    t_all_cap_minus_sum = tcap_minus.sel(
+                        index=[(aggr_idx, type_idx, y, s) for s in self.indices.Y.ord]
+                    ).sum()
+                    self.model.add_constraints(
+                        t_all_cap_minus_sum
+                        <= tcap_plus.sel(index=[(aggr_idx, type_idx, y)]),
+                        name=f"aggr_idx_{aggr_idx}_{cap.dims[0]}_t_idx_{type_idx}_Y_{y}"
+                        "_LOCAL_REDUCED_CAPACITY_UB_CONSTRAINT",
+                    )
+
+                    # definitions of t_cap in evolution equations:
+
+                    self.model.add_constraints(
+                        tcap.sel(index=[(aggr_idx, type_idx, y)])
+                        == cap.isel(**{cap.dims[0]: u_idxs, "year": y}).sum(),
+                        name=f"cap_{aggr_idx}_{cap.dims[0]}_t_idx_{type_idx}_Y_{y}_CAP_LOCAL_SUM_CONSTRAINT",
+                    )
+
+    def _build_n_min_max_power_constraints(
+        self,
+        unit_ii: IndexingSet,
+        unit_par: GeneratorParameters | StorageParameters,
+        unit_var: GeneratorVariables | StorageVariables,
+    ) -> None:
+        """Slavkov problem"""
+        for u_idx, u_name in unit_ii.mapping.items():
+            for lbs_idx in self.parameters.lbs.buses.keys():
+                lbs_buses = set().union(
+                    *list(self.parameters.lbs.buses[lbs_idx].values())
+                )
+                unit_buses = (
+                    {unit_par.bus[u_idx]}
+                    if isinstance(unit_par, StorageParameters)
+                    else unit_par.buses[u_idx]
+                )
+                if not unit_buses.isdisjoint(lbs_buses):
+                    self._build_n_min_max_power_for_aggr_constraints(
+                        lbs_idx,
+                        u_idx,
+                        u_name,
+                        unit_par,
+                        unit_var,
+                    )
+
+    def _build_n_min_max_power_for_aggr_constraints(
+        self,
+        lbs_idx: int,
+        u_idx: int,
+        u_name: str,
+        unit_par: GeneratorParameters | StorageParameters,
+        unit_var: GeneratorVariables | StorageVariables,
+    ) -> None:
+        aggr_idx = [
+            ii
+            for ii in self.indices.AGGR.ord
+            if self.parameters.aggr.lbs_indicator[ii, lbs_idx] == 1
+        ].pop()
+        for y in self.indices.Y.ord[1:]:
+            if u_idx in unit_par.min_device_nom_power:
+                min_aggregated_power = (
+                    self.parameters.aggr.n_consumers[aggr_idx][y]
+                    * unit_par.min_device_nom_power[u_idx]
+                    * self.variables.frac.fraction.isel(
+                        aggr=aggr_idx, lbs=lbs_idx, year=y
+                    )
+                )
+                self.model.add_constraints(
+                    min_aggregated_power
+                    <= unit_var.cap.isel(**{unit_var.cap.dims[0]: u_idx, "year": y}),
+                    name=f"{aggr_idx}_{u_name}_{y}_DEVICE_MIN_POWER_CONSTRAINT",
+                )
+            if u_idx in unit_par.max_device_nom_power:
+                max_aggregated_power = (
+                    self.parameters.aggr.n_consumers[aggr_idx][y]
+                    * unit_par.max_device_nom_power[u_idx]
+                    * self.variables.frac.fraction.isel(
+                        aggr=aggr_idx, lbs=lbs_idx, year=y
+                    )
+                )
+                self.model.add_constraints(
+                    max_aggregated_power
+                    >= unit_var.cap.isel(**{unit_var.cap.dims[0]: u_idx, "year": y}),
+                    name=f"{aggr_idx}_{u_name}_{y}_DEVICE_MAX_POWER_CONSTRAIN",
+                )
+
+    @staticmethod
+    def _get_unit_idx_from_type(
+        unit_t_idx: dict[int, int], type_idx: int, unit_in_aggr: set[int]
+    ) -> list[int]:
+        return [
+            u_idx
+            for u_idx, u_type_idx in unit_t_idx.items()
+            if u_type_idx == type_idx and u_idx in unit_in_aggr
+        ]
+
+    @staticmethod
+    def _s_range(y: int, lt: int, bt: int) -> range:
+        return range(max(0, y - lt - bt + 1), y - bt + 1)
+
+    @staticmethod
+    def _t_range(y: int, s: int, lt: int, bt: int) -> range:
+        return range(s + bt, min(y, s + bt + lt - 1) + 1)
```

### Comparing `pyzefir-0.4.1/pyzefir/optimization/linopy/constraints_builder/fraction_constraints_builder.py` & `pyzefir-0.4.22/pyzefir/optimization/linopy/constraints_builder/fraction_constraints_builder.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,65 +1,73 @@
-# PyZefir
-# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-import xarray as xr
-
-from pyzefir.optimization.linopy.constraints_builder.builder import (
-    PartialConstraintsBuilder,
-)
-
-
-class FractionConstraintsBuilder(PartialConstraintsBuilder):
-    def build_constraints(self) -> None:
-        self.build_base_fraction_constraint()
-        self.build_fraction_upper_bound_constraint()
-        self.build_lbs_involvement_in_consumer_aggregates_constraint()
-
-    def build_base_fraction_constraint(self) -> None:
-        """Fixing fractions value in year y=0 of each local balancing stack in each aggregated consumer."""
-        base_fraction = xr.DataArray(
-            data=self.parameters.aggr.fr_base,
-            coords=[self.indices.AGGR.ord, self.indices.LBS.ii],
-            dims=["aggr", "lbs"],
-        )
-        self.model.add_constraints(
-            self.variables.frac.fraction.sel(year=0) == base_fraction,
-            name="BASE_FRACTION_CONSTRAINT",
-        )
-
-    def build_fraction_upper_bound_constraint(self) -> None:
-        """
-        If given local balancing stack lbs is available for a given aggregated consumer aggr, then frac[aggr, lbs] <= 1,
-        otherwise frac[aggr, lbs] <= 0.
-        """
-        lbs_indicator = xr.DataArray(
-            data=self.parameters.aggr.lbs_indicator,
-            coords=[self.indices.AGGR.ord, self.indices.LBS.ii],
-            dims=["aggr", "lbs"],
-        )
-        self.model.add_constraints(
-            self.variables.frac.fraction <= lbs_indicator,
-            name="FRACTION_UPPER_BOUND_CONSTRAINT",
-        )
-
-    def build_lbs_involvement_in_consumer_aggregates_constraint(self) -> None:
-        """
-        Sum of all fractions of all local balancing stacks in a given aggregated consumer must be equal to 1 in every
-        year.
-        """
-        self.model.add_constraints(
-            self.variables.frac.fraction.sum("lbs") == 1.0,
-            name="LBS_INVOLVEMENT_IN_CONSUMER_AGGREGATES_CONSTRAINT",
-        )
+# PyZefir
+# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+import logging
+
+import xarray as xr
+
+from pyzefir.optimization.linopy.constraints_builder.builder import (
+    PartialConstraintsBuilder,
+)
+
+_logger = logging.getLogger(__name__)
+
+
+class FractionConstraintsBuilder(PartialConstraintsBuilder):
+    def build_constraints(self) -> None:
+        _logger.info("Fraction constraints builder is working...")
+        self.build_base_fraction_constraint()
+        self.build_fraction_upper_bound_constraint()
+        self.build_lbs_involvement_in_consumer_aggregates_constraint()
+        _logger.info("Fraction constraints builder is finished!")
+
+    def build_base_fraction_constraint(self) -> None:
+        """Fixing fractions value in year y=0 of each local balancing stack in each aggregated consumer."""
+        base_fraction = xr.DataArray(
+            data=self.parameters.aggr.fr_base,
+            coords=[self.indices.AGGR.ord, self.indices.LBS.ii],
+            dims=["aggr", "lbs"],
+        )
+        self.model.add_constraints(
+            self.variables.frac.fraction.sel(year=0) == base_fraction,
+            name="BASE_FRACTION_CONSTRAINT",
+        )
+        _logger.debug("Build base fraction constraint: Done")
+
+    def build_fraction_upper_bound_constraint(self) -> None:
+        """
+        If given local balancing stack lbs is available for a given aggregated consumer aggr, then frac[aggr, lbs] <= 1,
+        otherwise frac[aggr, lbs] <= 0.
+        """
+        lbs_indicator = xr.DataArray(
+            data=self.parameters.aggr.lbs_indicator,
+            coords=[self.indices.AGGR.ord, self.indices.LBS.ii],
+            dims=["aggr", "lbs"],
+        )
+        self.model.add_constraints(
+            self.variables.frac.fraction <= lbs_indicator,
+            name="FRACTION_UPPER_BOUND_CONSTRAINT",
+        )
+        _logger.debug("Build fraction upper bound constraint: Done")
+
+    def build_lbs_involvement_in_consumer_aggregates_constraint(self) -> None:
+        """
+        Sum of all fractions of all local balancing stacks in a given aggregated consumer must be equal to 1 in every
+        year.
+        """
+        self.model.add_constraints(
+            self.variables.frac.fraction.sum("lbs") == 1.0,
+            name="LBS_INVOLVEMENT_IN_CONSUMER_AGGREGATES_CONSTRAINT",
+        )
+        _logger.debug("Build lbs involvement in consumer aggregates constraint: Done")
```

### Comparing `pyzefir-0.4.1/pyzefir/optimization/linopy/constraints_builder/generation_constraints_builder.py` & `pyzefir-0.4.22/pyzefir/optimization/linopy/constraints_builder/generation_constraints_builder.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,115 +1,127 @@
-# PyZefir
-# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-import xarray as xr
-
-from pyzefir.optimization.linopy.constraints_builder.builder import (
-    PartialConstraintsBuilder,
-)
-from pyzefir.utils.functions import demand_chunk_unit_indices
-
-
-class GenerationConstraintsBuilder(PartialConstraintsBuilder):
-    def build_constraints(self) -> None:
-        self.generation_vs_capacity_constraints()
-        self.generation_and_dump_energy()
-        self.total_dump_energy()
-
-    def generation_vs_capacity_constraints(self) -> None:
-        for gen_idx, gen_name in self.indices.GEN.mapping.items():
-            generation_brutto = self.variables.gen.gen.isel(gen=gen_idx)
-            capacity = self.variables.gen.cap.isel(gen=gen_idx)
-            capacity_factor_id = self.parameters.gen.capacity_factors[gen_idx]
-            gen_to_tgen = self.parameters.gen.tgen
-            power_utilization = xr.DataArray(
-                self.parameters.tgen.power_utilization[gen_to_tgen[gen_idx]],
-                dims=["hour"],
-                coords={"hour": self.indices.H.ii},
-            )
-            if capacity_factor_id is not None:
-                capacity_factor = xr.DataArray(
-                    self.parameters.cf.profile[capacity_factor_id],
-                    dims=["hour"],
-                    coords={"hour": self.indices.H.ii},
-                )
-                self.model.add_constraints(
-                    generation_brutto == capacity_factor * capacity * power_utilization,
-                    name=f"{gen_name}_NON_DISPATCHABLE_GEN_CAP_CONSTRAINT",
-                )
-            else:
-                self.model.add_constraints(
-                    generation_brutto <= capacity * power_utilization,
-                    name=f"{gen_name}_DISPATCHABLE_GEN_CAP_CONSTRAINT",
-                )
-
-    def generation_and_dump_energy(self) -> None:
-        for gen_idx, gen_name in self.indices.GEN.mapping.items():
-            for energy_type_idx, energy_type_name in self.indices.ET.mapping.items():
-                energy_type_generation = self.variables.gen.gen_et.isel(
-                    gen=gen_idx, et=energy_type_idx
-                )
-                energy_type_dump_energy = self.variables.gen.dump_et.isel(
-                    gen=gen_idx, et=energy_type_idx
-                )
-                if energy_type_name in self.parameters.gen.ett[gen_idx]:
-                    generation_brutto = self.variables.gen.gen.isel(gen=gen_idx)
-                    efficiency = self.parameters.gen.eff[gen_idx][energy_type_name]
-                    demch_params = self.parameters.demand_chunks_parameters
-
-                    # TODO: check if this is correct (dem_idxs always empty)
-                    dem_idxs = [
-                        dem_idx
-                        for dem_idx, tag in demch_params.tag.items()
-                        if gen_idx
-                        in demand_chunk_unit_indices(
-                            dem_idx, demch_params.tag, self.parameters.gen.tags
-                        )
-                        and demch_params.energy_type[dem_idx] == energy_type_name
-                    ]
-                    dch = self.variables.gen.gen_dch.isel(
-                        et=energy_type_idx, demch=dem_idxs, gen=gen_idx
-                    )
-
-                    if dch.size == 0:
-                        dch = 0
-
-                    self.model.add_constraints(
-                        generation_brutto * efficiency
-                        == energy_type_generation + energy_type_dump_energy + dch,
-                        name=f"{gen_name}_{energy_type_idx}_GENERATION_DUMP_CONSTRAINT",
-                    )
-                else:
-                    self.model.add_constraints(
-                        energy_type_dump_energy + energy_type_generation == 0,
-                        name=f"{gen_name}_{energy_type_idx}_GENERATION_DUMP_CONSTRAINT",
-                    )
-
-    def total_dump_energy(self) -> None:
-        for gen_idx, gen_name in self.indices.GEN.mapping.items():
-            de_et_sum = 0.0
-            for et_name in self.parameters.gen.ett[gen_idx]:
-                de_et_sum += (
-                    self.variables.gen.dump_et.isel(
-                        gen=gen_idx,
-                        et=self.indices.ET.inverse[et_name],
-                    )
-                    / self.parameters.gen.eff[gen_idx][et_name]
-                )
-
-            self.model.add_constraints(
-                de_et_sum == self.variables.gen.dump.isel(gen=gen_idx),
-                name=f"{gen_name}_TOTAL_DUMP_ENERGY",
-            )
+# PyZefir
+# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+import logging
+
+import xarray as xr
+
+from pyzefir.optimization.linopy.constraints_builder.builder import (
+    PartialConstraintsBuilder,
+)
+from pyzefir.utils.functions import demand_chunk_unit_indices
+
+_logger = logging.getLogger(__name__)
+
+
+class GenerationConstraintsBuilder(PartialConstraintsBuilder):
+    def build_constraints(self) -> None:
+        _logger.info("Generation constraints builder is working...")
+        self.generation_vs_capacity_constraints()
+        self.generation_and_dump_energy()
+        self.total_dump_energy()
+        _logger.info("Generation constraints builder is finished!")
+
+    def generation_vs_capacity_constraints(self) -> None:
+        for gen_idx, gen_name in self.indices.GEN.mapping.items():
+            generation_brutto = self.variables.gen.gen.isel(gen=gen_idx)
+            capacity = self.variables.gen.cap.isel(gen=gen_idx)
+            capacity_factor_id = self.parameters.gen.capacity_factors[gen_idx]
+            gen_to_tgen = self.parameters.gen.tgen
+            power_utilization = xr.DataArray(
+                self.parameters.tgen.power_utilization[gen_to_tgen[gen_idx]],
+                dims=["hour"],
+                coords={"hour": self.indices.H.ii},
+            )
+            if capacity_factor_id is not None:
+                capacity_factor = xr.DataArray(
+                    self.parameters.cf.profile[capacity_factor_id],
+                    dims=["hour"],
+                    coords={"hour": self.indices.H.ii},
+                )
+                self.model.add_constraints(
+                    generation_brutto == capacity_factor * capacity * power_utilization,
+                    name=f"{gen_name}_NON_DISPATCHABLE_GEN_CAP_CONSTRAINT",
+                )
+            else:
+                self.model.add_constraints(
+                    generation_brutto <= capacity * power_utilization,
+                    name=f"{gen_name}_DISPATCHABLE_GEN_CAP_CONSTRAINT",
+                )
+        _logger.debug("Build generation vs capacity constraints: Done")
+
+    def generation_and_dump_energy(self) -> None:
+        for gen_idx, gen_name in self.indices.GEN.mapping.items():
+            for energy_type_idx, energy_type_name in self.indices.ET.mapping.items():
+                energy_type_generation = self.variables.gen.gen_et.isel(
+                    gen=gen_idx, et=energy_type_idx
+                )
+                energy_type_dump_energy = self.variables.gen.dump_et.isel(
+                    gen=gen_idx, et=energy_type_idx
+                )
+                if energy_type_name in self.parameters.gen.ett[gen_idx]:
+                    generation_brutto = self.variables.gen.gen.isel(gen=gen_idx)
+                    efficiency = xr.DataArray(
+                        self.parameters.gen.eff[gen_idx][energy_type_name],
+                        dims=["hour"],
+                        coords={"hour": self.indices.H.ii},
+                    )
+                    demch_params = self.parameters.demand_chunks_parameters
+
+                    # TODO: check if this is correct (dem_idxs always empty)
+                    dem_idxs = [
+                        dem_idx
+                        for dem_idx, tag in demch_params.tag.items()
+                        if gen_idx
+                        in demand_chunk_unit_indices(
+                            dem_idx, demch_params.tag, self.parameters.gen.tags
+                        )
+                        and demch_params.energy_type[dem_idx] == energy_type_name
+                    ]
+                    dch = self.variables.gen.gen_dch.isel(
+                        et=energy_type_idx, demch=dem_idxs, gen=gen_idx
+                    )
+
+                    if dch.size == 0:
+                        dch = 0
+                    self.model.add_constraints(
+                        generation_brutto * efficiency
+                        == energy_type_generation + energy_type_dump_energy + dch,
+                        name=f"{gen_name}_{energy_type_idx}_GENERATION_DUMP_CONSTRAINT",
+                    )
+                else:
+                    self.model.add_constraints(
+                        energy_type_dump_energy + energy_type_generation == 0,
+                        name=f"{gen_name}_{energy_type_idx}_GENERATION_DUMP_CONSTRAINT",
+                    )
+        _logger.debug("Build generation and dump energy constraints: Done")
+
+    def total_dump_energy(self) -> None:
+        for gen_idx, gen_name in self.indices.GEN.mapping.items():
+            de_et_sum = 0.0
+            for et_name in self.parameters.gen.ett[gen_idx]:
+                de_et_sum += self.variables.gen.dump_et.isel(
+                    gen=gen_idx,
+                    et=self.indices.ET.inverse[et_name],
+                ) / xr.DataArray(
+                    self.parameters.gen.eff[gen_idx][et_name],
+                    dims=["hour"],
+                    coords={"hour": self.indices.H.ii},
+                )
+
+            self.model.add_constraints(
+                de_et_sum == self.variables.gen.dump.isel(gen=gen_idx),
+                name=f"{gen_name}_TOTAL_DUMP_ENERGY",
+            )
+        _logger.debug("Build total dump energy constraints: Done")
```

### Comparing `pyzefir-0.4.1/pyzefir/optimization/linopy/constraints_builder/generation_ramp.py` & `pyzefir-0.4.22/pyzefir/optimization/linopy/constraints_builder/generation_ramp.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,45 +1,51 @@
-# PyZefir
-# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-import numpy as np
-
-from pyzefir.optimization.linopy.constraints_builder.builder import (
-    PartialConstraintsBuilder,
-)
-
-
-class RampConstraintsBuilder(PartialConstraintsBuilder):
-    def build_constraints(self) -> None:
-        self.ramp_up_constraint()
-
-    def ramp_up_constraint(self) -> None:
-        for gen_idx, gen_name in self.indices.GEN.mapping.items():
-            t_idx = self.parameters.gen.tgen[gen_idx]
-            ramp = self.parameters.tgen.ramp[t_idx]
-            if not np.isnan(ramp):
-                gen = self.variables.gen.gen
-                cap = self.variables.gen.cap
-                gen_ramp = gen.isel(gen=gen_idx, hour=slice(1, None, None)) - gen.isel(
-                    gen=gen_idx, hour=slice(None, -1, None)
-                )
-                self.model.add_constraints(
-                    gen_ramp <= cap.isel(gen=gen_idx) * ramp,
-                    name=f"{gen_name}_RAMP_PLUS_CONSTRAINT",
-                )
-                self.model.add_constraints(
-                    gen_ramp >= -cap.isel(gen=gen_idx) * ramp,
-                    name=f"{gen_name}_RAMP_MINUS_CONSTRAINT",
-                )
+# PyZefir
+# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+import logging
+
+import numpy as np
+
+from pyzefir.optimization.linopy.constraints_builder.builder import (
+    PartialConstraintsBuilder,
+)
+
+_logger = logging.getLogger(__name__)
+
+
+class RampConstraintsBuilder(PartialConstraintsBuilder):
+    def build_constraints(self) -> None:
+        _logger.info("Ramp constraints builder is working...")
+        self.ramp_up_constraint()
+        _logger.info("Ramp constraints builder is finished!")
+
+    def ramp_up_constraint(self) -> None:
+        for gen_idx, gen_name in self.indices.GEN.mapping.items():
+            t_idx = self.parameters.gen.tgen[gen_idx]
+            ramp = self.parameters.tgen.ramp[t_idx]
+            if not np.isnan(ramp):
+                gen = self.variables.gen.gen
+                cap = self.variables.gen.cap
+                gen_ramp = gen.isel(gen=gen_idx, hour=slice(1, None, None)) - gen.isel(
+                    gen=gen_idx, hour=slice(None, -1, None)
+                )
+                self.model.add_constraints(
+                    gen_ramp <= cap.isel(gen=gen_idx) * ramp,
+                    name=f"{gen_name}_RAMP_PLUS_CONSTRAINT",
+                )
+                self.model.add_constraints(
+                    gen_ramp >= -cap.isel(gen=gen_idx) * ramp,
+                    name=f"{gen_name}_RAMP_MINUS_CONSTRAINT",
+                )
+        _logger.debug("Build ramp up constraint: Done")
```

### Comparing `pyzefir-0.4.1/pyzefir/optimization/linopy/constraints_builder/line_flow_constraints_builder.py` & `pyzefir-0.4.22/pyzefir/optimization/linopy/constraints_builder/line_flow_constraints_builder.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,35 +1,41 @@
-# PyZefir
-# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-import numpy as np
-
-from pyzefir.optimization.linopy.constraints_builder.builder import (
-    PartialConstraintsBuilder,
-)
-
-
-class LineFlowConstraintsBuilder(PartialConstraintsBuilder):
-    def build_constraints(self) -> None:
-        self.build_max_flow_constraints()
-
-    def build_max_flow_constraints(self) -> None:
-        for line_idx, line_name in self.indices.LINE.mapping.items():
-            max_capacity = self.parameters.line.cap[line_idx]
-            if not np.isnan(max_capacity):
-                self.model.add_constraints(
-                    self.variables.line.flow.isel(line=line_idx) <= max_capacity,
-                    name=f"{line_name}_LINE_FLOW_UPPER_BOUND_CONSTRAINT",
-                )
+# PyZefir
+# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+import logging
+
+import numpy as np
+
+from pyzefir.optimization.linopy.constraints_builder.builder import (
+    PartialConstraintsBuilder,
+)
+
+_logger = logging.getLogger(__name__)
+
+
+class LineFlowConstraintsBuilder(PartialConstraintsBuilder):
+    def build_constraints(self) -> None:
+        _logger.info("Line flow constraints builder is working...")
+        self.build_max_flow_constraints()
+        _logger.info("Line flow constraints builder is finished!")
+
+    def build_max_flow_constraints(self) -> None:
+        for line_idx, line_name in self.indices.LINE.mapping.items():
+            max_capacity = self.parameters.line.cap[line_idx]
+            if not np.isnan(max_capacity):
+                self.model.add_constraints(
+                    self.variables.line.flow.isel(line=line_idx) <= max_capacity,
+                    name=f"{line_name}_LINE_FLOW_UPPER_BOUND_CONSTRAINT",
+                )
+        _logger.debug("Build max flow constraints: Done")
```

### Comparing `pyzefir-0.4.1/pyzefir/optimization/linopy/constraints_builder/scenario_constraints_builder.py` & `pyzefir-0.4.22/pyzefir/optimization/linopy/constraints_builder/scenario_constraints_builder.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,473 +1,495 @@
-# PyZefir
-# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-import numpy as np
-import xarray as xr
-from linopy import LinearExpression
-
-from pyzefir.optimization.linopy.constraints_builder.builder import (
-    PartialConstraintsBuilder,
-)
-from pyzefir.optimization.linopy.preprocessing.indices import IndexingSet
-from pyzefir.optimization.linopy.preprocessing.parameters.generator_parameters import (
-    GeneratorParameters,
-)
-from pyzefir.optimization.linopy.preprocessing.parameters.generator_type_parameters import (
-    GeneratorTypeParameters,
-)
-from pyzefir.optimization.linopy.preprocessing.parameters.storage_parameters import (
-    StorageParameters,
-)
-from pyzefir.optimization.linopy.preprocessing.parameters.storage_type_parameters import (
-    StorageTypeParameters,
-)
-from pyzefir.optimization.linopy.preprocessing.variables.generator_variables import (
-    GeneratorVariables,
-)
-from pyzefir.optimization.linopy.preprocessing.variables.storage_variables import (
-    StorageVariables,
-)
-from pyzefir.utils.functions import invert_dict_of_sets
-
-
-class ScenarioConstraintsBuilder(PartialConstraintsBuilder):
-    def build_constraints(self) -> None:
-        self.max_fuel_consumption_constraints()
-        self.max_fraction_constraints()
-        self.min_fraction_constraints()
-        self.max_fraction_increase_constraints()
-        self.max_fraction_decrease_constraints()
-        self.energy_source_type_capacity_constraints()
-        self.energy_source_capacity_constraints()
-        self.emission_constraints()
-        self._min_generation_fraction_constraint()
-        self._max_generation_fraction_constraint()
-        self.power_reserve_constraint()
-
-    def max_fuel_consumption_constraints(self) -> None:
-        for fuel_idx in self.indices.FUEL.mapping.keys():
-            if fuel_idx not in self.parameters.fuel.availability or all(
-                np.isnan(self.parameters.fuel.availability[fuel_idx])
-            ):
-                continue
-            max_fuel_availability = self.parameters.fuel.availability[fuel_idx]
-            for year_idx in self.indices.Y.mapping.keys():
-                if np.isnan(max_fuel_availability[year_idx]):
-                    continue
-
-                total_fuel_consumption = 0.0
-                for gen_idx in self.indices.GEN.mapping.keys():
-                    if fuel_idx == self.parameters.gen.fuel[gen_idx]:
-                        total_fuel_consumption += self.expr.fuel_consumption(
-                            fuel_idx,
-                            gen_idx,
-                            self.parameters.scenario_parameters.hourly_scale,
-                        ).isel(year=year_idx)
-
-                if total_fuel_consumption:
-                    self.model.add_constraints(
-                        total_fuel_consumption <= max_fuel_availability[year_idx],
-                        name=f"MAX_FUEL_{fuel_idx}_AVAILABILITY_CONSTRAINT_{year_idx}",
-                    )
-
-    def energy_source_type_capacity_constraints(self) -> None:
-        self._generator_type_capacity_constraints()
-        self._storage_type_capacity_constraints()
-
-    def energy_source_capacity_constraints(self) -> None:
-        self._storage_capacity_constraints()
-        self._generator_capacity_constraints()
-
-    def _generator_type_capacity_constraints(self) -> None:
-        self._add_cap_constraints_per_energy_source_type(
-            energy_source_idx=self.indices.GEN,
-            energy_source_to_type_dict=self.parameters.gen.tgen,
-            type_parameters=self.parameters.tgen,
-            variables=self.variables.gen,
-            element_name="GEN",
-        )
-
-    def _storage_type_capacity_constraints(self) -> None:
-        self._add_cap_constraints_per_energy_source_type(
-            energy_source_idx=self.indices.STOR,
-            energy_source_to_type_dict=self.parameters.stor.tstor,
-            type_parameters=self.parameters.tstor,
-            variables=self.variables.stor,
-            element_name="STOR",
-        )
-
-    def _generator_capacity_constraints(self) -> None:
-        self._add_cap_constraints_per_energy_source(
-            energy_source_idx=self.indices.GEN,
-            parameters=self.parameters.gen,
-            variables=self.variables.gen,
-            element_name="GEN",
-        )
-
-    def _storage_capacity_constraints(self) -> None:
-        self._add_cap_constraints_per_energy_source(
-            energy_source_idx=self.indices.STOR,
-            parameters=self.parameters.stor,
-            variables=self.variables.stor,
-            element_name="STOR",
-        )
-
-    def _add_cap_constraints_per_energy_source(
-        self,
-        energy_source_idx: IndexingSet,
-        parameters: StorageParameters | GeneratorParameters,
-        variables: GeneratorVariables | StorageVariables,
-        element_name: str,
-    ) -> None:
-        for idx in energy_source_idx.mapping.keys():
-            for year in self.indices.Y.mapping.keys() - [0]:
-                unit_min_capacity = parameters.unit_min_capacity[idx][year]
-                unit_max_capacity = parameters.unit_max_capacity[idx][year]
-                unit_min_capacity_increase = parameters.unit_min_capacity_increase[idx][
-                    year
-                ]
-                unit_max_capacity_increase = parameters.unit_max_capacity_increase[idx][
-                    year
-                ]
-
-                if not np.isnan(unit_min_capacity):
-                    self.model.add_constraints(
-                        variables.cap.isel({element_name.lower(): idx, "year": year})
-                        >= unit_min_capacity,
-                        name=f"{idx}_{year}_{element_name}_CAP_MIN_CONSTRAINT",
-                    )
-                if not np.isnan(unit_max_capacity):
-                    self.model.add_constraints(
-                        variables.cap.isel({element_name.lower(): idx, "year": year})
-                        <= unit_max_capacity,
-                        name=f"{idx}_{year}_{element_name}_CAP_MAX_CONSTRAINT",
-                    )
-                if not np.isnan(unit_min_capacity_increase):
-                    self.model.add_constraints(
-                        variables.cap.isel({element_name.lower(): idx, "year": year})
-                        - variables.cap.isel(
-                            {element_name.lower(): idx, "year": year - 1}
-                        )
-                        >= unit_min_capacity_increase,
-                        name=f"{idx}_{year}_{element_name}_DELTA_CAP_MIN_CONSTRAINT",
-                    )
-                if not np.isnan(unit_max_capacity_increase):
-                    self.model.add_constraints(
-                        variables.cap.isel({element_name.lower(): idx, "year": year})
-                        - variables.cap.isel(
-                            {element_name.lower(): idx, "year": year - 1}
-                        )
-                        <= unit_max_capacity_increase,
-                        name=f"{idx}_{year}_{element_name}_DELTA_CAP_MAX_CONSTRAINT",
-                    )
-
-    def _add_cap_constraints_per_energy_source_type(
-        self,
-        energy_source_idx: IndexingSet,
-        energy_source_to_type_dict: dict[int, int],
-        type_parameters: GeneratorTypeParameters | StorageTypeParameters,
-        variables: GeneratorVariables | StorageVariables,
-        element_name: str,
-    ) -> None:
-        for type_idx in dict.fromkeys(energy_source_to_type_dict.values()):
-            energy_sources_idx = [
-                energy_source_idx
-                for energy_source_idx in energy_source_idx.mapping.keys()
-                if energy_source_to_type_dict[energy_source_idx] == type_idx
-            ]
-
-            for year_idx in self.indices.Y.mapping.keys() - [0]:
-                min_capacity = type_parameters.min_capacity[type_idx][year_idx]
-                max_capacity = type_parameters.max_capacity[type_idx][year_idx]
-                min_capacity_increase = type_parameters.min_capacity_increase[type_idx][
-                    year_idx
-                ]
-                max_capacity_increase = type_parameters.max_capacity_increase[type_idx][
-                    year_idx
-                ]
-
-                if not np.isnan(min_capacity):
-                    self.model.add_constraints(
-                        variables.cap.isel(
-                            **{
-                                element_name.lower(): energy_sources_idx,
-                                "year": year_idx,
-                            }
-                        ).sum()
-                        >= min_capacity,
-                        name=f"{type_idx}_{year_idx}_T{element_name}_CAP_MIN_CONSTRAINT",
-                    )
-                if not np.isnan(max_capacity):
-                    self.model.add_constraints(
-                        variables.cap.isel(
-                            **{
-                                element_name.lower(): energy_sources_idx,
-                                "year": year_idx,
-                            }
-                        ).sum()
-                        <= max_capacity,
-                        name=f"{type_idx}_{year_idx}_T{element_name}_CAP_MAX_CONSTRAINT",
-                    )
-                if not np.isnan(min_capacity_increase):
-                    self.model.add_constraints(
-                        variables.cap.isel(
-                            **{
-                                element_name.lower(): energy_sources_idx,
-                                "year": year_idx,
-                            }
-                        ).sum()
-                        - variables.cap.isel(
-                            **{
-                                element_name.lower(): energy_sources_idx,
-                                "year": year_idx - 1,
-                            }
-                        ).sum()
-                        >= min_capacity_increase,
-                        name=f"{type_idx}_{year_idx}_T{element_name}_DELTA_CAP_MIN_CONSTRAINT",
-                    )
-                if not np.isnan(max_capacity_increase):
-                    self.model.add_constraints(
-                        variables.cap.isel(
-                            **{
-                                element_name.lower(): energy_sources_idx,
-                                "year": year_idx,
-                            }
-                        ).sum()
-                        - variables.cap.isel(
-                            **{
-                                element_name.lower(): energy_sources_idx,
-                                "year": year_idx - 1,
-                            }
-                        ).sum()
-                        <= max_capacity_increase,
-                        name=f"{type_idx}_{year_idx}_T{element_name}_DELTA_CAP_MAX_CONSTRAINT",
-                    )
-
-    def min_fraction_constraints(self) -> None:
-        min_fraction = self.parameters.aggr.min_fraction
-        for aggr_idx, fraction_dict in min_fraction.items():
-            for lbs_idx, fraction_series in fraction_dict.items():
-                not_nan_idx = ~np.isnan(fraction_series)
-                if not not_nan_idx.any():
-                    continue
-                variable_year_frac = self.variables.frac.fraction.isel(
-                    aggr=aggr_idx, lbs=lbs_idx, year=not_nan_idx
-                )
-                lbs_min_fraction = xr.DataArray(
-                    fraction_series,
-                    dims="year",
-                    coords={"year": self.indices.Y.ii},
-                ).isel(year=not_nan_idx)
-
-                self.model.add_constraints(
-                    variable_year_frac >= lbs_min_fraction,
-                    name=f"{aggr_idx}_{lbs_idx}_FRAC_MIN_CONSTRAINT",
-                )
-
-    def max_fraction_constraints(self) -> None:
-        max_fraction = self.parameters.aggr.max_fraction
-        for aggr_idx, fraction_dict in max_fraction.items():
-            for lbs_idx, fraction_series in fraction_dict.items():
-                not_nan_idx = ~np.isnan(fraction_series)
-                if not not_nan_idx.any():
-                    continue
-                variable_year_frac = self.variables.frac.fraction.isel(
-                    aggr=aggr_idx, lbs=lbs_idx, year=not_nan_idx
-                )
-                lbs_max_fraction = xr.DataArray(
-                    fraction_series,
-                    dims="year",
-                    coords={"year": self.indices.Y.ii},
-                ).isel(year=not_nan_idx)
-
-                self.model.add_constraints(
-                    variable_year_frac <= lbs_max_fraction,
-                    name=f"{aggr_idx}_{lbs_idx}_FRAC_MAX_CONSTRAINT",
-                )
-
-    def max_fraction_increase_constraints(self) -> None:
-        max_fraction_increase = self.parameters.aggr.max_fraction_increase
-        for aggr_idx, fraction_dict in max_fraction_increase.items():
-            for lbs_idx, fraction_series in fraction_dict.items():
-                not_nan_idx = ~np.isnan(fraction_series)
-                if not not_nan_idx.any():
-                    continue
-                not_nan_idx = np.where(not_nan_idx)[0]
-                variable_year_frac = self.variables.frac.fraction.isel(
-                    aggr=aggr_idx, lbs=lbs_idx
-                )
-                lbs_max_fraction_increase = xr.DataArray(
-                    fraction_series,
-                    dims="year",
-                    coords={"year": self.indices.Y.ii},
-                ).isel(year=not_nan_idx)
-
-                self.model.add_constraints(
-                    variable_year_frac.isel(year=not_nan_idx)
-                    - variable_year_frac.isel(year=not_nan_idx - 1)
-                    <= lbs_max_fraction_increase,
-                    name=f"{aggr_idx}_{lbs_idx}_FRAC_MAX_INCREASE_CONSTRAINT",
-                )
-
-    def max_fraction_decrease_constraints(self) -> None:
-        max_fraction_decrease = self.parameters.aggr.max_fraction_decrease
-        for aggr_idx, fraction_dict in max_fraction_decrease.items():
-            for lbs_idx, fraction_series in fraction_dict.items():
-                not_nan_idx = ~np.isnan(fraction_series)
-                if not not_nan_idx.any():
-                    continue
-                not_nan_idx = np.where(not_nan_idx)[0]
-                variable_year_frac = self.variables.frac.fraction.isel(
-                    aggr=aggr_idx, lbs=lbs_idx
-                )
-                lbs_max_fraction_decrease = xr.DataArray(
-                    fraction_series,
-                    dims="year",
-                    coords={"year": self.indices.Y.ii},
-                ).isel(year=not_nan_idx)
-
-                self.model.add_constraints(
-                    variable_year_frac.isel(year=not_nan_idx - 1)
-                    - variable_year_frac.isel(year=not_nan_idx)
-                    <= lbs_max_fraction_decrease,
-                    name=f"{aggr_idx}_{lbs_idx}_FRAC_MAX_DECREASE_CONSTRAINT",
-                )
-
-    def emission_constraints(self) -> None:
-        for et in self.parameters.scenario_parameters.rel_em_limit.keys():
-            if not np.isnan(
-                self.parameters.scenario_parameters.base_total_emission[et]
-            ):
-                base_total_em = (
-                    self.parameters.scenario_parameters.base_total_emission[et]
-                    * self.parameters.scenario_parameters.hourly_scale
-                )
-                for y_idx in self.indices.Y.mapping.keys():
-                    if not np.isnan(
-                        self.parameters.scenario_parameters.rel_em_limit[et][y_idx]
-                    ):
-                        total_em = 0.0
-                        for fuel_idx in self.indices.FUEL.mapping.keys():
-                            for gen_idx in self.indices.GEN.mapping.keys():
-                                if fuel_idx == self.parameters.gen.fuel[gen_idx]:
-                                    total_em += (
-                                        self.expr.fuel_consumption(
-                                            fuel_idx,
-                                            gen_idx,
-                                            self.parameters.scenario_parameters.hourly_scale,
-                                        ).isel(year=y_idx)
-                                        * self.parameters.fuel.u_emission[fuel_idx][et]
-                                        * (1 - self.parameters.gen.em_red[gen_idx][et])
-                                    )
-
-                        self.model.add_constraints(
-                            total_em
-                            <= base_total_em
-                            * self.parameters.scenario_parameters.rel_em_limit[et][
-                                y_idx
-                            ],
-                            name=f"{et}_{y_idx}_EMISSIONS_CONSTRAINT",
-                        )
-
-    @staticmethod
-    def _unit_of_given_tag(unit_tags: dict[int, set[int]], tag_idx: int) -> set[int]:
-        """returns set of units of a given tag"""
-        return {gen_idx for gen_idx, tag_set in unit_tags.items() if tag_idx in tag_set}
-
-    def _get_tags(
-        self, tag: int, subtag: int
-    ) -> tuple[set[int], set[int], set[int], set[int]]:
-        tag_gen_idxs = ScenarioConstraintsBuilder._unit_of_given_tag(
-            self.parameters.gen.tags, tag
-        )
-        subtag_gen_idxs = ScenarioConstraintsBuilder._unit_of_given_tag(
-            self.parameters.gen.tags, subtag
-        )
-        tag_stor_idxs = ScenarioConstraintsBuilder._unit_of_given_tag(
-            self.parameters.stor.tags, tag
-        )
-        subtag_stor_idxs = ScenarioConstraintsBuilder._unit_of_given_tag(
-            self.parameters.stor.tags, subtag
-        )
-        return tag_gen_idxs, subtag_gen_idxs, tag_stor_idxs, subtag_stor_idxs
-
-    def _expr_gen(
-        self, et: str, gen_idxs: set[int], stor_idxs: set[int]
-    ) -> LinearExpression | float:
-        gen_et_var = self.variables.gen.gen_et
-        stor_et_var = self.variables.stor.gen
-        return (
-            gen_et_var.isel(gen=list(gen_idxs), et=self.indices.ET.inverse[et]).sum()
-            + stor_et_var.isel(stor=list(stor_idxs)).sum()
-        )
-
-    def _min_generation_fraction_constraint(self) -> None:
-        min_gen_frac_params = (
-            self.parameters.scenario_parameters.min_generation_fraction
-        )
-        if min_gen_frac_params is not None:
-            for et, min_gen_frac_per_et in min_gen_frac_params.items():
-                for tags, min_gen_frac in min_gen_frac_per_et.items():
-                    tag, subtag = tags
-                    (
-                        tag_gen_idxs,
-                        subtag_gen_idxs,
-                        tag_stor_idxs,
-                        subtag_stor_idxs,
-                    ) = self._get_tags(tag, subtag)
-                    self.model.add_constraints(
-                        self._expr_gen(et, subtag_gen_idxs, subtag_stor_idxs)
-                        >= self._expr_gen(et, tag_gen_idxs, tag_stor_idxs)
-                        * min_gen_frac,
-                        name=f"{tag}_MIN_GENERATION_FRACTION_CONSTRAINT",
-                    )
-
-    def _max_generation_fraction_constraint(self) -> None:
-        max_gen_frac_params = (
-            self.parameters.scenario_parameters.max_generation_fraction
-        )
-        if max_gen_frac_params is not None:
-            for et, max_gen_frac_per_et in max_gen_frac_params.items():
-                for tags, max_gen_frac in max_gen_frac_per_et.items():
-                    tag, subtag = tags
-                    (
-                        tag_gen_idxs,
-                        subtag_gen_idxs,
-                        tag_stor_idxs,
-                        subtag_stor_idxs,
-                    ) = self._get_tags(tag, subtag)
-                    self.model.add_constraints(
-                        self._expr_gen(et, subtag_gen_idxs, subtag_stor_idxs)
-                        <= self._expr_gen(et, tag_gen_idxs, tag_stor_idxs)
-                        * max_gen_frac,
-                        name=f"{tag}_MAX_GENERATION_FRACTION_CONSTRAINT",
-                    )
-
-    def power_reserve_constraint(self) -> None:
-        power_reserves = self.parameters.scenario_parameters.power_reserves
-        if power_reserves:
-            cap = self.variables.gen.cap
-            gen_et = self.variables.gen.gen_et
-            gens_of_tag = invert_dict_of_sets(self.parameters.gen.tags)
-            for energy_type, tag_to_reserve in power_reserves.items():
-                et = self.indices.ET.inverse[energy_type]
-                for tag, reserve in tag_to_reserve.items():
-                    self.model.add_constraints(
-                        cap.isel(gen=list(gens_of_tag[tag])).sum(["gen"])
-                        - gen_et.isel(gen=list(gens_of_tag[tag]), et=et).sum(["gen"])
-                        >= reserve,
-                        name=f"ENERGY_TYPE_{et}_TAG_{tag}_POWER_RESERVE_CONSTRAINT",
-                    )
+# PyZefir
+# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+import logging
+
+import numpy as np
+import xarray as xr
+from linopy import LinearExpression
+
+from pyzefir.optimization.linopy.constraints_builder.builder import (
+    PartialConstraintsBuilder,
+)
+from pyzefir.optimization.linopy.preprocessing.indices import IndexingSet
+from pyzefir.optimization.linopy.preprocessing.parameters.generator_parameters import (
+    GeneratorParameters,
+)
+from pyzefir.optimization.linopy.preprocessing.parameters.generator_type_parameters import (
+    GeneratorTypeParameters,
+)
+from pyzefir.optimization.linopy.preprocessing.parameters.storage_parameters import (
+    StorageParameters,
+)
+from pyzefir.optimization.linopy.preprocessing.parameters.storage_type_parameters import (
+    StorageTypeParameters,
+)
+from pyzefir.optimization.linopy.preprocessing.variables.generator_variables import (
+    GeneratorVariables,
+)
+from pyzefir.optimization.linopy.preprocessing.variables.storage_variables import (
+    StorageVariables,
+)
+from pyzefir.utils.functions import invert_dict_of_sets
+
+_logger = logging.getLogger(__name__)
+
+
+class ScenarioConstraintsBuilder(PartialConstraintsBuilder):
+    def build_constraints(self) -> None:
+        _logger.info("Scenario constraints builder is working...")
+        self.max_fuel_consumption_constraints()
+        self.max_fraction_constraints()
+        self.min_fraction_constraints()
+        self.max_fraction_increase_constraints()
+        self.max_fraction_decrease_constraints()
+        self.energy_source_type_capacity_constraints()
+        self.energy_source_capacity_constraints()
+        self.emission_constraints()
+        self._min_generation_fraction_constraint()
+        self._max_generation_fraction_constraint()
+        self.power_reserve_constraint()
+        _logger.info("Scenario constraints builder is finished!")
+
+    def max_fuel_consumption_constraints(self) -> None:
+        for fuel_idx in self.indices.FUEL.mapping.keys():
+            if fuel_idx not in self.parameters.fuel.availability or all(
+                np.isnan(self.parameters.fuel.availability[fuel_idx])
+            ):
+                continue
+            max_fuel_availability = self.parameters.fuel.availability[fuel_idx]
+            for year_idx in self.indices.Y.mapping.keys():
+                if np.isnan(max_fuel_availability[year_idx]):
+                    continue
+
+                total_fuel_consumption = 0.0
+                for gen_idx in self.indices.GEN.mapping.keys():
+                    if fuel_idx == self.parameters.gen.fuel[gen_idx]:
+                        total_fuel_consumption += self.expr.fuel_consumption(
+                            fuel_idx,
+                            gen_idx,
+                            self.parameters.scenario_parameters.hourly_scale,
+                        ).isel(year=year_idx)
+
+                if total_fuel_consumption:
+                    self.model.add_constraints(
+                        total_fuel_consumption <= max_fuel_availability[year_idx],
+                        name=f"MAX_FUEL_{fuel_idx}_AVAILABILITY_CONSTRAINT_{year_idx}",
+                    )
+        _logger.debug("Build max fuel consumption constraints: Done")
+
+    def energy_source_type_capacity_constraints(self) -> None:
+        _logger.debug("Building energy source type capacity constraints...")
+        self._generator_type_capacity_constraints()
+        self._storage_type_capacity_constraints()
+        _logger.debug("Build energy source type capacity constraints: Done")
+
+    def energy_source_capacity_constraints(self) -> None:
+        _logger.debug("Building energy source capacity constraints...")
+        self._storage_capacity_constraints()
+        self._generator_capacity_constraints()
+        _logger.debug("Build energy source capacity constraints: Done")
+
+    def _generator_type_capacity_constraints(self) -> None:
+        self._add_cap_constraints_per_energy_source_type(
+            energy_source_idx=self.indices.GEN,
+            energy_source_to_type_dict=self.parameters.gen.tgen,
+            type_parameters=self.parameters.tgen,
+            variables=self.variables.gen,
+            element_name="GEN",
+        )
+        _logger.debug("Build generator type capacity constraints: Done")
+
+    def _storage_type_capacity_constraints(self) -> None:
+        self._add_cap_constraints_per_energy_source_type(
+            energy_source_idx=self.indices.STOR,
+            energy_source_to_type_dict=self.parameters.stor.tstor,
+            type_parameters=self.parameters.tstor,
+            variables=self.variables.stor,
+            element_name="STOR",
+        )
+        _logger.debug("Build storage type capacity constraints: Done")
+
+    def _generator_capacity_constraints(self) -> None:
+        self._add_cap_constraints_per_energy_source(
+            energy_source_idx=self.indices.GEN,
+            parameters=self.parameters.gen,
+            variables=self.variables.gen,
+            element_name="GEN",
+        )
+        _logger.debug("Build generator capacity constraints: Done")
+
+    def _storage_capacity_constraints(self) -> None:
+        self._add_cap_constraints_per_energy_source(
+            energy_source_idx=self.indices.STOR,
+            parameters=self.parameters.stor,
+            variables=self.variables.stor,
+            element_name="STOR",
+        )
+        _logger.debug("Build storage capacity constraints: Done")
+
+    def _add_cap_constraints_per_energy_source(
+        self,
+        energy_source_idx: IndexingSet,
+        parameters: StorageParameters | GeneratorParameters,
+        variables: GeneratorVariables | StorageVariables,
+        element_name: str,
+    ) -> None:
+        for idx in energy_source_idx.mapping.keys():
+            for year in self.indices.Y.mapping.keys() - [0]:
+                unit_min_capacity = parameters.unit_min_capacity[idx][year]
+                unit_max_capacity = parameters.unit_max_capacity[idx][year]
+                unit_min_capacity_increase = parameters.unit_min_capacity_increase[idx][
+                    year
+                ]
+                unit_max_capacity_increase = parameters.unit_max_capacity_increase[idx][
+                    year
+                ]
+
+                if not np.isnan(unit_min_capacity):
+                    self.model.add_constraints(
+                        variables.cap.isel({element_name.lower(): idx, "year": year})
+                        >= unit_min_capacity,
+                        name=f"{idx}_{year}_{element_name}_CAP_MIN_CONSTRAINT",
+                    )
+                if not np.isnan(unit_max_capacity):
+                    self.model.add_constraints(
+                        variables.cap.isel({element_name.lower(): idx, "year": year})
+                        <= unit_max_capacity,
+                        name=f"{idx}_{year}_{element_name}_CAP_MAX_CONSTRAINT",
+                    )
+                if not np.isnan(unit_min_capacity_increase):
+                    self.model.add_constraints(
+                        variables.cap.isel({element_name.lower(): idx, "year": year})
+                        - variables.cap.isel(
+                            {element_name.lower(): idx, "year": year - 1}
+                        )
+                        >= unit_min_capacity_increase,
+                        name=f"{idx}_{year}_{element_name}_DELTA_CAP_MIN_CONSTRAINT",
+                    )
+                if not np.isnan(unit_max_capacity_increase):
+                    self.model.add_constraints(
+                        variables.cap.isel({element_name.lower(): idx, "year": year})
+                        - variables.cap.isel(
+                            {element_name.lower(): idx, "year": year - 1}
+                        )
+                        <= unit_max_capacity_increase,
+                        name=f"{idx}_{year}_{element_name}_DELTA_CAP_MAX_CONSTRAINT",
+                    )
+
+    def _add_cap_constraints_per_energy_source_type(
+        self,
+        energy_source_idx: IndexingSet,
+        energy_source_to_type_dict: dict[int, int],
+        type_parameters: GeneratorTypeParameters | StorageTypeParameters,
+        variables: GeneratorVariables | StorageVariables,
+        element_name: str,
+    ) -> None:
+        for type_idx in dict.fromkeys(energy_source_to_type_dict.values()):
+            energy_sources_idx = [
+                energy_source_idx
+                for energy_source_idx in energy_source_idx.mapping.keys()
+                if energy_source_to_type_dict[energy_source_idx] == type_idx
+            ]
+
+            for year_idx in self.indices.Y.mapping.keys() - [0]:
+                min_capacity = type_parameters.min_capacity[type_idx][year_idx]
+                max_capacity = type_parameters.max_capacity[type_idx][year_idx]
+                min_capacity_increase = type_parameters.min_capacity_increase[type_idx][
+                    year_idx
+                ]
+                max_capacity_increase = type_parameters.max_capacity_increase[type_idx][
+                    year_idx
+                ]
+
+                if not np.isnan(min_capacity):
+                    self.model.add_constraints(
+                        variables.cap.isel(
+                            **{
+                                element_name.lower(): energy_sources_idx,
+                                "year": year_idx,
+                            }
+                        ).sum()
+                        >= min_capacity,
+                        name=f"{type_idx}_{year_idx}_T{element_name}_CAP_MIN_CONSTRAINT",
+                    )
+                if not np.isnan(max_capacity):
+                    self.model.add_constraints(
+                        variables.cap.isel(
+                            **{
+                                element_name.lower(): energy_sources_idx,
+                                "year": year_idx,
+                            }
+                        ).sum()
+                        <= max_capacity,
+                        name=f"{type_idx}_{year_idx}_T{element_name}_CAP_MAX_CONSTRAINT",
+                    )
+                if not np.isnan(min_capacity_increase):
+                    self.model.add_constraints(
+                        variables.cap.isel(
+                            **{
+                                element_name.lower(): energy_sources_idx,
+                                "year": year_idx,
+                            }
+                        ).sum()
+                        - variables.cap.isel(
+                            **{
+                                element_name.lower(): energy_sources_idx,
+                                "year": year_idx - 1,
+                            }
+                        ).sum()
+                        >= min_capacity_increase,
+                        name=f"{type_idx}_{year_idx}_T{element_name}_DELTA_CAP_MIN_CONSTRAINT",
+                    )
+                if not np.isnan(max_capacity_increase):
+                    self.model.add_constraints(
+                        variables.cap.isel(
+                            **{
+                                element_name.lower(): energy_sources_idx,
+                                "year": year_idx,
+                            }
+                        ).sum()
+                        - variables.cap.isel(
+                            **{
+                                element_name.lower(): energy_sources_idx,
+                                "year": year_idx - 1,
+                            }
+                        ).sum()
+                        <= max_capacity_increase,
+                        name=f"{type_idx}_{year_idx}_T{element_name}_DELTA_CAP_MAX_CONSTRAINT",
+                    )
+
+    def min_fraction_constraints(self) -> None:
+        min_fraction = self.parameters.aggr.min_fraction
+        for aggr_idx, fraction_dict in min_fraction.items():
+            for lbs_idx, fraction_series in fraction_dict.items():
+                not_nan_idx = ~np.isnan(fraction_series)
+                if not not_nan_idx.any():
+                    continue
+                variable_year_frac = self.variables.frac.fraction.isel(
+                    aggr=aggr_idx, lbs=lbs_idx, year=not_nan_idx
+                )
+                lbs_min_fraction = xr.DataArray(
+                    fraction_series,
+                    dims="year",
+                    coords={"year": self.indices.Y.ii},
+                ).isel(year=not_nan_idx)
+
+                self.model.add_constraints(
+                    variable_year_frac >= lbs_min_fraction,
+                    name=f"{aggr_idx}_{lbs_idx}_FRAC_MIN_CONSTRAINT",
+                )
+        _logger.debug("Build min fraction constraints: Done")
+
+    def max_fraction_constraints(self) -> None:
+        max_fraction = self.parameters.aggr.max_fraction
+        for aggr_idx, fraction_dict in max_fraction.items():
+            for lbs_idx, fraction_series in fraction_dict.items():
+                not_nan_idx = ~np.isnan(fraction_series)
+                if not not_nan_idx.any():
+                    continue
+                variable_year_frac = self.variables.frac.fraction.isel(
+                    aggr=aggr_idx, lbs=lbs_idx, year=not_nan_idx
+                )
+                lbs_max_fraction = xr.DataArray(
+                    fraction_series,
+                    dims="year",
+                    coords={"year": self.indices.Y.ii},
+                ).isel(year=not_nan_idx)
+
+                self.model.add_constraints(
+                    variable_year_frac <= lbs_max_fraction,
+                    name=f"{aggr_idx}_{lbs_idx}_FRAC_MAX_CONSTRAINT",
+                )
+        _logger.debug("Build max fraction constraints: Done")
+
+    def max_fraction_increase_constraints(self) -> None:
+        max_fraction_increase = self.parameters.aggr.max_fraction_increase
+        for aggr_idx, fraction_dict in max_fraction_increase.items():
+            for lbs_idx, fraction_series in fraction_dict.items():
+                not_nan_idx = ~np.isnan(fraction_series)
+                if not not_nan_idx.any():
+                    continue
+                not_nan_idx = np.where(not_nan_idx)[0]
+                variable_year_frac = self.variables.frac.fraction.isel(
+                    aggr=aggr_idx, lbs=lbs_idx
+                )
+                lbs_max_fraction_increase = xr.DataArray(
+                    fraction_series,
+                    dims="year",
+                    coords={"year": self.indices.Y.ii},
+                ).isel(year=not_nan_idx)
+
+                self.model.add_constraints(
+                    variable_year_frac.isel(year=not_nan_idx)
+                    - variable_year_frac.isel(year=not_nan_idx - 1)
+                    <= lbs_max_fraction_increase,
+                    name=f"{aggr_idx}_{lbs_idx}_FRAC_MAX_INCREASE_CONSTRAINT",
+                )
+        _logger.debug("Build max fraction increase constraints: Done")
+
+    def max_fraction_decrease_constraints(self) -> None:
+        max_fraction_decrease = self.parameters.aggr.max_fraction_decrease
+        for aggr_idx, fraction_dict in max_fraction_decrease.items():
+            for lbs_idx, fraction_series in fraction_dict.items():
+                not_nan_idx = ~np.isnan(fraction_series)
+                if not not_nan_idx.any():
+                    continue
+                not_nan_idx = np.where(not_nan_idx)[0]
+                variable_year_frac = self.variables.frac.fraction.isel(
+                    aggr=aggr_idx, lbs=lbs_idx
+                )
+                lbs_max_fraction_decrease = xr.DataArray(
+                    fraction_series,
+                    dims="year",
+                    coords={"year": self.indices.Y.ii},
+                ).isel(year=not_nan_idx)
+
+                self.model.add_constraints(
+                    variable_year_frac.isel(year=not_nan_idx - 1)
+                    - variable_year_frac.isel(year=not_nan_idx)
+                    <= lbs_max_fraction_decrease,
+                    name=f"{aggr_idx}_{lbs_idx}_FRAC_MAX_DECREASE_CONSTRAINT",
+                )
+        _logger.debug("Build max fraction decrease constraints: Done")
+
+    def emission_constraints(self) -> None:
+        for et in self.parameters.scenario_parameters.rel_em_limit.keys():
+            if not np.isnan(
+                self.parameters.scenario_parameters.base_total_emission[et]
+            ):
+                base_total_em = (
+                    self.parameters.scenario_parameters.base_total_emission[et]
+                    * self.parameters.scenario_parameters.hourly_scale
+                )
+                for y_idx in self.indices.Y.mapping.keys():
+                    if not np.isnan(
+                        self.parameters.scenario_parameters.rel_em_limit[et][y_idx]
+                    ):
+                        total_em = 0.0
+                        for fuel_idx in self.indices.FUEL.mapping.keys():
+                            for gen_idx in self.indices.GEN.mapping.keys():
+                                if fuel_idx == self.parameters.gen.fuel[gen_idx]:
+                                    total_em += (
+                                        self.expr.fuel_consumption(
+                                            fuel_idx,
+                                            gen_idx,
+                                            self.parameters.scenario_parameters.hourly_scale,
+                                        ).isel(year=y_idx)
+                                        * self.parameters.fuel.u_emission[fuel_idx][et]
+                                        * (1 - self.parameters.gen.em_red[gen_idx][et])
+                                    )
+
+                        self.model.add_constraints(
+                            total_em
+                            <= base_total_em
+                            * self.parameters.scenario_parameters.rel_em_limit[et][
+                                y_idx
+                            ],
+                            name=f"{et}_{y_idx}_EMISSIONS_CONSTRAINT",
+                        )
+        _logger.debug("Build emission constraints: Done")
+
+    @staticmethod
+    def _unit_of_given_tag(unit_tags: dict[int, set[int]], tag_idx: int) -> set[int]:
+        """returns set of units of a given tag"""
+        return {gen_idx for gen_idx, tag_set in unit_tags.items() if tag_idx in tag_set}
+
+    def _get_tags(
+        self, tag: int, subtag: int
+    ) -> tuple[set[int], set[int], set[int], set[int]]:
+        tag_gen_idxs = ScenarioConstraintsBuilder._unit_of_given_tag(
+            self.parameters.gen.tags, tag
+        )
+        subtag_gen_idxs = ScenarioConstraintsBuilder._unit_of_given_tag(
+            self.parameters.gen.tags, subtag
+        )
+        tag_stor_idxs = ScenarioConstraintsBuilder._unit_of_given_tag(
+            self.parameters.stor.tags, tag
+        )
+        subtag_stor_idxs = ScenarioConstraintsBuilder._unit_of_given_tag(
+            self.parameters.stor.tags, subtag
+        )
+        return tag_gen_idxs, subtag_gen_idxs, tag_stor_idxs, subtag_stor_idxs
+
+    def _expr_gen(
+        self, et: str, gen_idxs: set[int], stor_idxs: set[int]
+    ) -> LinearExpression | float:
+        gen_et_var = self.variables.gen.gen_et
+        stor_et_var = self.variables.stor.gen
+        return (
+            gen_et_var.isel(gen=list(gen_idxs), et=self.indices.ET.inverse[et]).sum()
+            + stor_et_var.isel(stor=list(stor_idxs)).sum()
+        )
+
+    def _min_generation_fraction_constraint(self) -> None:
+        min_gen_frac_params = (
+            self.parameters.scenario_parameters.min_generation_fraction
+        )
+        if min_gen_frac_params is not None:
+            for et, min_gen_frac_per_et in min_gen_frac_params.items():
+                for tags, min_gen_frac in min_gen_frac_per_et.items():
+                    tag, subtag = tags
+                    (
+                        tag_gen_idxs,
+                        subtag_gen_idxs,
+                        tag_stor_idxs,
+                        subtag_stor_idxs,
+                    ) = self._get_tags(tag, subtag)
+                    self.model.add_constraints(
+                        self._expr_gen(et, subtag_gen_idxs, subtag_stor_idxs)
+                        >= self._expr_gen(et, tag_gen_idxs, tag_stor_idxs)
+                        * min_gen_frac,
+                        name=f"{tag}_MIN_GENERATION_FRACTION_CONSTRAINT",
+                    )
+        _logger.debug("Build min generation fraction constraints: Done")
+
+    def _max_generation_fraction_constraint(self) -> None:
+        max_gen_frac_params = (
+            self.parameters.scenario_parameters.max_generation_fraction
+        )
+        if max_gen_frac_params is not None:
+            for et, max_gen_frac_per_et in max_gen_frac_params.items():
+                for tags, max_gen_frac in max_gen_frac_per_et.items():
+                    tag, subtag = tags
+                    (
+                        tag_gen_idxs,
+                        subtag_gen_idxs,
+                        tag_stor_idxs,
+                        subtag_stor_idxs,
+                    ) = self._get_tags(tag, subtag)
+                    self.model.add_constraints(
+                        self._expr_gen(et, subtag_gen_idxs, subtag_stor_idxs)
+                        <= self._expr_gen(et, tag_gen_idxs, tag_stor_idxs)
+                        * max_gen_frac,
+                        name=f"{tag}_MAX_GENERATION_FRACTION_CONSTRAINT",
+                    )
+        _logger.debug("Build max generation fraction constraints: Done")
+
+    def power_reserve_constraint(self) -> None:
+        power_reserves = self.parameters.scenario_parameters.power_reserves
+        if power_reserves:
+            cap = self.variables.gen.cap
+            gen_et = self.variables.gen.gen_et
+            gens_of_tag = invert_dict_of_sets(self.parameters.gen.tags)
+            for energy_type, tag_to_reserve in power_reserves.items():
+                et = self.indices.ET.inverse[energy_type]
+                for tag, reserve in tag_to_reserve.items():
+                    self.model.add_constraints(
+                        cap.isel(gen=list(gens_of_tag[tag])).sum(["gen"])
+                        - gen_et.isel(gen=list(gens_of_tag[tag]), et=et).sum(["gen"])
+                        >= reserve,
+                        name=f"ENERGY_TYPE_{et}_TAG_{tag}_POWER_RESERVE_CONSTRAINT",
+                    )
+        _logger.debug("Build power reserve constraints: Done")
```

### Comparing `pyzefir-0.4.1/pyzefir/optimization/linopy/expression_handler.py` & `pyzefir-0.4.22/pyzefir/optimization/linopy/expression_handler.py`

 * *Ordering differences only*

 * *Files 26% similar despite different names*

```diff
@@ -1,169 +1,169 @@
-# PyZefir
-# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-import numpy as np
-import xarray as xr
-from linopy import LinearExpression, Variable
-
-from pyzefir.optimization.linopy.preprocessing.indices import Indices
-from pyzefir.optimization.linopy.preprocessing.opt_parameters import (
-    OptimizationParameters,
-)
-from pyzefir.optimization.linopy.preprocessing.opt_variables import (
-    OptimizationVariables,
-)
-
-
-class ExpressionHandler:
-    """Encapsulation of simple linear expressions
-
-    Encapsulation of simple linear expressions, that describes important
-    modelling concepts (brutto-netto energy conversion, fuel usage, fuel emission etc.)
-    """
-
-    def __init__(
-        self,
-        indices: Indices,
-        variables: OptimizationVariables,
-        parameters: OptimizationParameters,
-    ) -> None:
-        self.indices = indices
-        self.parameters = parameters
-        self.variables = variables
-
-    def fraction_dem(self, bus_idx: int) -> LinearExpression | float:
-        """Fraction demand
-
-        Demand in bus related to fractions of local technology stacks in consumer aggregates.
-
-        Args:
-            bus_idx (int): bus index
-        Returns:
-            fraction_dem
-        """
-        if bus_idx not in self.parameters.bus.lbs_mapping:
-            return 0.0
-
-        lbs_idx, energy_type = (
-            self.parameters.bus.lbs_mapping[bus_idx],
-            self.parameters.bus.et[bus_idx],
-        )
-        aggr_idx = self.parameters.lbs.aggr_idx[lbs_idx]
-        dem, frac = (
-            self.parameters.aggr.dem[aggr_idx][energy_type],
-            self.variables.frac.fraction.isel(aggr=aggr_idx, lbs=lbs_idx),
-        )
-
-        return xr.DataArray(dem, dims=["hour", "year"]) * frac
-
-    def gen_netto_g(self, gen_idx: int, energy_type: str) -> LinearExpression:
-        """Generator netto generation (taking into account losses)
-
-        Args:
-            gen_idx (int): generator index
-            energy_type (str): type of produced energy
-        Returns:
-            MLinExpr: Linear expression for Generator netto generation
-        """
-        k = self.parameters.gen.eff[gen_idx][energy_type]
-        v = self.variables.gen.gen.isel(gen=gen_idx)
-        return self.scale(k, v)
-
-    def gen_netto_st(self, st_idx: int) -> LinearExpression:
-        """Storage netto generation (taking into account generation losses)
-
-        Args:
-            st_idx (int): storage index
-        Returns:
-            MLinExpr: Expression for storage netto generation
-        """
-        k = self.parameters.stor.gen_eff[st_idx]
-        v = self.variables.stor.gen.isel(stor=st_idx)
-        return self.scale(k, v)
-
-    def load_netto_st(self, st_idx: int) -> LinearExpression:
-        """Storage netto energy loading (taking into account loading losses)
-
-        Args:
-            st_idx (int): storage index
-        Returns:
-            MLinExpr: Linear expression for storage netto energy loading
-        """
-        k = self.parameters.stor.load_eff[st_idx]
-        v = self.variables.stor.load.isel(stor=st_idx)
-        return self.scale(k, v)
-
-    def netto_flow_l(self, line_idx: int) -> LinearExpression:
-        """Line netto energy flow (taking into account losses)
-
-        Args:
-            line_idx (int): line index
-        Returns:
-             MLinExpr: Linear expression for line netto flow
-        : MLinExpr
-        """
-        k, v = (
-            1 - self.parameters.line.loss[line_idx],
-            self.variables.line.flow.isel(line=line_idx),
-        )
-        return self.scale(k, v)
-
-    def p_inst_st(self, st_idx: int) -> LinearExpression:
-        """Storage installed power
-
-        Args:
-            st_idx (int): storage index
-        Returns:
-            MLinExpr: Linear expression for storage installed power
-        """
-        k, v = (
-            self.parameters.stor.p2cap[st_idx],
-            self.variables.stor.cap.isel(stor=st_idx),
-        )
-        return self.scale(k, v)
-
-    @staticmethod
-    def discount_rate(yearly_rate: np.ndarray) -> np.ndarray:
-        """Vector of discount rates for each year.
-
-        Returns:
-            np.ndarray: discount rate
-        """
-        return np.cumprod((1 + yearly_rate) ** (-1))
-
-    @staticmethod
-    def scale(_k: float | np.ndarray, _v: Variable) -> LinearExpression:
-        return _k * _v
-
-    def fuel_consumption(
-        self, fuel_idx: int, gen_idx: int, hourly_scale: float
-    ) -> LinearExpression:
-        """Fuel consumption
-
-        Args:
-            fuel_idx (int): fuel index
-            gen_idx (int): generator index
-            hourly_scale: (float): hourly scale
-        Returns:
-            MLinExpr: Linear expression for fuel consumption multiply by hourly scale
-        """
-
-        if self.parameters.gen.fuel[gen_idx] != fuel_idx:
-            return LinearExpression(np.zeros(len(self.indices.Y)))
-        return (
-            self.variables.gen.gen.isel(gen=gen_idx).sum(["hour"])
-            / self.parameters.fuel.energy_per_unit[fuel_idx]
-        ) * hourly_scale
+# PyZefir
+# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+import numpy as np
+import xarray as xr
+from linopy import LinearExpression, Variable
+
+from pyzefir.optimization.linopy.preprocessing.indices import Indices
+from pyzefir.optimization.linopy.preprocessing.opt_parameters import (
+    OptimizationParameters,
+)
+from pyzefir.optimization.linopy.preprocessing.opt_variables import (
+    OptimizationVariables,
+)
+
+
+class ExpressionHandler:
+    """Encapsulation of simple linear expressions
+
+    Encapsulation of simple linear expressions, that describes important
+    modelling concepts (brutto-netto energy conversion, fuel usage, fuel emission etc.)
+    """
+
+    def __init__(
+        self,
+        indices: Indices,
+        variables: OptimizationVariables,
+        parameters: OptimizationParameters,
+    ) -> None:
+        self.indices = indices
+        self.parameters = parameters
+        self.variables = variables
+
+    def fraction_dem(self, bus_idx: int) -> LinearExpression | float:
+        """Fraction demand
+
+        Demand in bus related to fractions of local technology stacks in consumer aggregates.
+
+        Args:
+            bus_idx (int): bus index
+        Returns:
+            fraction_dem
+        """
+        if bus_idx not in self.parameters.bus.lbs_mapping:
+            return 0.0
+
+        lbs_idx, energy_type = (
+            self.parameters.bus.lbs_mapping[bus_idx],
+            self.parameters.bus.et[bus_idx],
+        )
+        aggr_idx = self.parameters.lbs.aggr_idx[lbs_idx]
+        dem, frac = (
+            self.parameters.aggr.dem[aggr_idx][energy_type],
+            self.variables.frac.fraction.isel(aggr=aggr_idx, lbs=lbs_idx),
+        )
+
+        return xr.DataArray(dem, dims=["hour", "year"]) * frac
+
+    def gen_netto_g(self, gen_idx: int, energy_type: str) -> LinearExpression:
+        """Generator netto generation (taking into account losses)
+
+        Args:
+            gen_idx (int): generator index
+            energy_type (str): type of produced energy
+        Returns:
+            MLinExpr: Linear expression for Generator netto generation
+        """
+        k = self.parameters.gen.eff[gen_idx][energy_type]
+        v = self.variables.gen.gen.isel(gen=gen_idx)
+        return self.scale(k, v)
+
+    def gen_netto_st(self, st_idx: int) -> LinearExpression:
+        """Storage netto generation (taking into account generation losses)
+
+        Args:
+            st_idx (int): storage index
+        Returns:
+            MLinExpr: Expression for storage netto generation
+        """
+        k = self.parameters.stor.gen_eff[st_idx]
+        v = self.variables.stor.gen.isel(stor=st_idx)
+        return self.scale(k, v)
+
+    def load_netto_st(self, st_idx: int) -> LinearExpression:
+        """Storage netto energy loading (taking into account loading losses)
+
+        Args:
+            st_idx (int): storage index
+        Returns:
+            MLinExpr: Linear expression for storage netto energy loading
+        """
+        k = self.parameters.stor.load_eff[st_idx]
+        v = self.variables.stor.load.isel(stor=st_idx)
+        return self.scale(k, v)
+
+    def netto_flow_l(self, line_idx: int) -> LinearExpression:
+        """Line netto energy flow (taking into account losses)
+
+        Args:
+            line_idx (int): line index
+        Returns:
+             MLinExpr: Linear expression for line netto flow
+        : MLinExpr
+        """
+        k, v = (
+            1 - self.parameters.line.loss[line_idx],
+            self.variables.line.flow.isel(line=line_idx),
+        )
+        return self.scale(k, v)
+
+    def p_inst_st(self, st_idx: int) -> LinearExpression:
+        """Storage installed power
+
+        Args:
+            st_idx (int): storage index
+        Returns:
+            MLinExpr: Linear expression for storage installed power
+        """
+        k, v = (
+            self.parameters.stor.p2cap[st_idx],
+            self.variables.stor.cap.isel(stor=st_idx),
+        )
+        return self.scale(k, v)
+
+    @staticmethod
+    def discount_rate(yearly_rate: np.ndarray) -> np.ndarray:
+        """Vector of discount rates for each year.
+
+        Returns:
+            np.ndarray: discount rate
+        """
+        return np.cumprod((1 + yearly_rate) ** (-1))
+
+    @staticmethod
+    def scale(_k: float | np.ndarray, _v: Variable) -> LinearExpression:
+        return _k * _v
+
+    def fuel_consumption(
+        self, fuel_idx: int, gen_idx: int, hourly_scale: float
+    ) -> LinearExpression:
+        """Fuel consumption
+
+        Args:
+            fuel_idx (int): fuel index
+            gen_idx (int): generator index
+            hourly_scale: (float): hourly scale
+        Returns:
+            MLinExpr: Linear expression for fuel consumption multiply by hourly scale
+        """
+
+        if self.parameters.gen.fuel[gen_idx] != fuel_idx:
+            return LinearExpression(np.zeros(len(self.indices.Y)))
+        return (
+            self.variables.gen.gen.isel(gen=gen_idx).sum(["hour"])
+            / self.parameters.fuel.energy_per_unit[fuel_idx]
+        ) * hourly_scale
```

### Comparing `pyzefir-0.4.1/pyzefir/optimization/linopy/model.py` & `pyzefir-0.4.22/pyzefir/optimization/linopy/model.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,269 +1,282 @@
-# PyZefir
-# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-
-import logging
-
-from linopy import Model
-
-from pyzefir.optimization.input_data import OptimizationInputData
-from pyzefir.optimization.linopy.constraints_builder.balancing_constraints_builder import (
-    BalancingConstraintsBuilder,
-)
-from pyzefir.optimization.linopy.constraints_builder.capacity_evolution_constraints_builder import (
-    CapacityEvolutionConstrBuilder,
-)
-from pyzefir.optimization.linopy.constraints_builder.fraction_constraints_builder import (
-    FractionConstraintsBuilder,
-)
-from pyzefir.optimization.linopy.constraints_builder.generation_constraints_builder import (
-    GenerationConstraintsBuilder,
-)
-from pyzefir.optimization.linopy.constraints_builder.generation_ramp import (
-    RampConstraintsBuilder,
-)
-from pyzefir.optimization.linopy.constraints_builder.line_flow_constraints_builder import (
-    LineFlowConstraintsBuilder,
-)
-from pyzefir.optimization.linopy.constraints_builder.scenario_constraints_builder import (
-    ScenarioConstraintsBuilder,
-)
-from pyzefir.optimization.linopy.constraints_builder.storage_constraints_builder import (
-    StorageConstraintsBuilder,
-)
-from pyzefir.optimization.linopy.objective_builder.capex_objective_builder import (
-    CapexObjectiveBuilder,
-)
-from pyzefir.optimization.linopy.objective_builder.curtailed_energy_cost import (
-    CurtailedEnergyCostObjectiveBuilder,
-)
-from pyzefir.optimization.linopy.objective_builder.dsr_penalty_objective_builder import (
-    DsrPenaltyObjectiveBuilder,
-)
-from pyzefir.optimization.linopy.objective_builder.emission_fee_objective_builder import (
-    EmissionFeeObjectiveBuilder,
-)
-from pyzefir.optimization.linopy.objective_builder.ens_penalty_builder import (
-    EnsPenaltyCostObjectiveBuilder,
-)
-from pyzefir.optimization.linopy.objective_builder.opex_objective_builder import (
-    OpexObjectiveBuilder,
-)
-from pyzefir.optimization.linopy.objective_builder.transmission_fee_objective_builder import (
-    TransmissionFeeObjectiveBuilder,
-)
-from pyzefir.optimization.linopy.objective_builder.var_cost_objective_builder import (
-    VarCostObjectiveBuilder,
-)
-from pyzefir.optimization.linopy.preprocessing.indices import Indices
-from pyzefir.optimization.linopy.preprocessing.opt_parameters import (
-    OptimizationParameters,
-)
-from pyzefir.optimization.linopy.preprocessing.opt_variables import (
-    OptimizationVariables,
-)
-from pyzefir.optimization.model import (
-    OptimizationError,
-    OptimizationModel,
-    OptimizationStatus,
-)
-from pyzefir.optimization.results import Results
-
-
-class LinopyOptimizationModel(OptimizationModel):
-    """
-    This class is responsible for the optimization model creation.
-    It uses the Linopy library to create the model.
-    """
-
-    _constraint_builders = [
-        ScenarioConstraintsBuilder,
-        BalancingConstraintsBuilder,
-        FractionConstraintsBuilder,
-        LineFlowConstraintsBuilder,
-        GenerationConstraintsBuilder,
-        StorageConstraintsBuilder,
-        RampConstraintsBuilder,
-        CapacityEvolutionConstrBuilder,
-    ]
-    _objective_builders = [
-        CapexObjectiveBuilder,
-        VarCostObjectiveBuilder,
-        EnsPenaltyCostObjectiveBuilder,
-        OpexObjectiveBuilder,
-        EmissionFeeObjectiveBuilder,
-        TransmissionFeeObjectiveBuilder,
-        DsrPenaltyObjectiveBuilder,
-        CurtailedEnergyCostObjectiveBuilder,
-    ]
-
-    def __init__(self) -> None:
-        """
-        Initializes the model.
-        """
-        self._indices: Indices | None = (
-            None  # TODO: replae indicies with indexed xarrays
-        )
-
-        self._input_data: OptimizationInputData | None = None
-        self._model: Model | None = None
-        self._parameters: OptimizationParameters | None = None
-        self._variables: OptimizationVariables | None = None
-
-        self._results: Results | None = None
-        self._status = OptimizationStatus.NOT_COMPUTED
-
-    def build(self, input_data: OptimizationInputData) -> None:
-        """
-        Builds the model.
-        """
-        self._input_data = input_data
-        self._indices = Indices(self.input_data.network, self.input_data.config)
-        self._model = Model()
-        self._parameters = OptimizationParameters(
-            self.input_data.network, self.indices, self.input_data.config
-        )
-        self._variables = OptimizationVariables(
-            self.model, self.indices, self.input_data.config, self.parameters
-        )
-        self._set_constraints()
-        self._set_objective_function()
-
-    def _set_constraints(self) -> None:
-        for builder in self._constraint_builders:
-            builder(
-                self.indices, self.parameters, self.variables, self.model
-            ).build_constraints()
-
-    def _set_objective_function(self) -> None:
-        obj_expression = 0.0
-        for builder in self._objective_builders:
-            obj_expression += builder(
-                self.indices, self.parameters, self.variables, self.model
-            ).build_expression()
-
-        self.model.add_objective(obj_expression, sense="min")
-
-    @property
-    def input_data(self) -> OptimizationInputData:
-        """
-        Returns the input data.
-        Returns:
-            OptimizationInputData: input data
-        Raises:
-            ValueError: if input data is not initialized yet
-        """
-        if self._input_data is None:
-            raise ValueError(
-                "intput data is not initialized yet, please call the build method"
-            )
-        return self._input_data
-
-    def optimize(self) -> None:
-        """
-        Runs the optimization.
-        """
-        self.model.solve(
-            solver_name=self.input_data.config.solver_name,
-            io_api="direct",
-            log_fn=self.input_data.config.opt_logs_dump_path,
-            solution_fn=self.input_data.config.sol_dump_path,
-            keep_files=True,
-        )
-        self.update_model_status()
-        if self.status == OptimizationStatus.OPTIMAL:
-            self._results = Results(
-                objective_value=self.model.objective.value,
-                variables=self.variables,
-                indices=self.indices,
-                parameters=self.parameters,
-            )
-        else:
-            logging.getLogger(__name__).warning(
-                "Model cannot be solved, optimization status is %s", self.status.name
-            )
-
-    @property
-    def results(self) -> Results:
-        """
-        Returns the results.
-        Returns:
-            Results: results
-        """
-        match self._status:
-            case OptimizationStatus.OPTIMAL:
-                return self._results
-            case OptimizationStatus.WARNING:
-                exception_message = (
-                    f"You are trying to get result of the optimization, but the optimization status is "
-                    f"{self._status.name}."
-                )
-                raise OptimizationError(exception_message)
-            case _:
-                raise OptimizationError(
-                    f"You are trying to get result of the optimization, but the optimization status is "
-                    f"{self._status.name}. "
-                )
-
-    @property
-    def status(self) -> OptimizationStatus:
-        """
-        Returns the status.
-        Returns:
-            OptimizationStatus: status
-        """
-        return self._status
-
-    @property
-    def parameters(self) -> OptimizationParameters:
-        if self._parameters is None:
-            raise ValueError(
-                "parameters are not initialized yet, please call the build method first"
-            )
-        return self._parameters
-
-    @property
-    def variables(self) -> OptimizationVariables:
-        if self._variables is None:
-            raise ValueError(
-                "variables are not initialized yet, please call the build method"
-            )
-        return self._variables
-
-    @property
-    def indices(self) -> Indices:
-        if self._indices is None:
-            raise ValueError(
-                "indices are not initialized yet, please call the build method first"
-            )
-        return self._indices
-
-    @property
-    def model(self) -> Model:
-        if self._model is None:
-            raise ValueError(
-                "model is not initialized yet, please call the build method first"
-            )
-        return self._model
-
-    def update_model_status(self) -> None:
-        match self.model.status:
-            case "ok":
-                self._status = OptimizationStatus.OPTIMAL
-            case "warning":
-                self._status = OptimizationStatus.WARNING
-            case _:
-                self._status = OptimizationStatus.NOT_COMPUTED
+# PyZefir
+# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+
+import logging
+
+from linopy import Model, solvers
+
+from pyzefir.optimization.input_data import OptimizationInputData
+from pyzefir.optimization.linopy.constraints_builder.balancing_constraints_builder import (
+    BalancingConstraintsBuilder,
+)
+from pyzefir.optimization.linopy.constraints_builder.capacity_binding_builder import (
+    CapacityBindingBuilder,
+)
+from pyzefir.optimization.linopy.constraints_builder.capacity_evolution_constraints_builder import (
+    CapacityEvolutionConstrBuilder,
+)
+from pyzefir.optimization.linopy.constraints_builder.fraction_constraints_builder import (
+    FractionConstraintsBuilder,
+)
+from pyzefir.optimization.linopy.constraints_builder.generation_constraints_builder import (
+    GenerationConstraintsBuilder,
+)
+from pyzefir.optimization.linopy.constraints_builder.generation_ramp import (
+    RampConstraintsBuilder,
+)
+from pyzefir.optimization.linopy.constraints_builder.line_flow_constraints_builder import (
+    LineFlowConstraintsBuilder,
+)
+from pyzefir.optimization.linopy.constraints_builder.scenario_constraints_builder import (
+    ScenarioConstraintsBuilder,
+)
+from pyzefir.optimization.linopy.constraints_builder.storage_constraints_builder import (
+    StorageConstraintsBuilder,
+)
+from pyzefir.optimization.linopy.objective_builder.capex_objective_builder import (
+    CapexObjectiveBuilder,
+)
+from pyzefir.optimization.linopy.objective_builder.curtailed_energy_cost import (
+    CurtailedEnergyCostObjectiveBuilder,
+)
+from pyzefir.optimization.linopy.objective_builder.dsr_penalty_objective_builder import (
+    DsrPenaltyObjectiveBuilder,
+)
+from pyzefir.optimization.linopy.objective_builder.emission_fee_objective_builder import (
+    EmissionFeeObjectiveBuilder,
+)
+from pyzefir.optimization.linopy.objective_builder.ens_penalty_builder import (
+    EnsPenaltyCostObjectiveBuilder,
+)
+from pyzefir.optimization.linopy.objective_builder.generation_compensation_objective_builder import (
+    GenerationCompensationObjectiveBuilder,
+)
+from pyzefir.optimization.linopy.objective_builder.opex_objective_builder import (
+    OpexObjectiveBuilder,
+)
+from pyzefir.optimization.linopy.objective_builder.transmission_fee_objective_builder import (
+    TransmissionFeeObjectiveBuilder,
+)
+from pyzefir.optimization.linopy.objective_builder.var_cost_objective_builder import (
+    VarCostObjectiveBuilder,
+)
+from pyzefir.optimization.linopy.preprocessing.indices import Indices
+from pyzefir.optimization.linopy.preprocessing.opt_parameters import (
+    OptimizationParameters,
+)
+from pyzefir.optimization.linopy.preprocessing.opt_variables import (
+    OptimizationVariables,
+)
+from pyzefir.optimization.model import (
+    OptimizationError,
+    OptimizationModel,
+    OptimizationStatus,
+)
+from pyzefir.optimization.results import Results
+
+
+class LinopyOptimizationModel(OptimizationModel):
+    """
+    This class is responsible for the optimization model creation.
+    It uses the Linopy library to create the model.
+    """
+
+    _constraint_builders = [
+        ScenarioConstraintsBuilder,
+        BalancingConstraintsBuilder,
+        FractionConstraintsBuilder,
+        LineFlowConstraintsBuilder,
+        GenerationConstraintsBuilder,
+        StorageConstraintsBuilder,
+        RampConstraintsBuilder,
+        CapacityEvolutionConstrBuilder,
+        CapacityBindingBuilder,
+    ]
+    _objective_builders = [
+        CapexObjectiveBuilder,
+        VarCostObjectiveBuilder,
+        EnsPenaltyCostObjectiveBuilder,
+        OpexObjectiveBuilder,
+        EmissionFeeObjectiveBuilder,
+        TransmissionFeeObjectiveBuilder,
+        DsrPenaltyObjectiveBuilder,
+        CurtailedEnergyCostObjectiveBuilder,
+        GenerationCompensationObjectiveBuilder,
+    ]
+    _direct_solvers = ["gurobi", "highs"]
+
+    def __init__(self) -> None:
+        """
+        Initializes the model.
+        """
+        self._indices: Indices | None = (
+            None  # TODO: replae indicies with indexed xarrays
+        )
+
+        self._input_data: OptimizationInputData | None = None
+        self._model: Model | None = None
+        self._parameters: OptimizationParameters | None = None
+        self._variables: OptimizationVariables | None = None
+
+        self._results: Results | None = None
+        self._status = OptimizationStatus.NOT_COMPUTED
+
+    def build(self, input_data: OptimizationInputData) -> None:
+        """
+        Builds the model.
+        """
+        self._input_data = input_data
+        self._indices = Indices(self.input_data.network, self.input_data.config)
+        self._model = Model()
+        self._parameters = OptimizationParameters(
+            self.input_data.network, self.indices, self.input_data.config
+        )
+        self._variables = OptimizationVariables(
+            self.model, self.indices, self.input_data.config
+        )
+        self._set_constraints()
+        self._set_objective_function()
+
+    def _set_constraints(self) -> None:
+        for builder in self._constraint_builders:
+            builder(
+                self.indices, self.parameters, self.variables, self.model
+            ).build_constraints()
+
+    def _set_objective_function(self) -> None:
+        obj_expression = 0.0
+        for builder in self._objective_builders:
+            obj_expression += builder(
+                self.indices, self.parameters, self.variables, self.model
+            ).build_expression()
+
+        self.model.add_objective(obj_expression, sense="min")
+
+    @property
+    def input_data(self) -> OptimizationInputData:
+        """
+        Returns the input data.
+        Returns:
+            OptimizationInputData: input data
+        Raises:
+            ValueError: if input data is not initialized yet
+        """
+        if self._input_data is None:
+            raise ValueError(
+                "intput data is not initialized yet, please call the build method"
+            )
+        return self._input_data
+
+    def optimize(self) -> None:
+        """
+        Runs the optimization.
+        """
+        config = self.input_data.config
+        solver = config.solver_name or solvers.available_solvers[0]
+        solver_settings = config.solver_settings.get(solver, {})
+        self.model.solve(
+            solver_name=solver,
+            io_api="direct" if solver in self._direct_solvers else "lp",
+            log_fn=config.opt_logs_dump_path,
+            solution_fn=config.sol_dump_path,
+            keep_files=True,
+            **solver_settings,
+        )
+        self.update_model_status()
+        if self.status == OptimizationStatus.OPTIMAL:
+            self._results = Results(
+                objective_value=self.model.objective.value,
+                variables=self.variables,
+                indices=self.indices,
+                parameters=self.parameters,
+            )
+        else:
+            logging.getLogger(__name__).warning(
+                "Model cannot be solved, optimization status is %s", self.status.name
+            )
+
+    @property
+    def results(self) -> Results:
+        """
+        Returns the results.
+        Returns:
+            Results: results
+        """
+        match self._status:
+            case OptimizationStatus.OPTIMAL:
+                return self._results
+            case OptimizationStatus.WARNING:
+                exception_message = (
+                    f"You are trying to get result of the optimization, but the optimization status is "
+                    f"{self._status.name}."
+                )
+                raise OptimizationError(exception_message)
+            case _:
+                raise OptimizationError(
+                    f"You are trying to get result of the optimization, but the optimization status is "
+                    f"{self._status.name}. "
+                )
+
+    @property
+    def status(self) -> OptimizationStatus:
+        """
+        Returns the status.
+        Returns:
+            OptimizationStatus: status
+        """
+        return self._status
+
+    @property
+    def parameters(self) -> OptimizationParameters:
+        if self._parameters is None:
+            raise ValueError(
+                "parameters are not initialized yet, please call the build method first"
+            )
+        return self._parameters
+
+    @property
+    def variables(self) -> OptimizationVariables:
+        if self._variables is None:
+            raise ValueError(
+                "variables are not initialized yet, please call the build method"
+            )
+        return self._variables
+
+    @property
+    def indices(self) -> Indices:
+        if self._indices is None:
+            raise ValueError(
+                "indices are not initialized yet, please call the build method first"
+            )
+        return self._indices
+
+    @property
+    def model(self) -> Model:
+        if self._model is None:
+            raise ValueError(
+                "model is not initialized yet, please call the build method first"
+            )
+        return self._model
+
+    def update_model_status(self) -> None:
+        match self.model.status:
+            case "ok":
+                self._status = OptimizationStatus.OPTIMAL
+            case "warning":
+                self._status = OptimizationStatus.WARNING
+            case _:
+                self._status = OptimizationStatus.NOT_COMPUTED
```

### Comparing `pyzefir-0.4.1/pyzefir/optimization/linopy/objective_builder/__init__.py` & `pyzefir-0.4.22/pyzefir/optimization/linopy/constraints_builder/builder.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,47 +1,54 @@
-# PyZefir
-# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-from abc import abstractmethod
-
-from linopy import LinearExpression, Model
-
-from pyzefir.optimization.linopy.expression_handler import ExpressionHandler
-from pyzefir.optimization.linopy.preprocessing.indices import Indices
-from pyzefir.optimization.linopy.preprocessing.opt_parameters import (
-    OptimizationParameters,
-)
-from pyzefir.optimization.linopy.preprocessing.opt_variables import (
-    OptimizationVariables,
-)
-
-
-class ObjectiveBuilder:
-    def __init__(
-        self,
-        indices: Indices,
-        parameters: OptimizationParameters,
-        variables: OptimizationVariables,
-        model: Model,
-    ) -> None:
-        self.indices = indices
-        self.parameters = parameters
-        self.variables = variables
-        self.model = model
-        self.expr = ExpressionHandler(indices, variables, parameters)
-
-    @abstractmethod
-    def build_expression(self) -> LinearExpression:
-        pass
+# PyZefir
+# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+import abc
+
+from linopy import Model
+
+from pyzefir.optimization.linopy.expression_handler import ExpressionHandler
+from pyzefir.optimization.linopy.preprocessing.indices import Indices
+from pyzefir.optimization.linopy.preprocessing.opt_parameters import (
+    OptimizationParameters,
+)
+from pyzefir.optimization.linopy.preprocessing.opt_variables import (
+    OptimizationVariables,
+)
+
+
+class PartialConstraintsBuilder(metaclass=abc.ABCMeta):
+    """
+    An abstract class to represent build of some constraints set
+    """
+
+    def __init__(
+        self,
+        indices: Indices,
+        parameters: OptimizationParameters,
+        variables: OptimizationVariables,
+        model: Model,
+    ) -> None:
+        self.indices = indices
+        self.parameters = parameters
+        self.variables = variables
+        self.model = model
+        self.expr = ExpressionHandler(indices, variables, parameters)
+
+    @abc.abstractmethod
+    def build_constraints(self) -> None:
+        """
+        Creating optimization constraints.
+        """
+        raise NotImplementedError
```

### Comparing `pyzefir-0.4.1/pyzefir/optimization/linopy/objective_builder/capex_objective_builder.py` & `pyzefir-0.4.22/pyzefir/optimization/linopy/objective_builder/capex_objective_builder.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,260 +1,266 @@
-# PyZefir
-# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-import numpy as np
-from linopy import LinearExpression
-from linopy.variables import Variable
-
-from pyzefir.optimization.linopy.objective_builder import ObjectiveBuilder
-from pyzefir.optimization.linopy.preprocessing.indices import IndexingSet
-from pyzefir.optimization.linopy.preprocessing.parameters.generator_type_parameters import (
-    GeneratorTypeParameters,
-)
-from pyzefir.optimization.linopy.preprocessing.parameters.storage_type_parameters import (
-    StorageTypeParameters,
-)
-from pyzefir.utils.functions import get_dict_vals
-
-
-class CapexObjectiveBuilder(ObjectiveBuilder):
-    def build_expression(self) -> LinearExpression:
-        return self.global_capex() + self.local_capex()
-
-    def local_capex(self) -> LinearExpression:
-        generator_capex = self._local_capex(
-            tcap_plus=self.variables.tgen.tcap_plus,
-            unit_type_param=self.parameters.tgen,
-            aggr_map=self.indices.aggr_tgen_map,
-        )
-        storage_capex = self._local_capex(
-            tcap_plus=self.variables.tstor.tcap_plus,
-            unit_type_param=self.parameters.tstor,
-            aggr_map=self.indices.aggr_tstor_map,
-        )
-        return generator_capex + storage_capex
-
-    def global_capex(self) -> LinearExpression:
-        generator_capex = self._global_capex(
-            cap_plus=self.variables.gen.cap_plus,
-            unit_type_param=self.parameters.tgen,
-            unit_type_idx=self.parameters.gen.tgen,
-            non_lbs_unit_idxs=get_dict_vals(self.parameters.bus.generators).difference(
-                get_dict_vals(self.indices.aggr_gen_map)
-            ),
-        )
-        storage_capex = self._global_capex(
-            cap_plus=self.variables.stor.cap_plus,
-            unit_type_param=self.parameters.tstor,
-            unit_type_idx=self.parameters.stor.tstor,
-            non_lbs_unit_idxs=get_dict_vals(self.parameters.bus.storages).difference(
-                get_dict_vals(self.indices.aggr_stor_map)
-            ),
-        )
-        return generator_capex + storage_capex
-
-    def _global_capex(
-        self,
-        cap_plus: Variable,
-        unit_type_param: GeneratorTypeParameters | StorageTypeParameters,
-        unit_type_idx: dict,
-        non_lbs_unit_idxs: set,
-    ) -> LinearExpression | float:
-        """
-        Total investment cost for global (non-lbs) technologies for all years
-
-        Args:
-            cap_plus (Variable): capex increase labeled by unit index
-            unit_type_param (GeneratorTypeParameters | StorageTypeParameters): technology type index
-            unit_type_idx: dict[int, int]: technology index of a given unit index
-            non_lbs_unit_idxs: set[int]: set of non-lbs (global) units
-
-        Returns:
-            Linear expression of capex cost
-
-        """
-        disc_rate = self.expr.discount_rate(
-            self.parameters.scenario_parameters.discount_rate
-        )
-        y_idxs = self.indices.Y
-        unit_capex = 0.0
-        for u_idx in non_lbs_unit_idxs:
-            ut_idx = unit_type_idx[u_idx]
-            capex = unit_type_param.capex[ut_idx]
-            lt = unit_type_param.lt[ut_idx]
-
-            for s_idx in y_idxs.ord:
-                unit_capex += self.global_capex_per_unit_per_year(
-                    capex=capex,
-                    cap_plus=cap_plus,
-                    disc_rate=disc_rate,
-                    lt=lt,
-                    s_idx=s_idx,
-                    u_idx=u_idx,
-                    y_idxs=y_idxs,
-                )
-        return unit_capex
-
-    @staticmethod
-    def global_capex_per_unit_per_year(
-        capex: np.ndarray,
-        cap_plus: Variable,
-        disc_rate: np.ndarray,
-        lt: int,
-        s_idx: int,
-        u_idx: int,
-        y_idxs: IndexingSet,
-    ) -> LinearExpression | float:
-        """
-        Capex for a given year for global (non-lbs) technologies
-        Takes a single year index as a single argument s_idx, calculates the corresponding capex cost in this year
-        The function also requires the whole set of years, given by y_idxs
-
-
-        Args:
-            capex (ndarray): yearly capex cost parameter
-            cap_plus (Variable): capex increase labeled by unit index
-            disc_rate (ndarray): yearly discount rate
-            lt (int): life time of a given technology
-            s_idx (int): single year index, specifying the year for capex calculation
-            ut_idx (int): technology type index
-            aggr_idx (int): index of a given aggregate
-            y_idxs (IndexingSet): set of years
-
-        Returns:
-            Linear expression of a yearly investment cost
-        """
-        am_indicator = CapexObjectiveBuilder._amortization_matrix_indicator(
-            lt=lt, yy=y_idxs
-        )
-        res = 0.0
-        for y_idx in y_idxs.ord:
-            res += (
-                am_indicator[s_idx, y_idx]
-                * capex[s_idx]
-                * cap_plus.sel(index=(u_idx, s_idx))
-                * disc_rate[y_idx]
-                / lt
-            )
-        return res
-
-    def _local_capex(
-        self,
-        tcap_plus: Variable,
-        unit_type_param: GeneratorTypeParameters | StorageTypeParameters,
-        aggr_map: dict[..., set],
-    ) -> LinearExpression | float:
-        """
-        Total investment cost for local (lbs) technologies for all years
-
-        Args:
-            tcap_plus (Variable): capex increase labeled by unit type index and aggregate index
-            unit_type_param (GeneratorTypeParameters | StorageTypeParameters): technology type index
-            unit_type_idx: dict[int, int]: technology index of a given unit index
-            non_lbs_unit_idxs: set[int]: set of non-lbs (global) units
-
-        Returns:
-            Linear expression of capex cost
-
-        """
-        disc_rate = self.expr.discount_rate(
-            self.parameters.scenario_parameters.discount_rate
-        )
-        y_idxs = self.indices.Y
-        unit_type_capex = 0.0
-        for aggr_idx, ut_idxs in aggr_map.items():
-            for ut_idx in ut_idxs:
-                capex = unit_type_param.capex[ut_idx]
-                lt = unit_type_param.lt[ut_idx]
-                for s_idx in y_idxs.ord:
-                    unit_type_capex += self.local_capex_per_unit_per_year(
-                        capex=capex,
-                        tcap_plus=tcap_plus,
-                        disc_rate=disc_rate,
-                        lt=lt,
-                        s_idx=s_idx,
-                        ut_idx=ut_idx,
-                        aggr_idx=aggr_idx,
-                        y_idxs=y_idxs,
-                    )
-        return unit_type_capex
-
-    @staticmethod
-    def local_capex_per_unit_per_year(
-        capex: np.ndarray,
-        tcap_plus: Variable,
-        disc_rate: np.ndarray,
-        lt: int,
-        s_idx: int,
-        ut_idx: int,
-        aggr_idx: int,
-        y_idxs: IndexingSet,
-    ) -> LinearExpression | float:
-        """
-        Capex for a given year for local (lbs) technologies
-        Takes a single year index as a single argument s_idx, calculates the corresponding capex cost in this year
-        The function also requires the whole set of years, given by y_idxs
-
-        Args:
-            capex (ndarray): yearly capex cost parameter
-            tcap_plus (Variable): capex increase labeled by unit type index and aggregate index
-            disc_rate (ndarray): yearly discount rate
-            lt (int): life time of a given technology
-            s_idx (int): single year index, specifying the year for capex calculation
-            ut_idx (int): technology type index
-            aggr_idx (int): index of a given aggregate
-            y_idxs (IndexingSet): set of years
-
-        Returns:
-            Linear expression of a yearly investment cost
-        """
-        am_indicator = CapexObjectiveBuilder._amortization_matrix_indicator(
-            lt=lt, yy=y_idxs
-        )
-        res = 0.0
-        for y_idx in y_idxs.ord:
-            res += (
-                am_indicator[s_idx, y_idx]
-                * tcap_plus.sel(index=(aggr_idx, ut_idx, s_idx))
-                * capex[s_idx]
-                * disc_rate[y_idx]
-                / lt
-            )
-        return res
-
-    @staticmethod
-    def _amortization_matrix_indicator(
-        lt: int,
-        yy: IndexingSet,
-    ) -> np.ndarray:
-        """
-        Indicator matrix for y-index range in capex expression specifying the summation in capex expression
-        The resulting matrix is composed of 0 and 1; zero means there is no capex contribution from the corresponding
-        element
-
-        Args:
-            lt (int): unit lifetime
-            yy (IndexingSet): year indices
-
-        Returns:
-            np.ndarray
-        """
-
-        return np.array(
-            [
-                ((yy.ord >= y) & (yy.ord <= min(y + lt - 1, len(yy)))).astype(int)
-                for y in yy.ord
-            ]
-        )
+# PyZefir
+# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+import logging
+
+import numpy as np
+from linopy import LinearExpression
+from linopy.variables import Variable
+
+from pyzefir.optimization.linopy.objective_builder import ObjectiveBuilder
+from pyzefir.optimization.linopy.preprocessing.indices import IndexingSet
+from pyzefir.optimization.linopy.preprocessing.parameters.generator_type_parameters import (
+    GeneratorTypeParameters,
+)
+from pyzefir.optimization.linopy.preprocessing.parameters.storage_type_parameters import (
+    StorageTypeParameters,
+)
+from pyzefir.utils.functions import get_dict_vals
+
+_logger = logging.getLogger(__name__)
+
+
+class CapexObjectiveBuilder(ObjectiveBuilder):
+    def build_expression(self) -> LinearExpression:
+        _logger.info("Building capex objective...")
+        return self.global_capex() + self.local_capex()
+
+    def local_capex(self) -> LinearExpression:
+        generator_capex = self._local_capex(
+            tcap_plus=self.variables.tgen.tcap_plus,
+            unit_type_param=self.parameters.tgen,
+            aggr_map=self.indices.aggr_tgen_map,
+        )
+        storage_capex = self._local_capex(
+            tcap_plus=self.variables.tstor.tcap_plus,
+            unit_type_param=self.parameters.tstor,
+            aggr_map=self.indices.aggr_tstor_map,
+        )
+        _logger.info("Building local capex expression: Done")
+        return generator_capex + storage_capex
+
+    def global_capex(self) -> LinearExpression:
+        generator_capex = self._global_capex(
+            cap_plus=self.variables.gen.cap_plus,
+            unit_type_param=self.parameters.tgen,
+            unit_type_idx=self.parameters.gen.tgen,
+            non_lbs_unit_idxs=get_dict_vals(self.parameters.bus.generators).difference(
+                get_dict_vals(self.indices.aggr_gen_map)
+            ),
+        )
+        storage_capex = self._global_capex(
+            cap_plus=self.variables.stor.cap_plus,
+            unit_type_param=self.parameters.tstor,
+            unit_type_idx=self.parameters.stor.tstor,
+            non_lbs_unit_idxs=get_dict_vals(self.parameters.bus.storages).difference(
+                get_dict_vals(self.indices.aggr_stor_map)
+            ),
+        )
+        _logger.info("Building global capex expression: Done")
+        return generator_capex + storage_capex
+
+    def _global_capex(
+        self,
+        cap_plus: Variable,
+        unit_type_param: GeneratorTypeParameters | StorageTypeParameters,
+        unit_type_idx: dict,
+        non_lbs_unit_idxs: set,
+    ) -> LinearExpression | float:
+        """
+        Total investment cost for global (non-lbs) technologies for all years
+
+        Args:
+            cap_plus (Variable): capex increase labeled by unit index
+            unit_type_param (GeneratorTypeParameters | StorageTypeParameters): technology type index
+            unit_type_idx: dict[int, int]: technology index of a given unit index
+            non_lbs_unit_idxs: set[int]: set of non-lbs (global) units
+
+        Returns:
+            Linear expression of capex cost
+
+        """
+        disc_rate = self.expr.discount_rate(
+            self.parameters.scenario_parameters.discount_rate
+        )
+        y_idxs = self.indices.Y
+        unit_capex = 0.0
+        for u_idx in non_lbs_unit_idxs:
+            ut_idx = unit_type_idx[u_idx]
+            capex = unit_type_param.capex[ut_idx]
+            lt = unit_type_param.lt[ut_idx]
+
+            for s_idx in y_idxs.ord:
+                unit_capex += self.global_capex_per_unit_per_year(
+                    capex=capex,
+                    cap_plus=cap_plus,
+                    disc_rate=disc_rate,
+                    lt=lt,
+                    s_idx=s_idx,
+                    u_idx=u_idx,
+                    y_idxs=y_idxs,
+                )
+        return unit_capex
+
+    @staticmethod
+    def global_capex_per_unit_per_year(
+        capex: np.ndarray,
+        cap_plus: Variable,
+        disc_rate: np.ndarray,
+        lt: int,
+        s_idx: int,
+        u_idx: int,
+        y_idxs: IndexingSet,
+    ) -> LinearExpression | float:
+        """
+        Capex for a given year for global (non-lbs) technologies
+        Takes a single year index as a single argument s_idx, calculates the corresponding capex cost in this year
+        The function also requires the whole set of years, given by y_idxs
+
+
+        Args:
+            capex (ndarray): yearly capex cost parameter
+            cap_plus (Variable): capex increase labeled by unit index
+            disc_rate (ndarray): yearly discount rate
+            lt (int): life time of a given technology
+            s_idx (int): single year index, specifying the year for capex calculation
+            ut_idx (int): technology type index
+            aggr_idx (int): index of a given aggregate
+            y_idxs (IndexingSet): set of years
+
+        Returns:
+            Linear expression of a yearly investment cost
+        """
+        am_indicator = CapexObjectiveBuilder._amortization_matrix_indicator(
+            lt=lt, yy=y_idxs
+        )
+        res = 0.0
+        for y_idx in y_idxs.ord:
+            res += (
+                am_indicator[y_idx, s_idx]
+                * capex[y_idx]
+                * cap_plus.sel(index=(u_idx, y_idx))
+                * disc_rate[s_idx]
+                / lt
+            )
+        return res
+
+    def _local_capex(
+        self,
+        tcap_plus: Variable,
+        unit_type_param: GeneratorTypeParameters | StorageTypeParameters,
+        aggr_map: dict[..., set],
+    ) -> LinearExpression | float:
+        """
+        Total investment cost for local (lbs) technologies for all years
+
+        Args:
+            tcap_plus (Variable): capex increase labeled by unit type index and aggregate index
+            unit_type_param (GeneratorTypeParameters | StorageTypeParameters): technology type index
+            unit_type_idx: dict[int, int]: technology index of a given unit index
+            non_lbs_unit_idxs: set[int]: set of non-lbs (global) units
+
+        Returns:
+            Linear expression of capex cost
+
+        """
+        disc_rate = self.expr.discount_rate(
+            self.parameters.scenario_parameters.discount_rate
+        )
+        y_idxs = self.indices.Y
+        unit_type_capex = 0.0
+        for aggr_idx, ut_idxs in aggr_map.items():
+            for ut_idx in ut_idxs:
+                capex = unit_type_param.capex[ut_idx]
+                lt = unit_type_param.lt[ut_idx]
+                for s_idx in y_idxs.ord:
+                    unit_type_capex += self.local_capex_per_unit_per_year(
+                        capex=capex,
+                        tcap_plus=tcap_plus,
+                        disc_rate=disc_rate,
+                        lt=lt,
+                        s_idx=s_idx,
+                        ut_idx=ut_idx,
+                        aggr_idx=aggr_idx,
+                        y_idxs=y_idxs,
+                    )
+        return unit_type_capex
+
+    @staticmethod
+    def local_capex_per_unit_per_year(
+        capex: np.ndarray,
+        tcap_plus: Variable,
+        disc_rate: np.ndarray,
+        lt: int,
+        s_idx: int,
+        ut_idx: int,
+        aggr_idx: int,
+        y_idxs: IndexingSet,
+    ) -> LinearExpression | float:
+        """
+        Capex for a given year for local (lbs) technologies
+        Takes a single year index as a single argument s_idx, calculates the corresponding capex cost in this year
+        The function also requires the whole set of years, given by y_idxs
+
+        Args:
+            capex (ndarray): yearly capex cost parameter
+            tcap_plus (Variable): capex increase labeled by unit type index and aggregate index
+            disc_rate (ndarray): yearly discount rate
+            lt (int): life time of a given technology
+            s_idx (int): single year index, specifying the year for capex calculation
+            ut_idx (int): technology type index
+            aggr_idx (int): index of a given aggregate
+            y_idxs (IndexingSet): set of years
+
+        Returns:
+            Linear expression of a yearly investment cost
+        """
+        am_indicator = CapexObjectiveBuilder._amortization_matrix_indicator(
+            lt=lt, yy=y_idxs
+        )
+        res = 0.0
+        for y_idx in y_idxs.ord:
+            res += (
+                am_indicator[y_idx, s_idx]
+                * tcap_plus.sel(index=(aggr_idx, ut_idx, y_idx))
+                * capex[y_idx]
+                * disc_rate[s_idx]
+                / lt
+            )
+        return res
+
+    @staticmethod
+    def _amortization_matrix_indicator(
+        lt: int,
+        yy: IndexingSet,
+    ) -> np.ndarray:
+        """
+        Indicator matrix for y-index range in capex expression specifying the summation in capex expression
+        The resulting matrix is composed of 0 and 1; zero means there is no capex contribution from the corresponding
+        element
+
+        Args:
+            lt (int): unit lifetime
+            yy (IndexingSet): year indices
+
+        Returns:
+            np.ndarray
+        """
+
+        return np.array(
+            [
+                ((yy.ord >= y) & (yy.ord <= min(y + lt - 1, len(yy)))).astype(int)
+                for y in yy.ord
+            ]
+        )
```

### Comparing `pyzefir-0.4.1/pyzefir/optimization/linopy/objective_builder/dsr_penalty_objective_builder.py` & `pyzefir-0.4.22/pyzefir/parser/utils.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,32 +1,24 @@
-# PyZefir
-# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-from linopy import LinearExpression
-
-from pyzefir.optimization.linopy.objective_builder import ObjectiveBuilder
-
-
-class DsrPenaltyObjectiveBuilder(ObjectiveBuilder):
-    def build_expression(self) -> LinearExpression | float:
-        if self.parameters.bus.dsr_type:
-            shift_minus = self.variables.bus.shift_minus
-            penalization = self.parameters.dsr.penalization
-            bus_parameters = self.parameters.bus
-            result: LinearExpression = 0.0
-            for bus_idx, dsr_idx in bus_parameters.dsr_type.items():
-                result += shift_minus.isel(bus=bus_idx).sum() * penalization[dsr_idx]
-            return result.sum()
-        return 0.0
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+from typing import Final
+
+
+def sanitize_dataset_name(dataset_name: str) -> str:
+    return dataset_name.replace("-", "").replace(" ", "_").replace("__", "_")
+
+
+TRUE_VALUES: Final[list[str]] = ["YES"]
```

### Comparing `pyzefir-0.4.1/pyzefir/optimization/linopy/objective_builder/emission_fee_objective_builder.py` & `pyzefir-0.4.22/pyzefir/optimization/linopy/objective_builder/emission_fee_objective_builder.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,61 +1,65 @@
-# PyZefir
-# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-from linopy import LinearExpression
-
-from pyzefir.optimization.linopy.expression_handler import ExpressionHandler
-from pyzefir.optimization.linopy.objective_builder import ObjectiveBuilder
-
-
-class EmissionFeeObjectiveBuilder(ObjectiveBuilder):
-    def build_expression(self) -> LinearExpression | float:
-        result = 0.0
-        if not (
-            not self.parameters.gen.fuel
-            or all(not fuel for fuel in self.parameters.gen.fuel.values())
-            or all(not em_fee for em_fee in self.parameters.gen.emission_fee.values())
-        ):
-            eh = ExpressionHandler(self.indices, self.variables, self.parameters)
-            for gen_idx in self.indices.GEN.ord:
-                for year_idx in self.indices.Y.ord:
-                    result += self.yearly_generator_emission_cost(
-                        year_idx=year_idx, gen_idx=gen_idx, eh=eh
-                    )
-
-        return result
-
-    def yearly_generator_emission_cost(
-        self, year_idx: int, gen_idx: int, eh: ExpressionHandler
-    ) -> LinearExpression | float:
-        fuel_idx = self.parameters.gen.fuel[gen_idx]
-        if fuel_idx is None:
-            return 0.0
-        fc = eh.fuel_consumption(
-            fuel_idx, gen_idx, self.parameters.scenario_parameters.hourly_scale
-        ).isel(year=year_idx)
-        total_emission = 0.0
-        for emission_fee_idx in self.parameters.gen.emission_fee[gen_idx]:
-            emission_type = self.parameters.emf.emission_type[emission_fee_idx]
-            generator_emission = (
-                fc
-                * self.parameters.fuel.u_emission[fuel_idx][emission_type]
-                * (1 - self.parameters.gen.em_red[gen_idx][emission_type])
-            )
-            total_emission += (
-                generator_emission
-                * self.parameters.emf.price[emission_fee_idx][year_idx]
-            )
-        return total_emission
+# PyZefir
+# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+import logging
+
+from linopy import LinearExpression
+
+from pyzefir.optimization.linopy.expression_handler import ExpressionHandler
+from pyzefir.optimization.linopy.objective_builder import ObjectiveBuilder
+
+_logger = logging.getLogger(__name__)
+
+
+class EmissionFeeObjectiveBuilder(ObjectiveBuilder):
+    def build_expression(self) -> LinearExpression | float:
+        _logger.info("Building emission fee objective...")
+        result = 0.0
+        if not (
+            not self.parameters.gen.fuel
+            or all(not fuel for fuel in self.parameters.gen.fuel.values())
+            or all(not em_fee for em_fee in self.parameters.gen.emission_fee.values())
+        ):
+            eh = ExpressionHandler(self.indices, self.variables, self.parameters)
+            for gen_idx in self.indices.GEN.ord:
+                for year_idx in self.indices.Y.ord:
+                    result += self.yearly_generator_emission_cost(
+                        year_idx=year_idx, gen_idx=gen_idx, eh=eh
+                    )
+        _logger.info("Emission fee objective: Done")
+        return result
+
+    def yearly_generator_emission_cost(
+        self, year_idx: int, gen_idx: int, eh: ExpressionHandler
+    ) -> LinearExpression | float:
+        fuel_idx = self.parameters.gen.fuel[gen_idx]
+        if fuel_idx is None:
+            return 0.0
+        fc = eh.fuel_consumption(
+            fuel_idx, gen_idx, self.parameters.scenario_parameters.hourly_scale
+        ).isel(year=year_idx)
+        total_emission = 0.0
+        for emission_fee_idx in self.parameters.gen.emission_fee[gen_idx]:
+            emission_type = self.parameters.emf.emission_type[emission_fee_idx]
+            generator_emission = (
+                fc
+                * self.parameters.fuel.u_emission[fuel_idx][emission_type]
+                * (1 - self.parameters.gen.em_red[gen_idx][emission_type])
+            )
+            total_emission += (
+                generator_emission
+                * self.parameters.emf.price[emission_fee_idx][year_idx]
+            )
+        return total_emission
```

### Comparing `pyzefir-0.4.1/pyzefir/optimization/linopy/objective_builder/opex_objective_builder.py` & `pyzefir-0.4.22/pyzefir/optimization/linopy/objective_builder/opex_objective_builder.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,51 +1,58 @@
-# PyZefir
-# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-import xarray as xr
-from linopy import LinearExpression
-
-from pyzefir.optimization.linopy.objective_builder import ObjectiveBuilder
-
-
-class OpexObjectiveBuilder(ObjectiveBuilder):
-    def build_expression(self) -> LinearExpression:
-        return self.generator_opex() + self.storage_opex()
-
-    def generator_opex(self) -> LinearExpression:
-        opex = xr.DataArray(
-            [
-                self.parameters.tgen.opex[self.parameters.gen.tgen[gen_idx]]
-                for gen_idx in self.indices.GEN.ord
-            ],
-            dims=["gen", "year"],
-            coords=[self.indices.GEN.ii, self.indices.Y.ii],
-            name="opex",
-        )
-        return (opex * self.variables.gen.cap).sum()
-
-    def storage_opex(self) -> LinearExpression | float:
-        if self.indices.STOR.ord.size:
-            opex = xr.DataArray(
-                [
-                    self.parameters.tstor.opex[self.parameters.stor.tstor[stor_idx]]
-                    for stor_idx in self.indices.STOR.ord
-                ],
-                dims=["stor", "year"],
-                coords=[self.indices.STOR.ii, self.indices.Y.ii],
-                name="opex",
-            )
-            return (opex * self.variables.stor.cap).sum()
-        return 0
+# PyZefir
+# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+import logging
+
+import xarray as xr
+from linopy import LinearExpression
+
+from pyzefir.optimization.linopy.objective_builder import ObjectiveBuilder
+
+_logger = logging.getLogger(__name__)
+
+
+class OpexObjectiveBuilder(ObjectiveBuilder):
+    def build_expression(self) -> LinearExpression:
+        _logger.info("Building opex objective...")
+        return self.generator_opex() + self.storage_opex()
+
+    def generator_opex(self) -> LinearExpression:
+        opex = xr.DataArray(
+            [
+                self.parameters.tgen.opex[self.parameters.gen.tgen[gen_idx]]
+                for gen_idx in self.indices.GEN.ord
+            ],
+            dims=["gen", "year"],
+            coords=[self.indices.GEN.ii, self.indices.Y.ii],
+            name="opex",
+        )
+        _logger.info("Building generator opex expression: Done")
+        return (opex * self.variables.gen.cap).sum()
+
+    def storage_opex(self) -> LinearExpression | float:
+        if self.indices.STOR.ord.size:
+            opex = xr.DataArray(
+                [
+                    self.parameters.tstor.opex[self.parameters.stor.tstor[stor_idx]]
+                    for stor_idx in self.indices.STOR.ord
+                ],
+                dims=["stor", "year"],
+                coords=[self.indices.STOR.ii, self.indices.Y.ii],
+                name="opex",
+            )
+            _logger.info("Building generator opex expression: Done")
+            return (opex * self.variables.stor.cap).sum()
+        _logger.warning("Size of storage not set, returning default expression.")
+        return 0
```

### Comparing `pyzefir-0.4.1/pyzefir/optimization/linopy/objective_builder/var_cost_objective_builder.py` & `pyzefir-0.4.22/pyzefir/optimization/linopy/objective_builder/generation_compensation_objective_builder.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,41 +1,57 @@
-# PyZefir
-# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-import xarray as xr
-from linopy import LinearExpression
-
-from pyzefir.optimization.linopy.objective_builder import ObjectiveBuilder
-
-
-class VarCostObjectiveBuilder(ObjectiveBuilder):
-    def build_expression(self) -> LinearExpression | float:
-        expr = 0.0
-        for gen_idx in self.indices.GEN.ord:
-            if self.parameters.gen.fuel[gen_idx] is not None:
-                expr += self.generator_var_cost(gen_idx)
-
-        return expr
-
-    def generator_var_cost(self, gen_idx: int) -> LinearExpression | float:
-        fuel_idx = self.parameters.gen.fuel[gen_idx]
-        hourly_scale = self.parameters.scenario_parameters.hourly_scale
-        cost = self.parameters.fuel.unit_cost[fuel_idx]
-        fuel_consumption = self.expr.fuel_consumption(fuel_idx, gen_idx, hourly_scale)
-
-        return (
-            fuel_consumption
-            * xr.DataArray(cost, dims=["year"], coords=[self.indices.Y.ii], name="cost")
-        ).sum()
+# PyZefir
+# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+import logging
+
+import xarray as xr
+from linopy import LinearExpression
+
+from pyzefir.optimization.linopy.objective_builder import ObjectiveBuilder
+
+_logger = logging.getLogger(__name__)
+
+
+class GenerationCompensationObjectiveBuilder(ObjectiveBuilder):
+    def build_expression(self) -> LinearExpression | float:
+        _logger.info("Building generation compensation objective...")
+        gen_to_type_dict = {
+            k: v
+            for k, v in self.parameters.gen.tgen.items()
+            if v in self.parameters.tgen.generation_compensation.keys()
+        }
+        expr = sum(
+            [
+                self.generator_compensation(gen_idx, tgen_idx)
+                for gen_idx, tgen_idx in gen_to_type_dict.items()
+            ]
+        )
+        _logger.info("Variable generation compensation objective: Done")
+        return expr
+
+    def generator_compensation(
+        self, gen_idx: int, tgen_idx: int
+    ) -> LinearExpression | float:
+        hourly_scale = self.parameters.scenario_parameters.hourly_scale
+        compensation = self.parameters.tgen.generation_compensation[tgen_idx]
+        generation = self.variables.gen.gen.isel(gen=gen_idx).sum(["hour"])
+        return (
+            -generation
+            * xr.DataArray(
+                compensation,
+                dims=["year"],
+                coords=[self.indices.Y.ii],
+                name="compensation",
+            )
+        ).sum() * hourly_scale
```

### Comparing `pyzefir-0.4.1/pyzefir/optimization/linopy/preprocessing/__init__.py` & `pyzefir-0.4.22/pyzefir/model/network_elements/energy_sources/__init__.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,15 +1,15 @@
-# PyZefir
-# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
```

### Comparing `pyzefir-0.4.1/pyzefir/optimization/linopy/preprocessing/opt_parameters.py` & `pyzefir-0.4.22/pyzefir/optimization/linopy/preprocessing/opt_parameters.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,148 +1,150 @@
-# PyZefir
-# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-from pyzefir.model.network import Network
-from pyzefir.optimization.linopy.preprocessing.indices import Indices
-from pyzefir.optimization.linopy.preprocessing.parameters.aggregated_consumer_parameters import (
-    AggregatedConsumerParameters,
-)
-from pyzefir.optimization.linopy.preprocessing.parameters.bus_parameters import (
-    BusParameters,
-)
-from pyzefir.optimization.linopy.preprocessing.parameters.capacity_factor_parameters import (
-    CapacityFactorParameters,
-)
-from pyzefir.optimization.linopy.preprocessing.parameters.demand_chunks_parameters import (
-    DemandChunkParameters,
-)
-from pyzefir.optimization.linopy.preprocessing.parameters.dsr_parameters import (
-    DsrParameters,
-)
-from pyzefir.optimization.linopy.preprocessing.parameters.emission_fee_parameters import (
-    EmissionFeeParameters,
-)
-from pyzefir.optimization.linopy.preprocessing.parameters.fuel_parameters import (
-    FuelParameters,
-)
-from pyzefir.optimization.linopy.preprocessing.parameters.generator_parameters import (
-    GeneratorParameters,
-)
-from pyzefir.optimization.linopy.preprocessing.parameters.generator_type_parameters import (
-    GeneratorTypeParameters,
-)
-from pyzefir.optimization.linopy.preprocessing.parameters.line_parameters import (
-    LineParameters,
-)
-from pyzefir.optimization.linopy.preprocessing.parameters.local_balancing_stack_parameters import (
-    LBSParameters,
-)
-from pyzefir.optimization.linopy.preprocessing.parameters.scenario_parameters import (
-    ScenarioParameters,
-)
-from pyzefir.optimization.linopy.preprocessing.parameters.storage_parameters import (
-    StorageParameters,
-)
-from pyzefir.optimization.linopy.preprocessing.parameters.storage_type_parameters import (
-    StorageTypeParameters,
-)
-from pyzefir.optimization.linopy.preprocessing.parameters.transmission_fee_parameters import (
-    TransmissionFeeParameters,
-)
-from pyzefir.optimization.opt_config import OptConfig
-from pyzefir.utils.functions import tag_str_to_idx
-
-
-class OptimizationParameters:
-    """
-    All optimization parameters.
-    """
-
-    def __init__(
-        self, network: Network, indices: Indices, opt_config: OptConfig
-    ) -> None:
-        self.fuel: FuelParameters = FuelParameters(
-            network.fuels, indices, scale=opt_config.money_scale
-        )
-        """ fuels parameters """
-        self.cf: CapacityFactorParameters = CapacityFactorParameters(
-            network.capacity_factors, indices
-        )
-        """ capacity factors parameters """
-        self.gen: GeneratorParameters = GeneratorParameters(
-            network.generators,
-            network.generator_types,
-            indices,
-        )
-        """ generators parameters """
-        self.stor: StorageParameters = StorageParameters(
-            network.storages, network.storage_types, indices
-        )
-        """ storages parameters """
-        self.tgen: GeneratorTypeParameters = GeneratorTypeParameters(
-            network.generator_types,
-            indices,
-            scale=opt_config.money_scale,
-        )
-        """ generator types parameters """
-        self.tstor: StorageTypeParameters = StorageTypeParameters(
-            network.storage_types, indices, scale=opt_config.money_scale
-        )
-        """ storage types parameters """
-        self.tf: TransmissionFeeParameters = TransmissionFeeParameters(
-            network.transmission_fees, indices
-        )
-        """ transmission fees parameters """
-        self.line: LineParameters = LineParameters(network.lines, indices)
-        """ lines parameters """
-        self.bus: BusParameters = BusParameters(
-            network.buses, network.local_balancing_stacks, indices
-        )
-        """ buses parameters """
-        self.aggr: AggregatedConsumerParameters = AggregatedConsumerParameters(
-            network.aggregated_consumers, network.demand_profiles, indices
-        )
-        """ aggregated consumers parameters """
-        self.lbs: LBSParameters = LBSParameters(
-            network.local_balancing_stacks, network.aggregated_consumers, indices
-        )
-        """ local balancing stacks parameters """
-        self.scenario_parameters: ScenarioParameters = ScenarioParameters(
-            indices=indices,
-            opt_config=opt_config,
-            rel_em_limit={
-                key: series.to_numpy()
-                for key, series in network.constants.relative_emission_limits.items()
-            },
-            base_total_emission=network.constants.base_total_emission,
-            min_generation_fraction=tag_str_to_idx(
-                network.constants.min_generation_fraction, indices.TAGS.inverse
-            ),
-            max_generation_fraction=tag_str_to_idx(
-                network.constants.max_generation_fraction, indices.TAGS.inverse
-            ),
-            power_reserves=network.constants.power_reserves,
-            numeric_tolerance=network.constants.numeric_tolerance,
-        )
-        self.emf: EmissionFeeParameters = EmissionFeeParameters(
-            network.emission_fees, indices, scale=opt_config.money_scale
-        )
-        """ emission fees parameters """
-        self.demand_chunks_parameters: DemandChunkParameters = DemandChunkParameters(
-            network.demand_chunks, indices
-        )
-        """ demand chunks parameters """
-        self.dsr: DsrParameters = DsrParameters(network.dsr, indices)
-        """DSR parameters"""
+# PyZefir
+# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+from pyzefir.model.network import Network
+from pyzefir.optimization.linopy.preprocessing.indices import Indices
+from pyzefir.optimization.linopy.preprocessing.parameters.aggregated_consumer_parameters import (
+    AggregatedConsumerParameters,
+)
+from pyzefir.optimization.linopy.preprocessing.parameters.bus_parameters import (
+    BusParameters,
+)
+from pyzefir.optimization.linopy.preprocessing.parameters.capacity_factor_parameters import (
+    CapacityFactorParameters,
+)
+from pyzefir.optimization.linopy.preprocessing.parameters.demand_chunks_parameters import (
+    DemandChunkParameters,
+)
+from pyzefir.optimization.linopy.preprocessing.parameters.dsr_parameters import (
+    DsrParameters,
+)
+from pyzefir.optimization.linopy.preprocessing.parameters.emission_fee_parameters import (
+    EmissionFeeParameters,
+)
+from pyzefir.optimization.linopy.preprocessing.parameters.fuel_parameters import (
+    FuelParameters,
+)
+from pyzefir.optimization.linopy.preprocessing.parameters.generator_parameters import (
+    GeneratorParameters,
+)
+from pyzefir.optimization.linopy.preprocessing.parameters.generator_type_parameters import (
+    GeneratorTypeParameters,
+)
+from pyzefir.optimization.linopy.preprocessing.parameters.line_parameters import (
+    LineParameters,
+)
+from pyzefir.optimization.linopy.preprocessing.parameters.local_balancing_stack_parameters import (
+    LBSParameters,
+)
+from pyzefir.optimization.linopy.preprocessing.parameters.scenario_parameters import (
+    ScenarioParameters,
+)
+from pyzefir.optimization.linopy.preprocessing.parameters.storage_parameters import (
+    StorageParameters,
+)
+from pyzefir.optimization.linopy.preprocessing.parameters.storage_type_parameters import (
+    StorageTypeParameters,
+)
+from pyzefir.optimization.linopy.preprocessing.parameters.transmission_fee_parameters import (
+    TransmissionFeeParameters,
+)
+from pyzefir.optimization.opt_config import OptConfig
+from pyzefir.utils.functions import tag_str_to_idx
+
+
+class OptimizationParameters:
+    """
+    All optimization parameters.
+    """
+
+    def __init__(
+        self, network: Network, indices: Indices, opt_config: OptConfig
+    ) -> None:
+        self.fuel: FuelParameters = FuelParameters(
+            network.fuels, indices, scale=opt_config.money_scale
+        )
+        """ fuels parameters """
+        self.cf: CapacityFactorParameters = CapacityFactorParameters(
+            network.capacity_factors, indices
+        )
+        """ capacity factors parameters """
+        self.gen: GeneratorParameters = GeneratorParameters(
+            network.generators,
+            network.generator_types,
+            indices,
+        )
+        """ generators parameters """
+        self.stor: StorageParameters = StorageParameters(
+            network.storages, network.storage_types, indices
+        )
+        """ storages parameters """
+        self.tgen: GeneratorTypeParameters = GeneratorTypeParameters(
+            network.generator_types,
+            indices,
+            scale=opt_config.money_scale,
+        )
+        """ generator types parameters """
+        self.tstor: StorageTypeParameters = StorageTypeParameters(
+            network.storage_types, indices, scale=opt_config.money_scale
+        )
+        """ storage types parameters """
+        self.tf: TransmissionFeeParameters = TransmissionFeeParameters(
+            network.transmission_fees, indices, scale=opt_config.money_scale
+        )
+        """ transmission fees parameters """
+        self.line: LineParameters = LineParameters(network.lines, indices)
+        """ lines parameters """
+        self.bus: BusParameters = BusParameters(
+            network.buses, network.local_balancing_stacks, indices
+        )
+        """ buses parameters """
+        self.aggr: AggregatedConsumerParameters = AggregatedConsumerParameters(
+            network.aggregated_consumers, network.demand_profiles, indices
+        )
+        """ aggregated consumers parameters """
+        self.lbs: LBSParameters = LBSParameters(
+            network.local_balancing_stacks, network.aggregated_consumers, indices
+        )
+        """ local balancing stacks parameters """
+        self.scenario_parameters: ScenarioParameters = ScenarioParameters(
+            indices=indices,
+            opt_config=opt_config,
+            rel_em_limit={
+                key: series.to_numpy()
+                for key, series in network.constants.relative_emission_limits.items()
+            },
+            base_total_emission=network.constants.base_total_emission,
+            min_generation_fraction=tag_str_to_idx(
+                network.constants.min_generation_fraction, indices.TAGS.inverse
+            ),
+            max_generation_fraction=tag_str_to_idx(
+                network.constants.max_generation_fraction, indices.TAGS.inverse
+            ),
+            power_reserves=network.constants.power_reserves,
+            ens_penalty_cost=network.constants.ens_penalty_cost,
+        )
+        self.emf: EmissionFeeParameters = EmissionFeeParameters(
+            network.emission_fees, indices, scale=opt_config.money_scale
+        )
+        """ emission fees parameters """
+        self.demand_chunks_parameters: DemandChunkParameters = DemandChunkParameters(
+            network.demand_chunks, indices
+        )
+        """ demand chunks parameters """
+        self.dsr: DsrParameters = DsrParameters(
+            network.dsr, indices, scale=opt_config.money_scale
+        )
+        """DSR parameters"""
```

### Comparing `pyzefir-0.4.1/pyzefir/optimization/linopy/preprocessing/opt_variables.py` & `pyzefir-0.4.22/pyzefir/optimization/linopy/preprocessing/opt_variables.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,72 +1,68 @@
-# PyZefir
-# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-from linopy import Model
-
-from pyzefir.optimization.linopy.preprocessing.indices import Indices
-from pyzefir.optimization.linopy.preprocessing.opt_parameters import (
-    OptimizationParameters,
-)
-from pyzefir.optimization.linopy.preprocessing.variables.bus_variables import (
-    BusVariables,
-)
-from pyzefir.optimization.linopy.preprocessing.variables.fraction_variables import (
-    FractionVariables,
-)
-from pyzefir.optimization.linopy.preprocessing.variables.generator_type_variables import (
-    GeneratorTypeVariables,
-)
-from pyzefir.optimization.linopy.preprocessing.variables.generator_variables import (
-    GeneratorVariables,
-)
-from pyzefir.optimization.linopy.preprocessing.variables.line_variables import (
-    LineVariables,
-)
-from pyzefir.optimization.linopy.preprocessing.variables.storage_type_variables import (
-    StorageTypeVariables,
-)
-from pyzefir.optimization.linopy.preprocessing.variables.storage_variables import (
-    StorageVariables,
-)
-from pyzefir.optimization.opt_config import OptConfig
-
-
-class OptimizationVariables:
-    """
-    All optimization variables.
-    """
-
-    def __init__(
-        self,
-        model: Model,
-        indices: Indices,
-        opt_config: OptConfig,
-        parameters: OptimizationParameters | None = None,
-    ) -> None:
-        self.bus = BusVariables(model, indices, opt_config, parameters)
-        """ bus variables """
-        self.frac = FractionVariables(model, indices)
-        """ fraction variables """
-        self.tgen = GeneratorTypeVariables(model, indices)
-        """ generator type variables """
-        self.gen = GeneratorVariables(model, indices)
-        """ generators variables """
-        self.stor = StorageVariables(model, indices)
-        """ storage variables """
-        self.tstor = StorageTypeVariables(model, indices)
-        """ storage type variables """
-        self.line = LineVariables(model, indices)
-        """ line variables """
+# PyZefir
+# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+from linopy import Model
+
+from pyzefir.optimization.linopy.preprocessing.indices import Indices
+from pyzefir.optimization.linopy.preprocessing.variables.bus_variables import (
+    BusVariables,
+)
+from pyzefir.optimization.linopy.preprocessing.variables.fraction_variables import (
+    FractionVariables,
+)
+from pyzefir.optimization.linopy.preprocessing.variables.generator_type_variables import (
+    GeneratorTypeVariables,
+)
+from pyzefir.optimization.linopy.preprocessing.variables.generator_variables import (
+    GeneratorVariables,
+)
+from pyzefir.optimization.linopy.preprocessing.variables.line_variables import (
+    LineVariables,
+)
+from pyzefir.optimization.linopy.preprocessing.variables.storage_type_variables import (
+    StorageTypeVariables,
+)
+from pyzefir.optimization.linopy.preprocessing.variables.storage_variables import (
+    StorageVariables,
+)
+from pyzefir.optimization.opt_config import OptConfig
+
+
+class OptimizationVariables:
+    """
+    All optimization variables.
+    """
+
+    def __init__(
+        self,
+        model: Model,
+        indices: Indices,
+        opt_config: OptConfig,
+    ) -> None:
+        self.bus = BusVariables(model, indices, opt_config)
+        """ bus variables """
+        self.frac = FractionVariables(model, indices)
+        """ fraction variables """
+        self.tgen = GeneratorTypeVariables(model, indices)
+        """ generator type variables """
+        self.gen = GeneratorVariables(model, indices)
+        """ generators variables """
+        self.stor = StorageVariables(model, indices)
+        """ storage variables """
+        self.tstor = StorageTypeVariables(model, indices)
+        """ storage type variables """
+        self.line = LineVariables(model, indices)
+        """ line variables """
```

### Comparing `pyzefir-0.4.1/pyzefir/optimization/linopy/preprocessing/parameters/__init__.py` & `pyzefir-0.4.22/pyzefir/optimization/linopy/preprocessing/parameters/__init__.py`

 * *Ordering differences only*

 * *Files 18% similar despite different names*

```diff
@@ -1,152 +1,152 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-from abc import ABC
-from typing import Any, Iterable, TypeVar
-
-import numpy as np
-from numpy import ndarray
-from pandas import Series
-
-from pyzefir.model.network import NetworkElementsDict
-from pyzefir.model.network_element import NetworkElement
-from pyzefir.model.network_elements import EnergySource, EnergySourceType
-from pyzefir.optimization.linopy.preprocessing.indices import IndexingSet, Indices
-from pyzefir.utils.functions import is_none_general
-
-T = TypeVar("T")
-
-
-class ModelParameters(ABC):
-    @staticmethod
-    def fetch_energy_source_type_prop(
-        elements: NetworkElementsDict[EnergySource],
-        types: NetworkElementsDict[EnergySourceType],
-        II: IndexingSet,
-        prop: str,
-        sample: ndarray | None = None,
-    ) -> dict[int, Any]:
-        return {
-            ii: ModelParameters.sample_series(
-                getattr(types[elements[name].energy_source_type], prop), sample
-            )
-            for ii, name in II.mapping.items()
-        }
-
-    @staticmethod
-    def fetch_element_prop(
-        d: NetworkElementsDict[NetworkElement],
-        II: IndexingSet,
-        prop: str,
-        sample: ndarray | None = None,
-    ) -> dict[int, Any]:
-        return {
-            ii: ModelParameters.sample_series(getattr(d[name], prop), sample)
-            for ii, name in II.mapping.items()
-            if not is_none_general(getattr(d[name], prop))
-        }
-
-    @staticmethod
-    def sample_series(data: Series | Any, sample: Iterable | None) -> ndarray | Any:
-        if isinstance(data, Series):
-            return data.values[sample] if sample is not None else data.values
-        else:
-            return data
-
-    @staticmethod
-    def get_index_from_prop(
-        elements: NetworkElementsDict[NetworkElement],
-        element_idx: IndexingSet,
-        idx_to_get: IndexingSet,
-        prop: str,
-    ) -> dict[int, int]:
-        return {
-            ii: idx_to_get.inverse[getattr(elements[name], prop)]
-            for ii, name in element_idx.mapping.items()
-        }
-
-    @staticmethod
-    def get_index_from_prop_if_not_none(
-        elements: NetworkElementsDict[NetworkElement],
-        element_idx: IndexingSet,
-        idx_to_get: IndexingSet,
-        prop: str,
-    ) -> dict[int, int]:
-        return {
-            ii: idx_to_get.inverse[getattr(elements[name], prop)]
-            for ii, name in element_idx.mapping.items()
-            if getattr(elements[name], prop) is not None
-        }
-
-    @staticmethod
-    def get_index_from_type_prop(
-        elements: NetworkElementsDict[EnergySource],
-        types: NetworkElementsDict[EnergySourceType],
-        element_idx: IndexingSet,
-        idx: IndexingSet,
-        prop_name: str,
-    ) -> dict[int, int]:
-        result = dict()
-        for element_idx, element_name in element_idx.mapping.items():
-            element = elements[element_name]
-            element_type = types[element.energy_source_type]
-            prop = getattr(element_type, prop_name)
-            result[element_idx] = idx.inverse[prop] if prop is not None else None
-
-        return result
-
-    @staticmethod
-    def scale(values: dict[T, ndarray], scale: float) -> dict[T, ndarray]:
-        return {k: v / scale for k, v in values.items()}
-
-    @staticmethod
-    def get_prop_from_elements_if_not_none(
-        elements: NetworkElementsDict[NetworkElement],
-        element_idx: IndexingSet,
-        prop: str,
-    ) -> dict[int, Any]:
-        return {
-            ii: getattr(elements[name], prop)
-            for ii, name in element_idx.mapping.items()
-            if getattr(elements[name], prop) is not None
-        }
-
-    @staticmethod
-    def get_set_prop_from_element(
-        elements: NetworkElementsDict[NetworkElement],
-        prop: str,
-        element_idx: IndexingSet,
-        prop_idx: IndexingSet,
-    ) -> dict[int, set[int]]:
-        return {
-            ii: {prop_idx.inverse[el_name] for el_name in getattr(elements[name], prop)}
-            for ii, name in element_idx.mapping.items()
-        }
-
-    @staticmethod
-    def get_balancing_periods(
-        dsr: NetworkElementsDict[NetworkElement], indices: Indices
-    ) -> dict[int, list[range]]:
-        hours = indices.H.ord
-        res = dict()
-        for dsr_name, dsr_content in dsr.items():
-            markers = np.asarray(hours)[:: dsr_content.balancing_period_len]
-            if hours[-1] not in markers:
-                markers = np.append(markers, hours[-1])
-            res[indices.DSR.inverse[dsr_name]] = [
-                range(markers[idx], markers[idx + 1]) for idx in range(len(markers) - 1)
-            ]
-        return res
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+from abc import ABC
+from typing import Any, Iterable, TypeVar
+
+import numpy as np
+from numpy import ndarray
+from pandas import Series
+
+from pyzefir.model.network import NetworkElementsDict
+from pyzefir.model.network_element import NetworkElement
+from pyzefir.model.network_elements import EnergySource, EnergySourceType
+from pyzefir.optimization.linopy.preprocessing.indices import IndexingSet, Indices
+from pyzefir.utils.functions import is_none_general
+
+T = TypeVar("T")
+
+
+class ModelParameters(ABC):
+    @staticmethod
+    def fetch_energy_source_type_prop(
+        elements: NetworkElementsDict[EnergySource],
+        types: NetworkElementsDict[EnergySourceType],
+        II: IndexingSet,
+        prop: str,
+        sample: ndarray | None = None,
+    ) -> dict[int, Any]:
+        return {
+            ii: ModelParameters.sample_series(
+                getattr(types[elements[name].energy_source_type], prop), sample
+            )
+            for ii, name in II.mapping.items()
+        }
+
+    @staticmethod
+    def fetch_element_prop(
+        d: NetworkElementsDict[NetworkElement],
+        II: IndexingSet,
+        prop: str,
+        sample: ndarray | None = None,
+    ) -> dict[int, Any]:
+        return {
+            ii: ModelParameters.sample_series(getattr(d[name], prop), sample)
+            for ii, name in II.mapping.items()
+            if not is_none_general(getattr(d[name], prop))
+        }
+
+    @staticmethod
+    def sample_series(data: Series | Any, sample: Iterable | None) -> ndarray | Any:
+        if isinstance(data, Series):
+            return data.values[sample] if sample is not None else data.values
+        else:
+            return data
+
+    @staticmethod
+    def get_index_from_prop(
+        elements: NetworkElementsDict[NetworkElement],
+        element_idx: IndexingSet,
+        idx_to_get: IndexingSet,
+        prop: str,
+    ) -> dict[int, int]:
+        return {
+            ii: idx_to_get.inverse[getattr(elements[name], prop)]
+            for ii, name in element_idx.mapping.items()
+        }
+
+    @staticmethod
+    def get_index_from_prop_if_not_none(
+        elements: NetworkElementsDict[NetworkElement],
+        element_idx: IndexingSet,
+        idx_to_get: IndexingSet,
+        prop: str,
+    ) -> dict[int, int]:
+        return {
+            ii: idx_to_get.inverse[getattr(elements[name], prop)]
+            for ii, name in element_idx.mapping.items()
+            if getattr(elements[name], prop) is not None
+        }
+
+    @staticmethod
+    def get_index_from_type_prop(
+        elements: NetworkElementsDict[EnergySource],
+        types: NetworkElementsDict[EnergySourceType],
+        element_idx: IndexingSet,
+        idx: IndexingSet,
+        prop_name: str,
+    ) -> dict[int, int]:
+        result = dict()
+        for element_idx, element_name in element_idx.mapping.items():
+            element = elements[element_name]
+            element_type = types[element.energy_source_type]
+            prop = getattr(element_type, prop_name)
+            result[element_idx] = idx.inverse[prop] if prop is not None else None
+
+        return result
+
+    @staticmethod
+    def scale(values: dict[T, ndarray], scale: float) -> dict[T, ndarray]:
+        return {k: v / scale for k, v in values.items()}
+
+    @staticmethod
+    def get_prop_from_elements_if_not_none(
+        elements: NetworkElementsDict[NetworkElement],
+        element_idx: IndexingSet,
+        prop: str,
+    ) -> dict[int, Any]:
+        return {
+            ii: getattr(elements[name], prop)
+            for ii, name in element_idx.mapping.items()
+            if getattr(elements[name], prop) is not None
+        }
+
+    @staticmethod
+    def get_set_prop_from_element(
+        elements: NetworkElementsDict[NetworkElement],
+        prop: str,
+        element_idx: IndexingSet,
+        prop_idx: IndexingSet,
+    ) -> dict[int, set[int]]:
+        return {
+            ii: {prop_idx.inverse[el_name] for el_name in getattr(elements[name], prop)}
+            for ii, name in element_idx.mapping.items()
+        }
+
+    @staticmethod
+    def get_balancing_periods(
+        dsr: NetworkElementsDict[NetworkElement], indices: Indices
+    ) -> dict[int, list[range]]:
+        hours = indices.H.ord
+        res = dict()
+        for dsr_name, dsr_content in dsr.items():
+            markers = np.asarray(hours)[:: dsr_content.balancing_period_len]
+            if hours[-1] not in markers:
+                markers = np.append(markers, hours[-1])
+            res[indices.DSR.inverse[dsr_name]] = [
+                range(markers[idx], markers[idx + 1]) for idx in range(len(markers) - 1)
+            ]
+        return res
```

### Comparing `pyzefir-0.4.1/pyzefir/optimization/linopy/preprocessing/parameters/capacity_factor_parameters.py` & `pyzefir-0.4.22/pyzefir/optimization/linopy/preprocessing/parameters/capacity_factor_parameters.py`

 * *Ordering differences only*

 * *Files 10% similar despite different names*

```diff
@@ -1,32 +1,32 @@
-# PyZefir
-# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-from dataclasses import dataclass
-
-from pyzefir.model.network import NetworkElementsDict
-from pyzefir.optimization.linopy.preprocessing.indices import Indices
-from pyzefir.optimization.linopy.preprocessing.parameters import ModelParameters
-
-
-@dataclass
-class CapacityFactorParameters(ModelParameters):
-    """Profiled carrier parameters (sun, wind, etc.)"""
-
-    def __init__(self, capacity_factors: NetworkElementsDict, indices: Indices) -> None:
-        self.profile = self.fetch_element_prop(
-            capacity_factors, indices.CF, "profile", sample=indices.H.ii
-        )
-        """ capacity factor hourly profile; capacity_factor -> (h -> cf_profile[y]) """
+# PyZefir
+# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+from dataclasses import dataclass
+
+from pyzefir.model.network import NetworkElementsDict
+from pyzefir.optimization.linopy.preprocessing.indices import Indices
+from pyzefir.optimization.linopy.preprocessing.parameters import ModelParameters
+
+
+@dataclass
+class CapacityFactorParameters(ModelParameters):
+    """Profiled carrier parameters (sun, wind, etc.)"""
+
+    def __init__(self, capacity_factors: NetworkElementsDict, indices: Indices) -> None:
+        self.profile = self.fetch_element_prop(
+            capacity_factors, indices.CF, "profile", sample=indices.H.ii
+        )
+        """ capacity factor hourly profile; capacity_factor -> (h -> cf_profile[y]) """
```

### Comparing `pyzefir-0.4.1/pyzefir/optimization/linopy/preprocessing/parameters/demand_chunks_parameters.py` & `pyzefir-0.4.22/pyzefir/optimization/linopy/preprocessing/parameters/demand_chunks_parameters.py`

 * *Ordering differences only*

 * *Files 24% similar despite different names*

```diff
@@ -1,64 +1,64 @@
-# PyZefir
-# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-from dataclasses import dataclass
-
-import numpy as np
-
-from pyzefir.model.network import NetworkElementsDict
-from pyzefir.optimization.linopy.preprocessing.indices import Indices
-from pyzefir.optimization.linopy.preprocessing.parameters import ModelParameters
-
-
-@dataclass
-class DemandChunkParameters(ModelParameters):
-    """Generator parameters"""
-
-    def __init__(
-        self,
-        demand_chunks: NetworkElementsDict,
-        indices: Indices,
-    ) -> None:
-        self.energy_type = self.fetch_element_prop(
-            demand_chunks, indices.DEMCH, "energy_type"
-        )
-        "energy type"
-        self.tag = {
-            k: indices.TAGS.inverse[v]
-            for k, v in self.fetch_element_prop(
-                demand_chunks, indices.DEMCH, "tag"
-            ).items()
-        }
-        "tags involved"
-        self.demand = self.fetch_element_prop(demand_chunks, indices.DEMCH, "demand")
-        "demand to cover"
-        self.periods = self.fetch_element_prop(demand_chunks, indices.DEMCH, "periods")
-        self.periods = self.sample_periods(self.periods, indices.H.ii)
-        """ time periods """
-
-    @staticmethod
-    def sample_periods(
-        periods: dict[int, np.ndarray], hour_sample: np.ndarray
-    ) -> dict[int, np.ndarray]:
-        result = dict()
-        for demand_chunk_idx, period_data in periods.items():
-            in_hour_sample = [
-                interval
-                for interval in period_data
-                if set(range(*interval)).issubset(set(hour_sample))
-            ]
-            result[demand_chunk_idx] = np.array(in_hour_sample)
-        return result
+# PyZefir
+# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+from dataclasses import dataclass
+
+import numpy as np
+
+from pyzefir.model.network import NetworkElementsDict
+from pyzefir.optimization.linopy.preprocessing.indices import Indices
+from pyzefir.optimization.linopy.preprocessing.parameters import ModelParameters
+
+
+@dataclass
+class DemandChunkParameters(ModelParameters):
+    """Generator parameters"""
+
+    def __init__(
+        self,
+        demand_chunks: NetworkElementsDict,
+        indices: Indices,
+    ) -> None:
+        self.energy_type = self.fetch_element_prop(
+            demand_chunks, indices.DEMCH, "energy_type"
+        )
+        "energy type"
+        self.tag = {
+            k: indices.TAGS.inverse[v]
+            for k, v in self.fetch_element_prop(
+                demand_chunks, indices.DEMCH, "tag"
+            ).items()
+        }
+        "tags involved"
+        self.demand = self.fetch_element_prop(demand_chunks, indices.DEMCH, "demand")
+        "demand to cover"
+        self.periods = self.fetch_element_prop(demand_chunks, indices.DEMCH, "periods")
+        self.periods = self.sample_periods(self.periods, indices.H.ii)
+        """ time periods """
+
+    @staticmethod
+    def sample_periods(
+        periods: dict[int, np.ndarray], hour_sample: np.ndarray
+    ) -> dict[int, np.ndarray]:
+        result = dict()
+        for demand_chunk_idx, period_data in periods.items():
+            in_hour_sample = [
+                interval
+                for interval in period_data
+                if set(range(*interval)).issubset(set(hour_sample))
+            ]
+            result[demand_chunk_idx] = np.array(in_hour_sample)
+        return result
```

### Comparing `pyzefir-0.4.1/pyzefir/optimization/linopy/preprocessing/parameters/dsr_parameters.py` & `pyzefir-0.4.22/pyzefir/optimization/linopy/preprocessing/parameters/dsr_parameters.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,58 +1,60 @@
-# PyZefir
-# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-from dataclasses import dataclass
-
-from pyzefir.model.network import NetworkElementsDict
-from pyzefir.optimization.linopy.preprocessing.indices import Indices
-from pyzefir.optimization.linopy.preprocessing.parameters import ModelParameters
-
-
-@dataclass
-class DsrParameters(ModelParameters):
-    """Generator parameters"""
-
-    def __init__(
-        self,
-        dsr: NetworkElementsDict,
-        indices: Indices,
-    ) -> None:
-        self.compensation_factor = self.get_prop_from_elements_if_not_none(
-            dsr, indices.DSR, "compensation_factor"
-        )
-        """ compensation factor parameters """
-        self.balancing_period_len = self.get_prop_from_elements_if_not_none(
-            dsr, indices.DSR, "balancing_period_len"
-        )
-        """ balancing period length """
-        self.penalization = self.get_prop_from_elements_if_not_none(
-            dsr, indices.DSR, "penalization"
-        )
-        """ penalization parameters for dsr """
-        self.relative_shift_limit = self.get_prop_from_elements_if_not_none(
-            dsr, indices.DSR, "relative_shift_limit"
-        )
-        """ relative shift limit """
-        self.relative_shift_limit = self.get_prop_from_elements_if_not_none(
-            dsr, indices.DSR, "relative_shift_limit"
-        )
-        """ absolute shift limit """
-        self.abs_shift_limit = self.get_prop_from_elements_if_not_none(
-            dsr, indices.DSR, "abs_shift_limit"
-        )
-        """ absolute shift limit """
-        self.balancing_periods = self.get_balancing_periods(dsr, indices)
-        """balancing periods for a given dsr"""
+# PyZefir
+# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+from dataclasses import dataclass
+
+from pyzefir.model.network import NetworkElementsDict
+from pyzefir.optimization.linopy.preprocessing.indices import Indices
+from pyzefir.optimization.linopy.preprocessing.parameters import ModelParameters
+
+
+@dataclass
+class DsrParameters(ModelParameters):
+    """Generator parameters"""
+
+    def __init__(
+        self,
+        dsr: NetworkElementsDict,
+        indices: Indices,
+        scale: float = 1.0,
+    ) -> None:
+        self.compensation_factor = self.get_prop_from_elements_if_not_none(
+            dsr, indices.DSR, "compensation_factor"
+        )
+        """ compensation factor parameters """
+        self.balancing_period_len = self.get_prop_from_elements_if_not_none(
+            dsr, indices.DSR, "balancing_period_len"
+        )
+        """ balancing period length """
+        self.penalization = self.scale(
+            self.get_prop_from_elements_if_not_none(dsr, indices.DSR, "penalization"),
+            scale=scale,
+        )
+        """ penalization parameters for dsr """
+        self.relative_shift_limit = self.get_prop_from_elements_if_not_none(
+            dsr, indices.DSR, "relative_shift_limit"
+        )
+        """ relative shift limit """
+        self.relative_shift_limit = self.get_prop_from_elements_if_not_none(
+            dsr, indices.DSR, "relative_shift_limit"
+        )
+        """ absolute shift limit """
+        self.abs_shift_limit = self.get_prop_from_elements_if_not_none(
+            dsr, indices.DSR, "abs_shift_limit"
+        )
+        """ absolute shift limit """
+        self.balancing_periods = self.get_balancing_periods(dsr, indices)
+        """balancing periods for a given dsr"""
```

### Comparing `pyzefir-0.4.1/pyzefir/optimization/linopy/preprocessing/parameters/emission_fee_parameters.py` & `pyzefir-0.4.22/pyzefir/optimization/linopy/preprocessing/parameters/transmission_fee_parameters.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,42 +1,38 @@
-# PyZefir
-# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-from dataclasses import dataclass
-
-import numpy as np
-
-from pyzefir.model.network import NetworkElementsDict
-from pyzefir.optimization.linopy.preprocessing.indices import Indices
-from pyzefir.optimization.linopy.preprocessing.parameters import ModelParameters
-
-
-@dataclass
-class EmissionFeeParameters(ModelParameters):
-    """Emission fee parameters"""
-
-    def __init__(
-        self,
-        emission_fees: NetworkElementsDict,
-        indices: Indices,
-        scale: float = 1.0,
-    ) -> None:
-        self.emission_type: dict[int, str] = self.fetch_element_prop(
-            d=emission_fees, II=indices.EMF, prop="emission_type"
-        )
-        self.price: dict[int, np.ndarray] = self.fetch_element_prop(
-            d=emission_fees, II=indices.EMF, prop="price", sample=indices.Y.ii
-        )
-        self.price = self.scale(self.price, scale)
+# PyZefir
+# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+from dataclasses import dataclass
+
+from pyzefir.model.network import NetworkElementsDict
+from pyzefir.optimization.linopy.preprocessing.indices import Indices
+from pyzefir.optimization.linopy.preprocessing.parameters import ModelParameters
+
+
+@dataclass
+class TransmissionFeeParameters(ModelParameters):
+    """Transmission fee parameters"""
+
+    def __init__(
+        self,
+        transmission_fees: NetworkElementsDict,
+        indices: Indices,
+        scale: float = 1.0,
+    ) -> None:
+        self.fee = self.fetch_element_prop(
+            transmission_fees, indices.TF, "fee", sample=indices.H.ii
+        )
+        """ transmission fee hourly profile; transmission_fee -> (h -> fee[y]) """
+        self.fee = self.scale(self.fee, scale)  # noqa
```

### Comparing `pyzefir-0.4.1/pyzefir/optimization/linopy/preprocessing/parameters/fuel_parameters.py` & `pyzefir-0.4.22/pyzefir/optimization/linopy/preprocessing/parameters/fuel_parameters.py`

 * *Ordering differences only*

 * *Files 11% similar despite different names*

```diff
@@ -1,45 +1,45 @@
-# PyZefir
-# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-from dataclasses import dataclass
-
-from pyzefir.model.network import NetworkElementsDict
-from pyzefir.optimization.linopy.preprocessing.indices import Indices
-from pyzefir.optimization.linopy.preprocessing.parameters import ModelParameters
-
-
-@dataclass
-class FuelParameters(ModelParameters):
-    """Fuel parameters (coal, gas, biomass, etc.)"""
-
-    def __init__(
-        self, fuels: NetworkElementsDict, indices: Indices, scale: float = 1.0
-    ) -> None:
-        self.u_emission = self.fetch_element_prop(fuels, indices.FUEL, "emission")
-        """ base emission per unit; fuel -> emission_type """
-        self.energy_per_unit = self.fetch_element_prop(
-            fuels, indices.FUEL, "energy_per_unit"
-        )
-        """ base energy per unit; fuel -> energy_per_unit """
-        self.unit_cost = self.fetch_element_prop(
-            fuels, indices.FUEL, "cost", sample=indices.Y.ii
-        )
-        """ cost per unit; fuel -> (y -> cost[y]) """
-        self.unit_cost = self.scale(self.unit_cost, scale)  # noqa
-        self.availability = self.fetch_element_prop(
-            fuels, indices.FUEL, "availability", sample=indices.Y.ii
-        )
-        """ total availability per year; fuel -> (y -> availability[y]) """
+# PyZefir
+# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+from dataclasses import dataclass
+
+from pyzefir.model.network import NetworkElementsDict
+from pyzefir.optimization.linopy.preprocessing.indices import Indices
+from pyzefir.optimization.linopy.preprocessing.parameters import ModelParameters
+
+
+@dataclass
+class FuelParameters(ModelParameters):
+    """Fuel parameters (coal, gas, biomass, etc.)"""
+
+    def __init__(
+        self, fuels: NetworkElementsDict, indices: Indices, scale: float = 1.0
+    ) -> None:
+        self.u_emission = self.fetch_element_prop(fuels, indices.FUEL, "emission")
+        """ base emission per unit; fuel -> emission_type """
+        self.energy_per_unit = self.fetch_element_prop(
+            fuels, indices.FUEL, "energy_per_unit"
+        )
+        """ base energy per unit; fuel -> energy_per_unit """
+        self.unit_cost = self.fetch_element_prop(
+            fuels, indices.FUEL, "cost", sample=indices.Y.ii
+        )
+        """ cost per unit; fuel -> (y -> cost[y]) """
+        self.unit_cost = self.scale(self.unit_cost, scale)  # noqa
+        self.availability = self.fetch_element_prop(
+            fuels, indices.FUEL, "availability", sample=indices.Y.ii
+        )
+        """ total availability per year; fuel -> (y -> availability[y]) """
```

### Comparing `pyzefir-0.4.1/pyzefir/optimization/linopy/preprocessing/parameters/generator_parameters.py` & `pyzefir-0.4.22/pyzefir/optimization/linopy/preprocessing/parameters/generator_parameters.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,131 +1,157 @@
-# PyZefir
-# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-from dataclasses import dataclass
-
-from numpy import ndarray
-
-from pyzefir.model.network import NetworkElementsDict
-from pyzefir.model.network_elements import Generator, GeneratorType
-from pyzefir.optimization.linopy.preprocessing.indices import IndexingSet, Indices
-from pyzefir.optimization.linopy.preprocessing.parameters import ModelParameters
-
-
-@dataclass
-class GeneratorParameters(ModelParameters):
-    """Generator parameters"""
-
-    def __init__(
-        self,
-        generators: NetworkElementsDict,
-        generator_types: NetworkElementsDict,
-        indices: Indices,
-    ) -> None:
-        self.base_cap = self.fetch_element_prop(
-            generators, indices.GEN, "unit_base_cap"
-        )
-        """ generator base capacity """
-        self.power_utilization = self.fetch_energy_source_type_prop(
-            generators, generator_types, indices.GEN, "power_utilization"
-        )
-        """ power utilization factor """
-        self.buses = self.get_set_prop_from_element(
-            generators, "buses", indices.GEN, indices.BUS
-        )
-        """ list of generator buses """
-        self.fuel = self.get_index_from_type_prop(
-            generators, generator_types, indices.GEN, indices.FUEL, "fuel"
-        )
-        """ generator fuel """
-        self.capacity_factors = self.get_index_from_type_prop(
-            generators, generator_types, indices.GEN, indices.CF, "capacity_factor"
-        )
-        """ generator capacity factors """
-        self.ett = self.fetch_energy_source_type_prop(
-            generators, generator_types, indices.GEN, "energy_types"
-        )
-        """ generator energy types """
-        self.eff = self.fetch_energy_source_type_prop(
-            generators, generator_types, indices.GEN, "efficiency"
-        )
-        """ generator efficiency """
-        self.conv_rate = self.get_conversion_rate(
-            generators, generator_types, indices.GEN, indices.H
-        )
-        """
-        conversion rate: (et -> Vector[h] - how many units of energy et needs to be provided to produce one unit
-        of energy in a given hour h
-        """
-        self.em_red = self.fetch_energy_source_type_prop(
-            generators, generator_types, indices.GEN, "emission_reduction"
-        )
-        """ generator reduction of carrier base emission """
-        self.unit_max_capacity = self.fetch_element_prop(
-            generators, indices.GEN, "unit_max_capacity", sample=indices.Y.ii
-        )
-        """ generator max capacity in a given year """
-        self.unit_min_capacity = self.fetch_element_prop(
-            generators, indices.GEN, "unit_min_capacity", sample=indices.Y.ii
-        )
-        """ generator min capacity in a given year """
-        self.unit_max_capacity_increase = self.fetch_element_prop(
-            generators, indices.GEN, "unit_max_capacity_increase", sample=indices.Y.ii
-        )
-        """ generator unit_max_capacity_increase upper bound of capacity increase in a given year """
-        self.unit_min_capacity_increase = self.fetch_element_prop(
-            generators, indices.GEN, "unit_min_capacity_increase", sample=indices.Y.ii
-        )
-        """ generator unit_min_capacity_increase lower bound of capacity increase in a given year """
-        self.min_device_nom_power = self.get_prop_from_elements_if_not_none(
-            generators, indices.GEN, "min_device_nom_power"
-        )
-        """ generator minimal device nominal power """
-        self.max_device_nom_power = self.get_prop_from_elements_if_not_none(
-            generators, indices.GEN, "max_device_nom_power"
-        )
-        """ generator maximum device nominal power """
-        self.tgen = {
-            i: indices.TGEN.inverse[generators[gen].energy_source_type]
-            for i, gen in indices.GEN.mapping.items()
-        }
-        """ generator type """
-        self.emission_fee: dict[int, set[int]] = self.get_set_prop_from_element(
-            generators, "emission_fee", indices.GEN, indices.EMF
-        )
-        """ emission fee """
-        self.tags = self.get_set_prop_from_element(
-            generators, "tags", indices.GEN, indices.TAGS
-        )
-        """ generator tags """
-
-    @staticmethod
-    def get_conversion_rate(
-        generators: NetworkElementsDict[Generator],
-        generator_types: NetworkElementsDict[GeneratorType],
-        gen_idx: IndexingSet,
-        h_idx: IndexingSet,
-    ) -> dict[int, dict[str, ndarray]]:
-        result: dict[int, dict[str, ndarray]] = dict()
-        for ii, gen_name in gen_idx.mapping.items():
-            gen = generators[gen_name]
-            gen_type = generator_types[gen.energy_source_type]
-            conv_rate = gen_type.conversion_rate
-            result[ii] = dict()
-            if conv_rate:
-                for et in conv_rate:
-                    result[ii][et] = conv_rate[et].iloc[h_idx.ii].values
-
-        return result
+# PyZefir
+# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+from dataclasses import dataclass
+
+import pandas as pd
+from numpy import ndarray
+
+from pyzefir.model.network import NetworkElementsDict
+from pyzefir.model.network_elements import Generator, GeneratorType
+from pyzefir.optimization.linopy.preprocessing.indices import IndexingSet, Indices
+from pyzefir.optimization.linopy.preprocessing.parameters import ModelParameters
+
+
+@dataclass
+class GeneratorParameters(ModelParameters):
+    """Generator parameters"""
+
+    def __init__(
+        self,
+        generators: NetworkElementsDict,
+        generator_types: NetworkElementsDict,
+        indices: Indices,
+    ) -> None:
+        self.base_cap = self.fetch_element_prop(
+            generators, indices.GEN, "unit_base_cap"
+        )
+        """ generator base capacity """
+        self.power_utilization = self.fetch_energy_source_type_prop(
+            generators, generator_types, indices.GEN, "power_utilization"
+        )
+        """ power utilization factor """
+        self.buses = self.get_set_prop_from_element(
+            generators, "buses", indices.GEN, indices.BUS
+        )
+        """ list of generator buses """
+        self.fuel = self.get_index_from_type_prop(
+            generators, generator_types, indices.GEN, indices.FUEL, "fuel"
+        )
+        """ generator fuel """
+        self.capacity_factors = self.get_index_from_type_prop(
+            generators, generator_types, indices.GEN, indices.CF, "capacity_factor"
+        )
+        """ generator capacity factors """
+        self.ett = self.fetch_energy_source_type_prop(
+            generators, generator_types, indices.GEN, "energy_types"
+        )
+        """ generator energy types """
+        self.eff = self.get_frame_data_prop_from_element(
+            generators, generator_types, indices.GEN, indices.H, "efficiency"
+        )
+        """ generator efficiency: (et -> Vector[h])- efficiency of energy in a given hour h"""
+        self.conv_rate = self.get_frame_data_prop_from_element(
+            generators, generator_types, indices.GEN, indices.H, "conversion_rate"
+        )
+        """
+        conversion rate: (et -> Vector[h]) - how many units of energy et needs to be provided to produce one unit
+        of energy in a given hour h
+        """
+        self.em_red = self.fetch_energy_source_type_prop(
+            generators, generator_types, indices.GEN, "emission_reduction"
+        )
+        """ generator reduction of carrier base emission """
+        self.unit_max_capacity = self.fetch_element_prop(
+            generators, indices.GEN, "unit_max_capacity", sample=indices.Y.ii
+        )
+        """ generator max capacity in a given year """
+        self.unit_min_capacity = self.fetch_element_prop(
+            generators, indices.GEN, "unit_min_capacity", sample=indices.Y.ii
+        )
+        """ generator min capacity in a given year """
+        self.unit_max_capacity_increase = self.fetch_element_prop(
+            generators, indices.GEN, "unit_max_capacity_increase", sample=indices.Y.ii
+        )
+        """ generator unit_max_capacity_increase upper bound of capacity increase in a given year """
+        self.unit_min_capacity_increase = self.fetch_element_prop(
+            generators, indices.GEN, "unit_min_capacity_increase", sample=indices.Y.ii
+        )
+        """ generator unit_min_capacity_increase lower bound of capacity increase in a given year """
+        self.min_device_nom_power = self.get_prop_from_elements_if_not_none(
+            generators, indices.GEN, "min_device_nom_power"
+        )
+        """ generator minimal device nominal power """
+        self.max_device_nom_power = self.get_prop_from_elements_if_not_none(
+            generators, indices.GEN, "max_device_nom_power"
+        )
+        """ generator maximum device nominal power """
+        self.tgen = {
+            i: indices.TGEN.inverse[generators[gen].energy_source_type]
+            for i, gen in indices.GEN.mapping.items()
+        }
+        """ generator type """
+        self.emission_fee: dict[int, set[int]] = self.get_set_prop_from_element(
+            generators, "emission_fee", indices.GEN, indices.EMF
+        )
+        """ emission fee """
+        self.tags = self.get_set_prop_from_element(
+            generators, "tags", indices.GEN, indices.TAGS
+        )
+        """ generator tags """
+        self.capacity_binding = self.fetch_element_prop(
+            generators, indices.GEN, "generator_binding"
+        )
+
+    @staticmethod
+    def get_frame_data_prop_from_element(
+        generators: NetworkElementsDict[Generator],
+        generator_types: NetworkElementsDict[GeneratorType],
+        gen_idx: IndexingSet,
+        h_idx: IndexingSet,
+        prop: str,
+    ) -> dict[int, dict[str, ndarray]]:
+        """
+        Returns a dictionary where the keys are the indices of the generators in the
+        generators parameter and the values are dictionaries where the keys are the
+        energy types and the values are numpy arrays containing the values of the
+        specified property for the specified energy type at the specified hour index.
+
+        Args:
+            generators (NetworkElementsDict[Generator]): The generators in the network.
+            generator_types (NetworkElementsDict[GeneratorType]): The generator types in the network.
+            gen_idx (IndexingSet): The set of indices for the generators.
+            h_idx (IndexingSet): The set of indices for the hours.
+            prop (str): The name of the property to retrieve.
+
+        Returns:
+            dict[int, dict[str, ndarray]]: A dictionary where the keys are the indices of the generators in the
+            generators parameter and the values are dictionaries where the keys are
+            the energy types and the values are numpy arrays containing the values of
+            the specified property for the specified energy type at the specified
+            hour index.
+
+        """
+        result: dict[int, dict[str, ndarray]] = dict()
+        for ii, gen_name in gen_idx.mapping.items():
+            gen_type = generator_types[generators[gen_name].energy_source_type]
+            gen_prop = getattr(gen_type, prop)
+            if isinstance(gen_prop, dict):
+                gen_prop = pd.DataFrame(gen_prop) if gen_prop else None
+            result[ii] = dict()
+            if gen_prop is not None:
+                for et in gen_prop:
+                    result[ii][et] = gen_prop[et].iloc[h_idx.ii].values
+        return result
```

### Comparing `pyzefir-0.4.1/pyzefir/optimization/linopy/preprocessing/parameters/generator_type_parameters.py` & `pyzefir-0.4.22/pyzefir/optimization/linopy/preprocessing/parameters/generator_type_parameters.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,93 +1,103 @@
-# PyZefir
-# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-from dataclasses import dataclass
-
-from pyzefir.model.network import NetworkElementsDict
-from pyzefir.optimization.linopy.preprocessing.indices import Indices
-from pyzefir.optimization.linopy.preprocessing.parameters import ModelParameters
-
-
-@dataclass
-class GeneratorTypeParameters(ModelParameters):
-    """Generator Type parameters"""
-
-    def __init__(
-        self,
-        generator_types: NetworkElementsDict,
-        indices: Indices,
-        scale: float = 1.0,
-    ) -> None:
-        self.max_capacity = self.fetch_element_prop(
-            generator_types, indices.TGEN, "max_capacity", sample=indices.Y.ii
-        )
-        """ generator max capacity in a given year """
-        self.min_capacity = self.fetch_element_prop(
-            generator_types, indices.TGEN, "min_capacity", sample=indices.Y.ii
-        )
-        """ generator min capacity in a given year """
-        self.max_capacity_increase = self.fetch_element_prop(
-            generator_types, indices.TGEN, "max_capacity_increase", sample=indices.Y.ii
-        )
-        """ generator capacity increase upper bound of capacity increase in a given year """
-        self.min_capacity_increase = self.fetch_element_prop(
-            generator_types, indices.TGEN, "min_capacity_increase", sample=indices.Y.ii
-        )
-        """ generator capacity increase lower bound of capacity increase in a given year """
-        self.capex = self.scale(
-            self.fetch_element_prop(  # noqa
-                generator_types, indices.TGEN, "capex", sample=indices.Y.ii
-            ),
-            scale,
-        )
-        """ generator type capex per capacity unit """
-        self.opex = self.scale(
-            self.fetch_element_prop(
-                generator_types, indices.TGEN, "opex", sample=indices.Y.ii
-            ),
-            scale,
-        )
-        """ generator type opex per capacity unit """
-        self.lt = self.fetch_element_prop(
-            generator_types,
-            indices.TGEN,
-            "life_time",
-        )
-        """ generator type life time """
-        self.bt = self.fetch_element_prop(
-            generator_types,
-            indices.TGEN,
-            "build_time",
-        )
-        """ generator type build time """
-        self.ramp = self.fetch_element_prop(
-            generator_types, indices.TGEN, "ramp", sample=indices.Y.ii
-        )
-        """change in generation from one hour to the next"""
-        self.tags = self.get_set_prop_from_element(
-            generator_types, "tags", indices.TGEN, indices.T_TAGS
-        )
-        """ generator type tags """
-        self.energy_curtailment_cost = self.fetch_element_prop(
-            generator_types,
-            indices.TGEN,
-            "energy_curtailment_cost",
-            sample=indices.Y.ii,
-        )
-        self.power_utilization = self.fetch_element_prop(
-            generator_types, indices.TGEN, "power_utilization", sample=indices.H.ii
-        )
-        """ power utilization factor """
+# PyZefir
+# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+from dataclasses import dataclass
+
+from pyzefir.model.network import NetworkElementsDict
+from pyzefir.optimization.linopy.preprocessing.indices import Indices
+from pyzefir.optimization.linopy.preprocessing.parameters import ModelParameters
+
+
+@dataclass
+class GeneratorTypeParameters(ModelParameters):
+    """Generator Type parameters"""
+
+    def __init__(
+        self,
+        generator_types: NetworkElementsDict,
+        indices: Indices,
+        scale: float = 1.0,
+    ) -> None:
+        self.max_capacity = self.fetch_element_prop(
+            generator_types, indices.TGEN, "max_capacity", sample=indices.Y.ii
+        )
+        """ generator max capacity in a given year """
+        self.min_capacity = self.fetch_element_prop(
+            generator_types, indices.TGEN, "min_capacity", sample=indices.Y.ii
+        )
+        """ generator min capacity in a given year """
+        self.max_capacity_increase = self.fetch_element_prop(
+            generator_types, indices.TGEN, "max_capacity_increase", sample=indices.Y.ii
+        )
+        """ generator capacity increase upper bound of capacity increase in a given year """
+        self.min_capacity_increase = self.fetch_element_prop(
+            generator_types, indices.TGEN, "min_capacity_increase", sample=indices.Y.ii
+        )
+        """ generator capacity increase lower bound of capacity increase in a given year """
+        self.capex = self.scale(
+            self.fetch_element_prop(  # noqa
+                generator_types, indices.TGEN, "capex", sample=indices.Y.ii
+            ),
+            scale,
+        )
+        """ generator type capex per capacity unit """
+        self.opex = self.scale(
+            self.fetch_element_prop(
+                generator_types, indices.TGEN, "opex", sample=indices.Y.ii
+            ),
+            scale,
+        )
+        """ generator type opex per capacity unit """
+        self.lt = self.fetch_element_prop(
+            generator_types,
+            indices.TGEN,
+            "life_time",
+        )
+        """ generator type life time """
+        self.bt = self.fetch_element_prop(
+            generator_types,
+            indices.TGEN,
+            "build_time",
+        )
+        """ generator type build time """
+        self.ramp = self.fetch_element_prop(
+            generator_types, indices.TGEN, "ramp", sample=indices.Y.ii
+        )
+        """change in generation from one hour to the next"""
+        self.tags = self.get_set_prop_from_element(
+            generator_types, "tags", indices.TGEN, indices.T_TAGS
+        )
+        """ generator type tags """
+        self.energy_curtailment_cost = self.fetch_element_prop(
+            generator_types,
+            indices.TGEN,
+            "energy_curtailment_cost",
+            sample=indices.Y.ii,
+        )
+        self.power_utilization = self.fetch_element_prop(
+            generator_types, indices.TGEN, "power_utilization", sample=indices.H.ii
+        )
+        """ power utilization factor """
+        self.generation_compensation = self.scale(
+            self.fetch_element_prop(
+                generator_types,
+                indices.TGEN,
+                "generation_compensation",
+                sample=indices.Y.ii,
+            ),
+            scale,
+        )
+        """ generation compensation parameter """
```

### Comparing `pyzefir-0.4.1/pyzefir/optimization/linopy/preprocessing/parameters/line_parameters.py` & `pyzefir-0.4.22/pyzefir/optimization/linopy/preprocessing/parameters/line_parameters.py`

 * *Ordering differences only*

 * *Files 15% similar despite different names*

```diff
@@ -1,44 +1,44 @@
-# PyZefir
-# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-from dataclasses import dataclass
-
-from pyzefir.model.network import NetworkElementsDict
-from pyzefir.optimization.linopy.preprocessing.indices import Indices
-from pyzefir.optimization.linopy.preprocessing.parameters import ModelParameters
-
-
-@dataclass
-class LineParameters(ModelParameters):
-    def __init__(self, lines: NetworkElementsDict, indices: Indices) -> None:
-        self.et = self.fetch_element_prop(lines, indices.LINE, "energy_type")
-        """ line energy type """
-        self.bus_from = self.get_index_from_prop(lines, indices.LINE, indices.BUS, "fr")
-        """ line starting bus """
-        self.bus_to = self.get_index_from_prop(lines, indices.LINE, indices.BUS, "to")
-        """ line end bus """
-        self.loss = self.fetch_element_prop(lines, indices.LINE, "transmission_loss")
-        """ line transmission loss """
-        self.cap = self.fetch_element_prop(lines, indices.LINE, "max_capacity")
-        """ line capacity [for now it is given apriori and can not change] """
-        self.tf = {
-            key: indices.TF.inverse[val]
-            for key, val in self.fetch_element_prop(
-                lines, indices.LINE, "transmission_fee"
-            ).items()
-            if val
-        }
-        """ line transmission fee """
+# PyZefir
+# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+from dataclasses import dataclass
+
+from pyzefir.model.network import NetworkElementsDict
+from pyzefir.optimization.linopy.preprocessing.indices import Indices
+from pyzefir.optimization.linopy.preprocessing.parameters import ModelParameters
+
+
+@dataclass
+class LineParameters(ModelParameters):
+    def __init__(self, lines: NetworkElementsDict, indices: Indices) -> None:
+        self.et = self.fetch_element_prop(lines, indices.LINE, "energy_type")
+        """ line energy type """
+        self.bus_from = self.get_index_from_prop(lines, indices.LINE, indices.BUS, "fr")
+        """ line starting bus """
+        self.bus_to = self.get_index_from_prop(lines, indices.LINE, indices.BUS, "to")
+        """ line end bus """
+        self.loss = self.fetch_element_prop(lines, indices.LINE, "transmission_loss")
+        """ line transmission loss """
+        self.cap = self.fetch_element_prop(lines, indices.LINE, "max_capacity")
+        """ line capacity [for now it is given apriori and can not change] """
+        self.tf = {
+            key: indices.TF.inverse[val]
+            for key, val in self.fetch_element_prop(
+                lines, indices.LINE, "transmission_fee"
+            ).items()
+            if val
+        }
+        """ line transmission fee """
```

### Comparing `pyzefir-0.4.1/pyzefir/optimization/linopy/preprocessing/parameters/local_balancing_stack_parameters.py` & `pyzefir-0.4.22/pyzefir/optimization/linopy/preprocessing/parameters/local_balancing_stack_parameters.py`

 * *Ordering differences only*

 * *Files 16% similar despite different names*

```diff
@@ -1,81 +1,81 @@
-# PyZefir
-# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-from dataclasses import dataclass
-
-from pyzefir.model.network import NetworkElementsDict
-from pyzefir.model.network_elements import AggregatedConsumer, LocalBalancingStack
-from pyzefir.optimization.linopy.preprocessing.indices import IndexingSet, Indices
-from pyzefir.optimization.linopy.preprocessing.parameters import ModelParameters
-
-
-@dataclass
-class LBSParameters(ModelParameters):
-    def __init__(
-        self,
-        local_balancing_stacks: NetworkElementsDict,
-        aggregated_consumers: NetworkElementsDict,
-        indices: Indices,
-    ) -> None:
-        self.bus_out = self.get_bus_out(
-            local_balancing_stacks, indices.BUS, indices.LBS
-        )
-        """ bus, for which aggregated consumer demand will be included in balancing equation """
-        self.aggr_idx = self.get_aggr_idx(
-            aggregated_consumers, indices.AGGR, indices.LBS
-        )
-        """ aggregated consumer, to which given local balancing stack is / can be connected; lbs_id -> aggr_id """
-        self.buses = self.get_buses(local_balancing_stacks, indices.BUS, indices.LBS)
-
-    @staticmethod
-    def get_bus_out(
-        local_balancing_stacks: NetworkElementsDict[LocalBalancingStack],
-        bus_idx: IndexingSet,
-        lbs_idx: IndexingSet,
-    ) -> dict[int, dict[str, int]]:
-        return {
-            ii: {
-                et: bus_idx.inverse[bus]
-                for et, bus in local_balancing_stacks[name].buses_out.items()
-            }
-            for ii, name in lbs_idx.mapping.items()
-        }
-
-    @staticmethod
-    def get_aggr_idx(
-        aggregated_consumers: NetworkElementsDict[AggregatedConsumer],
-        aggr_idx: IndexingSet,
-        lbs_idx: IndexingSet,
-    ) -> dict[int, int]:
-        return {
-            lbs_idx.inverse[lbs_name]: aggr_id
-            for aggr_id, aggr_name in aggr_idx.mapping.items()
-            for lbs_name in aggregated_consumers[aggr_name].stack_base_fraction
-        }
-
-    @staticmethod
-    def get_buses(
-        local_balancing_stacks: NetworkElementsDict[LocalBalancingStack],
-        bus_idx: IndexingSet,
-        lbs_idx: IndexingSet,
-    ) -> dict[int, dict[str, set[int]]]:
-        return {
-            ii: {
-                et: {bus_idx.inverse[bus] for bus in buses}
-                for et, buses in local_balancing_stacks[name].buses.items()
-            }
-            for ii, name in lbs_idx.mapping.items()
-        }
+# PyZefir
+# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+from dataclasses import dataclass
+
+from pyzefir.model.network import NetworkElementsDict
+from pyzefir.model.network_elements import AggregatedConsumer, LocalBalancingStack
+from pyzefir.optimization.linopy.preprocessing.indices import IndexingSet, Indices
+from pyzefir.optimization.linopy.preprocessing.parameters import ModelParameters
+
+
+@dataclass
+class LBSParameters(ModelParameters):
+    def __init__(
+        self,
+        local_balancing_stacks: NetworkElementsDict,
+        aggregated_consumers: NetworkElementsDict,
+        indices: Indices,
+    ) -> None:
+        self.bus_out = self.get_bus_out(
+            local_balancing_stacks, indices.BUS, indices.LBS
+        )
+        """ bus, for which aggregated consumer demand will be included in balancing equation """
+        self.aggr_idx = self.get_aggr_idx(
+            aggregated_consumers, indices.AGGR, indices.LBS
+        )
+        """ aggregated consumer, to which given local balancing stack is / can be connected; lbs_id -> aggr_id """
+        self.buses = self.get_buses(local_balancing_stacks, indices.BUS, indices.LBS)
+
+    @staticmethod
+    def get_bus_out(
+        local_balancing_stacks: NetworkElementsDict[LocalBalancingStack],
+        bus_idx: IndexingSet,
+        lbs_idx: IndexingSet,
+    ) -> dict[int, dict[str, int]]:
+        return {
+            ii: {
+                et: bus_idx.inverse[bus]
+                for et, bus in local_balancing_stacks[name].buses_out.items()
+            }
+            for ii, name in lbs_idx.mapping.items()
+        }
+
+    @staticmethod
+    def get_aggr_idx(
+        aggregated_consumers: NetworkElementsDict[AggregatedConsumer],
+        aggr_idx: IndexingSet,
+        lbs_idx: IndexingSet,
+    ) -> dict[int, int]:
+        return {
+            lbs_idx.inverse[lbs_name]: aggr_id
+            for aggr_id, aggr_name in aggr_idx.mapping.items()
+            for lbs_name in aggregated_consumers[aggr_name].stack_base_fraction
+        }
+
+    @staticmethod
+    def get_buses(
+        local_balancing_stacks: NetworkElementsDict[LocalBalancingStack],
+        bus_idx: IndexingSet,
+        lbs_idx: IndexingSet,
+    ) -> dict[int, dict[str, set[int]]]:
+        return {
+            ii: {
+                et: {bus_idx.inverse[bus] for bus in buses}
+                for et, buses in local_balancing_stacks[name].buses.items()
+            }
+            for ii, name in lbs_idx.mapping.items()
+        }
```

### Comparing `pyzefir-0.4.1/pyzefir/optimization/linopy/preprocessing/parameters/scenario_parameters.py` & `pyzefir-0.4.22/pyzefir/optimization/linopy/preprocessing/parameters/scenario_parameters.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,60 +1,60 @@
-# PyZefir
-# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-from numpy import ndarray
-
-from pyzefir.optimization.linopy.preprocessing.indices import Indices
-from pyzefir.optimization.linopy.preprocessing.parameters import ModelParameters
-from pyzefir.optimization.opt_config import OptConfig
-
-
-class ScenarioParameters(ModelParameters):
-    def __init__(
-        self,
-        indices: Indices,
-        opt_config: OptConfig,
-        rel_em_limit: dict[str, ndarray],
-        min_generation_fraction: dict[str, dict[tuple[int, int], float]],
-        max_generation_fraction: dict[str, dict[tuple[int, int], float]],
-        base_total_emission: dict[str, float | int],
-        power_reserves: dict[str, dict[str, float]],
-        numeric_tolerance: float,
-    ) -> None:
-        self.discount_rate: ndarray = opt_config.discount_rate[indices.Y.ii]
-        """ discount rate included in capex formula """
-        self.rel_em_limit: dict[str, ndarray] = rel_em_limit
-        """ relative emission limit for each year """
-        self.hourly_scale: float = opt_config.hourly_scale
-        """  ratio of the hours for hours scale """
-        self.base_total_emission: dict[str, float | int] = base_total_emission
-        """ Total emissions for a given type for the base year """
-        self.min_generation_fraction: dict[str, dict[tuple[int, int], float]] = (
-            min_generation_fraction
-        )
-        """Min percentage usage of the units in the tag"""
-        self.max_generation_fraction: dict[str, dict[tuple[int, int], float]] = (
-            max_generation_fraction
-        )
-        """Max percentage usage of the units in the tag"""
-        self.power_reserves: dict[str, dict[int, float]] | None = {
-            energy_type: {indices.TAGS.inverse[tag]: val for tag, val in res.items()}
-            for energy_type, res in power_reserves.items()
-        }
-        """power reserves for energy type and a given tag"""
-        self.numeric_tolerance: float = numeric_tolerance
-        """numerical tolerance for relaxing some constraints"""
-        self.money_scale: float = opt_config.money_scale
-        """money scale parameter"""
+# PyZefir
+# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+from numpy import ndarray
+
+from pyzefir.optimization.linopy.preprocessing.indices import Indices
+from pyzefir.optimization.linopy.preprocessing.parameters import ModelParameters
+from pyzefir.optimization.opt_config import OptConfig
+
+
+class ScenarioParameters(ModelParameters):
+    def __init__(
+        self,
+        indices: Indices,
+        opt_config: OptConfig,
+        rel_em_limit: dict[str, ndarray],
+        min_generation_fraction: dict[str, dict[tuple[int, int], float]],
+        max_generation_fraction: dict[str, dict[tuple[int, int], float]],
+        base_total_emission: dict[str, float | int],
+        power_reserves: dict[str, dict[str, float]],
+        ens_penalty_cost: float,
+    ) -> None:
+        self.discount_rate: ndarray = opt_config.discount_rate[indices.Y.ii]
+        """ discount rate included in capex formula """
+        self.rel_em_limit: dict[str, ndarray] = rel_em_limit
+        """ relative emission limit for each year """
+        self.hourly_scale: float = opt_config.hourly_scale
+        """  ratio of the hours for hours scale """
+        self.base_total_emission: dict[str, float | int] = base_total_emission
+        """ Total emissions for a given type for the base year """
+        self.min_generation_fraction: dict[str, dict[tuple[int, int], float]] = (
+            min_generation_fraction
+        )
+        """Min percentage usage of the units in the tag"""
+        self.max_generation_fraction: dict[str, dict[tuple[int, int], float]] = (
+            max_generation_fraction
+        )
+        """Max percentage usage of the units in the tag"""
+        self.power_reserves: dict[str, dict[int, float]] | None = {
+            energy_type: {indices.TAGS.inverse[tag]: val for tag, val in res.items()}
+            for energy_type, res in power_reserves.items()
+        }
+        """power reserves for energy type and a given tag"""
+        self.money_scale: float = opt_config.money_scale
+        """money scale parameter"""
+        self.ens_penalty_cost: float = ens_penalty_cost
+        """set cost for ens. Letting to be equal zero means no ens"""
```

### Comparing `pyzefir-0.4.1/pyzefir/optimization/linopy/preprocessing/parameters/storage_parameters.py` & `pyzefir-0.4.22/pyzefir/optimization/linopy/preprocessing/parameters/storage_parameters.py`

 * *Ordering differences only*

 * *Files 12% similar despite different names*

```diff
@@ -1,88 +1,88 @@
-# PyZefir
-# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-from dataclasses import dataclass
-
-from pyzefir.model.network import NetworkElementsDict
-from pyzefir.optimization.linopy.preprocessing.indices import Indices
-from pyzefir.optimization.linopy.preprocessing.parameters import ModelParameters
-
-
-@dataclass
-class StorageParameters(ModelParameters):
-    def __init__(
-        self,
-        storages: NetworkElementsDict,
-        storage_types: NetworkElementsDict,
-        indices: Indices,
-    ) -> None:
-        self.base_cap = self.fetch_element_prop(storages, indices.STOR, "unit_base_cap")
-        """ storage base capacity """
-        self.et = self.fetch_energy_source_type_prop(
-            storages, storage_types, indices.STOR, "energy_type"
-        )
-        """ storage energy type """
-        self.gen_eff = self.fetch_energy_source_type_prop(
-            storages, storage_types, indices.STOR, "generation_efficiency"
-        )
-        """ storage generation efficiency """
-        self.load_eff = self.fetch_energy_source_type_prop(
-            storages, storage_types, indices.STOR, "load_efficiency"
-        )
-        """ storage load efficiency """
-        self.p2cap = self.fetch_energy_source_type_prop(
-            storages, storage_types, indices.STOR, "power_to_capacity"
-        )
-        """ power to capacity ratio """
-        self.bus = self.get_index_from_prop(storages, indices.STOR, indices.BUS, "bus")
-        """ storage bus """
-        self.cycle_len = self.fetch_energy_source_type_prop(
-            storages, storage_types, indices.STOR, "cycle_length"
-        )
-        """ length of the loading cycle """
-        self.unit_max_capacity = self.fetch_element_prop(
-            storages, indices.STOR, "unit_max_capacity", sample=indices.Y.ii
-        )
-        """ storage max capacity in a given year """
-        self.unit_min_capacity = self.fetch_element_prop(
-            storages, indices.STOR, "unit_min_capacity", sample=indices.Y.ii
-        )
-        """ storage min capacity in a given year """
-        self.unit_max_capacity_increase = self.fetch_element_prop(
-            storages, indices.STOR, "unit_max_capacity_increase", sample=indices.Y.ii
-        )
-        """ storage capacity increase upper bound of capacity increase in a given year """
-        self.unit_min_capacity_increase = self.fetch_element_prop(
-            storages, indices.STOR, "unit_min_capacity_increase", sample=indices.Y.ii
-        )
-        """ storage capacity increase lower bound of capacity increase in a given year """
-        self.min_device_nom_power = self.get_prop_from_elements_if_not_none(
-            storages, indices.STOR, "min_device_nom_power"
-        )
-        """ storage minimal device nominal power """
-        self.max_device_nom_power = self.get_prop_from_elements_if_not_none(
-            storages, indices.STOR, "max_device_nom_power"
-        )
-        """ storage power utilization """
-        self.tstor = {
-            i: indices.TSTOR.inverse[storages[gen].energy_source_type]
-            for i, gen in indices.STOR.mapping.items()
-        }
-        """ storage type """
-        self.tags = self.get_set_prop_from_element(
-            storages, "tags", indices.STOR, indices.TAGS
-        )
-        """ storage tags """
+# PyZefir
+# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+from dataclasses import dataclass
+
+from pyzefir.model.network import NetworkElementsDict
+from pyzefir.optimization.linopy.preprocessing.indices import Indices
+from pyzefir.optimization.linopy.preprocessing.parameters import ModelParameters
+
+
+@dataclass
+class StorageParameters(ModelParameters):
+    def __init__(
+        self,
+        storages: NetworkElementsDict,
+        storage_types: NetworkElementsDict,
+        indices: Indices,
+    ) -> None:
+        self.base_cap = self.fetch_element_prop(storages, indices.STOR, "unit_base_cap")
+        """ storage base capacity """
+        self.et = self.fetch_energy_source_type_prop(
+            storages, storage_types, indices.STOR, "energy_type"
+        )
+        """ storage energy type """
+        self.gen_eff = self.fetch_energy_source_type_prop(
+            storages, storage_types, indices.STOR, "generation_efficiency"
+        )
+        """ storage generation efficiency """
+        self.load_eff = self.fetch_energy_source_type_prop(
+            storages, storage_types, indices.STOR, "load_efficiency"
+        )
+        """ storage load efficiency """
+        self.p2cap = self.fetch_energy_source_type_prop(
+            storages, storage_types, indices.STOR, "power_to_capacity"
+        )
+        """ power to capacity ratio """
+        self.bus = self.get_index_from_prop(storages, indices.STOR, indices.BUS, "bus")
+        """ storage bus """
+        self.cycle_len = self.fetch_energy_source_type_prop(
+            storages, storage_types, indices.STOR, "cycle_length"
+        )
+        """ length of the loading cycle """
+        self.unit_max_capacity = self.fetch_element_prop(
+            storages, indices.STOR, "unit_max_capacity", sample=indices.Y.ii
+        )
+        """ storage max capacity in a given year """
+        self.unit_min_capacity = self.fetch_element_prop(
+            storages, indices.STOR, "unit_min_capacity", sample=indices.Y.ii
+        )
+        """ storage min capacity in a given year """
+        self.unit_max_capacity_increase = self.fetch_element_prop(
+            storages, indices.STOR, "unit_max_capacity_increase", sample=indices.Y.ii
+        )
+        """ storage capacity increase upper bound of capacity increase in a given year """
+        self.unit_min_capacity_increase = self.fetch_element_prop(
+            storages, indices.STOR, "unit_min_capacity_increase", sample=indices.Y.ii
+        )
+        """ storage capacity increase lower bound of capacity increase in a given year """
+        self.min_device_nom_power = self.get_prop_from_elements_if_not_none(
+            storages, indices.STOR, "min_device_nom_power"
+        )
+        """ storage minimal device nominal power """
+        self.max_device_nom_power = self.get_prop_from_elements_if_not_none(
+            storages, indices.STOR, "max_device_nom_power"
+        )
+        """ storage power utilization """
+        self.tstor = {
+            i: indices.TSTOR.inverse[storages[gen].energy_source_type]
+            for i, gen in indices.STOR.mapping.items()
+        }
+        """ storage type """
+        self.tags = self.get_set_prop_from_element(
+            storages, "tags", indices.STOR, indices.TAGS
+        )
+        """ storage tags """
```

### Comparing `pyzefir-0.4.1/pyzefir/optimization/linopy/preprocessing/parameters/storage_type_parameters.py` & `pyzefir-0.4.22/pyzefir/optimization/linopy/preprocessing/parameters/storage_type_parameters.py`

 * *Ordering differences only*

 * *Files 27% similar despite different names*

```diff
@@ -1,86 +1,86 @@
-# PyZefir
-# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-from dataclasses import dataclass
-
-from pyzefir.model.network import NetworkElementsDict
-from pyzefir.optimization.linopy.preprocessing.indices import Indices
-from pyzefir.optimization.linopy.preprocessing.parameters import ModelParameters
-
-
-@dataclass
-class StorageTypeParameters(ModelParameters):
-    """Storage Type parameters"""
-
-    def __init__(
-        self,
-        storage_types: NetworkElementsDict,
-        indices: Indices,
-        scale: float = 1.0,
-    ) -> None:
-        self.max_capacity = self.fetch_element_prop(
-            storage_types, indices.TSTOR, "max_capacity", sample=indices.Y.ii
-        )
-        """ storage max capacity in a given year """
-        self.min_capacity = self.fetch_element_prop(
-            storage_types, indices.TSTOR, "min_capacity", sample=indices.Y.ii
-        )
-        """ storage min capacity in a given year """
-        self.max_capacity_increase = self.fetch_element_prop(
-            storage_types, indices.TSTOR, "max_capacity_increase", sample=indices.Y.ii
-        )
-        """ storage capacity increase upper bound of capacity increase in a given year """
-        self.min_capacity_increase = self.fetch_element_prop(
-            storage_types, indices.TSTOR, "min_capacity_increase", sample=indices.Y.ii
-        )
-        """ storage capacity increase lower bound of capacity increase in a given year """
-        self.capex = self.scale(
-            self.fetch_element_prop(  # noqa
-                storage_types, indices.TSTOR, "capex", sample=indices.Y.ii
-            ),
-            scale,
-        )
-        """ storage type capex per capacity unit """
-        self.opex = self.scale(
-            self.fetch_element_prop(
-                storage_types, indices.TSTOR, "opex", sample=indices.Y.ii
-            ),
-            scale,
-        )
-        """ storage type opex per capacity unit """
-        self.lt = self.fetch_element_prop(
-            storage_types,
-            indices.TSTOR,
-            "life_time",
-        )
-        """ storage type life time """
-        self.bt = self.fetch_element_prop(
-            storage_types,
-            indices.TSTOR,
-            "build_time",
-        )
-        """ storage type build time """
-        self.energy_loss = self.fetch_element_prop(
-            storage_types, indices.TSTOR, "energy_loss", sample=indices.Y.ii
-        )
-        self.tags = self.get_set_prop_from_element(
-            storage_types, "tags", indices.TSTOR, indices.T_TAGS
-        )
-        """ storage type tags """
-        self.power_utilization = self.fetch_element_prop(
-            storage_types, indices.TSTOR, "power_utilization"
-        )
-        """ storage power utilization """
+# PyZefir
+# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+from dataclasses import dataclass
+
+from pyzefir.model.network import NetworkElementsDict
+from pyzefir.optimization.linopy.preprocessing.indices import Indices
+from pyzefir.optimization.linopy.preprocessing.parameters import ModelParameters
+
+
+@dataclass
+class StorageTypeParameters(ModelParameters):
+    """Storage Type parameters"""
+
+    def __init__(
+        self,
+        storage_types: NetworkElementsDict,
+        indices: Indices,
+        scale: float = 1.0,
+    ) -> None:
+        self.max_capacity = self.fetch_element_prop(
+            storage_types, indices.TSTOR, "max_capacity", sample=indices.Y.ii
+        )
+        """ storage max capacity in a given year """
+        self.min_capacity = self.fetch_element_prop(
+            storage_types, indices.TSTOR, "min_capacity", sample=indices.Y.ii
+        )
+        """ storage min capacity in a given year """
+        self.max_capacity_increase = self.fetch_element_prop(
+            storage_types, indices.TSTOR, "max_capacity_increase", sample=indices.Y.ii
+        )
+        """ storage capacity increase upper bound of capacity increase in a given year """
+        self.min_capacity_increase = self.fetch_element_prop(
+            storage_types, indices.TSTOR, "min_capacity_increase", sample=indices.Y.ii
+        )
+        """ storage capacity increase lower bound of capacity increase in a given year """
+        self.capex = self.scale(
+            self.fetch_element_prop(  # noqa
+                storage_types, indices.TSTOR, "capex", sample=indices.Y.ii
+            ),
+            scale,
+        )
+        """ storage type capex per capacity unit """
+        self.opex = self.scale(
+            self.fetch_element_prop(
+                storage_types, indices.TSTOR, "opex", sample=indices.Y.ii
+            ),
+            scale,
+        )
+        """ storage type opex per capacity unit """
+        self.lt = self.fetch_element_prop(
+            storage_types,
+            indices.TSTOR,
+            "life_time",
+        )
+        """ storage type life time """
+        self.bt = self.fetch_element_prop(
+            storage_types,
+            indices.TSTOR,
+            "build_time",
+        )
+        """ storage type build time """
+        self.energy_loss = self.fetch_element_prop(
+            storage_types, indices.TSTOR, "energy_loss", sample=indices.Y.ii
+        )
+        self.tags = self.get_set_prop_from_element(
+            storage_types, "tags", indices.TSTOR, indices.T_TAGS
+        )
+        """ storage type tags """
+        self.power_utilization = self.fetch_element_prop(
+            storage_types, indices.TSTOR, "power_utilization"
+        )
+        """ storage power utilization """
```

### Comparing `pyzefir-0.4.1/pyzefir/optimization/linopy/preprocessing/parameters/transmission_fee_parameters.py` & `pyzefir-0.4.22/pyzefir/optimization/linopy/preprocessing/parameters/emission_fee_parameters.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,38 +1,42 @@
-# PyZefir
-# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-from dataclasses import dataclass
-
-from pyzefir.model.network import NetworkElementsDict
-from pyzefir.optimization.linopy.preprocessing.indices import Indices
-from pyzefir.optimization.linopy.preprocessing.parameters import ModelParameters
-
-
-@dataclass
-class TransmissionFeeParameters(ModelParameters):
-    """Transmission fee parameters"""
-
-    def __init__(
-        self,
-        transmission_fees: NetworkElementsDict,
-        indices: Indices,
-        scale: float = 1.0,
-    ) -> None:
-        self.fee = self.fetch_element_prop(
-            transmission_fees, indices.TF, "fee", sample=indices.H.ii
-        )
-        """ transmission fee hourly profile; transmission_fee -> (h -> fee[y]) """
-        self.fee = self.scale(self.fee, scale)  # noqa
+# PyZefir
+# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+from dataclasses import dataclass
+
+import numpy as np
+
+from pyzefir.model.network import NetworkElementsDict
+from pyzefir.optimization.linopy.preprocessing.indices import Indices
+from pyzefir.optimization.linopy.preprocessing.parameters import ModelParameters
+
+
+@dataclass
+class EmissionFeeParameters(ModelParameters):
+    """Emission fee parameters"""
+
+    def __init__(
+        self,
+        emission_fees: NetworkElementsDict,
+        indices: Indices,
+        scale: float = 1.0,
+    ) -> None:
+        self.emission_type: dict[int, str] = self.fetch_element_prop(
+            d=emission_fees, II=indices.EMF, prop="emission_type"
+        )
+        self.price: dict[int, np.ndarray] = self.fetch_element_prop(
+            d=emission_fees, II=indices.EMF, prop="price", sample=indices.Y.ii
+        )
+        self.price = self.scale(self.price, scale)
```

### Comparing `pyzefir-0.4.1/pyzefir/optimization/linopy/preprocessing/utils.py` & `pyzefir-0.4.22/pyzefir/optimization/linopy/preprocessing/utils.py`

 * *Ordering differences only*

 * *Files 9% similar despite different names*

```diff
@@ -1,33 +1,33 @@
-# PyZefir
-# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-import numpy as np
-
-from pyzefir.model.network_elements.energy_source_types.generator_type import (
-    GeneratorType,
-)
-from pyzefir.model.network_elements.energy_source_types.storage_type import StorageType
-from pyzefir.model.network_elements.energy_sources.generator import Generator
-from pyzefir.model.network_elements.energy_sources.storage import Storage
-
-
-def create_unique_array_of_tags(
-    gen_items: list[Generator | GeneratorType],
-    storage_items: list[Storage | StorageType],
-) -> np.ndarray:
-    gen_tags = [t for ele in gen_items for t in ele.tags]
-    stor_tags = [t for ele in storage_items for t in ele.tags]
-    return np.unique(gen_tags + stor_tags)
+# PyZefir
+# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+import numpy as np
+
+from pyzefir.model.network_elements.energy_source_types.generator_type import (
+    GeneratorType,
+)
+from pyzefir.model.network_elements.energy_source_types.storage_type import StorageType
+from pyzefir.model.network_elements.energy_sources.generator import Generator
+from pyzefir.model.network_elements.energy_sources.storage import Storage
+
+
+def create_unique_array_of_tags(
+    gen_items: list[Generator | GeneratorType],
+    storage_items: list[Storage | StorageType],
+) -> np.ndarray:
+    gen_tags = [t for ele in gen_items for t in ele.tags]
+    stor_tags = [t for ele in storage_items for t in ele.tags]
+    return np.unique(gen_tags + stor_tags)
```

### Comparing `pyzefir-0.4.1/pyzefir/optimization/linopy/preprocessing/variables/__init__.py` & `pyzefir-0.4.22/pyzefir/optimization/linopy/preprocessing/variables/__init__.py`

 * *Ordering differences only*

 * *Files 12% similar despite different names*

```diff
@@ -1,21 +1,21 @@
-# PyZefir
-# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-from abc import ABC
-
-
-class VariableGroup(ABC):
-    pass
+# PyZefir
+# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+from abc import ABC
+
+
+class VariableGroup(ABC):
+    pass
```

### Comparing `pyzefir-0.4.1/pyzefir/optimization/linopy/preprocessing/variables/fraction_variables.py` & `pyzefir-0.4.22/pyzefir/optimization/linopy/preprocessing/variables/line_variables.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,39 +1,38 @@
-# PyZefir
-# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-import numpy as np
-import xarray as xr
-from linopy import Model
-
-from pyzefir.optimization.linopy.preprocessing.indices import Indices
-from pyzefir.optimization.linopy.preprocessing.variables import VariableGroup
-
-
-class FractionVariables(VariableGroup):
-    """Fraction variables"""
-
-    def __init__(self, model: Model, indices: Indices, binary_fraction: bool = False):
-        self.fraction = model.add_variables(
-            lower=xr.DataArray(
-                np.full((len(indices.AGGR), len(indices.LBS), len(indices.Y)), 0),
-                dims=["aggr", "lbs", "year"],
-                coords=[indices.AGGR.ii, indices.LBS.ii, indices.Y.ii],
-                name="fraction",
-            ),
-            name="FRACTION",
-            binary=binary_fraction,
-        )
-        """ fraction of local balancing stack in a given aggregated consumer """
+# PyZefir
+# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+import numpy as np
+import xarray as xr
+from linopy import Model
+
+from pyzefir.optimization.linopy.preprocessing.indices import Indices
+from pyzefir.optimization.linopy.preprocessing.variables import VariableGroup
+
+
+class LineVariables(VariableGroup):
+    """Line variables"""
+
+    def __init__(self, model: Model, indices: Indices):
+        self.flow = model.add_variables(
+            lower=xr.DataArray(
+                np.full((len(indices.LINE), len(indices.H), len(indices.Y)), 0),
+                dims=["line", "hour", "year"],
+                coords=[indices.LINE.ii, indices.H.ii, indices.Y.ii],
+                name="flow",
+            ),
+            name="L_FLOW",
+        )
+        """ line flow """
```

### Comparing `pyzefir-0.4.1/pyzefir/optimization/linopy/preprocessing/variables/generator_variables.py` & `pyzefir-0.4.22/pyzefir/optimization/linopy/preprocessing/variables/generator_variables.py`

 * *Ordering differences only*

 * *Files 25% similar despite different names*

```diff
@@ -1,157 +1,157 @@
-# PyZefir
-# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-from itertools import product
-
-import numpy as np
-import xarray as xr
-from linopy import Model
-
-from pyzefir.optimization.linopy.preprocessing.indices import Indices
-from pyzefir.optimization.linopy.preprocessing.variables import VariableGroup
-
-
-class GeneratorVariables(VariableGroup):
-    """Generator variables"""
-
-    def __init__(self, model: Model, indices: Indices) -> None:
-        self.gen = model.add_variables(
-            lower=xr.DataArray(
-                np.full((len(indices.GEN), len(indices.H), len(indices.Y)), 0),
-                dims=["gen", "hour", "year"],
-                coords=[indices.GEN.ii, indices.H.ii, indices.Y.ii],
-                name="gen",
-            ),
-            name="G_GEN",
-        )
-        """ generation """
-
-        self.gen_et = model.add_variables(
-            lower=xr.DataArray(
-                np.full(
-                    (len(indices.GEN), len(indices.ET), len(indices.H), len(indices.Y)),
-                    0,
-                ),
-                dims=["gen", "et", "hour", "year"],
-                coords=[indices.GEN.ii, indices.ET.ii, indices.H.ii, indices.Y.ii],
-                name="gen_et",
-            ),
-            name="G_GEN_ET",
-        )
-        """ energy_type -> generation[energy_type] """
-
-        self.gen_dch = model.add_variables(
-            lower=xr.DataArray(
-                np.full(
-                    (
-                        len(indices.ET),
-                        len(indices.DEMCH),
-                        len(indices.GEN),
-                        len(indices.H),
-                        len(indices.Y),
-                    ),
-                    0,
-                ),
-                dims=["et", "demch", "gen", "hour", "year"],
-                coords=[
-                    indices.ET.ii,
-                    indices.DEMCH.ii,
-                    indices.GEN.ii,
-                    indices.H.ii,
-                    indices.Y.ii,
-                ],
-                name="gen_dch",
-            ),
-            name="G_GEN_DCH",
-        )
-        """ generation to cover demand chunks """
-        self.dump = model.add_variables(
-            lower=xr.DataArray(
-                np.full((len(indices.GEN), len(indices.H), len(indices.Y)), 0),
-                dims=["gen", "hour", "year"],
-                coords=[indices.GEN.ii, indices.H.ii, indices.Y.ii],
-                name="dump",
-            ),
-            name="G_DUMP",
-        )
-        """ dump energy """
-        self.dump_et = model.add_variables(
-            lower=xr.DataArray(
-                np.full(
-                    (len(indices.GEN), len(indices.ET), len(indices.H), len(indices.Y)),
-                    0,
-                ),
-                dims=["gen", "et", "hour", "year"],
-                coords=[indices.GEN.ii, indices.ET.ii, indices.H.ii, indices.Y.ii],
-                name="dump_et",
-            ),
-            name="G_DUMP_ET",
-        )
-        """ energy_type -> dump[energy_type] """
-        self.cap = model.add_variables(
-            lower=xr.DataArray(
-                np.full((len(indices.GEN), len(indices.Y)), 0),
-                dims=["gen", "year"],
-                coords=[indices.GEN.ii, indices.Y.ii],
-                name="cap",
-            ),
-            name="G_CAP",
-        )
-        """ capacity """
-        non_aggr_gen_idx = set(indices.GEN.mapping.keys()) - {
-            aggr_gen_idx
-            for aggr_gen_idxs in indices.aggr_gen_map.values()
-            for aggr_gen_idx in aggr_gen_idxs
-        }
-        indexes = list(product(non_aggr_gen_idx, indices.Y.ord))
-        self.cap_plus = model.add_variables(
-            lower=xr.DataArray(
-                np.full(len(indexes), 0),
-                dims=["index"],
-                coords=dict(index=np.array(indexes, dtype="i,i")),
-                name="cap_plus",
-            ),
-            name="G_CAP_PLUS",
-        )
-        """ capacity increase """
-        self.cap_minus = model.add_variables(
-            lower=xr.DataArray(
-                np.full(len(indexes) * len(indices.Y), 0),
-                dims=["index"],
-                coords=dict(
-                    index=np.array(
-                        [
-                            index + (year,)
-                            for index, year in product(indexes, indices.Y.ii)
-                        ],
-                        dtype="i,i,i",
-                    ),
-                ),
-                name="cap_minus",
-            ),
-            name="G_CAP_MINUS",
-        )
-        """ capacity decrease """
-        self.cap_base_minus = model.add_variables(
-            lower=xr.DataArray(
-                np.full(len(indexes), 0),
-                dims=["index"],
-                coords=dict(index=np.array(indexes, dtype="i,i")),
-                name="cap_base_minus",
-            ),
-            name="G_CAP_BASE_MINUS",
-        )
-        """ base capacity decrease """
+# PyZefir
+# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+from itertools import product
+
+import numpy as np
+import xarray as xr
+from linopy import Model
+
+from pyzefir.optimization.linopy.preprocessing.indices import Indices
+from pyzefir.optimization.linopy.preprocessing.variables import VariableGroup
+
+
+class GeneratorVariables(VariableGroup):
+    """Generator variables"""
+
+    def __init__(self, model: Model, indices: Indices) -> None:
+        self.gen = model.add_variables(
+            lower=xr.DataArray(
+                np.full((len(indices.GEN), len(indices.H), len(indices.Y)), 0),
+                dims=["gen", "hour", "year"],
+                coords=[indices.GEN.ii, indices.H.ii, indices.Y.ii],
+                name="gen",
+            ),
+            name="G_GEN",
+        )
+        """ generation """
+
+        self.gen_et = model.add_variables(
+            lower=xr.DataArray(
+                np.full(
+                    (len(indices.GEN), len(indices.ET), len(indices.H), len(indices.Y)),
+                    0,
+                ),
+                dims=["gen", "et", "hour", "year"],
+                coords=[indices.GEN.ii, indices.ET.ii, indices.H.ii, indices.Y.ii],
+                name="gen_et",
+            ),
+            name="G_GEN_ET",
+        )
+        """ energy_type -> generation[energy_type] """
+
+        self.gen_dch = model.add_variables(
+            lower=xr.DataArray(
+                np.full(
+                    (
+                        len(indices.ET),
+                        len(indices.DEMCH),
+                        len(indices.GEN),
+                        len(indices.H),
+                        len(indices.Y),
+                    ),
+                    0,
+                ),
+                dims=["et", "demch", "gen", "hour", "year"],
+                coords=[
+                    indices.ET.ii,
+                    indices.DEMCH.ii,
+                    indices.GEN.ii,
+                    indices.H.ii,
+                    indices.Y.ii,
+                ],
+                name="gen_dch",
+            ),
+            name="G_GEN_DCH",
+        )
+        """ generation to cover demand chunks """
+        self.dump = model.add_variables(
+            lower=xr.DataArray(
+                np.full((len(indices.GEN), len(indices.H), len(indices.Y)), 0),
+                dims=["gen", "hour", "year"],
+                coords=[indices.GEN.ii, indices.H.ii, indices.Y.ii],
+                name="dump",
+            ),
+            name="G_DUMP",
+        )
+        """ dump energy """
+        self.dump_et = model.add_variables(
+            lower=xr.DataArray(
+                np.full(
+                    (len(indices.GEN), len(indices.ET), len(indices.H), len(indices.Y)),
+                    0,
+                ),
+                dims=["gen", "et", "hour", "year"],
+                coords=[indices.GEN.ii, indices.ET.ii, indices.H.ii, indices.Y.ii],
+                name="dump_et",
+            ),
+            name="G_DUMP_ET",
+        )
+        """ energy_type -> dump[energy_type] """
+        self.cap = model.add_variables(
+            lower=xr.DataArray(
+                np.full((len(indices.GEN), len(indices.Y)), 0),
+                dims=["gen", "year"],
+                coords=[indices.GEN.ii, indices.Y.ii],
+                name="cap",
+            ),
+            name="G_CAP",
+        )
+        """ capacity """
+        non_aggr_gen_idx = set(indices.GEN.mapping.keys()) - {
+            aggr_gen_idx
+            for aggr_gen_idxs in indices.aggr_gen_map.values()
+            for aggr_gen_idx in aggr_gen_idxs
+        }
+        indexes = list(product(non_aggr_gen_idx, indices.Y.ord))
+        self.cap_plus = model.add_variables(
+            lower=xr.DataArray(
+                np.full(len(indexes), 0),
+                dims=["index"],
+                coords=dict(index=np.array(indexes, dtype="i,i")),
+                name="cap_plus",
+            ),
+            name="G_CAP_PLUS",
+        )
+        """ capacity increase """
+        self.cap_minus = model.add_variables(
+            lower=xr.DataArray(
+                np.full(len(indexes) * len(indices.Y), 0),
+                dims=["index"],
+                coords=dict(
+                    index=np.array(
+                        [
+                            index + (year,)
+                            for index, year in product(indexes, indices.Y.ii)
+                        ],
+                        dtype="i,i,i",
+                    ),
+                ),
+                name="cap_minus",
+            ),
+            name="G_CAP_MINUS",
+        )
+        """ capacity decrease """
+        self.cap_base_minus = model.add_variables(
+            lower=xr.DataArray(
+                np.full(len(indexes), 0),
+                dims=["index"],
+                coords=dict(index=np.array(indexes, dtype="i,i")),
+                name="cap_base_minus",
+            ),
+            name="G_CAP_BASE_MINUS",
+        )
+        """ base capacity decrease """
```

### Comparing `pyzefir-0.4.1/pyzefir/optimization/linopy/preprocessing/variables/line_variables.py` & `pyzefir-0.4.22/pyzefir/structure_creator/structure_and_initial_state/utils.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,38 +1,26 @@
-# PyZefir
-# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-import numpy as np
-import xarray as xr
-from linopy import Model
-
-from pyzefir.optimization.linopy.preprocessing.indices import Indices
-from pyzefir.optimization.linopy.preprocessing.variables import VariableGroup
-
-
-class LineVariables(VariableGroup):
-    """Line variables"""
-
-    def __init__(self, model: Model, indices: Indices):
-        self.flow = model.add_variables(
-            lower=xr.DataArray(
-                np.full((len(indices.LINE), len(indices.H), len(indices.Y)), 0),
-                dims=["line", "hour", "year"],
-                coords=[indices.LINE.ii, indices.H.ii, indices.Y.ii],
-                name="flow",
-            ),
-            name="L_FLOW",
-        )
-        """ line flow """
+# PyZefir
+# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+
+import pandas as pd
+
+
+def handle_prefix_name(name: str) -> str:
+    return f"{name.replace(' ', '_')}_"
+
+
+def join_energy_types(types: pd.Series) -> str:
+    return ", ".join(set(types))
```

### Comparing `pyzefir-0.4.1/pyzefir/optimization/linopy/preprocessing/variables/storage_type_variables.py` & `pyzefir-0.4.22/pyzefir/optimization/linopy/preprocessing/variables/storage_type_variables.py`

 * *Ordering differences only*

 * *Files 18% similar despite different names*

```diff
@@ -1,88 +1,88 @@
-# PyZefir
-# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-from itertools import product
-
-import numpy as np
-import xarray as xr
-from linopy import Model
-
-from pyzefir.optimization.linopy.preprocessing.indices import Indices
-from pyzefir.optimization.linopy.preprocessing.variables import VariableGroup
-
-
-class StorageTypeVariables(VariableGroup):
-    """StorageType variables"""
-
-    def __init__(self, model: Model, indices: Indices) -> None:
-        indexes = [
-            (aggr_idx, aggr_stor_type_idx, year_idx)
-            for aggr_idx, aggr_stor_type_idxs in indices.aggr_tstor_map.items()
-            for aggr_stor_type_idx in aggr_stor_type_idxs
-            for year_idx in indices.Y.ord
-        ]
-
-        self.tcap = model.add_variables(
-            lower=xr.DataArray(
-                np.full(len(indexes), 0),
-                dims=["index"],
-                coords=dict(index=np.array(indexes, dtype="i,i,i")),
-                name="tcap",
-            ),
-            name="STOR_TYPE_CAP",
-        )
-        """ storage type capacity """
-
-        self.tcap_plus = model.add_variables(
-            lower=xr.DataArray(
-                np.full(len(indexes), 0),
-                dims=["index"],
-                coords=dict(index=np.array(indexes, dtype="i,i,i")),
-                name="tcap_plus",
-            ),
-            name="STOR_TYPE_CAP_PLUS",
-        )
-        """ storage type capacity increase """
-
-        self.tcap_minus = model.add_variables(
-            lower=xr.DataArray(
-                np.full(len(indexes) * len(indices.Y), 0),
-                dims=["index"],
-                coords=dict(
-                    index=np.array(
-                        [
-                            index + (year,)
-                            for index, year in product(indexes, indices.Y.ii)
-                        ],
-                        dtype="i,i,i,i",
-                    ),
-                ),
-                name="tcap_minus",
-            ),
-            name="STOR_TYPE_CAP_MINUS",
-        )
-        """ storage type capacity decrease """
-
-        self.tcap_base_minus = model.add_variables(
-            lower=xr.DataArray(
-                np.full(len(indexes), 0),
-                dims=["index"],
-                coords=dict(index=np.array(indexes, dtype="i,i,i")),
-                name="tcap_base_minus",
-            ),
-            name="STOR_TYPE_CAP_BASE_MINUS",
-        )
-        """ storage type base capacity decrease """
+# PyZefir
+# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+from itertools import product
+
+import numpy as np
+import xarray as xr
+from linopy import Model
+
+from pyzefir.optimization.linopy.preprocessing.indices import Indices
+from pyzefir.optimization.linopy.preprocessing.variables import VariableGroup
+
+
+class StorageTypeVariables(VariableGroup):
+    """StorageType variables"""
+
+    def __init__(self, model: Model, indices: Indices) -> None:
+        indexes = [
+            (aggr_idx, aggr_stor_type_idx, year_idx)
+            for aggr_idx, aggr_stor_type_idxs in indices.aggr_tstor_map.items()
+            for aggr_stor_type_idx in aggr_stor_type_idxs
+            for year_idx in indices.Y.ord
+        ]
+
+        self.tcap = model.add_variables(
+            lower=xr.DataArray(
+                np.full(len(indexes), 0),
+                dims=["index"],
+                coords=dict(index=np.array(indexes, dtype="i,i,i")),
+                name="tcap",
+            ),
+            name="STOR_TYPE_CAP",
+        )
+        """ storage type capacity """
+
+        self.tcap_plus = model.add_variables(
+            lower=xr.DataArray(
+                np.full(len(indexes), 0),
+                dims=["index"],
+                coords=dict(index=np.array(indexes, dtype="i,i,i")),
+                name="tcap_plus",
+            ),
+            name="STOR_TYPE_CAP_PLUS",
+        )
+        """ storage type capacity increase """
+
+        self.tcap_minus = model.add_variables(
+            lower=xr.DataArray(
+                np.full(len(indexes) * len(indices.Y), 0),
+                dims=["index"],
+                coords=dict(
+                    index=np.array(
+                        [
+                            index + (year,)
+                            for index, year in product(indexes, indices.Y.ii)
+                        ],
+                        dtype="i,i,i,i",
+                    ),
+                ),
+                name="tcap_minus",
+            ),
+            name="STOR_TYPE_CAP_MINUS",
+        )
+        """ storage type capacity decrease """
+
+        self.tcap_base_minus = model.add_variables(
+            lower=xr.DataArray(
+                np.full(len(indexes), 0),
+                dims=["index"],
+                coords=dict(index=np.array(indexes, dtype="i,i,i")),
+                name="tcap_base_minus",
+            ),
+            name="STOR_TYPE_CAP_BASE_MINUS",
+        )
+        """ storage type base capacity decrease """
```

### Comparing `pyzefir-0.4.1/pyzefir/optimization/linopy/preprocessing/variables/storage_variables.py` & `pyzefir-0.4.22/pyzefir/optimization/linopy/preprocessing/variables/storage_variables.py`

 * *Ordering differences only*

 * *Files 20% similar despite different names*

```diff
@@ -1,137 +1,137 @@
-# PyZefir
-# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-from itertools import product
-
-import numpy as np
-import xarray as xr
-from linopy import Model
-
-from pyzefir.optimization.linopy.preprocessing.indices import Indices
-from pyzefir.optimization.linopy.preprocessing.variables import VariableGroup
-
-
-class StorageVariables(VariableGroup):
-    """Storage variables"""
-
-    def __init__(self, model: Model, indices: Indices) -> None:
-        self.gen = model.add_variables(
-            lower=xr.DataArray(
-                np.full((len(indices.STOR), len(indices.H), len(indices.Y)), 0),
-                dims=["stor", "hour", "year"],
-                coords=[indices.STOR.ii, indices.H.ii, indices.Y.ii],
-                name="gen",
-            ),
-            name="S_GEN",
-        )
-        """ generation """
-
-        self.gen_dch = model.add_variables(
-            lower=xr.DataArray(
-                np.full(
-                    (
-                        len(indices.DEMCH),
-                        len(indices.STOR),
-                        len(indices.H),
-                        len(indices.Y),
-                    ),
-                    0,
-                ),
-                dims=["demch", "stor", "hour", "year"],
-                coords=[indices.DEMCH.ii, indices.STOR.ii, indices.H.ii, indices.Y.ii],
-                name="gen_dch",
-            ),
-            name="S_GEN_DCH",
-        )
-        """ generation to cover demand chunks """
-
-        self.load = model.add_variables(
-            lower=xr.DataArray(
-                np.full((len(indices.STOR), len(indices.H), len(indices.Y)), 0),
-                dims=["stor", "hour", "year"],
-                coords=[indices.STOR.ii, indices.H.ii, indices.Y.ii],
-                name="load",
-            ),
-            name="S_LOAD",
-        )
-        """ load """
-
-        self.soc = model.add_variables(
-            lower=xr.DataArray(
-                np.full((len(indices.STOR), len(indices.H), len(indices.Y)), 0),
-                dims=["stor", "hour", "year"],
-                coords=[indices.STOR.ii, indices.H.ii, indices.Y.ii],
-                name="soc",
-            ),
-            name="S_SOC",
-        )
-        """ state of charge """
-
-        self.cap = model.add_variables(
-            lower=xr.DataArray(
-                np.full((len(indices.STOR), len(indices.Y)), 0),
-                dims=["stor", "year"],
-                coords=[indices.STOR.ii, indices.Y.ii],
-                name="cap",
-            ),
-            name="S_CAP",
-        )
-        """ capacity """
-
-        non_aggr_stor_idx = set(indices.STOR.mapping.keys()) - {
-            aggr_stor_idx
-            for aggr_stor_idxs in indices.aggr_stor_map.values()
-            for aggr_stor_idx in aggr_stor_idxs
-        }
-        indexes = list(product(non_aggr_stor_idx, indices.Y.ord))
-
-        self.cap_plus = model.add_variables(
-            lower=xr.DataArray(
-                np.full(len(indexes), 0),
-                dims=["index"],
-                coords=dict(index=np.array(indexes, dtype="i,i")),
-                name="cap_plus",
-            ),
-            name="S_CAP_PLUS",
-        )
-        """ capacity increase """
-
-        self.cap_minus = model.add_variables(
-            lower=xr.DataArray(
-                np.full(len(indexes) * len(indices.Y), 0),
-                dims=["index"],
-                coords=dict(
-                    index=np.array(
-                        list(product(non_aggr_stor_idx, indices.Y.ord, indices.Y.ord)),
-                        dtype="i,i,i",
-                    )
-                ),
-                name="cap_minus",
-            ),
-            name="S_CAP_MINUS",
-        )
-        """ capacity decrease """
-
-        self.cap_base_minus = model.add_variables(
-            lower=xr.DataArray(
-                np.full(len(indexes), 0),
-                dims=["index"],
-                coords=dict(index=np.array(indexes, dtype="i,i")),
-                name="cap_base_minus",
-            ),
-            name="S_CAP_BASE_MINUS",
-        )
-        """ base capacity decrease """
+# PyZefir
+# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+from itertools import product
+
+import numpy as np
+import xarray as xr
+from linopy import Model
+
+from pyzefir.optimization.linopy.preprocessing.indices import Indices
+from pyzefir.optimization.linopy.preprocessing.variables import VariableGroup
+
+
+class StorageVariables(VariableGroup):
+    """Storage variables"""
+
+    def __init__(self, model: Model, indices: Indices) -> None:
+        self.gen = model.add_variables(
+            lower=xr.DataArray(
+                np.full((len(indices.STOR), len(indices.H), len(indices.Y)), 0),
+                dims=["stor", "hour", "year"],
+                coords=[indices.STOR.ii, indices.H.ii, indices.Y.ii],
+                name="gen",
+            ),
+            name="S_GEN",
+        )
+        """ generation """
+
+        self.gen_dch = model.add_variables(
+            lower=xr.DataArray(
+                np.full(
+                    (
+                        len(indices.DEMCH),
+                        len(indices.STOR),
+                        len(indices.H),
+                        len(indices.Y),
+                    ),
+                    0,
+                ),
+                dims=["demch", "stor", "hour", "year"],
+                coords=[indices.DEMCH.ii, indices.STOR.ii, indices.H.ii, indices.Y.ii],
+                name="gen_dch",
+            ),
+            name="S_GEN_DCH",
+        )
+        """ generation to cover demand chunks """
+
+        self.load = model.add_variables(
+            lower=xr.DataArray(
+                np.full((len(indices.STOR), len(indices.H), len(indices.Y)), 0),
+                dims=["stor", "hour", "year"],
+                coords=[indices.STOR.ii, indices.H.ii, indices.Y.ii],
+                name="load",
+            ),
+            name="S_LOAD",
+        )
+        """ load """
+
+        self.soc = model.add_variables(
+            lower=xr.DataArray(
+                np.full((len(indices.STOR), len(indices.H), len(indices.Y)), 0),
+                dims=["stor", "hour", "year"],
+                coords=[indices.STOR.ii, indices.H.ii, indices.Y.ii],
+                name="soc",
+            ),
+            name="S_SOC",
+        )
+        """ state of charge """
+
+        self.cap = model.add_variables(
+            lower=xr.DataArray(
+                np.full((len(indices.STOR), len(indices.Y)), 0),
+                dims=["stor", "year"],
+                coords=[indices.STOR.ii, indices.Y.ii],
+                name="cap",
+            ),
+            name="S_CAP",
+        )
+        """ capacity """
+
+        non_aggr_stor_idx = set(indices.STOR.mapping.keys()) - {
+            aggr_stor_idx
+            for aggr_stor_idxs in indices.aggr_stor_map.values()
+            for aggr_stor_idx in aggr_stor_idxs
+        }
+        indexes = list(product(non_aggr_stor_idx, indices.Y.ord))
+
+        self.cap_plus = model.add_variables(
+            lower=xr.DataArray(
+                np.full(len(indexes), 0),
+                dims=["index"],
+                coords=dict(index=np.array(indexes, dtype="i,i")),
+                name="cap_plus",
+            ),
+            name="S_CAP_PLUS",
+        )
+        """ capacity increase """
+
+        self.cap_minus = model.add_variables(
+            lower=xr.DataArray(
+                np.full(len(indexes) * len(indices.Y), 0),
+                dims=["index"],
+                coords=dict(
+                    index=np.array(
+                        list(product(non_aggr_stor_idx, indices.Y.ord, indices.Y.ord)),
+                        dtype="i,i,i",
+                    )
+                ),
+                name="cap_minus",
+            ),
+            name="S_CAP_MINUS",
+        )
+        """ capacity decrease """
+
+        self.cap_base_minus = model.add_variables(
+            lower=xr.DataArray(
+                np.full(len(indexes), 0),
+                dims=["index"],
+                coords=dict(index=np.array(indexes, dtype="i,i")),
+                name="cap_base_minus",
+            ),
+            name="S_CAP_BASE_MINUS",
+        )
+        """ base capacity decrease """
```

### Comparing `pyzefir-0.4.1/pyzefir/optimization/opt_config.py` & `pyzefir-0.4.22/pyzefir/optimization/opt_config.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,146 +1,159 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-from pathlib import Path
-
-from numpy import arange, diff, ndarray, zeros
-from numpy.random import choice
-
-
-class OptConfigError(Exception):
-    pass
-
-
-class OptConfigErrorGroup(OptConfigError, ExceptionGroup):
-    pass
-
-
-class OptConfig:
-    """
-    Class containing the configuration for an optimization engine setup and run
-    """
-
-    def __init__(
-        self,
-        hours: int | ndarray,
-        years: int | ndarray,
-        discount_rate: ndarray | None = None,
-        hour_sample: int | ndarray | None = None,
-        year_sample: int | ndarray | None = None,
-        sol_dump_path: Path | None = None,
-        opt_logs_dump_path: Path | None = None,
-        money_scale: float = 1.0,
-        ens: bool = True,
-        use_hourly_scale: bool = True,
-        solver_name: str | None = None,
-    ):
-        self.hours: ndarray = hours if isinstance(hours, ndarray) else arange(hours)
-        """ sequence of all hours in a year """
-        self.years: ndarray = years if isinstance(years, ndarray) else arange(years)
-        """ sequence of all years """
-        self.sol_dump_path: Path | None = sol_dump_path
-        """ path where *.sol file will be dumped """
-        self.opt_logs_dump_path: Path | None = opt_logs_dump_path
-        """ path where linopy log file will be dumped """
-        self.discount_rate: ndarray = (
-            discount_rate if isinstance(discount_rate, ndarray) else zeros(years)
-        )
-        """ capital discount rate """
-        self.hour_sample: ndarray = self.get_sample(
-            self.hours, hour_sample, use_arange=False
-        )
-        """ subsequence of hours sequence (sample of hours that will be used in the model) """
-        self.year_sample: ndarray = self.get_sample(
-            self.years, year_sample, use_arange=True
-        )
-        """ subsequence of years sequence (sample of years that will be used in the model) """
-        self.money_scale = money_scale
-        """ numeric scale parameter """
-        self.ens = ens
-        """ use ens associated with buses if not balanced """
-        self.hourly_scale: float = (
-            len(self.hours) / len(self.hour_sample) if use_hourly_scale else 1.0
-        )
-        """ ratio of the total number of hours to the total number of hours in given sample"""
-        self.solver_name: str | None = solver_name
-        """ name of the solver to be used """
-        self.validate()
-
-    def validate(self) -> None:
-        """
-        validate if discount_rate, hours and years are 1D arrays
-        validate if discount_rate and years have the same shape
-        validate ens type
-        validate if money_scale is >= 1
-        validate if year_sample is consecutive
-        """
-        exception_list: list[OptConfigError] = []
-        if (
-            not len(self.discount_rate.shape)
-            == len(self.hours.shape)
-            == len(self.years.shape)
-            == 1
-        ):
-            exception_list.append(
-                OptConfigError("discount_rate, hours and years must be 1D arrays")
-            )
-        if not self.discount_rate.shape == self.years.shape:
-            exception_list.append(
-                OptConfigError("discount_rate shape is different than years shape")
-            )
-        if not isinstance(self.ens, bool):
-            exception_list.append(
-                OptConfigError(
-                    f"ens flag must be of type bool, "
-                    f"but it is {type(self.ens).__name__} instead"
-                )
-            )
-        if self.money_scale < 1:
-            exception_list.append(
-                OptConfigError("money scale must be greater or equal 1")
-            )
-
-        if not (diff(self.year_sample) == 1).all() or self.year_sample[0] != 0:
-            exception_list.append(
-                OptConfigError("year sample must be consecutive starting from 0")
-            )
-
-        if exception_list:
-            raise OptConfigErrorGroup("Errors in configuration: ", exception_list)
-
-    @staticmethod
-    def get_sample(
-        idx: ndarray, sample: int | ndarray | None, use_arange: bool = False
-    ) -> ndarray:
-        if isinstance(sample, int):
-            if use_arange:
-                if sample <= len(idx):
-                    result = arange(sample)
-                else:
-                    raise OptConfigError(
-                        f"year sample {sample} must be less than or equal to year shape {len(idx)}"
-                    )
-            else:
-                result = choice(idx.shape[0], sample, replace=False)
-        elif isinstance(sample, ndarray):
-            result = sample
-        elif sample is None:
-            result = idx
-        else:
-            raise OptConfigError(
-                f"sample must be {int}, {ndarray} or {None}, but is of type {type(sample)}"
-            )
-        return result
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+import logging
+from pathlib import Path
+from typing import Any
+
+import numpy as np
+from numpy import arange, diff, ndarray, zeros
+from numpy.random import choice
+
+_logger = logging.getLogger(__name__)
+
+
+class OptConfigError(Exception):
+    pass
+
+
+class OptConfigErrorGroup(OptConfigError, ExceptionGroup):
+    pass
+
+
+class OptConfig:
+    """
+    Class containing the configuration for an optimization engine setup and run
+    """
+
+    def __init__(
+        self,
+        hours: int | ndarray,
+        years: int | ndarray,
+        discount_rate: ndarray | None = None,
+        hour_sample: int | ndarray | None = None,
+        year_sample: int | ndarray | None = None,
+        sol_dump_path: Path | None = None,
+        opt_logs_dump_path: Path | None = None,
+        money_scale: float = 1.0,
+        ens: float = np.nan,
+        use_hourly_scale: bool = True,
+        solver_name: str | None = None,
+        solver_settings: dict[str, dict[str, Any]] | None = None,
+    ):
+        self.hours: ndarray = hours if isinstance(hours, ndarray) else arange(hours)
+        """ sequence of all hours in a year """
+        self.years: ndarray = years if isinstance(years, ndarray) else arange(years)
+        """ sequence of all years """
+        self.sol_dump_path: Path | None = sol_dump_path
+        """ path where *.sol file will be dumped """
+        self.opt_logs_dump_path: Path | None = opt_logs_dump_path
+        """ path where linopy log file will be dumped """
+        self.discount_rate: ndarray = (
+            discount_rate if isinstance(discount_rate, ndarray) else zeros(years)
+        )
+        """ capital discount rate """
+        self.hour_sample: ndarray = self.get_sample(
+            self.hours, hour_sample, use_arange=False
+        )
+        """ subsequence of hours sequence (sample of hours that will be used in the model) """
+        self.year_sample: ndarray = self.get_sample(
+            self.years, year_sample, use_arange=True
+        )
+        """ subsequence of years sequence (sample of years that will be used in the model) """
+        self.money_scale = money_scale
+        """ numeric scale parameter """
+        self.ens = ens
+        """ use ens associated with buses if not balanced """
+        self.hourly_scale: float = (
+            len(self.hours) / len(self.hour_sample) if use_hourly_scale else 1.0
+        )
+        """ ratio of the total number of hours to the total number of hours in given sample"""
+        self.solver_name: str | None = solver_name
+        """ name of the solver to be used """
+        self.solver_settings: dict[str, dict[str, Any]] = (
+            solver_settings if solver_settings else {}
+        )
+        """ settings for the solvers """
+        self.validate()
+
+    def validate(self) -> None:
+        """
+        validate if discount_rate, hours and years are 1D arrays
+        validate if discount_rate and years have the same shape
+        validate ens type
+        validate if money_scale is >= 1
+        validate if year_sample is consecutive
+        """
+        exception_list: list[OptConfigError] = []
+        if (
+            not len(self.discount_rate.shape)
+            == len(self.hours.shape)
+            == len(self.years.shape)
+            == 1
+        ):
+            exception_list.append(
+                OptConfigError("discount_rate, hours and years must be 1D arrays")
+            )
+        if not self.discount_rate.shape == self.years.shape:
+            exception_list.append(
+                OptConfigError("discount_rate shape is different than years shape")
+            )
+        if not isinstance(self.ens, float):
+            exception_list.append(
+                OptConfigError(
+                    f"ens flag must be of type float, "
+                    f"but it is {type(self.ens).__name__} instead"
+                )
+            )
+        if self.money_scale < 1:
+            exception_list.append(
+                OptConfigError("money scale must be greater or equal 1")
+            )
+
+        if not np.all(diff(self.year_sample) == 1) or self.year_sample[0] != 0:
+            exception_list.append(
+                OptConfigError("year sample must be consecutive starting from 0")
+            )
+
+        if exception_list:
+            _logger.exception(
+                "Got error in optimization configuration: %s", exception_list
+            )
+            raise OptConfigErrorGroup("Errors in configuration: ", exception_list)
+        _logger.info("Optimalization configuration validation: OK")
+
+    @staticmethod
+    def get_sample(
+        idx: ndarray, sample: int | ndarray | None, use_arange: bool = False
+    ) -> ndarray:
+        if isinstance(sample, int):
+            if use_arange:
+                if sample <= len(idx):
+                    result = arange(sample)
+                else:
+                    raise OptConfigError(
+                        f"year sample {sample} must be less than or equal to year shape {len(idx)}"
+                    )
+            else:
+                result = choice(idx.shape[0], sample, replace=False)
+        elif isinstance(sample, ndarray):
+            result = sample
+        elif sample is None:
+            result = idx
+        else:
+            raise OptConfigError(
+                f"sample must be {int}, {ndarray} or {None}, but is of type {type(sample)}"
+            )
+        return result
```

### Comparing `pyzefir-0.4.1/pyzefir/parser/__init__.py` & `pyzefir-0.4.22/pyzefir/optimization/__init__.py`

 * *Ordering differences only*

 * *Files 23% similar despite different names*

```diff
@@ -1,15 +1,15 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
```

### Comparing `pyzefir-0.4.1/pyzefir/parser/csv_parser.py` & `pyzefir-0.4.22/pyzefir/parser/csv_parser.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,95 +1,105 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-import logging
-from pathlib import Path
-
-import pandas as pd
-
-from pyzefir.parser.utils import TRUE_VALUES
-from pyzefir.parser.validator.dataframe_validator import DataFrameValidator
-from pyzefir.parser.validator.valid_structure import (
-    get_dataset_config_from_categories,
-    get_dataset_reference,
-)
-from pyzefir.utils.path_manager import (
-    CsvPathManager,
-    DataCategories,
-    get_datasets_from_categories,
-)
-
-logger = logging.getLogger(__name__)
-
-
-class CsvParserException(Exception):
-    pass
-
-
-class CsvParser:
-    def __init__(self, path_manager: CsvPathManager) -> None:
-        self._path_manager = path_manager
-
-    def load_dfs(self) -> dict[str, dict[str, pd.DataFrame]]:
-        name_df_dict: dict[str, dict[str, pd.DataFrame]] = dict()
-        for category in DataCategories.get_main_categories():
-            name_df_dict[category] = self._get_dfs_from_category(category=category)
-        logger.debug("Entire set of dfs is valid and uploaded")
-        return name_df_dict
-
-    def _get_dfs_from_category(self, category: str) -> dict[str, pd.DataFrame]:
-        category_dict = dict()
-        if category in DataCategories.get_dynamic_categories():
-            for csv_path in self._path_manager.get_path(category).glob("*.csv"):
-                dataset_name = csv_path.stem
-                df = self._read_and_validate_csv_file(
-                    category=category, dataset_name=dataset_name, csv_path=csv_path
-                )
-                category_dict[dataset_name] = df
-        else:
-            for dataset_name in get_datasets_from_categories(data_category=category):
-                csv_path = self._path_manager.get_path(
-                    data_category=category, dataset_name=dataset_name
-                )
-                df = self._read_and_validate_csv_file(
-                    category=category, dataset_name=dataset_name, csv_path=csv_path
-                )
-                category_dict[dataset_name] = df
-
-        return category_dict
-
-    @staticmethod
-    def _read_and_validate_csv_file(
-        category: str, dataset_name: str, csv_path: Path
-    ) -> pd.DataFrame:
-        if not csv_path.is_file():
-            logger.error(f"File {dataset_name}.csv not found")
-            raise CsvParserException(f"Required file: {csv_path} does not exists ")
-        df = pd.read_csv(csv_path, true_values=TRUE_VALUES)
-        if df.empty:
-            return df
-        columns_dict = {col: dtype.name for col, dtype in df.dtypes.items()}
-        columns_valid_config = get_dataset_config_from_categories(
-            category, dataset_name
-        )
-        dataset_reference = get_dataset_reference(category, dataset_name)
-        DataFrameValidator(
-            df=df,
-            dataframe_structure=columns_dict,
-            valid_structure=columns_valid_config,
-            dataset_reference=dataset_reference,
-        ).validate()
-        logger.debug(f"Dataframe {dataset_name} is valid")
-        return df
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+import logging
+from pathlib import Path
+
+import pandas as pd
+
+from pyzefir.parser.utils import TRUE_VALUES
+from pyzefir.parser.validator.dataframe_validator import DataFrameValidator
+from pyzefir.parser.validator.valid_structure import (
+    get_dataset_config_from_categories,
+    get_dataset_reference,
+)
+from pyzefir.utils.path_manager import (
+    CsvPathManager,
+    DataCategories,
+    get_datasets_from_categories,
+    get_optional_datasets_from_categories,
+)
+
+logger = logging.getLogger(__name__)
+
+
+class CsvParserException(Exception):
+    pass
+
+
+class CsvParser:
+    def __init__(self, path_manager: CsvPathManager) -> None:
+        self._path_manager = path_manager
+
+    def load_dfs(self) -> dict[str, dict[str, pd.DataFrame]]:
+        name_df_dict: dict[str, dict[str, pd.DataFrame]] = dict()
+        for category in DataCategories.get_main_categories():
+            name_df_dict[category] = self._get_dfs_from_category(category=category)
+        logger.debug("Entire set of dfs is valid and uploaded")
+        return name_df_dict
+
+    def _get_dfs_from_category(self, category: str) -> dict[str, pd.DataFrame]:
+        category_dict = dict()
+        if category in DataCategories.get_dynamic_categories():
+            for csv_path in self._path_manager.get_path(category).glob("*.csv"):
+                dataset_name = csv_path.stem
+                df = self._read_and_validate_csv_file(
+                    category=category, dataset_name=dataset_name, csv_path=csv_path
+                )
+                df.columns = df.columns.astype(str)
+                category_dict[dataset_name] = df
+        else:
+            for dataset_name in get_datasets_from_categories(data_category=category):
+                csv_path = self._path_manager.get_path(
+                    data_category=category, dataset_name=dataset_name
+                )
+                df = self._read_and_validate_csv_file(
+                    category=category, dataset_name=dataset_name, csv_path=csv_path
+                )
+                df.columns = df.columns.astype(str)
+                category_dict[dataset_name] = df
+
+        return category_dict
+
+    @staticmethod
+    def _read_and_validate_csv_file(
+        category: str, dataset_name: str, csv_path: Path
+    ) -> pd.DataFrame:
+        if not csv_path.is_file():
+            if dataset_name in get_optional_datasets_from_categories(category):
+                columns = get_dataset_config_from_categories(
+                    category, dataset_name
+                ).columns
+                return pd.DataFrame(
+                    {col: pd.Series(dtype=dtype) for col, dtype in columns.items()}
+                )
+            logger.error(f"File {dataset_name}.csv not found")
+            raise CsvParserException(f"Required file: {csv_path} does not exists ")
+        df = pd.read_csv(csv_path, true_values=TRUE_VALUES)
+        if df.empty:
+            return df
+        columns_dict = {col: dtype.name for col, dtype in df.dtypes.items()}
+        columns_valid_config = get_dataset_config_from_categories(
+            category, dataset_name
+        )
+        dataset_reference = get_dataset_reference(category, dataset_name)
+        DataFrameValidator(
+            df=df,
+            dataframe_structure=columns_dict,
+            valid_structure=columns_valid_config,
+            dataset_reference=dataset_reference,
+        ).validate()
+        logger.debug(f"Dataframe {dataset_name} is valid")
+        return df
```

### Comparing `pyzefir-0.4.1/pyzefir/parser/elements_parsers/__init__.py` & `pyzefir-0.4.22/pyzefir/parser/__init__.py`

 * *Ordering differences only*

 * *Files 23% similar despite different names*

```diff
@@ -1,15 +1,15 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
```

### Comparing `pyzefir-0.4.1/pyzefir/parser/elements_parsers/aggregated_consumer_parser.py` & `pyzefir-0.4.22/pyzefir/parser/elements_parsers/aggregated_consumer_parser.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,178 +1,179 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-from collections import defaultdict
-
-import numpy as np
-import pandas as pd
-
-from pyzefir.model.network_elements import AggregatedConsumer
-from pyzefir.parser.elements_parsers.element_parser import AbstractElementParser
-from pyzefir.parser.utils import sanitize_dataset_name
-
-
-class AggregatedConsumerParser(AbstractElementParser):
-    def __init__(
-        self,
-        aggregated_consumer_df: pd.DataFrame,
-        stack_df: pd.DataFrame,
-        stack_fraction_df: pd.DataFrame,
-        yearly_energy_usage_df: pd.DataFrame,
-        fraction_df: pd.DataFrame,
-        number_of_years: int,
-        n_consumers: pd.DataFrame,
-    ) -> None:
-        self.stack_fraction_df = stack_fraction_df
-        self.stack_df = stack_df
-        self.aggregated_consumer_df = aggregated_consumer_df
-        self.yearly_energy_usage_df = yearly_energy_usage_df
-        self.fraction_df = fraction_df
-        self._years = number_of_years
-        self.n_consumers = n_consumers
-
-    def create(self) -> tuple[AggregatedConsumer, ...]:
-        n_consumers = self._create_consumers(self.n_consumers, self._years)
-        fraction = self._create_fractions(self.stack_df, self.fraction_df, self._years)
-        stack_base_fractions = self._create_stack_base_fractions(
-            self.stack_fraction_df, self.stack_df
-        )
-        yearly_energy_usage = self._create_yearly_energy_usage(
-            self.yearly_energy_usage_df
-        )
-        aggregated_consumers = self.aggregated_consumer_df.apply(
-            self._create_aggregated_consumer,
-            axis=1,
-            args=(
-                stack_base_fractions,
-                yearly_energy_usage,
-                fraction,
-                n_consumers,
-                self._years,
-            ),
-        )
-        return tuple(aggregated_consumers)
-
-    @staticmethod
-    def _create_consumers(
-        consumers_df: pd.DataFrame, n_years: int
-    ) -> dict[str, pd.Series]:
-        return (
-            consumers_df.set_index("year_idx").reindex(range(n_years)).to_dict("series")
-        )
-
-    @staticmethod
-    def _create_fractions(
-        stack_df: pd.DataFrame, fraction_df: pd.DataFrame, years: int
-    ) -> dict[str, dict[str, dict[str, pd.Series]]]:
-        """Creates aggregate_fraction dict for every AggregatedConsumer"""
-        fractions_df = stack_df.merge(fraction_df, how="left")
-        fractions_dict: dict[str, dict[str, dict[str, pd.Series]]] = dict()
-        grouped = fractions_df.groupby(["technology_stack", "aggregate"])
-        fraction_attributes = [
-            "min_fraction",
-            "max_fraction",
-            "max_fraction_decrease",
-            "max_fraction_increase",
-        ]
-        for fraction_attr in fraction_attributes:
-            fractions_attr_dict: dict[str, dict[str, pd.Series]] = dict()
-            if fraction_attr not in fraction_df.columns:
-                fractions_dict[fraction_attr] = dict()
-                continue
-            for (tech_stack, aggregate), group_data in grouped:
-                year_series = group_data.set_index("year")[fraction_attr]
-                fraction_series = pd.Series(index=range(years), dtype=float)
-                if not all(pd.isna(year_series.index)):
-                    fraction_series.loc[year_series.index] = year_series
-                if aggregate in fractions_attr_dict:
-                    fractions_attr_dict[aggregate][tech_stack] = fraction_series
-                else:
-                    fractions_attr_dict[aggregate] = {tech_stack: fraction_series}
-            fractions_dict[fraction_attr] = fractions_attr_dict
-        return fractions_dict
-
-    @staticmethod
-    def _create_stack_base_fractions(
-        stacks_fractions_df: pd.DataFrame,
-        stacks_df: pd.DataFrame,
-    ) -> dict[str, dict[str, float]]:
-        """Creates stack_base_fraction dict for every AggregatedConsumer"""
-        stacks_fractions_df = stacks_fractions_df.copy(deep=True)
-        stacks_df = stacks_df.copy(deep=True)
-
-        stacks_fractions_df.set_index("technology_stack", inplace=True, drop=True)
-        stacks_df.set_index("technology_stack", inplace=True, drop=True)
-        fraction_df = (
-            stacks_df.join(stacks_fractions_df, how="left", rsuffix="DROP")
-            .filter(regex="^(?!.*DROP)")
-            .fillna(0)
-        )
-
-        stack_base_fraction_dict: dict[str, dict[str, float]] = dict()
-        for stack, aggr, fraction in fraction_df.itertuples():
-            if aggr in stack_base_fraction_dict:
-                stack_base_fraction_dict[aggr][stack] = fraction
-            else:
-                stack_base_fraction_dict[aggr] = {stack: fraction}
-        return stack_base_fraction_dict
-
-    @staticmethod
-    def _create_yearly_energy_usage(
-        yearly_demand_df: pd.DataFrame,
-    ) -> dict[str, dict[str, pd.Series]]:
-        yearly_demand_df = yearly_demand_df.copy(deep=True)
-        result: defaultdict[str, dict[str, pd.Series]] = defaultdict(dict)
-        grouped = yearly_demand_df.groupby(["aggregate", "energy_type"])
-        for (aggregate, energy_type), group in grouped:
-            group = group.set_index("year_idx")
-            result[aggregate][energy_type] = group["value"]
-        return dict(result)
-
-    @staticmethod
-    def _create_aggregated_consumer(
-        df_row: pd.Series,
-        stack_base_fractions: dict[str, dict[str, float]],
-        yearly_energy_usage: dict[str, dict[str, pd.Series]],
-        fraction: dict[str, dict[str, dict[str, pd.Series]]],
-        n_consumers: dict[str, pd.Series],
-        n_years: int,
-    ) -> AggregatedConsumer:
-        return AggregatedConsumer(
-            name=df_row["name"],
-            demand_profile=sanitize_dataset_name(df_row["demand_type"]),
-            stack_base_fraction=stack_base_fractions.get(df_row["name"]),
-            yearly_energy_usage=yearly_energy_usage[df_row["name"]],
-            n_consumers=n_consumers.get(
-                df_row["name"], pd.Series([df_row["n_consumers_base"]] * n_years)
-            ),
-            min_fraction=fraction["min_fraction"].get(
-                df_row["name"], pd.Series([np.nan] * n_years)
-            ),
-            max_fraction=fraction["max_fraction"].get(
-                df_row["name"], pd.Series([np.nan] * n_years)
-            ),
-            max_fraction_decrease=fraction["max_fraction_decrease"].get(
-                df_row["name"], pd.Series([np.nan] * n_years)
-            ),
-            max_fraction_increase=fraction["max_fraction_increase"].get(
-                df_row["name"], pd.Series([np.nan] * n_years)
-            ),
-            average_area=(
-                float(df_row["average_area"])
-                if not pd.isna(df_row["average_area"])
-                else None
-            ),
-        )
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+from collections import defaultdict
+
+import numpy as np
+import pandas as pd
+
+from pyzefir.model.network_elements import AggregatedConsumer
+from pyzefir.parser.elements_parsers.element_parser import AbstractElementParser
+from pyzefir.parser.utils import sanitize_dataset_name
+
+
+class AggregatedConsumerParser(AbstractElementParser):
+    def __init__(
+        self,
+        aggregated_consumer_df: pd.DataFrame,
+        stack_df: pd.DataFrame,
+        stack_fraction_df: pd.DataFrame,
+        yearly_energy_usage_df: pd.DataFrame,
+        fraction_df: pd.DataFrame,
+        number_of_years: int,
+        n_consumers: pd.DataFrame,
+    ) -> None:
+        self.stack_fraction_df = stack_fraction_df
+        self.stack_df = stack_df
+        self.aggregated_consumer_df = aggregated_consumer_df
+        self.yearly_energy_usage_df = yearly_energy_usage_df
+        self.fraction_df = fraction_df
+        self._years = number_of_years
+        self.n_consumers = n_consumers
+
+    def create(self) -> tuple[AggregatedConsumer, ...]:
+        n_consumers = self._create_consumers(self.n_consumers, self._years)
+        fraction = self._create_fractions(self.stack_df, self.fraction_df, self._years)
+        stack_base_fractions = self._create_stack_base_fractions(
+            self.stack_fraction_df, self.stack_df
+        )
+        yearly_energy_usage = self._create_yearly_energy_usage(
+            self.yearly_energy_usage_df
+        )
+        aggregated_consumers = self.aggregated_consumer_df.apply(
+            self._create_aggregated_consumer,
+            axis=1,
+            args=(
+                stack_base_fractions,
+                yearly_energy_usage,
+                fraction,
+                n_consumers,
+                self._years,
+            ),
+            result_type="reduce",
+        )
+        return tuple(aggregated_consumers)
+
+    @staticmethod
+    def _create_consumers(
+        consumers_df: pd.DataFrame, n_years: int
+    ) -> dict[str, pd.Series]:
+        return (
+            consumers_df.set_index("year_idx").reindex(range(n_years)).to_dict("series")
+        )
+
+    @staticmethod
+    def _create_fractions(
+        stack_df: pd.DataFrame, fraction_df: pd.DataFrame, years: int
+    ) -> dict[str, dict[str, dict[str, pd.Series]]]:
+        """Creates aggregate_fraction dict for every AggregatedConsumer"""
+        fractions_df = stack_df.merge(fraction_df, how="left")
+        fractions_dict: dict[str, dict[str, dict[str, pd.Series]]] = dict()
+        grouped = fractions_df.groupby(["technology_stack", "aggregate"])
+        fraction_attributes = [
+            "min_fraction",
+            "max_fraction",
+            "max_fraction_decrease",
+            "max_fraction_increase",
+        ]
+        for fraction_attr in fraction_attributes:
+            fractions_attr_dict: dict[str, dict[str, pd.Series]] = dict()
+            if fraction_attr not in fraction_df.columns:
+                fractions_dict[fraction_attr] = dict()
+                continue
+            for (tech_stack, aggregate), group_data in grouped:
+                year_series = group_data.set_index("year")[fraction_attr]
+                fraction_series = pd.Series(index=range(years), dtype=float)
+                if not all(pd.isna(year_series.index)):
+                    fraction_series.loc[year_series.index] = year_series
+                if aggregate in fractions_attr_dict:
+                    fractions_attr_dict[aggregate][tech_stack] = fraction_series
+                else:
+                    fractions_attr_dict[aggregate] = {tech_stack: fraction_series}
+            fractions_dict[fraction_attr] = fractions_attr_dict
+        return fractions_dict
+
+    @staticmethod
+    def _create_stack_base_fractions(
+        stacks_fractions_df: pd.DataFrame,
+        stacks_df: pd.DataFrame,
+    ) -> dict[str, dict[str, float]]:
+        """Creates stack_base_fraction dict for every AggregatedConsumer"""
+        stacks_fractions_df = stacks_fractions_df.copy(deep=True)
+        stacks_df = stacks_df.copy(deep=True)
+
+        stacks_fractions_df.set_index("technology_stack", inplace=True, drop=True)
+        stacks_df.set_index("technology_stack", inplace=True, drop=True)
+        fraction_df = (
+            stacks_df.join(stacks_fractions_df, how="left", rsuffix="DROP")
+            .filter(regex="^(?!.*DROP)")
+            .fillna(0)
+        )
+
+        stack_base_fraction_dict: dict[str, dict[str, float]] = dict()
+        for stack, aggr, fraction in fraction_df.itertuples():
+            if aggr in stack_base_fraction_dict:
+                stack_base_fraction_dict[aggr][stack] = fraction
+            else:
+                stack_base_fraction_dict[aggr] = {stack: fraction}
+        return stack_base_fraction_dict
+
+    @staticmethod
+    def _create_yearly_energy_usage(
+        yearly_demand_df: pd.DataFrame,
+    ) -> dict[str, dict[str, pd.Series]]:
+        yearly_demand_df = yearly_demand_df.copy(deep=True)
+        result: defaultdict[str, dict[str, pd.Series]] = defaultdict(dict)
+        grouped = yearly_demand_df.groupby(["aggregate", "energy_type"])
+        for (aggregate, energy_type), group in grouped:
+            group = group.set_index("year_idx")
+            result[aggregate][energy_type] = group["value"]
+        return dict(result)
+
+    @staticmethod
+    def _create_aggregated_consumer(
+        df_row: pd.Series,
+        stack_base_fractions: dict[str, dict[str, float]],
+        yearly_energy_usage: dict[str, dict[str, pd.Series]],
+        fraction: dict[str, dict[str, dict[str, pd.Series]]],
+        n_consumers: dict[str, pd.Series],
+        n_years: int,
+    ) -> AggregatedConsumer:
+        return AggregatedConsumer(
+            name=str(df_row["name"]),
+            demand_profile=str(sanitize_dataset_name(df_row["demand_type"])),
+            stack_base_fraction=stack_base_fractions[df_row["name"]],
+            yearly_energy_usage=yearly_energy_usage[df_row["name"]],
+            n_consumers=n_consumers.get(
+                df_row["name"], pd.Series([df_row["n_consumers_base"]] * n_years)
+            ),
+            min_fraction=fraction["min_fraction"].get(
+                df_row["name"], pd.Series([np.nan] * n_years)
+            ),
+            max_fraction=fraction["max_fraction"].get(
+                df_row["name"], pd.Series([np.nan] * n_years)
+            ),
+            max_fraction_decrease=fraction["max_fraction_decrease"].get(
+                df_row["name"], pd.Series([np.nan] * n_years)
+            ),
+            max_fraction_increase=fraction["max_fraction_increase"].get(
+                df_row["name"], pd.Series([np.nan] * n_years)
+            ),
+            average_area=(
+                float(df_row["average_area"])
+                if not pd.isna(df_row["average_area"])
+                else None
+            ),
+        )
```

### Comparing `pyzefir-0.4.1/pyzefir/parser/elements_parsers/bus_parser.py` & `pyzefir-0.4.22/pyzefir/parser/elements_parsers/bus_parser.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,38 +1,40 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-import pandas as pd
-
-from pyzefir.model.network_elements import Bus
-from pyzefir.parser.elements_parsers.element_parser import AbstractElementParser
-
-
-class BusParser(AbstractElementParser):
-    def __init__(
-        self,
-        bus_df: pd.DataFrame,
-    ) -> None:
-        self.bus_df = bus_df
-
-    def create(self) -> tuple[Bus, ...]:
-        return tuple(
-            Bus(
-                name=row["name"],
-                energy_type=row["energy_type"],
-                dsr_type=row["dsr_type"] if not pd.isnull(row["dsr_type"]) else None,
-            )
-            for row in self.bus_df.to_dict(orient="records")
-        )
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+import pandas as pd
+
+from pyzefir.model.network_elements import Bus
+from pyzefir.parser.elements_parsers.element_parser import AbstractElementParser
+
+
+class BusParser(AbstractElementParser):
+    def __init__(
+        self,
+        bus_df: pd.DataFrame,
+    ) -> None:
+        self.bus_df = bus_df
+
+    def create(self) -> tuple[Bus, ...]:
+        return tuple(
+            Bus(
+                name=str(row["name"]),
+                energy_type=str(row["energy_type"]),
+                dsr_type=(
+                    str(row["dsr_type"]) if not pd.isnull(row["dsr_type"]) else None
+                ),
+            )
+            for row in self.bus_df.to_dict(orient="records")
+        )
```

### Comparing `pyzefir-0.4.1/pyzefir/parser/elements_parsers/capacity_factor_parser.py` & `pyzefir-0.4.22/pyzefir/parser/elements_parsers/capacity_factor_parser.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,39 +1,39 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-import pandas as pd
-
-from pyzefir.model.network_elements import CapacityFactor
-from pyzefir.parser.elements_parsers.element_parser import AbstractElementParser
-
-
-class CapacityFactorParser(AbstractElementParser):
-    def __init__(
-        self,
-        capacity_factors_df: pd.DataFrame,
-    ):
-        self.capacity_factors_df = capacity_factors_df.copy(deep=True)
-
-    def create(self) -> tuple[CapacityFactor, ...]:
-        self.capacity_factors_df.set_index("hour_idx", inplace=True, drop=True)
-
-        capacity_factors = []
-        for col in self.capacity_factors_df.columns:
-            capacity_factor = CapacityFactor(
-                name=col, profile=self.capacity_factors_df[col]
-            )
-            capacity_factors.append(capacity_factor)
-        return tuple(capacity_factors)
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+import pandas as pd
+
+from pyzefir.model.network_elements import CapacityFactor
+from pyzefir.parser.elements_parsers.element_parser import AbstractElementParser
+
+
+class CapacityFactorParser(AbstractElementParser):
+    def __init__(
+        self,
+        capacity_factors_df: pd.DataFrame,
+    ):
+        self.capacity_factors_df = capacity_factors_df.copy(deep=True)
+
+    def create(self) -> tuple[CapacityFactor, ...]:
+        self.capacity_factors_df.set_index("hour_idx", inplace=True, drop=True)
+
+        capacity_factors = []
+        for col in self.capacity_factors_df.columns:
+            capacity_factor = CapacityFactor(
+                name=str(col), profile=self.capacity_factors_df[col]
+            )
+            capacity_factors.append(capacity_factor)
+        return tuple(capacity_factors)
```

### Comparing `pyzefir-0.4.1/pyzefir/parser/elements_parsers/demand_chunk_parser.py` & `pyzefir-0.4.22/pyzefir/parser/elements_parsers/demand_chunk_parser.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,49 +1,49 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-import pandas as pd
-
-from pyzefir.model.network_elements import DemandChunk
-from pyzefir.parser.elements_parsers.element_parser import AbstractElementParser
-from pyzefir.utils.path_manager import DataSubCategories
-
-
-class DemandChunkParser(AbstractElementParser):
-    def __init__(
-        self,
-        demand_chunk_dict: dict[str, pd.DataFrame],
-    ) -> None:
-        self.demand_chunk_dict = demand_chunk_dict
-
-    def create(self) -> tuple[DemandChunk, ...]:
-        demand_chunks: list[DemandChunk] = list()
-        for _, demand_chunk_config in self.demand_chunk_dict[
-            DataSubCategories.DEMAND_CHUNKS
-        ].iterrows():
-            demand_chunk = DemandChunk(
-                name=demand_chunk_config["name"],
-                tag=demand_chunk_config["tag"],
-                energy_type=demand_chunk_config["energy_type"],
-                periods=self.demand_chunk_dict[demand_chunk_config["name"]][
-                    ["period_start", "period_end"]
-                ].to_numpy(),
-                demand=self.demand_chunk_dict[demand_chunk_config["name"]]
-                .drop(columns=["period_start", "period_end"])
-                .to_numpy(),
-            )
-            demand_chunks.append(demand_chunk)
-
-        return tuple(demand_chunks)
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+import pandas as pd
+
+from pyzefir.model.network_elements import DemandChunk
+from pyzefir.parser.elements_parsers.element_parser import AbstractElementParser
+from pyzefir.utils.path_manager import DataSubCategories
+
+
+class DemandChunkParser(AbstractElementParser):
+    def __init__(
+        self,
+        demand_chunk_dict: dict[str, pd.DataFrame],
+    ) -> None:
+        self.demand_chunk_dict = demand_chunk_dict
+
+    def create(self) -> tuple[DemandChunk, ...]:
+        demand_chunks: list[DemandChunk] = list()
+        for _, demand_chunk_config in self.demand_chunk_dict[
+            DataSubCategories.DEMAND_CHUNKS
+        ].iterrows():
+            demand_chunk = DemandChunk(
+                name=str(demand_chunk_config["name"]),
+                tag=str(demand_chunk_config["tag"]),
+                energy_type=str(demand_chunk_config["energy_type"]),
+                periods=self.demand_chunk_dict[demand_chunk_config["name"]][
+                    ["period_start", "period_end"]
+                ].to_numpy(),
+                demand=self.demand_chunk_dict[demand_chunk_config["name"]]
+                .drop(columns=["period_start", "period_end"])
+                .to_numpy(),
+            )
+            demand_chunks.append(demand_chunk)
+
+        return tuple(demand_chunks)
```

### Comparing `pyzefir-0.4.1/pyzefir/parser/elements_parsers/demand_profile_parser.py` & `pyzefir-0.4.22/pyzefir/parser/elements_parsers/demand_profile_parser.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,39 +1,39 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-import pandas as pd
-
-from pyzefir.model.network_elements import DemandProfile
-from pyzefir.parser.elements_parsers.element_parser import AbstractElementParser
-
-
-class DemandProfileParser(AbstractElementParser):
-    def __init__(
-        self,
-        demand_dict: dict[str, pd.DataFrame],
-    ) -> None:
-        self.demand_dict = demand_dict
-
-    def create(self) -> tuple[DemandProfile, ...]:
-        demand_profiles: list[DemandProfile] = list()
-        for name, demand_df in self.demand_dict.items():
-            demand_profile = DemandProfile(
-                name=name,
-                normalized_profile=demand_df.set_index("hour_idx").to_dict("series"),
-            )
-            demand_profiles.append(demand_profile)
-
-        return tuple(demand_profiles)
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+import pandas as pd
+
+from pyzefir.model.network_elements import DemandProfile
+from pyzefir.parser.elements_parsers.element_parser import AbstractElementParser
+
+
+class DemandProfileParser(AbstractElementParser):
+    def __init__(
+        self,
+        demand_dict: dict[str, pd.DataFrame],
+    ) -> None:
+        self.demand_dict = demand_dict
+
+    def create(self) -> tuple[DemandProfile, ...]:
+        demand_profiles: list[DemandProfile] = list()
+        for name, demand_df in self.demand_dict.items():
+            demand_profile = DemandProfile(
+                name=str(name),
+                normalized_profile=demand_df.set_index("hour_idx").to_dict("series"),
+            )
+            demand_profiles.append(demand_profile)
+
+        return tuple(demand_profiles)
```

### Comparing `pyzefir-0.4.1/pyzefir/parser/elements_parsers/dsr_parser.py` & `pyzefir-0.4.22/pyzefir/parser/elements_parsers/dsr_parser.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,49 +1,49 @@
-# PyZefir
-# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-import pandas as pd
-
-from pyzefir.model.network_elements.dsr import DSR
-from pyzefir.parser.elements_parsers.element_parser import AbstractElementParser
-
-
-class DSRParser(AbstractElementParser):
-    def __init__(
-        self,
-        dsr_df: pd.DataFrame,
-    ) -> None:
-        self.dsr_df = dsr_df
-
-    def create(self) -> tuple[DSR, ...]:
-        return tuple(
-            DSR(
-                name=row["name"],
-                compensation_factor=row["compensation_factor"],
-                balancing_period_len=row["balancing_period_len"],
-                penalization=row["penalization"],
-                relative_shift_limit=(
-                    row["relative_shift_limit"]
-                    if not pd.isnull(row["relative_shift_limit"])
-                    else None
-                ),
-                abs_shift_limit=(
-                    row["abs_shift_limit"]
-                    if not pd.isnull(row["abs_shift_limit"])
-                    else None
-                ),
-            )
-            for row in self.dsr_df.to_dict(orient="records")
-        )
+# PyZefir
+# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+import pandas as pd
+
+from pyzefir.model.network_elements.dsr import DSR
+from pyzefir.parser.elements_parsers.element_parser import AbstractElementParser
+
+
+class DSRParser(AbstractElementParser):
+    def __init__(
+        self,
+        dsr_df: pd.DataFrame,
+    ) -> None:
+        self.dsr_df = dsr_df
+
+    def create(self) -> tuple[DSR, ...]:
+        return tuple(
+            DSR(
+                name=str(row["name"]),
+                compensation_factor=float(row["compensation_factor"]),
+                balancing_period_len=int(row["balancing_period_len"]),
+                penalization=float(row["penalization"]),
+                relative_shift_limit=(
+                    float(row["relative_shift_limit"])
+                    if not pd.isnull(row["relative_shift_limit"])
+                    else None
+                ),
+                abs_shift_limit=(
+                    float(row["abs_shift_limit"])
+                    if not pd.isnull(row["abs_shift_limit"])
+                    else None
+                ),
+            )
+            for row in self.dsr_df.to_dict(orient="records")
+        )
```

### Comparing `pyzefir-0.4.1/pyzefir/parser/elements_parsers/element_parser.py` & `pyzefir-0.4.22/pyzefir/parser/elements_parsers/element_parser.py`

 * *Ordering differences only*

 * *Files 21% similar despite different names*

```diff
@@ -1,25 +1,25 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-from abc import ABC, abstractmethod
-
-from pyzefir.model.network_element import NetworkElement
-
-
-class AbstractElementParser(ABC):
-    @abstractmethod
-    def create(self) -> tuple[NetworkElement, ...]:
-        raise NotImplementedError
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+from abc import ABC, abstractmethod
+
+from pyzefir.model.network_element import NetworkElement
+
+
+class AbstractElementParser(ABC):
+    @abstractmethod
+    def create(self) -> tuple[NetworkElement, ...]:
+        raise NotImplementedError
```

### Comparing `pyzefir-0.4.1/pyzefir/parser/elements_parsers/emission_fee_parser.py` & `pyzefir-0.4.22/pyzefir/parser/elements_parsers/emission_fee_parser.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,40 +1,40 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-import pandas as pd
-
-from pyzefir.model.network_elements.emission_fee import EmissionFee
-from pyzefir.parser.elements_parsers.element_parser import AbstractElementParser
-
-
-class EmissionFeeParser(AbstractElementParser):
-    def __init__(
-        self,
-        emission_type_df: pd.DataFrame,
-        emission_fee_df: pd.DataFrame,
-    ) -> None:
-        self.emission_fee_df = emission_fee_df.set_index("year_idx")
-        self.emission_type_df = emission_type_df.set_index("emission_fee").squeeze()
-
-    def create(self) -> tuple[EmissionFee, ...]:
-        return tuple(
-            EmissionFee(
-                name=name,
-                price=self.emission_fee_df[name].astype(float),
-                emission_type=self.emission_type_df[name],
-            )
-            for name in self.emission_fee_df.columns
-        )
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+import pandas as pd
+
+from pyzefir.model.network_elements.emission_fee import EmissionFee
+from pyzefir.parser.elements_parsers.element_parser import AbstractElementParser
+
+
+class EmissionFeeParser(AbstractElementParser):
+    def __init__(
+        self,
+        emission_type_df: pd.DataFrame,
+        emission_fee_df: pd.DataFrame,
+    ) -> None:
+        self.emission_fee_df = emission_fee_df.set_index("year_idx")
+        self.emission_type_df = emission_type_df.set_index("emission_fee").squeeze()
+
+    def create(self) -> tuple[EmissionFee, ...]:
+        return tuple(
+            EmissionFee(
+                name=str(name),
+                price=self.emission_fee_df[name].astype(float),
+                emission_type=str(self.emission_type_df[name]),
+            )
+            for name in self.emission_fee_df.columns
+        )
```

### Comparing `pyzefir-0.4.1/pyzefir/parser/elements_parsers/energy_source_unit_parser.py` & `pyzefir-0.4.22/pyzefir/parser/elements_parsers/energy_source_unit_parser.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,198 +1,209 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-import pandas as pd
-
-from pyzefir.model.network_elements import Generator, Storage
-from pyzefir.parser.elements_parsers.aggregated_consumer_parser import (
-    AggregatedConsumerParser,
-)
-from pyzefir.parser.elements_parsers.element_parser import AbstractElementParser
-from pyzefir.parser.elements_parsers.utils import create_tags_list, get_float_or_none
-
-
-class EnergySourceUnitParser(AbstractElementParser):
-    def __init__(
-        self,
-        df_generators: pd.DataFrame,
-        df_storages: pd.DataFrame,
-        df_element_energy_evolution: pd.DataFrame,
-        df_technology_bus: pd.DataFrame,
-        df_technology: pd.DataFrame,
-        df_tech_stack_bus: pd.DataFrame,
-        df_tech_stack_aggregate: pd.DataFrame,
-        df_tech_stack: pd.DataFrame,
-        df_aggregates: pd.DataFrame,
-        n_years: int,
-        df_generator_emission_fee: pd.DataFrame,
-        n_consumers: pd.DataFrame,
-    ) -> None:
-        self.df_technology_bus = df_technology_bus.copy(deep=True)
-        self.df_generators = df_generators.copy(deep=True)
-        self.df_storages = df_storages.copy(deep=True)
-        self.df_element_energy_evolution = df_element_energy_evolution.copy(deep=True)
-        self.df_technology = df_technology.copy(deep=True).set_index("technology")
-        self.df_tech_stack_bus = df_tech_stack_bus
-        self.df_tech_stack_aggregate = df_tech_stack_aggregate
-        self.df_tech_stack = df_tech_stack
-        self.df_aggregates = df_aggregates
-        self.df_base_cap = self._create_base_cap_df(n_consumers)
-        self.n_years = n_years
-        self.generator_emission_fee = (
-            df_generator_emission_fee.copy(deep=True)
-            .groupby("generator")["emission_fee"]
-            .apply(list)
-            .to_dict()
-        )
-
-    def _get_set_of_buses_from_dataframe(self, name: str) -> set[str]:
-        df_technology_bus = self.df_technology_bus.loc[
-            self.df_technology_bus["technology"] == name
-        ]
-        return set(df_technology_bus["bus"].to_list())
-
-    def _get_bus_from_dataframe(self, name: str) -> str:
-        df_technology_bus = self.df_technology_bus.loc[
-            self.df_technology_bus["technology"] == name
-        ]
-        return df_technology_bus["bus"].iloc[0]
-
-    def _create_generator(self, df_row: pd.Series) -> Generator:
-        name = df_row["name"]
-        technology_evolution_df = self.df_element_energy_evolution[
-            self.df_element_energy_evolution["technology_name"] == name
-        ].set_index("year_idx")
-        return Generator(
-            name=name,
-            bus=self._get_set_of_buses_from_dataframe(name),
-            energy_source_type=df_row["generator_type"],
-            unit_base_cap=self.df_base_cap.loc[name]["unit_base_capacity"],
-            unit_min_capacity=technology_evolution_df["min_capacity"].reindex(
-                range(self.n_years)
-            ),
-            unit_max_capacity=technology_evolution_df["max_capacity"].reindex(
-                range(self.n_years)
-            ),
-            unit_min_capacity_increase=technology_evolution_df[
-                "max_capacity_increase"
-            ].reindex(range(self.n_years)),
-            unit_max_capacity_increase=technology_evolution_df[
-                "min_capacity_increase"
-            ].reindex(range(self.n_years)),
-            min_device_nom_power=get_float_or_none(df_row["min_device_nom_power"]),
-            max_device_nom_power=get_float_or_none(df_row["max_device_nom_power"]),
-            emission_fee=(
-                set(self.generator_emission_fee[name])
-                if name in self.generator_emission_fee
-                else set()
-            ),
-            tags=create_tags_list(df_row[4:]),
-        )
-
-    def _create_storage(self, df_row: pd.Series) -> Storage:
-        name = df_row["name"]
-        technology_evolution_df = self.df_element_energy_evolution[
-            self.df_element_energy_evolution["technology_name"] == name
-        ].set_index("year_idx")
-        return Storage(
-            name=name,
-            bus=self._get_bus_from_dataframe(name),
-            energy_source_type=df_row["storage_type"],
-            unit_base_cap=self.df_base_cap.loc[name]["unit_base_capacity"],
-            unit_min_capacity=technology_evolution_df["min_capacity"].reindex(
-                range(self.n_years)
-            ),
-            unit_max_capacity=technology_evolution_df["max_capacity"].reindex(
-                range(self.n_years)
-            ),
-            unit_min_capacity_increase=technology_evolution_df[
-                "max_capacity_increase"
-            ].reindex(range(self.n_years)),
-            unit_max_capacity_increase=technology_evolution_df[
-                "min_capacity_increase"
-            ].reindex(range(self.n_years)),
-            min_device_nom_power=get_float_or_none(df_row["min_device_nom_power"]),
-            max_device_nom_power=get_float_or_none(df_row["max_device_nom_power"]),
-            tags=create_tags_list(df_row[4:]),
-        )
-
-    def create(self) -> tuple[tuple[Generator, ...], tuple[Storage, ...]]:
-        generators = tuple(self.df_generators.apply(self._create_generator, axis=1))
-        storages = tuple(self.df_storages.apply(self._create_storage, axis=1))
-
-        return generators, storages
-
-    def _create_base_cap_df(self, n_consumer: pd.DataFrame) -> pd.DataFrame:
-        cols = ["name", "min_device_nom_power", "max_device_nom_power"]
-        energy_sources = pd.concat(
-            [self.df_generators.loc[:, cols], self.df_storages.loc[:, cols]]
-        )
-
-        energy_sources = energy_sources.join(self.df_technology, on="name")
-
-        # try to connect energy source to any tech stack
-        energy_sources = energy_sources.join(
-            self.df_technology_bus.set_index("technology"), on="name"
-        )
-        energy_sources = energy_sources.join(
-            self.df_tech_stack_bus.set_index("bus"), on="bus"
-        )
-        energy_sources = energy_sources.join(
-            self.df_tech_stack.set_index("technology_stack"), on="technology_stack"
-        )
-        energy_sources = energy_sources.join(
-            self.df_aggregates.set_index("name"), on="aggregate"
-        )
-        energy_sources = energy_sources.reset_index(drop=True)
-
-        # update base_consumer values for year_idx=0
-        n_consumer_dict = AggregatedConsumerParser._create_consumers(
-            n_consumer, n_years=1
-        )
-        for aggr, n_consumer_series in n_consumer_dict.items():
-            if 0 in n_consumer_series:
-                energy_sources.loc[
-                    energy_sources["aggregate"] == aggr, "n_consumers_base"
-                ] = n_consumer_series[0]
-
-        # update missing base capacity values
-        energy_sources["unit_base_capacity"] = energy_sources["base_capacity"]
-        missing_base_cap = energy_sources[
-            pd.isna(energy_sources["base_capacity"])
-            & ~pd.isna(energy_sources["technology_stack"])
-            & (
-                energy_sources["min_device_nom_power"]
-                == energy_sources["max_device_nom_power"]
-            )
-        ]
-        missing_base_cap.loc[:, "unit_base_capacity"] = (
-            missing_base_cap["base_fraction"]
-            * missing_base_cap["n_consumers_base"]
-            * missing_base_cap["max_device_nom_power"]
-        )
-        energy_sources["unit_base_capacity"].update(
-            missing_base_cap["unit_base_capacity"]
-        )
-
-        # we assume that either unit's buses are not connected to any tech stack,
-        # or they are all connected to the same stack
-        # then if any duplicates occur, we could safely drop them,
-        # because unit_base_capacity should be the same for all duplicated rows
-        energy_sources = energy_sources.loc[
-            :, ["name", "unit_base_capacity"]
-        ].set_index("name")
-        energy_sources = energy_sources[~energy_sources.index.duplicated()]
-        return energy_sources
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+import pandas as pd
+
+from pyzefir.model.network_elements import Generator, Storage
+from pyzefir.parser.elements_parsers.aggregated_consumer_parser import (
+    AggregatedConsumerParser,
+)
+from pyzefir.parser.elements_parsers.element_parser import AbstractElementParser
+from pyzefir.parser.elements_parsers.utils import create_tags_list, get_float_or_none
+
+
+class EnergySourceUnitParser(AbstractElementParser):
+    def __init__(
+        self,
+        df_generators: pd.DataFrame,
+        df_storages: pd.DataFrame,
+        df_element_energy_evolution: pd.DataFrame,
+        df_technology_bus: pd.DataFrame,
+        df_technology: pd.DataFrame,
+        df_tech_stack_bus: pd.DataFrame,
+        df_tech_stack_aggregate: pd.DataFrame,
+        df_tech_stack: pd.DataFrame,
+        df_aggregates: pd.DataFrame,
+        n_years: int,
+        df_generator_emission_fee: pd.DataFrame,
+        n_consumers: pd.DataFrame,
+        df_binding: pd.DataFrame,
+    ) -> None:
+        self.df_technology_bus = df_technology_bus.copy(deep=True)
+        self.df_generators = df_generators.copy(deep=True)
+        self.df_storages = df_storages.copy(deep=True)
+        self.df_element_energy_evolution = df_element_energy_evolution.copy(deep=True)
+        self.df_technology = df_technology.copy(deep=True).set_index("technology")
+        self.df_tech_stack_bus = df_tech_stack_bus
+        self.df_tech_stack_aggregate = df_tech_stack_aggregate
+        self.df_tech_stack = df_tech_stack
+        self.df_aggregates = df_aggregates
+        self.df_base_cap = self._create_base_cap_df(n_consumers)
+        self.n_years = n_years
+        self.generator_emission_fee = (
+            df_generator_emission_fee.copy(deep=True)
+            .groupby("generator")["emission_fee"]
+            .apply(list)
+            .to_dict()
+        )
+        self.df_binding = df_binding.copy(deep=True).set_index("generator").squeeze()
+
+    def _get_set_of_buses_from_dataframe(self, name: str) -> set[str]:
+        df_technology_bus = self.df_technology_bus.loc[
+            self.df_technology_bus["technology"] == name
+        ]
+        return set(df_technology_bus["bus"].to_list())
+
+    def _get_bus_from_dataframe(self, name: str) -> str:
+        df_technology_bus = self.df_technology_bus.loc[
+            self.df_technology_bus["technology"] == name
+        ]
+        return df_technology_bus["bus"].iloc[0]
+
+    def _create_generator(self, df_row: pd.Series) -> Generator:
+        name = str(df_row["name"])
+        technology_evolution_df = self.df_element_energy_evolution[
+            self.df_element_energy_evolution["technology_name"] == name
+        ].set_index("year_idx")
+        return Generator(
+            name=name,
+            generator_binding=(
+                str(self.df_binding[name]) if name in self.df_binding else None
+            ),
+            bus=self._get_set_of_buses_from_dataframe(name),
+            energy_source_type=str(df_row["generator_type"]),
+            unit_base_cap=float(self.df_base_cap.loc[name]["unit_base_capacity"]),
+            unit_min_capacity=technology_evolution_df["min_capacity"].reindex(
+                range(self.n_years)
+            ),
+            unit_max_capacity=technology_evolution_df["max_capacity"].reindex(
+                range(self.n_years)
+            ),
+            unit_min_capacity_increase=technology_evolution_df[
+                "min_capacity_increase"
+            ].reindex(range(self.n_years)),
+            unit_max_capacity_increase=technology_evolution_df[
+                "max_capacity_increase"
+            ].reindex(range(self.n_years)),
+            min_device_nom_power=get_float_or_none(df_row["min_device_nom_power"]),
+            max_device_nom_power=get_float_or_none(df_row["max_device_nom_power"]),
+            emission_fee=(
+                set(self.generator_emission_fee[name])
+                if name in self.generator_emission_fee
+                else set()
+            ),
+            tags=create_tags_list(df_row[4:]),
+        )
+
+    def _create_storage(self, df_row: pd.Series) -> Storage:
+        name = str(df_row["name"])
+        technology_evolution_df = self.df_element_energy_evolution[
+            self.df_element_energy_evolution["technology_name"] == name
+        ].set_index("year_idx")
+        return Storage(
+            name=name,
+            bus=self._get_bus_from_dataframe(name),
+            energy_source_type=str(df_row["storage_type"]),
+            unit_base_cap=float(self.df_base_cap.loc[name]["unit_base_capacity"]),
+            unit_min_capacity=technology_evolution_df["min_capacity"].reindex(
+                range(self.n_years)
+            ),
+            unit_max_capacity=technology_evolution_df["max_capacity"].reindex(
+                range(self.n_years)
+            ),
+            unit_min_capacity_increase=technology_evolution_df[
+                "min_capacity_increase"
+            ].reindex(range(self.n_years)),
+            unit_max_capacity_increase=technology_evolution_df[
+                "max_capacity_increase"
+            ].reindex(range(self.n_years)),
+            min_device_nom_power=get_float_or_none(df_row["min_device_nom_power"]),
+            max_device_nom_power=get_float_or_none(df_row["max_device_nom_power"]),
+            tags=create_tags_list(df_row[4:]),
+        )
+
+    def create(self) -> tuple[tuple[Generator, ...], tuple[Storage, ...]]:
+        generators = tuple(
+            self.df_generators.apply(
+                self._create_generator, axis=1, result_type="reduce"
+            )
+        )
+        storages = tuple(
+            self.df_storages.apply(self._create_storage, axis=1, result_type="reduce")
+        )
+
+        return generators, storages
+
+    def _create_base_cap_df(self, n_consumer: pd.DataFrame) -> pd.DataFrame:
+        cols = ["name", "min_device_nom_power", "max_device_nom_power"]
+        energy_sources = pd.concat(
+            [self.df_generators.loc[:, cols], self.df_storages.loc[:, cols]]
+        )
+
+        energy_sources = energy_sources.join(self.df_technology, on="name")
+
+        # try to connect energy source to any tech stack
+        energy_sources = energy_sources.join(
+            self.df_technology_bus.set_index("technology"), on="name"
+        )
+        energy_sources = energy_sources.join(
+            self.df_tech_stack_bus.set_index("bus"), on="bus"
+        )
+        energy_sources = energy_sources.join(
+            self.df_tech_stack.set_index("technology_stack"), on="technology_stack"
+        )
+        energy_sources = energy_sources.join(
+            self.df_aggregates.set_index("name"), on="aggregate"
+        )
+        energy_sources = energy_sources.reset_index(drop=True)
+
+        # update base_consumer values for year_idx=0
+        n_consumer_dict = AggregatedConsumerParser._create_consumers(
+            n_consumer, n_years=1
+        )
+        for aggr, n_consumer_series in n_consumer_dict.items():
+            if 0 in n_consumer_series:
+                energy_sources.loc[
+                    energy_sources["aggregate"] == aggr, "n_consumers_base"
+                ] = n_consumer_series[0]
+
+        # update missing base capacity values
+        energy_sources["unit_base_capacity"] = energy_sources["base_capacity"]
+        missing_base_cap = energy_sources[
+            pd.isna(energy_sources["base_capacity"])
+            & ~pd.isna(energy_sources["technology_stack"])
+            & (
+                energy_sources["min_device_nom_power"]
+                == energy_sources["max_device_nom_power"]
+            )
+        ]
+        missing_base_cap.loc[:, "unit_base_capacity"] = (
+            missing_base_cap["base_fraction"]
+            * missing_base_cap["n_consumers_base"]
+            * missing_base_cap["max_device_nom_power"]
+        )
+        energy_sources["unit_base_capacity"].update(
+            missing_base_cap["unit_base_capacity"]
+        )
+
+        # we assume that either unit's buses are not connected to any tech stack,
+        # or they are all connected to the same stack
+        # then if any duplicates occur, we could safely drop them,
+        # because unit_base_capacity should be the same for all duplicated rows
+        energy_sources = energy_sources.loc[
+            :, ["name", "unit_base_capacity"]
+        ].set_index("name")
+        energy_sources = energy_sources[~energy_sources.index.duplicated()]
+        return energy_sources
```

### Comparing `pyzefir-0.4.1/pyzefir/parser/elements_parsers/fuel_parser.py` & `pyzefir-0.4.22/pyzefir/parser/elements_parsers/fuel_parser.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,85 +1,88 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-import pandas as pd
-
-from pyzefir.model.network_elements import Fuel
-from pyzefir.parser.elements_parsers.element_parser import AbstractElementParser
-from pyzefir.utils.path_manager import DataSubCategories
-
-
-class FuelParser(AbstractElementParser):
-    def __init__(
-        self,
-        emission_per_unit_df: pd.DataFrame,
-        energy_per_unit_df: pd.DataFrame,
-        fuel_prices_df: pd.DataFrame,
-        fuel_availability_df: pd.DataFrame,
-    ) -> None:
-        self.fuel_availability_df = fuel_availability_df
-        self.fuel_prices_df = fuel_prices_df
-        self.energy_per_unit_df = energy_per_unit_df
-        self.emission_per_unit_df = emission_per_unit_df
-
-    def create(self) -> tuple[Fuel, ...]:
-        energy_per_unit_df = self.energy_per_unit_df.copy(deep=True)
-        emission_per_unit_df = self.emission_per_unit_df.copy(deep=True)
-        fuel_availability = self.fuel_availability_df.copy(deep=True)
-        fuel_prices = self.fuel_prices_df.copy(deep=True)
-
-        fuel_df = FuelParser._merge_energy_emission_data(
-            energy_per_unit_df, emission_per_unit_df
-        )
-
-        return tuple(
-            fuel_df.apply(
-                FuelParser._create_fuel, axis=1, args=(fuel_prices, fuel_availability)
-            )
-        )
-
-    @staticmethod
-    def _create_fuel(
-        df_row: pd.Series, fuel_prices: pd.DataFrame, fuel_availability: pd.DataFrame
-    ) -> Fuel:
-        return Fuel(
-            name=str(df_row.name),
-            emission={
-                emission_type: value for emission_type, value in df_row[1:].items()
-            },
-            availability=(
-                fuel_availability[df_row.name]
-                if df_row.name in fuel_availability.columns
-                else None
-            ),
-            cost=fuel_prices[df_row.name],
-            energy_per_unit=df_row["energy_per_unit"],
-        )
-
-    @staticmethod
-    def _merge_energy_emission_data(
-        energy_per_unit_df: pd.DataFrame, emission_per_unit_df: pd.DataFrame
-    ) -> pd.DataFrame:
-        energy_per_unit_df = energy_per_unit_df.set_index("name", drop=True)
-        emission_per_unit_df = emission_per_unit_df.set_index("name", drop=True)
-
-        fuel_df = pd.concat([energy_per_unit_df, emission_per_unit_df], axis=1)
-        if fuel_df.isnull().values.any():
-            raise ValueError(
-                f"Fuel names in {DataSubCategories.EMISSION_PER_UNIT} must "
-                f"match with {DataSubCategories.ENERGY_PER_UNIT}"
-            )
-
-        return fuel_df
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+import pandas as pd
+
+from pyzefir.model.network_elements import Fuel
+from pyzefir.parser.elements_parsers.element_parser import AbstractElementParser
+from pyzefir.utils.path_manager import DataSubCategories
+
+
+class FuelParser(AbstractElementParser):
+    def __init__(
+        self,
+        emission_per_unit_df: pd.DataFrame,
+        energy_per_unit_df: pd.DataFrame,
+        fuel_prices_df: pd.DataFrame,
+        fuel_availability_df: pd.DataFrame,
+    ) -> None:
+        self.fuel_availability_df = fuel_availability_df
+        self.fuel_prices_df = fuel_prices_df
+        self.energy_per_unit_df = energy_per_unit_df
+        self.emission_per_unit_df = emission_per_unit_df
+
+    def create(self) -> tuple[Fuel, ...]:
+        energy_per_unit_df = self.energy_per_unit_df.copy(deep=True)
+        emission_per_unit_df = self.emission_per_unit_df.copy(deep=True)
+        fuel_availability = self.fuel_availability_df.copy(deep=True)
+        fuel_prices = self.fuel_prices_df.copy(deep=True)
+
+        fuel_df = FuelParser._merge_energy_emission_data(
+            energy_per_unit_df, emission_per_unit_df
+        )
+
+        return tuple(
+            fuel_df.apply(
+                FuelParser._create_fuel,
+                axis=1,
+                args=(fuel_prices, fuel_availability),
+                result_type="reduce",
+            )
+        )
+
+    @staticmethod
+    def _create_fuel(
+        df_row: pd.Series, fuel_prices: pd.DataFrame, fuel_availability: pd.DataFrame
+    ) -> Fuel:
+        return Fuel(
+            name=str(df_row.name),
+            emission={
+                emission_type: value for emission_type, value in df_row[1:].items()
+            },
+            availability=(
+                fuel_availability[df_row.name]
+                if df_row.name in fuel_availability.columns
+                else None
+            ),
+            cost=fuel_prices[df_row.name],
+            energy_per_unit=float(df_row["energy_per_unit"]),
+        )
+
+    @staticmethod
+    def _merge_energy_emission_data(
+        energy_per_unit_df: pd.DataFrame, emission_per_unit_df: pd.DataFrame
+    ) -> pd.DataFrame:
+        energy_per_unit_df = energy_per_unit_df.set_index("name", drop=True)
+        emission_per_unit_df = emission_per_unit_df.set_index("name", drop=True)
+
+        fuel_df = pd.concat([energy_per_unit_df, emission_per_unit_df], axis=1)
+        if fuel_df.isnull().values.any():
+            raise ValueError(
+                f"Fuel names in {DataSubCategories.EMISSION_PER_UNIT} must "
+                f"match with {DataSubCategories.ENERGY_PER_UNIT}"
+            )
+
+        return fuel_df
```

### Comparing `pyzefir-0.4.1/pyzefir/parser/elements_parsers/line_parser.py` & `pyzefir-0.4.22/pyzefir/parser/elements_parsers/line_parser.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,48 +1,48 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-import pandas as pd
-
-from pyzefir.model.network_elements import Line
-from pyzefir.parser.elements_parsers.element_parser import AbstractElementParser
-
-
-class LineParser(AbstractElementParser):
-    def __init__(self, line_df: pd.DataFrame) -> None:
-        self.line_df = line_df
-
-    def create(self) -> tuple[Line, ...]:
-        lines = self.line_df.apply(
-            self._create_line,
-            axis=1,
-        )
-        return tuple(lines)
-
-    @staticmethod
-    def _create_line(df_row: pd.Series) -> Line:
-        return Line(
-            name=df_row["name"],
-            energy_type=df_row["energy_type"],
-            fr=df_row["bus_from"],
-            to=df_row["bus_to"],
-            transmission_loss=df_row["transmission_loss"],
-            max_capacity=df_row["max_capacity"],
-            transmission_fee=(
-                None
-                if pd.isnull(df_row["transmission_fee"])
-                else df_row["transmission_fee"]
-            ),
-        )
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+import pandas as pd
+
+from pyzefir.model.network_elements import Line
+from pyzefir.parser.elements_parsers.element_parser import AbstractElementParser
+
+
+class LineParser(AbstractElementParser):
+    def __init__(self, line_df: pd.DataFrame) -> None:
+        self.line_df = line_df
+
+    def create(self) -> tuple[Line, ...]:
+        lines = self.line_df.apply(
+            self._create_line,
+            axis=1,
+        )
+        return tuple(lines)
+
+    @staticmethod
+    def _create_line(df_row: pd.Series) -> Line:
+        return Line(
+            name=str(df_row["name"]),
+            energy_type=str(df_row["energy_type"]),
+            fr=str(df_row["bus_from"]),
+            to=str(df_row["bus_to"]),
+            transmission_loss=float(df_row["transmission_loss"]),
+            max_capacity=float(df_row["max_capacity"]),
+            transmission_fee=(
+                None
+                if pd.isnull(df_row["transmission_fee"])
+                else str(df_row["transmission_fee"])
+            ),
+        )
```

### Comparing `pyzefir-0.4.1/pyzefir/parser/elements_parsers/local_balancing_stack_parser.py` & `pyzefir-0.4.22/pyzefir/parser/elements_parsers/local_balancing_stack_parser.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,64 +1,65 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-import pandas as pd
-
-from pyzefir.model.network_elements import LocalBalancingStack
-from pyzefir.parser.elements_parsers.element_parser import AbstractElementParser
-
-
-class LocalBalancingStackParser(AbstractElementParser):
-    def __init__(
-        self, stack_df: pd.DataFrame, bus_df: pd.DataFrame, stack_bus_df: pd.DataFrame
-    ) -> None:
-        self.stack_df = stack_df
-        self.stack_buses_mapping = self._prepare_stack_buses_mapping(
-            bus_df, stack_bus_df
-        )
-
-    def create(self) -> tuple[LocalBalancingStack, ...]:
-        stacks = self.stack_df.apply(
-            self._create_stack,
-            axis=1,
-        )
-        return tuple(stacks)
-
-    def _create_stack(
-        self,
-        df_row: pd.Series,
-    ) -> LocalBalancingStack:
-        return LocalBalancingStack(
-            name=df_row["name"],
-            buses_out={col: bus_name for col, bus_name in df_row[1:].items()},
-            buses=self.stack_buses_mapping[df_row["name"]],
-        )
-
-    @staticmethod
-    def _prepare_stack_buses_mapping(
-        bus_df: pd.DataFrame, stack_bus_df: pd.DataFrame
-    ) -> dict[str, dict[str, set[str]]]:
-        """
-        Creates dict containing mapping (lbs, energy_type) -> set[buses]
-        """
-        bus_df = bus_df.rename(columns={"name": "bus"})
-        stack_busses_df = pd.merge(bus_df, stack_bus_df, on="bus", how="inner")
-        return (
-            stack_busses_df.groupby("technology_stack")
-            .apply(
-                lambda group: group.groupby("energy_type")["bus"].apply(set).to_dict()
-            )
-            .to_dict()
-        )
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+import numpy as np
+import pandas as pd
+
+from pyzefir.model.network_elements import LocalBalancingStack
+from pyzefir.parser.elements_parsers.element_parser import AbstractElementParser
+
+
+class LocalBalancingStackParser(AbstractElementParser):
+    def __init__(
+        self, stack_df: pd.DataFrame, bus_df: pd.DataFrame, stack_bus_df: pd.DataFrame
+    ) -> None:
+        self.stack_df = stack_df
+        self.stack_buses_mapping = self._prepare_stack_buses_mapping(
+            bus_df, stack_bus_df
+        )
+
+    def create(self) -> tuple[LocalBalancingStack, ...]:
+        stacks = self.stack_df.apply(self._create_stack, axis=1, result_type="reduce")
+        return tuple(stacks)
+
+    def _create_stack(
+        self,
+        df_row: pd.Series,
+    ) -> LocalBalancingStack:
+        return LocalBalancingStack(
+            name=str(df_row["name"]),
+            buses_out={
+                col: bus_name
+                for col, bus_name in df_row[1:].items()
+                if not isinstance(bus_name, float) or not np.isnan(bus_name)
+            },
+            buses=self.stack_buses_mapping[df_row["name"]],
+        )
+
+    @staticmethod
+    def _prepare_stack_buses_mapping(
+        bus_df: pd.DataFrame, stack_bus_df: pd.DataFrame
+    ) -> dict[str, dict[str, set[str]]]:
+        """
+        Creates dict containing mapping (lbs, energy_type) -> set[buses]
+        """
+        bus_df = bus_df.rename(columns={"name": "bus"})
+        stack_busses_df = pd.merge(bus_df, stack_bus_df, on="bus", how="inner")
+        return (
+            stack_busses_df.groupby("technology_stack")
+            .apply(
+                lambda group: group.groupby("energy_type")["bus"].apply(set).to_dict()
+            )
+            .to_dict()
+        )
```

### Comparing `pyzefir-0.4.1/pyzefir/parser/elements_parsers/transmission_fee_parser.py` & `pyzefir-0.4.22/pyzefir/parser/elements_parsers/transmission_fee_parser.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,33 +1,33 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-import pandas as pd
-
-from pyzefir.model.network_elements import TransmissionFee
-from pyzefir.parser.elements_parsers.element_parser import AbstractElementParser
-
-
-class TransmissionFeeParser(AbstractElementParser):
-    def __init__(self, transmission_fee_df: pd.DataFrame) -> None:
-        self.transmission_fee_df = transmission_fee_df
-
-    def create(self) -> tuple[TransmissionFee, ...]:
-        self.transmission_fee_df.set_index("hour_idx", inplace=True)
-
-        return tuple(
-            TransmissionFee(name=name, fee=self.transmission_fee_df[name])
-            for name in self.transmission_fee_df.columns
-        )
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+import pandas as pd
+
+from pyzefir.model.network_elements import TransmissionFee
+from pyzefir.parser.elements_parsers.element_parser import AbstractElementParser
+
+
+class TransmissionFeeParser(AbstractElementParser):
+    def __init__(self, transmission_fee_df: pd.DataFrame) -> None:
+        self.transmission_fee_df = transmission_fee_df
+
+    def create(self) -> tuple[TransmissionFee, ...]:
+        self.transmission_fee_df.set_index("hour_idx", inplace=True)
+
+        return tuple(
+            TransmissionFee(name=str(name), fee=self.transmission_fee_df[name])
+            for name in self.transmission_fee_df.columns
+        )
```

### Comparing `pyzefir-0.4.1/pyzefir/parser/elements_parsers/utils.py` & `pyzefir-0.4.22/pyzefir/parser/elements_parsers/utils.py`

 * *Ordering differences only*

 * *Files 10% similar despite different names*

```diff
@@ -1,29 +1,29 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-import pandas as pd
-
-
-def get_series_or_none(series: pd.Series) -> pd.Series | None:
-    return None if series.empty or series.isna().all() else series
-
-
-def get_float_or_none(value: int | float) -> float | None:
-    return float(value) if not pd.isnull(value) else None
-
-
-def create_tags_list(tags: pd.Series) -> list[str]:
-    return tags[tags].index.to_list()
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+import pandas as pd
+
+
+def get_series_or_none(series: pd.Series) -> pd.Series | None:
+    return None if series.empty or series.isna().all() else series
+
+
+def get_float_or_none(value: int | float) -> float | None:
+    return float(value) if not pd.isnull(value) else None
+
+
+def create_tags_list(tags: pd.Series) -> list[str]:
+    return tags[tags].index.to_list()
```

### Comparing `pyzefir-0.4.1/pyzefir/parser/utils.py` & `pyzefir-0.4.22/pyzefir/structure_creator/__main__.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,24 +1,20 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-from typing import Final
-
-
-def sanitize_dataset_name(dataset_name: str) -> str:
-    return dataset_name.replace("-", "").replace(" ", "_").replace("__", "_")
-
-
-TRUE_VALUES: Final[list[str]] = ["YES"]
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+from pyzefir.structure_creator.cli.cli_wrapper import run_structure_creator_cli
+
+if __name__ == "__main__":
+    run_structure_creator_cli()
```

### Comparing `pyzefir-0.4.1/pyzefir/parser/validator/__init__.py` & `pyzefir-0.4.22/pyzefir/parser/elements_parsers/__init__.py`

 * *Ordering differences only*

 * *Files 23% similar despite different names*

```diff
@@ -1,15 +1,15 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
```

### Comparing `pyzefir-0.4.1/pyzefir/parser/validator/dataframe_validator.py` & `pyzefir-0.4.22/pyzefir/parser/validator/dataframe_validator.py`

 * *Ordering differences only*

 * *Files 12% similar despite different names*

```diff
@@ -1,211 +1,211 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-import logging
-from itertools import zip_longest
-from typing import Type
-
-import pandas as pd
-
-from pyzefir.parser.validator.valid_structure import (
-    DataFramesColumnsType,
-    DatasetConfig,
-)
-
-_logger = logging.getLogger(__name__)
-
-
-class DataFrameValidatorException(Exception):
-    pass
-
-
-class DataFrameValidatorGroupException(
-    DataFrameValidatorException,
-    ExceptionGroup,
-):
-    pass
-
-
-class DataFrameValidator:
-    def __init__(
-        self,
-        df: pd.DataFrame,
-        dataframe_structure: dict[str, str],
-        valid_structure: DatasetConfig,
-        dataset_reference: str,
-    ) -> None:
-        self.dataframe_structure = self._translate_pandas_type_to_python_type(
-            dataframe_structure, dataset_reference
-        )
-        self.valid_structure = valid_structure
-        self.dataset_reference = dataset_reference
-        self._df = df
-
-    def validate(self) -> None:
-        exception_list: list[DataFrameValidatorException] = []
-        self._check_dataframe_structure(exception_list=exception_list)
-        if exception_list:
-            raise DataFrameValidatorGroupException(
-                f"Following errors occurred while processing input file "
-                f"{self.dataset_reference}: ",
-                exception_list,
-            )
-
-    def _check_dynamic_column(
-        self,
-        column_type: Type[DataFramesColumnsType] | None,
-        column_name: str,
-        exception_list: list[DataFrameValidatorException],
-    ) -> None:
-        if not self.valid_structure.default_type:
-            exception_list.append(
-                DataFrameValidatorException(
-                    f"Dataframe column name {column_name} not found in required structure"
-                    f" {list(self.valid_structure.columns)}"
-                )
-            )
-        elif not any(
-            self._check_type_match(column_type, d, self._df, column_name)
-            for d in self.valid_structure.default_type
-        ):
-            exception_list.append(
-                DataFrameValidatorException(
-                    f"Type of dynamic column {column_name}: {column_type} not found"
-                    f" in allowed types {self.valid_structure.default_type}"
-                )
-            )
-
-    @staticmethod
-    def _check_type_match(
-        type_a: DataFramesColumnsType,
-        type_b: DataFramesColumnsType,
-        df: pd.DataFrame,
-        column_name: str,
-    ) -> bool:
-        """
-        Checks whether type_a is float and columns contains only NaN then return True
-        (we allowed empty columns at this step)
-        Checks whether type b matches type a.
-        Note the order of arguments i.e. int matches float,
-        but float does not match int (you can't cast float to int without an information loss)
-        """
-        if type_a is float and df[column_name].isnull().all():
-            _logger.debug(f"Dataframe column {column_name} it's empty")
-            return True
-        return type_a == type_b or (type_a is int and type_b is float)
-
-    def _check_static_column(
-        self,
-        column_name: str,
-        column_type: DataFramesColumnsType,
-        valid_column_name: str,
-        valid_type: DataFramesColumnsType,
-        exception_list: list[DataFrameValidatorException],
-    ) -> None:
-        if column_name != valid_column_name:
-            if column_name in self.valid_structure.columns:
-                exception_list.append(
-                    DataFrameValidatorException(
-                        f"Column {column_name} is misplaced. Should be on index "
-                        f"{list(self.valid_structure.columns).index(column_name)}, "
-                        f"but it is on {list(self.dataframe_structure).index(column_name)} instead"
-                    )
-                )
-                misplaced_column_type = self.valid_structure.columns[column_name]
-                if not self._check_type_match(
-                    column_type, misplaced_column_type, self._df, column_name
-                ):
-                    exception_list.append(
-                        DataFrameValidatorException(
-                            f"Dataframe column {column_name} type {column_type} "
-                            f"is different as in required structure {misplaced_column_type}"
-                        )
-                    )
-            else:
-                exception_list.append(
-                    DataFrameValidatorException(
-                        f"Dataframe column name {column_name} not found in required structure"
-                        f" {list(self.valid_structure.columns)}"
-                    )
-                )
-        elif not self._check_type_match(column_type, valid_type, self._df, column_name):
-            exception_list.append(
-                DataFrameValidatorException(
-                    f"Dataframe column {column_name} type {column_type} "
-                    f"is different as in required structure {valid_type}"
-                )
-            )
-
-    def _check_dataframe_structure(
-        self,
-        exception_list: list[DataFrameValidatorException],
-    ) -> None:
-        """
-        Following conditions are checked in this method:
-        1. If there are more columns in dataframe_structure than there are in valid_structure,
-        if yes then valid_column_name is None.
-            1a. If valid_column_name is None, then check if default type is
-            defined for given dataframe (that would mean that the given column
-            is "dynamic") and matches given column
-
-        2. Otherwise, we check if given column is equal to currently checked valid_column
-            2a. If no, then we check whether the given column is present in valid_structure
-                2aa. If yes, that means that the column is correct, but misplaced. Then we check its type.
-                2ab. If no, then the given column is not in a valid_structure.
-            2b. If yes, we just have to check if its type is correct
-        """
-        for column_name, valid_column_name in zip_longest(
-            self.dataframe_structure, self.valid_structure.columns
-        ):
-            column_type = self.dataframe_structure.get(column_name)
-            valid_type = self.valid_structure.columns.get(valid_column_name)
-            if valid_column_name is None:
-                self._check_dynamic_column(column_type, column_name, exception_list)
-            else:
-                self._check_static_column(
-                    column_name,
-                    column_type,
-                    valid_column_name,
-                    valid_type,
-                    exception_list,
-                )
-
-    @staticmethod
-    def _translate_pandas_type_to_python_type(
-        dataframe_structure: dict[str, str], dataset_reference: str
-    ) -> dict[str, DataFramesColumnsType]:
-        translated_structure: dict[str, DataFramesColumnsType] = dict()
-        for column_name, pandas_type_name in dataframe_structure.items():
-            match pandas_type_name:
-                case "int64":
-                    translated_structure[column_name] = int
-                case "float64":
-                    translated_structure[column_name] = float
-                case "object":
-                    translated_structure[column_name] = str
-                case "bool":
-                    translated_structure[column_name] = bool
-                case _:
-                    _logger.warning(
-                        f"Dataframe has unknown column type {pandas_type_name}"
-                    )
-                    raise DataFrameValidatorException(
-                        f"Dataset {dataset_reference} column type error. "
-                        f"Column: {column_name} type: {pandas_type_name} "
-                        f"cannot be translated into python type"
-                    )
-
-        return translated_structure
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+import logging
+from itertools import zip_longest
+from typing import Type
+
+import pandas as pd
+
+from pyzefir.parser.validator.valid_structure import (
+    DataFramesColumnsType,
+    DatasetConfig,
+)
+
+_logger = logging.getLogger(__name__)
+
+
+class DataFrameValidatorException(Exception):
+    pass
+
+
+class DataFrameValidatorGroupException(
+    DataFrameValidatorException,
+    ExceptionGroup,
+):
+    pass
+
+
+class DataFrameValidator:
+    def __init__(
+        self,
+        df: pd.DataFrame,
+        dataframe_structure: dict[str, str],
+        valid_structure: DatasetConfig,
+        dataset_reference: str,
+    ) -> None:
+        self.dataframe_structure = self._translate_pandas_type_to_python_type(
+            dataframe_structure, dataset_reference
+        )
+        self.valid_structure = valid_structure
+        self.dataset_reference = dataset_reference
+        self._df = df
+
+    def validate(self) -> None:
+        exception_list: list[DataFrameValidatorException] = []
+        self._check_dataframe_structure(exception_list=exception_list)
+        if exception_list:
+            raise DataFrameValidatorGroupException(
+                f"Following errors occurred while processing input file "
+                f"{self.dataset_reference}: ",
+                exception_list,
+            )
+
+    def _check_dynamic_column(
+        self,
+        column_type: Type[DataFramesColumnsType] | None,
+        column_name: str,
+        exception_list: list[DataFrameValidatorException],
+    ) -> None:
+        if not self.valid_structure.default_type:
+            exception_list.append(
+                DataFrameValidatorException(
+                    f"Dataframe column name {column_name} not found in required structure"
+                    f" {list(self.valid_structure.columns)}"
+                )
+            )
+        elif not any(
+            self._check_type_match(column_type, d, self._df, column_name)
+            for d in self.valid_structure.default_type
+        ):
+            exception_list.append(
+                DataFrameValidatorException(
+                    f"Type of dynamic column {column_name}: {column_type} not found"
+                    f" in allowed types {self.valid_structure.default_type}"
+                )
+            )
+
+    @staticmethod
+    def _check_type_match(
+        type_a: DataFramesColumnsType,
+        type_b: DataFramesColumnsType,
+        df: pd.DataFrame,
+        column_name: str,
+    ) -> bool:
+        """
+        Checks whether type_a is float and columns contains only NaN then return True
+        (we allowed empty columns at this step)
+        Checks whether type b matches type a.
+        Note the order of arguments i.e. int matches float,
+        but float does not match int (you can't cast float to int without an information loss)
+        """
+        if type_a is float and df[column_name].isnull().all():
+            _logger.debug(f"Dataframe column {column_name} it's empty")
+            return True
+        return type_a == type_b or (type_a is int and type_b is float)
+
+    def _check_static_column(
+        self,
+        column_name: str,
+        column_type: DataFramesColumnsType,
+        valid_column_name: str,
+        valid_type: DataFramesColumnsType,
+        exception_list: list[DataFrameValidatorException],
+    ) -> None:
+        if column_name != valid_column_name:
+            if column_name in self.valid_structure.columns:
+                exception_list.append(
+                    DataFrameValidatorException(
+                        f"Column {column_name} is misplaced. Should be on index "
+                        f"{list(self.valid_structure.columns).index(column_name)}, "
+                        f"but it is on {list(self.dataframe_structure).index(column_name)} instead"
+                    )
+                )
+                misplaced_column_type = self.valid_structure.columns[column_name]
+                if not self._check_type_match(
+                    column_type, misplaced_column_type, self._df, column_name
+                ):
+                    exception_list.append(
+                        DataFrameValidatorException(
+                            f"Dataframe column {column_name} type {column_type} "
+                            f"is different as in required structure {misplaced_column_type}"
+                        )
+                    )
+            else:
+                exception_list.append(
+                    DataFrameValidatorException(
+                        f"Dataframe column name {column_name} not found in required structure"
+                        f" {list(self.valid_structure.columns)}"
+                    )
+                )
+        elif not self._check_type_match(column_type, valid_type, self._df, column_name):
+            exception_list.append(
+                DataFrameValidatorException(
+                    f"Dataframe column {column_name} type {column_type} "
+                    f"is different as in required structure {valid_type}"
+                )
+            )
+
+    def _check_dataframe_structure(
+        self,
+        exception_list: list[DataFrameValidatorException],
+    ) -> None:
+        """
+        Following conditions are checked in this method:
+        1. If there are more columns in dataframe_structure than there are in valid_structure,
+        if yes then valid_column_name is None.
+            1a. If valid_column_name is None, then check if default type is
+            defined for given dataframe (that would mean that the given column
+            is "dynamic") and matches given column
+
+        2. Otherwise, we check if given column is equal to currently checked valid_column
+            2a. If no, then we check whether the given column is present in valid_structure
+                2aa. If yes, that means that the column is correct, but misplaced. Then we check its type.
+                2ab. If no, then the given column is not in a valid_structure.
+            2b. If yes, we just have to check if its type is correct
+        """
+        for column_name, valid_column_name in zip_longest(
+            self.dataframe_structure, self.valid_structure.columns
+        ):
+            column_type = self.dataframe_structure.get(column_name)
+            valid_type = self.valid_structure.columns.get(valid_column_name)
+            if valid_column_name is None:
+                self._check_dynamic_column(column_type, column_name, exception_list)
+            else:
+                self._check_static_column(
+                    column_name,
+                    column_type,
+                    valid_column_name,
+                    valid_type,
+                    exception_list,
+                )
+
+    @staticmethod
+    def _translate_pandas_type_to_python_type(
+        dataframe_structure: dict[str, str], dataset_reference: str
+    ) -> dict[str, DataFramesColumnsType]:
+        translated_structure: dict[str, DataFramesColumnsType] = dict()
+        for column_name, pandas_type_name in dataframe_structure.items():
+            match pandas_type_name:
+                case "int64":
+                    translated_structure[column_name] = int
+                case "float64":
+                    translated_structure[column_name] = float
+                case "object":
+                    translated_structure[column_name] = str
+                case "bool":
+                    translated_structure[column_name] = bool
+                case _:
+                    _logger.warning(
+                        f"Dataframe has unknown column type {pandas_type_name}"
+                    )
+                    raise DataFrameValidatorException(
+                        f"Dataset {dataset_reference} column type error. "
+                        f"Column: {column_name} type: {pandas_type_name} "
+                        f"cannot be translated into python type"
+                    )
+
+        return translated_structure
```

### Comparing `pyzefir-0.4.1/pyzefir/parser/validator/valid_structure.py` & `pyzefir-0.4.22/pyzefir/parser/validator/valid_structure.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,389 +1,405 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-import logging
-from dataclasses import dataclass
-from typing import Type
-
-from pyzefir.utils.path_manager import DataCategories, DataSubCategories
-
-DataFramesColumnsType = Type[str | int | float | bool]
-ColumnType = dict[str, DataFramesColumnsType]
-
-logger = logging.getLogger(__name__)
-
-
-class InvalidStructureException(Exception):
-    pass
-
-
-@dataclass
-class DatasetConfig:
-    columns: ColumnType
-    dataset_name: str
-    default_type: set[DataFramesColumnsType] | None = None
-
-
-def get_dataset_config_from_categories(
-    data_category: str, dataset_name: str
-) -> DatasetConfig:
-    dataset_validation_structure: dict[str, list[DatasetConfig] | DatasetConfig] = {
-        DataCategories.FUELS: [
-            DatasetConfig(
-                dataset_name=DataSubCategories.EMISSION_PER_UNIT,
-                columns={"name": str},
-                default_type={float},
-            ),
-            DatasetConfig(
-                dataset_name=DataSubCategories.ENERGY_PER_UNIT,
-                columns={"name": str, "energy_per_unit": float},
-            ),
-        ],
-        DataCategories.CAPACITY_FACTORS: [
-            DatasetConfig(
-                dataset_name=DataSubCategories.PROFILES,
-                columns={"hour_idx": int},
-                default_type={float},
-            )
-        ],
-        DataCategories.GENERATOR: [
-            DatasetConfig(
-                dataset_name=DataSubCategories.GENERATOR_TYPES,
-                columns={
-                    "name": str,
-                    "ramp": float,
-                    "build_time": int,
-                    "life_time": int,
-                    "power_utilization": float,
-                },
-                default_type={bool},
-            ),
-            DatasetConfig(
-                dataset_name=DataSubCategories.EFFICIENCY,
-                columns={
-                    "generator_type": str,
-                    "energy_type": str,
-                    "efficiency": float,
-                },
-            ),
-            DatasetConfig(
-                dataset_name=DataSubCategories.EMISSION_REDUCTION,
-                columns={"generator_type": str},
-                default_type={float},
-            ),
-            DatasetConfig(
-                dataset_name=DataSubCategories.GENERATOR_TYPE_ENERGY_CARRIER,
-                columns={
-                    "generator_type": str,
-                    "fuel_name": str,
-                    "capacity_factor_name": str,
-                },
-            ),
-            DatasetConfig(
-                dataset_name=DataSubCategories.GENERATOR_TYPE_ENERGY_TYPE,
-                columns={"generator_type": str, "energy_type": str},
-            ),
-            DatasetConfig(
-                dataset_name=DataSubCategories.POWER_UTILIZATION,
-                columns={"hour_idx": int},
-                default_type={float},
-            ),
-        ],
-        DataCategories.STORAGE: [
-            DatasetConfig(
-                dataset_name=DataSubCategories.PARAMETERS,
-                columns={
-                    "storage_type": str,
-                    "load_efficiency": float,
-                    "gen_efficiency": float,
-                    "cycle_length": int,
-                    "power_to_capacity": int,
-                    "energy_type": str,
-                    "energy_loss": float,
-                    "build_time": int,
-                    "life_time": int,
-                    "power_utilization": float,
-                },
-                default_type={bool},
-            )
-        ],
-        DataCategories.INITIAL_STATE: [
-            DatasetConfig(
-                dataset_name=DataSubCategories.TECHNOLOGY,
-                columns={"technology": str, "base_capacity": float},
-            ),
-            DatasetConfig(
-                dataset_name=DataSubCategories.TECHNOLOGYSTACK,
-                columns={
-                    "technology_stack": str,
-                    "aggregate": str,
-                    "base_fraction": float,
-                },
-            ),
-        ],
-        DataCategories.STRUCTURE: [
-            DatasetConfig(
-                dataset_name=DataSubCategories.ENERGY_TYPES, columns={"name": str}
-            ),
-            DatasetConfig(
-                dataset_name=DataSubCategories.EMISSION_TYPES,
-                columns={"name": str, "base_total_emission": float},
-            ),
-            DatasetConfig(
-                dataset_name=DataSubCategories.AGGREGATES,
-                columns={
-                    "name": str,
-                    "demand_type": str,
-                    "n_consumers_base": int,
-                    "average_area": float,
-                },
-            ),
-            DatasetConfig(
-                dataset_name=DataSubCategories.LINES,
-                columns={
-                    "name": str,
-                    "energy_type": str,
-                    "bus_from": str,
-                    "bus_to": str,
-                    "transmission_loss": float,
-                    "max_capacity": float,
-                    "transmission_fee": str,
-                },
-            ),
-            DatasetConfig(
-                dataset_name=DataSubCategories.BUSES,
-                columns={"name": str, "energy_type": str, "dsr_type": str},
-            ),
-            DatasetConfig(
-                dataset_name=DataSubCategories.GENERATORS,
-                columns={
-                    "name": str,
-                    "generator_type": str,
-                    "min_device_nom_power": float,
-                    "max_device_nom_power": float,
-                },
-                default_type={bool},
-            ),
-            DatasetConfig(
-                dataset_name=DataSubCategories.STORAGES,
-                columns={
-                    "name": str,
-                    "storage_type": str,
-                    "min_device_nom_power": float,
-                    "max_device_nom_power": float,
-                },
-                default_type={bool},
-            ),
-            DatasetConfig(
-                dataset_name=DataSubCategories.TECHNOLOGYSTACKS_BUSES_OUT,
-                columns={"name": str},
-                default_type={str},
-            ),
-            DatasetConfig(
-                dataset_name=DataSubCategories.TECHNOLOGY_BUS,
-                columns={"technology": str, "type": str, "bus": str},
-            ),
-            DatasetConfig(
-                dataset_name=DataSubCategories.TECHNOLOGYSTACK_BUSES,
-                columns={"technology_stack": str, "bus": str},
-            ),
-            DatasetConfig(
-                dataset_name=DataSubCategories.TECHNOLOGYSTACK_AGGREGATE,
-                columns={"technology_stack": str, "aggregate": str},
-            ),
-            DatasetConfig(
-                dataset_name=DataSubCategories.TRANSMISSION_FEES,
-                columns={"hour_idx": int},
-                default_type={float},
-            ),
-            DatasetConfig(
-                dataset_name=DataSubCategories.EMISSION_FEES_EMISSION_TYPES,
-                columns={"emission_type": str, "emission_fee": str},
-            ),
-            DatasetConfig(
-                dataset_name=DataSubCategories.GENERATOR_EMISSION_FEES,
-                columns={"generator": str, "emission_fee": str},
-            ),
-            DatasetConfig(
-                dataset_name=DataSubCategories.DSR,
-                columns={
-                    "name": str,
-                    "compensation_factor": float,
-                    "balancing_period_len": int,
-                    "penalization": float,
-                    "relative_shift_limit": float,
-                    "abs_shift_limit": float,
-                },
-            ),
-            DatasetConfig(
-                dataset_name=DataSubCategories.POWER_RESERVE,
-                columns={
-                    "tag_name": str,
-                    "energy_type": str,
-                    "power_reserve_value": float,
-                },
-            ),
-        ],
-        DataCategories.SCENARIO: [
-            DatasetConfig(
-                dataset_name=DataSubCategories.ENERGY_SOURCE_EVOLUTION_LIMITS,
-                columns={
-                    "year_idx": int,
-                    "technology_type": str,
-                    "max_capacity": float,
-                    "min_capacity": float,
-                    "max_capacity_increase": float,
-                    "min_capacity_increase": float,
-                },
-            ),
-            DatasetConfig(
-                dataset_name=DataSubCategories.ELEMENT_ENERGY_EVOLUTION_LIMITS,
-                columns={
-                    "year_idx": int,
-                    "technology_name": str,
-                    "max_capacity": float,
-                    "min_capacity": float,
-                    "max_capacity_increase": float,
-                    "min_capacity_increase": float,
-                },
-            ),
-            DatasetConfig(
-                dataset_name=DataSubCategories.GENERATION_FRACTION,
-                columns={
-                    "tag": str,
-                    "subtag": str,
-                    "energy_type": str,
-                    "min_generation_fraction": float,
-                    "max_generation_fraction": float,
-                },
-            ),
-            DatasetConfig(
-                dataset_name=DataSubCategories.COST_PARAMETERS,
-                columns={
-                    "year_idx": int,
-                    "technology_type": str,
-                    "CAPEX": float,
-                    "OPEX": float,
-                },
-            ),
-            DatasetConfig(
-                dataset_name=DataSubCategories.FUEL_AVAILABILITY,
-                columns={"year_idx": int},
-                default_type={float, int},
-            ),
-            DatasetConfig(
-                dataset_name=DataSubCategories.RELATIVE_EMISSION_LIMITS,
-                columns={"year_idx": int},
-                default_type={float},
-            ),
-            DatasetConfig(
-                dataset_name=DataSubCategories.FUEL_PRICES,
-                columns={"year_idx": int},
-                default_type={float},
-            ),
-            DatasetConfig(
-                dataset_name=DataSubCategories.CONSTANTS,
-                columns={"constants_name": str, "constants_value": int},
-            ),
-            DatasetConfig(
-                dataset_name=DataSubCategories.YEARLY_ENERGY_USAGE,
-                columns={
-                    "aggregate": str,
-                    "energy_type": str,
-                    "year_idx": int,
-                    "value": float,
-                },
-            ),
-            DatasetConfig(
-                dataset_name=DataSubCategories.FRACTIONS,
-                columns={
-                    "technology_stack": str,
-                    "aggregate": str,
-                    "year": int,
-                    "min_fraction": float,
-                    "max_fraction": float,
-                    "max_fraction_increase": float,
-                    "max_fraction_decrease": float,
-                },
-            ),
-            DatasetConfig(
-                dataset_name=DataSubCategories.N_CONSUMERS,
-                columns={"year_idx": int},
-                default_type={int},
-            ),
-            DatasetConfig(
-                dataset_name=DataSubCategories.CURTAILMENT_COST,
-                columns={"year_idx": int},
-                default_type={float},
-            ),
-            DatasetConfig(
-                dataset_name=DataSubCategories.EMISSION_FEES,
-                columns={"year_idx": int},
-                default_type={float},
-            ),
-        ],
-        DataCategories.DEMAND: DatasetConfig(
-            dataset_name=dataset_name, columns={"hour_idx": int}, default_type={float}
-        ),
-        DataCategories.CONVERSION_RATE: DatasetConfig(
-            dataset_name=dataset_name,
-            columns={
-                "hour_idx": int,
-            },
-            default_type={float},
-        ),
-        DataCategories.DEMAND_CHUNKS: [
-            DatasetConfig(
-                dataset_name=DataSubCategories.DEMAND_CHUNKS,
-                columns={
-                    "name": str,
-                    "tag": str,
-                    "energy_type": str,
-                },
-                default_type={float},
-            ),
-            DatasetConfig(
-                dataset_name=dataset_name,
-                columns={
-                    "period_start": int,
-                    "period_end": int,
-                },
-                default_type={int},
-            ),
-        ],
-    }
-
-    if (selected_category := dataset_validation_structure.get(data_category)) is None:
-        logger.warning(f"{data_category=} not in dataset_validation_structure keys")
-        raise InvalidStructureException(
-            f"{data_category=} not in dataset_validation_structure keys"
-        )
-    if isinstance(selected_category, DatasetConfig):
-        return selected_category
-    elif isinstance(selected_category, list):
-        for data_config in selected_category:
-            if data_config.dataset_name == dataset_name:
-                return data_config
-    logger.warning(
-        f"No dataset config found for category {data_category} and dataset {dataset_name}"
-    )
-    raise InvalidStructureException(
-        f"No dataset config found for category {data_category} and dataset {dataset_name}"
-    )
-
-
-def get_dataset_reference(category: str, dataset_name: str) -> str:
-    return f"{category} / {dataset_name}"
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+import logging
+from dataclasses import dataclass
+from typing import Type
+
+from pyzefir.utils.path_manager import DataCategories, DataSubCategories
+
+DataFramesColumnsType = Type[str | int | float | bool]
+ColumnType = dict[str, DataFramesColumnsType]
+
+logger = logging.getLogger(__name__)
+
+
+class InvalidStructureException(Exception):
+    pass
+
+
+@dataclass
+class DatasetConfig:
+    columns: ColumnType
+    dataset_name: str
+    default_type: set[DataFramesColumnsType] | None = None
+
+
+def get_dataset_config_from_categories(
+    data_category: str, dataset_name: str
+) -> DatasetConfig:
+    dataset_validation_structure: dict[str, list[DatasetConfig] | DatasetConfig] = {
+        DataCategories.FUELS: [
+            DatasetConfig(
+                dataset_name=DataSubCategories.EMISSION_PER_UNIT,
+                columns={"name": str},
+                default_type={float},
+            ),
+            DatasetConfig(
+                dataset_name=DataSubCategories.ENERGY_PER_UNIT,
+                columns={"name": str, "energy_per_unit": float},
+            ),
+        ],
+        DataCategories.CAPACITY_FACTORS: [
+            DatasetConfig(
+                dataset_name=DataSubCategories.PROFILES,
+                columns={"hour_idx": int},
+                default_type={float},
+            )
+        ],
+        DataCategories.GENERATOR: [
+            DatasetConfig(
+                dataset_name=DataSubCategories.GENERATOR_TYPES,
+                columns={
+                    "name": str,
+                    "ramp": float,
+                    "build_time": int,
+                    "life_time": int,
+                    "power_utilization": float,
+                },
+                default_type={bool},
+            ),
+            DatasetConfig(
+                dataset_name=DataSubCategories.EFFICIENCY,
+                columns={
+                    "generator_type": str,
+                    "energy_type": str,
+                    "efficiency": float,
+                },
+            ),
+            DatasetConfig(
+                dataset_name=DataSubCategories.EMISSION_REDUCTION,
+                columns={"generator_type": str},
+                default_type={float},
+            ),
+            DatasetConfig(
+                dataset_name=DataSubCategories.GENERATOR_TYPE_ENERGY_CARRIER,
+                columns={
+                    "generator_type": str,
+                    "fuel_name": str,
+                    "capacity_factor_name": str,
+                },
+            ),
+            DatasetConfig(
+                dataset_name=DataSubCategories.GENERATOR_TYPE_ENERGY_TYPE,
+                columns={"generator_type": str, "energy_type": str},
+            ),
+            DatasetConfig(
+                dataset_name=DataSubCategories.POWER_UTILIZATION,
+                columns={"hour_idx": int},
+                default_type={float},
+            ),
+        ],
+        DataCategories.STORAGE: [
+            DatasetConfig(
+                dataset_name=DataSubCategories.PARAMETERS,
+                columns={
+                    "storage_type": str,
+                    "load_efficiency": float,
+                    "gen_efficiency": float,
+                    "cycle_length": float,
+                    "power_to_capacity": float,
+                    "energy_type": str,
+                    "energy_loss": float,
+                    "build_time": int,
+                    "life_time": int,
+                    "power_utilization": float,
+                },
+                default_type={bool},
+            )
+        ],
+        DataCategories.INITIAL_STATE: [
+            DatasetConfig(
+                dataset_name=DataSubCategories.TECHNOLOGY,
+                columns={"technology": str, "base_capacity": float},
+            ),
+            DatasetConfig(
+                dataset_name=DataSubCategories.TECHNOLOGYSTACK,
+                columns={
+                    "technology_stack": str,
+                    "aggregate": str,
+                    "base_fraction": float,
+                },
+            ),
+        ],
+        DataCategories.STRUCTURE: [
+            DatasetConfig(
+                dataset_name=DataSubCategories.ENERGY_TYPES, columns={"name": str}
+            ),
+            DatasetConfig(
+                dataset_name=DataSubCategories.EMISSION_TYPES,
+                columns={"name": str, "base_total_emission": float},
+            ),
+            DatasetConfig(
+                dataset_name=DataSubCategories.AGGREGATES,
+                columns={
+                    "name": str,
+                    "demand_type": str,
+                    "n_consumers_base": int,
+                    "average_area": float,
+                },
+            ),
+            DatasetConfig(
+                dataset_name=DataSubCategories.LINES,
+                columns={
+                    "name": str,
+                    "energy_type": str,
+                    "bus_from": str,
+                    "bus_to": str,
+                    "transmission_loss": float,
+                    "max_capacity": float,
+                    "transmission_fee": str,
+                },
+            ),
+            DatasetConfig(
+                dataset_name=DataSubCategories.BUSES,
+                columns={"name": str, "energy_type": str, "dsr_type": str},
+            ),
+            DatasetConfig(
+                dataset_name=DataSubCategories.GENERATORS,
+                columns={
+                    "name": str,
+                    "generator_type": str,
+                    "min_device_nom_power": float,
+                    "max_device_nom_power": float,
+                },
+                default_type={bool},
+            ),
+            DatasetConfig(
+                dataset_name=DataSubCategories.STORAGES,
+                columns={
+                    "name": str,
+                    "storage_type": str,
+                    "min_device_nom_power": float,
+                    "max_device_nom_power": float,
+                },
+                default_type={bool},
+            ),
+            DatasetConfig(
+                dataset_name=DataSubCategories.TECHNOLOGYSTACKS_BUSES_OUT,
+                columns={"name": str},
+                default_type={str},
+            ),
+            DatasetConfig(
+                dataset_name=DataSubCategories.TECHNOLOGY_BUS,
+                columns={"technology": str, "type": str, "bus": str},
+            ),
+            DatasetConfig(
+                dataset_name=DataSubCategories.TECHNOLOGYSTACK_BUSES,
+                columns={"technology_stack": str, "bus": str},
+            ),
+            DatasetConfig(
+                dataset_name=DataSubCategories.TECHNOLOGYSTACK_AGGREGATE,
+                columns={"technology_stack": str, "aggregate": str},
+            ),
+            DatasetConfig(
+                dataset_name=DataSubCategories.TRANSMISSION_FEES,
+                columns={"hour_idx": int},
+                default_type={float},
+            ),
+            DatasetConfig(
+                dataset_name=DataSubCategories.EMISSION_FEES_EMISSION_TYPES,
+                columns={"emission_type": str, "emission_fee": str},
+            ),
+            DatasetConfig(
+                dataset_name=DataSubCategories.GENERATOR_EMISSION_FEES,
+                columns={"generator": str, "emission_fee": str},
+            ),
+            DatasetConfig(
+                dataset_name=DataSubCategories.DSR,
+                columns={
+                    "name": str,
+                    "compensation_factor": float,
+                    "balancing_period_len": int,
+                    "penalization": float,
+                    "relative_shift_limit": float,
+                    "abs_shift_limit": float,
+                },
+            ),
+            DatasetConfig(
+                dataset_name=DataSubCategories.POWER_RESERVE,
+                columns={
+                    "tag_name": str,
+                    "energy_type": str,
+                    "power_reserve_value": float,
+                },
+            ),
+            DatasetConfig(
+                dataset_name=DataSubCategories.GENERATOR_BINDING,
+                columns={"generator": str, "binding_name": str},
+            ),
+        ],
+        DataCategories.SCENARIO: [
+            DatasetConfig(
+                dataset_name=DataSubCategories.GENERATION_COMPENSATION,
+                columns={"year_idx": int},
+                default_type={float},
+            ),
+            DatasetConfig(
+                dataset_name=DataSubCategories.ENERGY_SOURCE_EVOLUTION_LIMITS,
+                columns={
+                    "year_idx": int,
+                    "technology_type": str,
+                    "max_capacity": float,
+                    "min_capacity": float,
+                    "max_capacity_increase": float,
+                    "min_capacity_increase": float,
+                },
+            ),
+            DatasetConfig(
+                dataset_name=DataSubCategories.ELEMENT_ENERGY_EVOLUTION_LIMITS,
+                columns={
+                    "year_idx": int,
+                    "technology_name": str,
+                    "max_capacity": float,
+                    "min_capacity": float,
+                    "max_capacity_increase": float,
+                    "min_capacity_increase": float,
+                },
+            ),
+            DatasetConfig(
+                dataset_name=DataSubCategories.GENERATION_FRACTION,
+                columns={
+                    "tag": str,
+                    "subtag": str,
+                    "energy_type": str,
+                    "min_generation_fraction": float,
+                    "max_generation_fraction": float,
+                },
+            ),
+            DatasetConfig(
+                dataset_name=DataSubCategories.COST_PARAMETERS,
+                columns={
+                    "year_idx": int,
+                    "technology_type": str,
+                    "CAPEX": float,
+                    "OPEX": float,
+                },
+            ),
+            DatasetConfig(
+                dataset_name=DataSubCategories.FUEL_AVAILABILITY,
+                columns={"year_idx": int},
+                default_type={float},
+            ),
+            DatasetConfig(
+                dataset_name=DataSubCategories.RELATIVE_EMISSION_LIMITS,
+                columns={"year_idx": int},
+                default_type={float},
+            ),
+            DatasetConfig(
+                dataset_name=DataSubCategories.FUEL_PRICES,
+                columns={"year_idx": int},
+                default_type={float},
+            ),
+            DatasetConfig(
+                dataset_name=DataSubCategories.CONSTANTS,
+                columns={"constants_name": str, "constants_value": int},
+            ),
+            DatasetConfig(
+                dataset_name=DataSubCategories.YEARLY_ENERGY_USAGE,
+                columns={
+                    "aggregate": str,
+                    "energy_type": str,
+                    "year_idx": int,
+                    "value": float,
+                },
+            ),
+            DatasetConfig(
+                dataset_name=DataSubCategories.FRACTIONS,
+                columns={
+                    "technology_stack": str,
+                    "aggregate": str,
+                    "year": int,
+                    "min_fraction": float,
+                    "max_fraction": float,
+                    "max_fraction_increase": float,
+                    "max_fraction_decrease": float,
+                },
+            ),
+            DatasetConfig(
+                dataset_name=DataSubCategories.N_CONSUMERS,
+                columns={"year_idx": int},
+                default_type={int},
+            ),
+            DatasetConfig(
+                dataset_name=DataSubCategories.CURTAILMENT_COST,
+                columns={"year_idx": int},
+                default_type={float},
+            ),
+            DatasetConfig(
+                dataset_name=DataSubCategories.EMISSION_FEES,
+                columns={"year_idx": int},
+                default_type={float},
+            ),
+        ],
+        DataCategories.DEMAND: DatasetConfig(
+            dataset_name=dataset_name, columns={"hour_idx": int}, default_type={float}
+        ),
+        DataCategories.CONVERSION_RATE: DatasetConfig(
+            dataset_name=dataset_name,
+            columns={
+                "hour_idx": int,
+            },
+            default_type={float},
+        ),
+        DataCategories.DEMAND_CHUNKS: [
+            DatasetConfig(
+                dataset_name=DataSubCategories.DEMAND_CHUNKS,
+                columns={
+                    "name": str,
+                    "tag": str,
+                    "energy_type": str,
+                },
+                default_type={float},
+            ),
+            DatasetConfig(
+                dataset_name=dataset_name,
+                columns={
+                    "period_start": int,
+                    "period_end": int,
+                },
+                default_type={float},
+            ),
+        ],
+        DataCategories.GENERATOR_TYPE_EFFICIENCY: DatasetConfig(
+            dataset_name=dataset_name,
+            columns={
+                "hour_idx": int,
+            },
+            default_type={float},
+        ),
+    }
+
+    if (selected_category := dataset_validation_structure.get(data_category)) is None:
+        logger.warning(f"{data_category=} not in dataset_validation_structure keys")
+        raise InvalidStructureException(
+            f"{data_category=} not in dataset_validation_structure keys"
+        )
+    if isinstance(selected_category, DatasetConfig):
+        return selected_category
+    elif isinstance(selected_category, list):
+        for data_config in selected_category:
+            if data_config.dataset_name == dataset_name:
+                return data_config
+    logger.warning(
+        f"No dataset config found for category {data_category} and dataset {dataset_name}"
+    )
+    raise InvalidStructureException(
+        f"No dataset config found for category {data_category} and dataset {dataset_name}"
+    )
+
+
+def get_dataset_reference(category: str, dataset_name: str) -> str:
+    return f"{category} / {dataset_name}"
```

### Comparing `pyzefir-0.4.1/pyzefir/postprocessing/__init__.py` & `pyzefir-0.4.22/pyzefir/parser/validator/__init__.py`

 * *Ordering differences only*

 * *Files 23% similar despite different names*

```diff
@@ -1,15 +1,15 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
```

### Comparing `pyzefir-0.4.1/pyzefir/postprocessing/results_exporters.py` & `pyzefir-0.4.22/pyzefir/postprocessing/results_exporters.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,130 +1,134 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-import logging
-from pathlib import Path
-
-import pandas as pd
-from sanitize_filename import sanitize
-
-from pyzefir.optimization.exportable_results import ExportableResultsGroup
-from pyzefir.postprocessing.results_handler import Exporter
-
-_logger = logging.getLogger(__name__)
-
-
-class CsvExporter(Exporter):
-    """Class for exporting data to Csv format."""
-
-    @staticmethod
-    def export_group_results(root_path: Path, result: ExportableResultsGroup) -> None:
-        """
-        Export exportable group results to Csv files.
-
-        Args:
-            root_path (Path): The root path for exporting the results.
-            result (ExportableResultsGroup): The exportable results to be parsed and exported.
-
-        Returns:
-            None
-        """
-        for field_name, field_value in result.__dict__.items():
-            output_path = root_path / field_name
-            output_path.mkdir(parents=True, exist_ok=True)
-            if isinstance(field_value, dict):
-                for df_name, df in field_value.items():
-                    df.to_csv(output_path / f"{sanitize(df_name)}.csv")
-                    _logger.debug(
-                        f"Data {df_name} saved under the path: {output_path / f'{sanitize(df_name)}.csv'} "
-                    )
-            else:
-                field_value.to_csv(output_path / f"{field_name}.csv")
-                _logger.debug(
-                    f"Data {field_name} saved under the path: {output_path / f'{field_name}.csv'}"
-                )
-
-    @staticmethod
-    def export_objective_result(
-        root_path: Path, objective_value_series: pd.Series
-    ) -> None:
-        """
-        Exports the given objective value series to a Csv file.
-
-        Parameters:
-            root_path (Path): The root path where the Csv file will be saved.
-            objective_value_series (pd.Series): A Pandas Series containing objective values.
-
-        Returns:
-            None
-        """
-        objective_value_series.to_csv(root_path / f"{objective_value_series.name}.csv")
-
-
-class XlsxExporter(Exporter):
-    """Class for exporting data to XLSX format."""
-
-    @staticmethod
-    def export_group_results(root_path: Path, result: ExportableResultsGroup) -> None:
-        """
-        Export exportable group results to Xlsx files.
-
-        Args:
-            root_path (Path): The root path for exporting the results.
-            result (ExportableResultsGroup): The exportable results to be parsed and exported.
-
-        Returns:
-            None
-        """
-        root_path.mkdir(parents=True, exist_ok=True)
-        for field_name, field_value in result.__dict__.items():
-            with pd.ExcelWriter(
-                (root_path / field_name).with_suffix(".xlsx"), engine="xlsxwriter"
-            ) as writer:
-                if isinstance(field_value, dict):
-                    if not field_value:
-                        _logger.info(
-                            f"No results found for: {field_name} when saving results to xlsx.  "
-                        )
-                        continue
-                    df = pd.concat(field_value, axis=1).sort_index(axis=1)
-                else:
-                    df = field_value
-                df.to_excel(writer, sheet_name=field_name)
-                _logger.debug(
-                    f"Data {field_name} saved under the path: {(root_path / field_name).with_suffix('.xlsx')} "
-                )
-
-    @staticmethod
-    def export_objective_result(
-        root_path: Path, objective_value_series: pd.Series
-    ) -> None:
-        """
-        Exports the given objective value series to a Xlsx file.
-
-        Parameters:
-            root_path (Path): The root path where the Xlsx file will be saved.
-            objective_value_series (pd.Series): A Pandas Series containing objective values.
-
-        Returns:
-            None
-        """
-        output_path = root_path / f"{objective_value_series.name}.xlsx"
-        objective_value_series.to_excel(
-            output_path, sheet_name=str(objective_value_series.name)
-        )
-        _logger.debug(
-            f"Data {objective_value_series.name} saved under the path: {output_path}"
-        )
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+import logging
+from pathlib import Path
+
+import pandas as pd
+from sanitize_filename import sanitize
+
+from pyzefir.optimization.exportable_results import ExportableResultsGroup
+from pyzefir.postprocessing.results_handler import Exporter
+
+_logger = logging.getLogger(__name__)
+
+
+class CsvExporter(Exporter):
+    """Class for exporting data to Csv format."""
+
+    @staticmethod
+    def export_group_results(root_path: Path, result: ExportableResultsGroup) -> None:
+        """
+        Export exportable group results to Csv files.
+
+        Args:
+            root_path (Path): The root path for exporting the results.
+            result (ExportableResultsGroup): The exportable results to be parsed and exported.
+
+        Returns:
+            None
+        """
+        if Exporter.is_results_group_empty(result):
+            return
+        for field_name, field_value in result.__dict__.items():
+            output_path = root_path / field_name
+            output_path.mkdir(parents=True, exist_ok=True)
+            if isinstance(field_value, dict):
+                for df_name, df in field_value.items():
+                    df.to_csv(output_path / f"{sanitize(df_name)}.csv")
+                    _logger.debug(
+                        f"Data {df_name} saved under the path: {output_path / f'{sanitize(df_name)}.csv'} "
+                    )
+            else:
+                field_value.to_csv(output_path / f"{field_name}.csv")
+                _logger.debug(
+                    f"Data {field_name} saved under the path: {output_path / f'{field_name}.csv'}"
+                )
+
+    @staticmethod
+    def export_objective_result(
+        root_path: Path, objective_value_series: pd.Series
+    ) -> None:
+        """
+        Exports the given objective value series to a Csv file.
+
+        Parameters:
+            root_path (Path): The root path where the Csv file will be saved.
+            objective_value_series (pd.Series): A Pandas Series containing objective values.
+
+        Returns:
+            None
+        """
+        objective_value_series.to_csv(root_path / f"{objective_value_series.name}.csv")
+
+
+class XlsxExporter(Exporter):
+    """Class for exporting data to XLSX format."""
+
+    @staticmethod
+    def export_group_results(root_path: Path, result: ExportableResultsGroup) -> None:
+        """
+        Export exportable group results to Xlsx files.
+
+        Args:
+            root_path (Path): The root path for exporting the results.
+            result (ExportableResultsGroup): The exportable results to be parsed and exported.
+
+        Returns:
+            None
+        """
+        if Exporter.is_results_group_empty(result):
+            return
+        root_path.mkdir(parents=True, exist_ok=True)
+        for field_name, field_value in result.__dict__.items():
+            with pd.ExcelWriter(
+                (root_path / field_name).with_suffix(".xlsx"), engine="xlsxwriter"
+            ) as writer:
+                if isinstance(field_value, dict):
+                    if not field_value:
+                        _logger.info(
+                            f"No results found for: {field_name} when saving results to xlsx.  "
+                        )
+                        continue
+                    df = pd.concat(field_value, axis=1).sort_index(axis=1)
+                else:
+                    df = field_value
+                df.to_excel(writer, sheet_name=field_name)
+                _logger.debug(
+                    f"Data {field_name} saved under the path: {(root_path / field_name).with_suffix('.xlsx')} "
+                )
+
+    @staticmethod
+    def export_objective_result(
+        root_path: Path, objective_value_series: pd.Series
+    ) -> None:
+        """
+        Exports the given objective value series to a Xlsx file.
+
+        Parameters:
+            root_path (Path): The root path where the Xlsx file will be saved.
+            objective_value_series (pd.Series): A Pandas Series containing objective values.
+
+        Returns:
+            None
+        """
+        output_path = root_path / f"{objective_value_series.name}.xlsx"
+        objective_value_series.to_excel(
+            output_path, sheet_name=str(objective_value_series.name)
+        )
+        _logger.debug(
+            f"Data {objective_value_series.name} saved under the path: {output_path}"
+        )
```

### Comparing `pyzefir-0.4.1/pyzefir/structure_creator/__init__.py` & `pyzefir-0.4.22/pyzefir/postprocessing/__init__.py`

 * *Ordering differences only*

 * *Files 23% similar despite different names*

```diff
@@ -1,15 +1,15 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
```

### Comparing `pyzefir-0.4.1/pyzefir/structure_creator/cli/__init__.py` & `pyzefir-0.4.22/pyzefir/structure_creator/__init__.py`

 * *Ordering differences only*

 * *Files 23% similar despite different names*

```diff
@@ -1,15 +1,15 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
```

### Comparing `pyzefir-0.4.1/pyzefir/structure_creator/data_loader/__init__.py` & `pyzefir-0.4.22/pyzefir/structure_creator/cli/__init__.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,15 +1,15 @@
-# PyZefir
-# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
```

### Comparing `pyzefir-0.4.1/pyzefir/structure_creator/excel_writer.py` & `pyzefir-0.4.22/pyzefir/structure_creator/excel_writer.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,38 +1,43 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-
-from pathlib import Path
-
-import pandas as pd
-
-
-def write_to_excel(
-    data: dict,
-    output_path: Path,
-    filename: str,
-) -> None:
-    output_path.mkdir(parents=True, exist_ok=True)
-    output_path = output_path / filename
-
-    with pd.ExcelWriter(
-        path=output_path,
-        engine="openpyxl",
-        mode="a" if output_path.is_file() else "w",
-        if_sheet_exists="replace" if output_path.is_file() else None,
-    ) as writer:
-        for sheet_name, sheet_data in data.items():
-            sheet_data.to_excel(writer, sheet_name=sheet_name, index=False)
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+
+import logging
+from pathlib import Path
+
+import pandas as pd
+
+_logger = logging.getLogger(__name__)
+
+
+def write_to_excel(
+    data: dict,
+    output_path: Path,
+    filename: str,
+) -> None:
+    output_path.mkdir(parents=True, exist_ok=True)
+    output_path = output_path / filename
+
+    with pd.ExcelWriter(
+        path=output_path,
+        engine="openpyxl",
+        mode="a" if output_path.is_file() else "w",
+        if_sheet_exists="replace" if output_path.is_file() else None,
+    ) as writer:
+        for sheet_name, sheet_data in data.items():
+            sheet_data.to_excel(writer, sheet_name=sheet_name, index=False)
+            _logger.debug("Data written to sheet %s in file %s", sheet_name, filename)
+        _logger.info("File %s has been saved at %s", filename, output_path)
```

### Comparing `pyzefir-0.4.1/pyzefir/structure_creator/scenario/__init__.py` & `pyzefir-0.4.22/pyzefir/structure_creator/scenario/__init__.py`

 * *Ordering differences only*

 * *Files 23% similar despite different names*

```diff
@@ -1,15 +1,15 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
```

### Comparing `pyzefir-0.4.1/pyzefir/structure_creator/scenario/main.py` & `pyzefir-0.4.22/pyzefir/structure_creator/scenario/main.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,300 +1,317 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-from pathlib import Path
-
-import numpy as np
-import pandas as pd
-
-from pyzefir.structure_creator.data_loader.input_data import ScenarioData
-from pyzefir.structure_creator.excel_writer import write_to_excel
-from pyzefir.structure_creator.scenario.constants_enums import (
-    ScenarioSheetName,
-    ScenarioSheetsColumnName,
-)
-from pyzefir.structure_creator.scenario.utils import (
-    get_lbs_name,
-    interpolate_missing_df_values,
-)
-
-
-def create_interpolated_attribute_dataframe(
-    df: pd.DataFrame, index_name: str, n_years: int
-) -> pd.DataFrame:
-    interpolated_values = interpolate_missing_df_values(
-        df.iloc[:, 1:].T, expected_idx=np.arange(n_years)
-    ).T
-    result = (
-        pd.concat([interpolated_values, df.iloc[:, 0]], axis=1).set_index(index_name).T
-    )
-    return result.reset_index().rename(
-        columns={"index": ScenarioSheetsColumnName.YEAR_IDX}
-    )
-
-
-def create_cost_parameters_df(
-    cost_parameters: dict[str, pd.DataFrame], n_years: int
-) -> pd.DataFrame:
-    def interpolate_and_transform(df: pd.DataFrame, column_name: str) -> pd.DataFrame:
-        interpolated_df = (
-            interpolate_missing_df_values(
-                df.set_index(ScenarioSheetsColumnName.TECHNOLOGY_TYPE).T,
-                expected_idx=np.arange(n_years),
-            )
-            .T.stack()
-            .reset_index(level=1, drop=True)
-            .reset_index()
-            .rename(columns={0: column_name})
-        )
-        return interpolated_df
-
-    capex_column = interpolate_and_transform(
-        cost_parameters[ScenarioSheetsColumnName.CAPEX],
-        ScenarioSheetsColumnName.CAPEX,
-    )
-    opex_column = interpolate_and_transform(
-        cost_parameters[ScenarioSheetsColumnName.OPEX], ScenarioSheetsColumnName.OPEX
-    )
-
-    result = pd.concat([capex_column, opex_column], axis=1)
-    result[ScenarioSheetsColumnName.YEAR_IDX] = result.index % n_years
-    result_columns_order = [
-        ScenarioSheetsColumnName.YEAR_IDX,
-        ScenarioSheetsColumnName.TECHNOLOGY_TYPE,
-        ScenarioSheetsColumnName.CAPEX,
-        ScenarioSheetsColumnName.OPEX,
-    ]
-
-    return result.loc[:, ~result.columns.duplicated()][result_columns_order]
-
-
-def create_yearly_demand_df(
-    yearly_demand: dict[str, pd.DataFrame], n_years: int
-) -> pd.DataFrame:
-    dfs = []
-    for energy_type, df in yearly_demand.items():
-        interpolated_demand = interpolate_missing_df_values(
-            df.iloc[:, 1:].T, expected_idx=np.arange(n_years)
-        )
-        aggregated_demand = (
-            pd.concat([df.iloc[:, 0], interpolated_demand.T], axis=1)
-            .set_index(ScenarioSheetsColumnName.AGGREGATE)
-            .stack()
-            .reset_index(level=1)
-            .rename(
-                columns={
-                    "level_1": ScenarioSheetsColumnName.YEAR_IDX,
-                    0: ScenarioSheetsColumnName.VALUE,
-                }
-            )
-        )
-        dfs.append(
-            aggregated_demand.assign(energy_type=energy_type)[
-                [
-                    ScenarioSheetsColumnName.ENERGY_TYPE,
-                    ScenarioSheetsColumnName.YEAR_IDX,
-                    ScenarioSheetsColumnName.VALUE,
-                ]
-            ].reset_index()
-        )
-
-    return pd.concat(dfs)
-
-
-def create_capacity_limits_df(
-    dfs: dict[str, pd.DataFrame], column_name: str, n_years: int
-) -> pd.DataFrame:
-    dfs_list = [
-        interpolate_missing_df_values(
-            df.set_index(column_name).T, np.arange(1, n_years)
-        )
-        .T.stack()
-        .rename(param)
-        for param, df in dfs.items()
-    ]
-    result = (
-        pd.concat(dfs_list, axis=1)
-        .reset_index()
-        .rename(columns={"level_1": ScenarioSheetsColumnName.YEAR_IDX})
-    )
-    result_columns_order = [
-        ScenarioSheetsColumnName.YEAR_IDX,
-        column_name,
-        ScenarioSheetsColumnName.MAX_CAPACITY,
-        ScenarioSheetsColumnName.MIN_CAPACITY,
-        ScenarioSheetsColumnName.MAX_CAPACITY_INCREASE,
-        ScenarioSheetsColumnName.MIN_CAPACITY_INCREASE,
-    ]
-
-    return result[result_columns_order]
-
-
-def create_fractions_df(fractions: dict[str, dict[str, pd.DataFrame]]) -> pd.DataFrame:
-    result = []
-
-    for lbs_type, data in fractions.items():
-        df_list = [
-            parameter_df.set_index(ScenarioSheetsColumnName.AGGREGATE)
-            .T.interpolate(method="linear", axis=0)
-            .stack()
-            .rename(parameter_name)
-            for parameter_name, parameter_df in data.items()
-        ]
-
-        df = (
-            pd.concat(df_list, axis=1)
-            .reset_index()
-            .rename(columns={"level_0": ScenarioSheetsColumnName.YEAR})
-        )
-        df[ScenarioSheetsColumnName.TECHNOLOGY_STACK] = df[
-            ScenarioSheetsColumnName.AGGREGATE
-        ].apply(lambda aggr_name: get_lbs_name(lbs_type=lbs_type, aggr_name=aggr_name))
-        result.append(df)
-
-    result_columns_order = [
-        ScenarioSheetsColumnName.TECHNOLOGY_STACK,
-        ScenarioSheetsColumnName.AGGREGATE,
-        ScenarioSheetsColumnName.YEAR,
-        ScenarioSheetsColumnName.MIN_FRACTION,
-        ScenarioSheetsColumnName.MAX_FRACTION,
-        ScenarioSheetsColumnName.MAX_FRACTION_INCREASE,
-        ScenarioSheetsColumnName.MAX_FRACTION_DECREASE,
-    ]
-    return pd.concat(result, axis=0)[result_columns_order]
-
-
-def create_constants_df(n_hours: int, n_years: int) -> pd.DataFrame:
-    data = [
-        {
-            ScenarioSheetsColumnName.CONSTANTS_NAME: "N_HOURS",
-            ScenarioSheetsColumnName.CONSTANTS_VALUE: n_hours,
-        },
-        {
-            ScenarioSheetsColumnName.CONSTANTS_NAME: "N_YEARS",
-            ScenarioSheetsColumnName.CONSTANTS_VALUE: n_years,
-        },
-    ]
-    return pd.DataFrame(data)
-
-
-def create_relative_emission_limits_df(
-    emission_types: list[str], n_years: int
-) -> pd.DataFrame:
-    df = pd.DataFrame(
-        index=pd.RangeIndex(
-            start=0, stop=n_years, name=ScenarioSheetsColumnName.YEAR_IDX
-        ),
-        columns=emission_types,
-    )
-    return df.reset_index()
-
-
-def create_emission_fees_df(
-    emission_fees_df: pd.DataFrame, n_years: int
-) -> pd.DataFrame:
-    result = (
-        interpolate_missing_df_values(
-            values=emission_fees_df.set_index(ScenarioSheetsColumnName.EMISSION_FEE).T,
-            expected_idx=np.arange(n_years),
-        )
-        .reset_index()
-        .rename(columns={"index": ScenarioSheetsColumnName.YEAR_IDX})
-    )
-    return result
-
-
-def create_scenario_data_dict(
-    scenario_data: ScenarioData,
-    n_years: int,
-    n_hours: int,
-) -> dict[ScenarioSheetName, pd.DataFrame]:
-    return {
-        ScenarioSheetName.COST_PARAMETERS: create_cost_parameters_df(
-            cost_parameters=scenario_data.cost_parameters, n_years=n_years
-        ),
-        ScenarioSheetName.YEARLY_ENERGY_USAGE: create_yearly_demand_df(
-            yearly_demand=scenario_data.yearly_demand, n_years=n_years
-        ),
-        ScenarioSheetName.N_CONSUMERS: create_interpolated_attribute_dataframe(
-            df=scenario_data.n_consumers,
-            index_name=ScenarioSheetsColumnName.AGGREGATE,
-            n_years=n_years,
-        ),
-        ScenarioSheetName.RELATIVE_EMISSION_LIMITS: create_interpolated_attribute_dataframe(
-            df=scenario_data.relative_emission_limits,
-            index_name=ScenarioSheetsColumnName.EMISSION_TYPE,
-            n_years=n_years,
-        ),
-        ScenarioSheetName.FUEL_PRICES: create_interpolated_attribute_dataframe(
-            df=scenario_data.fuel_parameters[ScenarioSheetsColumnName.FUEL_PRICE],
-            index_name=ScenarioSheetsColumnName.FUEL,
-            n_years=n_years,
-        ),
-        ScenarioSheetName.FUEL_AVAILABILITY: create_interpolated_attribute_dataframe(
-            df=scenario_data.fuel_parameters[
-                ScenarioSheetsColumnName.FUEL_AVAILABILITY
-            ],
-            index_name=ScenarioSheetsColumnName.FUEL,
-            n_years=n_years,
-        ),
-        ScenarioSheetName.ELEMENT_ENERGY_EVOLUTION_LIMITS: create_capacity_limits_df(
-            dfs=scenario_data.technology_cap_limits,
-            column_name=ScenarioSheetsColumnName.TECHNOLOGY_NAME,
-            n_years=n_years,
-        ),
-        ScenarioSheetName.ENERGY_SOURCE_EVOLUTION_LIMITS: create_capacity_limits_df(
-            dfs=scenario_data.technology_type_cap_limits,
-            column_name=ScenarioSheetsColumnName.TECHNOLOGY_TYPE,
-            n_years=n_years,
-        ),
-        ScenarioSheetName.FRACTIONS: create_fractions_df(
-            fractions=scenario_data.fractions
-        ),
-        ScenarioSheetName.CONSTANTS: create_constants_df(
-            n_hours=n_hours, n_years=n_years
-        ),
-        ScenarioSheetName.EMISSION_FEES: create_emission_fees_df(
-            emission_fees_df=scenario_data.cost_parameters[
-                ScenarioSheetsColumnName.EMISSION_FEES
-            ],
-            n_years=n_years,
-        ),
-        ScenarioSheetName.GENERATION_FRACTION: scenario_data.generation_fraction,
-        ScenarioSheetName.CURTAILMENT_COST: create_interpolated_attribute_dataframe(
-            df=scenario_data.cost_parameters[ScenarioSheetsColumnName.CURTAILMENT],
-            index_name=ScenarioSheetsColumnName.TECHNOLOGY_TYPE,
-            n_years=n_years,
-        ),
-    }
-
-
-def create_scenario(
-    scenario_data: ScenarioData,
-    output_path: Path,
-    scenario_name: str,
-    n_years: int,
-    n_hours: int,
-) -> None:
-    scenario_data_dict = create_scenario_data_dict(
-        scenario_data=scenario_data,
-        n_years=n_years,
-        n_hours=n_hours,
-    )
-    write_to_excel(
-        data=scenario_data_dict,
-        output_path=output_path,
-        filename=f"{scenario_name}.xlsx",
-    )
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+import logging
+from pathlib import Path
+
+import numpy as np
+import pandas as pd
+
+from pyzefir.structure_creator.data_loader.input_data import ScenarioData
+from pyzefir.structure_creator.excel_writer import write_to_excel
+from pyzefir.structure_creator.scenario.constants_enums import (
+    ScenarioSheetName,
+    ScenarioSheetsColumnName,
+)
+from pyzefir.structure_creator.scenario.utils import (
+    get_lbs_name,
+    interpolate_missing_df_values,
+)
+
+_logger = logging.getLogger(__name__)
+
+
+def create_interpolated_attribute_dataframe(
+    df: pd.DataFrame, index_name: str, n_years: int
+) -> pd.DataFrame:
+    interpolated_values = interpolate_missing_df_values(
+        df.iloc[:, 1:].T, expected_idx=np.arange(n_years)
+    ).T
+    result = (
+        pd.concat([interpolated_values, df.iloc[:, 0]], axis=1).set_index(index_name).T
+    )
+    return result.reset_index().rename(
+        columns={"index": ScenarioSheetsColumnName.YEAR_IDX}
+    )
+
+
+def create_cost_parameters_df(
+    cost_parameters: dict[str, pd.DataFrame], n_years: int
+) -> pd.DataFrame:
+    def interpolate_and_transform(df: pd.DataFrame, column_name: str) -> pd.DataFrame:
+        interpolated_df = (
+            interpolate_missing_df_values(
+                df.set_index(ScenarioSheetsColumnName.TECHNOLOGY_TYPE).T,
+                expected_idx=np.arange(n_years),
+            )
+            .T.stack()
+            .reset_index(level=1, drop=True)
+            .reset_index()
+            .rename(columns={0: column_name})
+        )
+        return interpolated_df
+
+    capex_column = interpolate_and_transform(
+        cost_parameters[ScenarioSheetsColumnName.CAPEX],
+        ScenarioSheetsColumnName.CAPEX,
+    )
+    opex_column = interpolate_and_transform(
+        cost_parameters[ScenarioSheetsColumnName.OPEX], ScenarioSheetsColumnName.OPEX
+    )
+
+    result = pd.concat([capex_column, opex_column], axis=1)
+    result[ScenarioSheetsColumnName.YEAR_IDX] = result.index % n_years
+    result_columns_order = [
+        ScenarioSheetsColumnName.YEAR_IDX,
+        ScenarioSheetsColumnName.TECHNOLOGY_TYPE,
+        ScenarioSheetsColumnName.CAPEX,
+        ScenarioSheetsColumnName.OPEX,
+    ]
+
+    return result.loc[:, ~result.columns.duplicated()][result_columns_order]
+
+
+def create_yearly_demand_df(
+    yearly_demand: dict[str, pd.DataFrame], n_years: int
+) -> pd.DataFrame:
+    dfs = []
+    for energy_type, df in yearly_demand.items():
+        interpolated_demand = interpolate_missing_df_values(
+            df.iloc[:, 1:].T, expected_idx=np.arange(n_years)
+        )
+        aggregated_demand = (
+            pd.concat([df.iloc[:, 0], interpolated_demand.T], axis=1)
+            .set_index(ScenarioSheetsColumnName.AGGREGATE)
+            .stack()
+            .reset_index(level=1)
+            .rename(
+                columns={
+                    "level_1": ScenarioSheetsColumnName.YEAR_IDX,
+                    0: ScenarioSheetsColumnName.VALUE,
+                }
+            )
+        )
+        dfs.append(
+            aggregated_demand.assign(energy_type=energy_type)[
+                [
+                    ScenarioSheetsColumnName.ENERGY_TYPE,
+                    ScenarioSheetsColumnName.YEAR_IDX,
+                    ScenarioSheetsColumnName.VALUE,
+                ]
+            ].reset_index()
+        )
+
+    return pd.concat(dfs)
+
+
+def create_capacity_limits_df(
+    dfs: dict[str, pd.DataFrame], column_name: str, n_years: int
+) -> pd.DataFrame:
+    dfs_list = [
+        interpolate_missing_df_values(
+            df.set_index(column_name).T, np.arange(1, n_years)
+        )
+        .T.stack()
+        .rename(param)
+        for param, df in dfs.items()
+    ]
+    result = (
+        pd.concat(dfs_list, axis=1)
+        .reset_index()
+        .rename(columns={"level_1": ScenarioSheetsColumnName.YEAR_IDX})
+    )
+    result_columns_order = [
+        ScenarioSheetsColumnName.YEAR_IDX,
+        column_name,
+        ScenarioSheetsColumnName.MAX_CAPACITY,
+        ScenarioSheetsColumnName.MIN_CAPACITY,
+        ScenarioSheetsColumnName.MAX_CAPACITY_INCREASE,
+        ScenarioSheetsColumnName.MIN_CAPACITY_INCREASE,
+    ]
+
+    return result[result_columns_order]
+
+
+def create_fractions_df(fractions: dict[str, dict[str, pd.DataFrame]]) -> pd.DataFrame:
+    result = []
+
+    for lbs_type, data in fractions.items():
+        df_list = [
+            parameter_df.set_index(ScenarioSheetsColumnName.AGGREGATE)
+            .T.interpolate(method="linear", axis=0)
+            .stack()
+            .rename(parameter_name)
+            for parameter_name, parameter_df in data.items()
+        ]
+
+        df = (
+            pd.concat(df_list, axis=1)
+            .reset_index()
+            .rename(columns={"level_0": ScenarioSheetsColumnName.YEAR})
+        )
+        df[ScenarioSheetsColumnName.TECHNOLOGY_STACK] = df[
+            ScenarioSheetsColumnName.AGGREGATE
+        ].apply(lambda aggr_name: get_lbs_name(lbs_type=lbs_type, aggr_name=aggr_name))
+        result.append(df)
+
+    result_columns_order = [
+        ScenarioSheetsColumnName.TECHNOLOGY_STACK,
+        ScenarioSheetsColumnName.AGGREGATE,
+        ScenarioSheetsColumnName.YEAR,
+        ScenarioSheetsColumnName.MIN_FRACTION,
+        ScenarioSheetsColumnName.MAX_FRACTION,
+        ScenarioSheetsColumnName.MAX_FRACTION_INCREASE,
+        ScenarioSheetsColumnName.MAX_FRACTION_DECREASE,
+    ]
+    return pd.concat(result, axis=0)[result_columns_order]
+
+
+def create_constants_df(n_hours: int, n_years: int) -> pd.DataFrame:
+    data = [
+        {
+            ScenarioSheetsColumnName.CONSTANTS_NAME: "N_HOURS",
+            ScenarioSheetsColumnName.CONSTANTS_VALUE: n_hours,
+        },
+        {
+            ScenarioSheetsColumnName.CONSTANTS_NAME: "N_YEARS",
+            ScenarioSheetsColumnName.CONSTANTS_VALUE: n_years,
+        },
+    ]
+    return pd.DataFrame(data)
+
+
+def create_relative_emission_limits_df(
+    emission_types: list[str], n_years: int
+) -> pd.DataFrame:
+    df = pd.DataFrame(
+        index=pd.RangeIndex(
+            start=0, stop=n_years, name=ScenarioSheetsColumnName.YEAR_IDX
+        ),
+        columns=emission_types,
+    )
+    return df.reset_index()
+
+
+def create_emission_fees_df(
+    emission_fees_df: pd.DataFrame, n_years: int
+) -> pd.DataFrame:
+    result = (
+        interpolate_missing_df_values(
+            values=emission_fees_df.set_index(ScenarioSheetsColumnName.EMISSION_FEE).T,
+            expected_idx=np.arange(n_years),
+        )
+        .reset_index()
+        .rename(columns={"index": ScenarioSheetsColumnName.YEAR_IDX})
+    )
+    return result
+
+
+def create_generation_compensation_df(df: pd.DataFrame) -> pd.DataFrame:
+    df = df.rename(
+        columns={
+            ScenarioSheetsColumnName.TECHNOLOGY_TYPE: ScenarioSheetsColumnName.YEAR_IDX
+        }
+    ).T.reset_index()
+    return df.set_axis(df.iloc[0], axis=1).drop(df.index[0])
+
+
+def create_scenario_data_dict(
+    scenario_data: ScenarioData,
+    n_years: int,
+    n_hours: int,
+) -> dict[ScenarioSheetName, pd.DataFrame]:
+    return {
+        ScenarioSheetName.COST_PARAMETERS: create_cost_parameters_df(
+            cost_parameters=scenario_data.cost_parameters, n_years=n_years
+        ),
+        ScenarioSheetName.YEARLY_ENERGY_USAGE: create_yearly_demand_df(
+            yearly_demand=scenario_data.yearly_demand, n_years=n_years
+        ),
+        ScenarioSheetName.N_CONSUMERS: create_interpolated_attribute_dataframe(
+            df=scenario_data.n_consumers,
+            index_name=ScenarioSheetsColumnName.AGGREGATE,
+            n_years=n_years,
+        ),
+        ScenarioSheetName.RELATIVE_EMISSION_LIMITS: create_interpolated_attribute_dataframe(
+            df=scenario_data.relative_emission_limits,
+            index_name=ScenarioSheetsColumnName.EMISSION_TYPE,
+            n_years=n_years,
+        ),
+        ScenarioSheetName.FUEL_PRICES: create_interpolated_attribute_dataframe(
+            df=scenario_data.fuel_parameters[ScenarioSheetsColumnName.FUEL_PRICE],
+            index_name=ScenarioSheetsColumnName.FUEL,
+            n_years=n_years,
+        ),
+        ScenarioSheetName.FUEL_AVAILABILITY: create_interpolated_attribute_dataframe(
+            df=scenario_data.fuel_parameters[
+                ScenarioSheetsColumnName.FUEL_AVAILABILITY
+            ],
+            index_name=ScenarioSheetsColumnName.FUEL,
+            n_years=n_years,
+        ),
+        ScenarioSheetName.ELEMENT_ENERGY_EVOLUTION_LIMITS: create_capacity_limits_df(
+            dfs=scenario_data.technology_cap_limits,
+            column_name=ScenarioSheetsColumnName.TECHNOLOGY_NAME,
+            n_years=n_years,
+        ),
+        ScenarioSheetName.ENERGY_SOURCE_EVOLUTION_LIMITS: create_capacity_limits_df(
+            dfs=scenario_data.technology_type_cap_limits,
+            column_name=ScenarioSheetsColumnName.TECHNOLOGY_TYPE,
+            n_years=n_years,
+        ),
+        ScenarioSheetName.FRACTIONS: create_fractions_df(
+            fractions=scenario_data.fractions
+        ),
+        ScenarioSheetName.CONSTANTS: create_constants_df(
+            n_hours=n_hours, n_years=n_years
+        ),
+        ScenarioSheetName.EMISSION_FEES: create_emission_fees_df(
+            emission_fees_df=scenario_data.cost_parameters[
+                ScenarioSheetsColumnName.EMISSION_FEES
+            ],
+            n_years=n_years,
+        ),
+        ScenarioSheetName.GENERATION_FRACTION: scenario_data.generation_fraction,
+        ScenarioSheetName.CURTAILMENT_COST: create_interpolated_attribute_dataframe(
+            df=scenario_data.cost_parameters[ScenarioSheetsColumnName.CURTAILMENT],
+            index_name=ScenarioSheetsColumnName.TECHNOLOGY_TYPE,
+            n_years=n_years,
+        ),
+        ScenarioSheetName.GENERATION_COMPENSATION: create_generation_compensation_df(
+            scenario_data.generation_compensation
+        ),
+    }
+
+
+def create_scenario(
+    scenario_data: ScenarioData,
+    output_path: Path,
+    scenario_name: str,
+    n_years: int,
+    n_hours: int,
+) -> None:
+    _logger.debug("Creating scenario data objects ...")
+    scenario_data_dict = create_scenario_data_dict(
+        scenario_data=scenario_data,
+        n_years=n_years,
+        n_hours=n_hours,
+    )
+    _logger.debug("Saving %s.xlsx ...", scenario_name)
+    write_to_excel(
+        data=scenario_data_dict,
+        output_path=output_path,
+        filename=f"{scenario_name}.xlsx",
+    )
```

### Comparing `pyzefir-0.4.1/pyzefir/structure_creator/structure_and_initial_state/__init__.py` & `pyzefir-0.4.22/pyzefir/structure_creator/structure_and_initial_state/__init__.py`

 * *Ordering differences only*

 * *Files 23% similar despite different names*

```diff
@@ -1,15 +1,15 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
```

### Comparing `pyzefir-0.4.1/pyzefir/structure_creator/structure_and_initial_state/dataclasses.py` & `pyzefir-0.4.22/pyzefir/structure_creator/structure_and_initial_state/dataclasses.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,80 +1,81 @@
-# PyZefir
-# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-from dataclasses import dataclass, field, fields
-
-import pandas as pd
-
-
-@dataclass
-class BaseData:
-    def convert_to_dict_of_dfs(self) -> dict[str, pd.DataFrame]:
-        dfs_dict = {}
-        for field_info in fields(self):
-            field_name = field_info.name
-            df_list = getattr(self, field_name)
-            if isinstance(df_list, list) and df_list:
-                dfs_dict[self._handle_field_name(field_name)] = pd.concat(df_list)
-        return dfs_dict
-
-    @staticmethod
-    def _handle_field_name(name: str) -> str:
-        if name == "TechnologyStack_Buses_out":
-            return name
-        return name.replace("__", " - ").replace("_", " ")
-
-
-@dataclass
-class StructureData(BaseData):
-    Energy_Types: list[pd.DataFrame] = field(default_factory=list)
-    Emission_Types: list[pd.DataFrame] = field(default_factory=list)
-    Aggregates: list[pd.DataFrame] = field(default_factory=list)
-    Lines: list[pd.DataFrame] = field(default_factory=list)
-    Transmission_Fees: list[pd.DataFrame] = field(default_factory=list)
-    Buses: list[pd.DataFrame] = field(default_factory=list)
-    Generators: list[pd.DataFrame] = field(default_factory=list)
-    Emission_Fees__Emission_Types: list[pd.DataFrame] = field(default_factory=list)
-    Generator__Emission_Fees: list[pd.DataFrame] = field(default_factory=list)
-    Storages: list[pd.DataFrame] = field(default_factory=list)
-    DSR: list[pd.DataFrame] = field(default_factory=list)
-    Technology__Bus: list[pd.DataFrame] = field(default_factory=list)
-    TechnologyStack_Buses_out: list[pd.DataFrame] = field(default_factory=list)
-    TechnologyStack_Buses: list[pd.DataFrame] = field(default_factory=list)
-    TechnologyStack__Aggregate: list[pd.DataFrame] = field(default_factory=list)
-    Power_Reserve: list[pd.DataFrame] = field(default_factory=list)
-
-    def __post_init__(self) -> None:
-        self.DSR = [
-            pd.DataFrame(
-                columns=[
-                    "name",
-                    "compensation_factor",
-                    "balancing_period_len",
-                    "penalization",
-                    "relative_shift_limit",
-                    "abs_shift_limit",
-                ]
-            )
-        ]
-        self.Power_Reserve = [
-            pd.DataFrame(columns=["tag_name", "energy_type", "power_reserve_value"])
-        ]
-
-
-@dataclass
-class InitialStateData(BaseData):
-    Technology: list[pd.DataFrame] = field(default_factory=list)
-    TechnologyStack: list[pd.DataFrame] = field(default_factory=list)
+# PyZefir
+# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+from dataclasses import dataclass, field, fields
+
+import pandas as pd
+
+
+@dataclass
+class BaseData:
+    def convert_to_dict_of_dfs(self) -> dict[str, pd.DataFrame]:
+        dfs_dict = {}
+        for field_info in fields(self):
+            field_name = field_info.name
+            df_list = getattr(self, field_name)
+            if isinstance(df_list, list) and df_list:
+                dfs_dict[self._handle_field_name(field_name)] = pd.concat(df_list)
+        return dfs_dict
+
+    @staticmethod
+    def _handle_field_name(name: str) -> str:
+        if name == "TechnologyStack_Buses_out":
+            return name
+        return name.replace("__", " - ").replace("_", " ")
+
+
+@dataclass
+class StructureData(BaseData):
+    Energy_Types: list[pd.DataFrame] = field(default_factory=list)
+    Emission_Types: list[pd.DataFrame] = field(default_factory=list)
+    Aggregates: list[pd.DataFrame] = field(default_factory=list)
+    Lines: list[pd.DataFrame] = field(default_factory=list)
+    Transmission_Fees: list[pd.DataFrame] = field(default_factory=list)
+    Buses: list[pd.DataFrame] = field(default_factory=list)
+    Generators: list[pd.DataFrame] = field(default_factory=list)
+    Emission_Fees__Emission_Types: list[pd.DataFrame] = field(default_factory=list)
+    Generator__Emission_Fees: list[pd.DataFrame] = field(default_factory=list)
+    Storages: list[pd.DataFrame] = field(default_factory=list)
+    DSR: list[pd.DataFrame] = field(default_factory=list)
+    Technology__Bus: list[pd.DataFrame] = field(default_factory=list)
+    TechnologyStack_Buses_out: list[pd.DataFrame] = field(default_factory=list)
+    TechnologyStack_Buses: list[pd.DataFrame] = field(default_factory=list)
+    TechnologyStack__Aggregate: list[pd.DataFrame] = field(default_factory=list)
+    Power_Reserve: list[pd.DataFrame] = field(default_factory=list)
+    Generator_Binding: list[pd.DataFrame] = field(default_factory=list)
+
+    def __post_init__(self) -> None:
+        self.DSR = [
+            pd.DataFrame(
+                columns=[
+                    "name",
+                    "compensation_factor",
+                    "balancing_period_len",
+                    "penalization",
+                    "relative_shift_limit",
+                    "abs_shift_limit",
+                ]
+            )
+        ]
+        self.Power_Reserve = [
+            pd.DataFrame(columns=["tag_name", "energy_type", "power_reserve_value"])
+        ]
+
+
+@dataclass
+class InitialStateData(BaseData):
+    Technology: list[pd.DataFrame] = field(default_factory=list)
+    TechnologyStack: list[pd.DataFrame] = field(default_factory=list)
```

### Comparing `pyzefir-0.4.1/pyzefir/structure_creator/structure_and_initial_state/preprocess_handlers.py` & `pyzefir-0.4.22/pyzefir/structure_creator/structure_and_initial_state/preprocess_handlers.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,123 +1,134 @@
-# PyZefir
-# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-import pandas as pd
-
-from pyzefir.structure_creator.structure_and_initial_state.utils import (
-    handle_prefix_name,
-)
-
-
-class LocalLbsHandler:
-    @staticmethod
-    def create_local_lbs_data(
-        lbs_type: dict[str, dict[str, pd.DataFrame]]
-    ) -> pd.DataFrame:
-        dfs: list[pd.DataFrame] = []
-        for lbs_name, lbs_data in lbs_type.items():
-            df = LocalLbsHandler._create_lbs_dataframe(lbs_name, lbs_data)
-            dfs.append(df)
-        return pd.concat(dfs)
-
-    @staticmethod
-    def _create_lbs_dataframe(lbs_name: str, lbs_data: dict[str, pd.DataFrame]) -> None:
-        bus_df = LocalLbsHandler._create_flat_bus_df(
-            lbs_data["TECHNOLOGY TO BUS"], lbs_data["BUSES"]
-        )
-        capa_df = LocalLbsHandler._create_flat_capacity(
-            {key: lbs_data[key] for key in ["BASE CAP", "MIN CAP", "MAX CAP"]}
-        )
-        technology_df = lbs_data["TECHNOLOGIES"].set_index("technology_id")
-        lines_df = (
-            LocalLbsHandler._create_flat_lines(lbs_data["LINES"], bus_df)
-            if "LINES" in lbs_data
-            else pd.DataFrame()
-        )
-        df = pd.concat([technology_df, capa_df, lines_df], axis=1)
-        merged_df = bus_df.merge(df, left_index=True, right_index=True)
-        merged_df.insert(0, "lbs", lbs_name)
-        return merged_df
-
-    @staticmethod
-    def _create_flat_bus_df(
-        tech_to_bus_df: pd.DataFrame, bus_df: pd.DataFrame
-    ) -> pd.DataFrame:
-        tech_df = tech_to_bus_df.melt(
-            id_vars=["technology_id"], var_name="bus_id", value_name="value"
-        )
-        tech_df = tech_df[tech_df["value"] == 1.0]
-        tech_df = tech_df.drop(columns="value")
-        df = pd.merge(tech_df, bus_df, on="bus_id")
-        return df.set_index("technology_id")
-
-    @staticmethod
-    def _create_flat_capacity(capa_dict: dict[str, pd.DataFrame]) -> pd.DataFrame:
-        dfs: list[pd.DataFrame] = []
-        for name, df in capa_dict.items():
-            df = df.set_index("technology_id")
-            df = df.add_prefix(handle_prefix_name(name))
-            dfs.append(df)
-        return pd.concat(dfs, axis=1)
-
-    @staticmethod
-    def _create_flat_lines(
-        lines_df: pd.DataFrame, bus_df: pd.DataFrame
-    ) -> pd.DataFrame:
-        index_dict = dict(zip(bus_df["bus_id"], bus_df.index))
-        lines_df = lines_df.rename(columns={"energy_type": "line_energy_type"})
-        lines_df.index = lines_df["bus_from_id"].map(index_dict)
-        return lines_df
-
-
-class GlobalSystemsHandler:
-    @staticmethod
-    def create_subsystem_dataframe(subsystems: dict[str, pd.DataFrame]) -> None:
-        connection_df = GlobalSystemsHandler._create_flat_subsystem_connection_df(
-            subsystems["TECHNOLOGY TO SUBSYSTEM"], subsystems["SUBSYSTEMS"]
-        )
-        transmission_fee_df = GlobalSystemsHandler._create_transmission_fees_df(
-            subsystems["SUBSYSTEM TRANSMISSION FEES"]
-        )
-        global_tech_df = subsystems["GLOBAL TECHNOLOGIES"].set_index("global_tech_id")
-        merged_df = connection_df.merge(
-            global_tech_df, left_index=True, right_index=True
-        )
-        merged_df = merged_df.merge(
-            transmission_fee_df, left_on="subsystem_id", right_index=True
-        )
-        merged_df = merged_df.reset_index()
-        merged_df = merged_df.rename(
-            columns={"global_tech_id": "gen_name", "subsystem_id": "bus_name"}
-        )
-        return merged_df.reset_index()
-
-    @staticmethod
-    def _create_flat_subsystem_connection_df(
-        tech_to_sub_df: pd.DataFrame, subsystem_df: pd.DataFrame
-    ) -> pd.DataFrame:
-        tech_to_sub_df = tech_to_sub_df.melt(
-            id_vars="global_tech_id", var_name="subsystem_id", value_name="value"
-        )
-        merged_df = tech_to_sub_df.merge(subsystem_df, on="subsystem_id")
-        merged_df = merged_df[merged_df["value"] == 1]
-        merged_df = merged_df.drop(columns="value")
-        return merged_df.set_index("global_tech_id")
-
-    @staticmethod
-    def _create_transmission_fees_df(tf_df: pd.DataFrame) -> pd.DataFrame:
-        tf_df = tf_df.set_index("aggregate_id").T
-        tf_df = tf_df.add_prefix(handle_prefix_name("TF"))
-        return tf_df
+# PyZefir
+# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+import pandas as pd
+
+from pyzefir.structure_creator.structure_and_initial_state.utils import (
+    handle_prefix_name,
+)
+
+
+class LocalLbsHandler:
+    @staticmethod
+    def create_local_lbs_data(
+        lbs_type: dict[str, dict[str, pd.DataFrame]]
+    ) -> pd.DataFrame:
+        dfs: list[pd.DataFrame] = []
+        for lbs_name, lbs_data in lbs_type.items():
+            df = LocalLbsHandler._create_lbs_dataframe(lbs_name, lbs_data)
+            dfs.append(df)
+        return pd.concat(dfs)
+
+    @staticmethod
+    def _create_lbs_dataframe(lbs_name: str, lbs_data: dict[str, pd.DataFrame]) -> None:
+        bus_df = LocalLbsHandler._create_flat_bus_df(
+            lbs_data["TECHNOLOGY TO BUS"], lbs_data["BUSES"]
+        )
+        capa_df = LocalLbsHandler._create_flat_capacity(
+            {key: lbs_data[key] for key in ["BASE CAP", "MIN CAP", "MAX CAP"]}
+        )
+        technology_df = lbs_data["TECHNOLOGIES"].set_index("technology_id")
+        lines_df = (
+            LocalLbsHandler._create_flat_lines(lbs_data["LINES"], bus_df)
+            if "LINES" in lbs_data
+            else pd.DataFrame()
+        )
+        if "TAGS" in lbs_data:
+            tags_df = lbs_data["TAGS"].set_index("technology_id").add_prefix("TAG_")
+            df = pd.concat([technology_df, capa_df, lines_df, tags_df], axis=1)
+        else:
+            df = pd.concat([technology_df, capa_df, lines_df], axis=1)
+        merged_df = bus_df.merge(df, left_index=True, right_index=True)
+        merged_df.insert(0, "lbs", lbs_name)
+        return merged_df
+
+    @staticmethod
+    def _create_flat_bus_df(
+        tech_to_bus_df: pd.DataFrame, bus_df: pd.DataFrame
+    ) -> pd.DataFrame:
+        tech_df = tech_to_bus_df.melt(
+            id_vars=["technology_id"], var_name="bus_id", value_name="value"
+        )
+        tech_df = tech_df[tech_df["value"] == 1.0]
+        tech_df = tech_df.drop(columns="value")
+        df = pd.merge(tech_df, bus_df, on="bus_id")
+        return df.set_index("technology_id")
+
+    @staticmethod
+    def _create_flat_capacity(capa_dict: dict[str, pd.DataFrame]) -> pd.DataFrame:
+        dfs: list[pd.DataFrame] = []
+        for name, df in capa_dict.items():
+            df = df.set_index("technology_id")
+            df = df.add_prefix(handle_prefix_name(name))
+            dfs.append(df)
+        return pd.concat(dfs, axis=1)
+
+    @staticmethod
+    def _create_flat_lines(
+        lines_df: pd.DataFrame, bus_df: pd.DataFrame
+    ) -> pd.DataFrame:
+        index_dict = dict(zip(bus_df["bus_id"], bus_df.index))
+        lines_df = lines_df.rename(columns={"energy_type": "line_energy_type"})
+        lines_df.index = lines_df["bus_from_id"].map(index_dict)
+        return lines_df
+
+
+class GlobalSystemsHandler:
+    @staticmethod
+    def create_subsystem_dataframe(subsystems: dict[str, pd.DataFrame]) -> None:
+        connection_df = GlobalSystemsHandler._create_flat_subsystem_connection_df(
+            subsystems["TECHNOLOGY TO SUBSYSTEM"], subsystems["SUBSYSTEMS"]
+        )
+        transmission_fee_df = GlobalSystemsHandler._create_transmission_fees_df(
+            subsystems["SUBSYSTEM TRANSMISSION FEES"]
+        )
+        global_tech_df = subsystems["GLOBAL TECHNOLOGIES"].set_index("global_tech_id")
+        merged_df = connection_df.merge(
+            global_tech_df, left_index=True, right_index=True
+        )
+        merged_df = merged_df.merge(
+            transmission_fee_df, left_on="subsystem_id", right_index=True
+        )
+        if "TAGS" in subsystems:
+            tags_df = subsystems["TAGS"].set_index("global_tech_id").add_prefix("TAG_")
+            merged_df = merged_df.merge(tags_df, left_index=True, right_index=True)
+        merged_df = merged_df.reset_index()
+        merged_df = merged_df.rename(
+            columns={
+                "global_tech_id": "gen_name",
+                "subsystem_id": "bus_name",
+                "binding_id": "binding_name",
+            }
+        )
+        return merged_df.reset_index()
+
+    @staticmethod
+    def _create_flat_subsystem_connection_df(
+        tech_to_sub_df: pd.DataFrame, subsystem_df: pd.DataFrame
+    ) -> pd.DataFrame:
+        tech_to_sub_df = tech_to_sub_df.melt(
+            id_vars="global_tech_id", var_name="subsystem_id", value_name="value"
+        )
+        merged_df = tech_to_sub_df.merge(subsystem_df, on="subsystem_id")
+        merged_df = merged_df[merged_df["value"] == 1]
+        merged_df = merged_df.drop(columns="value")
+        return merged_df.set_index("global_tech_id")
+
+    @staticmethod
+    def _create_transmission_fees_df(tf_df: pd.DataFrame) -> pd.DataFrame:
+        tf_df = tf_df.set_index("aggregate_id").T
+        tf_df = tf_df.add_prefix(handle_prefix_name("TF"))
+        return tf_df
```

### Comparing `pyzefir-0.4.1/pyzefir/structure_creator/structure_and_initial_state/structure_element_creators.py` & `pyzefir-0.4.22/pyzefir/structure_creator/structure_and_initial_state/structure_element_creators.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,346 +1,388 @@
-# PyZefir
-# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-import numpy as np
-import pandas as pd
-
-from pyzefir.structure_creator.structure_and_initial_state.utils import (
-    join_energy_types,
-)
-
-
-class LineStructureCreator:
-    @staticmethod
-    def _create_lines_dataframe(
-        first_df: pd.DataFrame, second_df: pd.DataFrame, energy_type: str
-    ) -> pd.DataFrame:
-        return (
-            pd.merge(
-                first_df.assign(key=1),
-                second_df.assign(key=1),
-                on="key",
-            )
-            .drop("key", axis=1)
-            .assign(
-                name=lambda x: x["bus_name_x"] + " > " + x["bus_name_y"],
-                energy_type=energy_type,
-                bus_from=lambda x: x["bus_name_x"],
-                bus_to=lambda x: x["bus_name_y"],
-                transmission_loss=lambda x: (
-                    x["transmission_loss"]
-                    if "transmission_loss" in x.columns
-                    else np.nan
-                ),
-                max_capacity=np.nan,
-                transmission_fee=lambda x: (
-                    x["transmission_fee"] if "transmission_fee" in x.columns else np.nan
-                ),
-            )[
-                [
-                    "name",
-                    "energy_type",
-                    "bus_from",
-                    "bus_to",
-                    "transmission_loss",
-                    "max_capacity",
-                    "transmission_fee",
-                ]
-            ]
-        )
-
-    @staticmethod
-    def create_lines(
-        df_data: pd.DataFrame,
-        global_subsystem_config: pd.DataFrame,
-        aggr_name: str,
-    ) -> pd.DataFrame:
-        dfs: list[pd.DataFrame] = []
-        global_subsystem_config = global_subsystem_config.rename(
-            columns={f"TF_{aggr_name}": "transmission_fee"}
-        )
-        subsystems = global_subsystem_config["bus_name"].unique()
-        energy_types_dict = (
-            global_subsystem_config.groupby("bus_name")["energy_type"]
-            .agg(join_energy_types)
-            .to_dict()
-        )
-        for subsystem in subsystems:
-            et: str = energy_types_dict[subsystem]
-            filtered_df = df_data[
-                df_data[subsystem] & (df_data["energy_type"] == et)
-            ].drop_duplicates(subset="bus_name")
-            global_bus = global_subsystem_config[
-                global_subsystem_config["bus_name"] == subsystem
-            ].drop_duplicates(subset="bus_name")
-            result_df = LineStructureCreator._create_lines_dataframe(
-                global_bus, filtered_df, et
-            )
-            dfs.append(result_df)
-        df = pd.concat(dfs)
-        return df
-
-    @staticmethod
-    def create_local_lbs_lines(
-        df_data: pd.DataFrame,
-    ) -> pd.DataFrame:
-        if (
-            "bus_from_id" not in df_data.columns
-            or df_data["bus_from_id"].isnull().all()
-        ):
-            return pd.DataFrame()
-        df = df_data.copy()
-        local_lines_df = df[["bus_from_id", "bus_to_id", "line_energy_type"]].dropna()
-        local_lines_configs: list[tuple] = [
-            (
-                local_lines_df.at[idx, "bus_from_id"],
-                local_lines_df.at[idx, "bus_to_id"],
-                local_lines_df.at[idx, "line_energy_type"],
-            )
-            for idx in local_lines_df.index
-        ]
-        dfs: list[pd.DataFrame] = []
-        for bus_fr, bus_to, et in local_lines_configs:
-            bus_fr_df_filtered = df[
-                (df["bus_id"] == bus_fr) & (df["energy_type"] == et)
-            ].drop_duplicates(subset="bus_name")
-            bus_to_df_filtered = df[
-                (df["bus_id"] == bus_to) & (df["energy_type"] == et)
-            ].drop_duplicates(subset="bus_name")
-            result_df = LineStructureCreator._create_lines_dataframe(
-                bus_fr_df_filtered, bus_to_df_filtered, et
-            )
-            dfs.append(result_df)
-        df = pd.concat(dfs)
-        return df
-
-
-class LbsStructureCreator:
-    @staticmethod
-    def create_technologystack_aggr_df(
-        df_data: pd.DataFrame,
-        aggr_name: str,
-    ) -> pd.DataFrame:
-        df = df_data.copy()
-        df = df[["lbs"]].drop_duplicates()
-        df["aggregate"] = aggr_name
-        df = df.rename(columns={"lbs": "technology_stack"})
-        return df
-
-
-class GeneratorStructureCreator:
-    @staticmethod
-    def create_generator_storage_df(
-        df_data: pd.DataFrame,
-        aggr_name: str | None = None,
-    ) -> tuple[pd.DataFrame, pd.DataFrame]:
-        df = df_data.copy()
-        if aggr_name is not None:
-            capa_df = GeneratorStructureCreator._handle_capacity(df, aggr_name)
-        else:
-            capa_df = pd.DataFrame()
-        df = df[["gen_name", "technology_type", "technology_class", "tag"]]
-        df = df.rename(columns={"gen_name": "name"})
-        df = pd.concat([df, capa_df], axis=1)
-
-        df_generator = df[df["technology_class"] == "GENERATOR"].drop(
-            columns=["technology_class"]
-        )
-        tags_df = GeneratorStructureCreator._create_tag_df(df_generator)
-        df_generator = pd.concat([df_generator, tags_df], axis=1).drop(columns=["tag"])
-        df_generator = df_generator.rename(
-            columns={"technology_type": "generator_type"}
-        )
-
-        df_storage = df[df["technology_class"] == "STORAGE"].drop(
-            columns=["technology_class", "tag"]
-        )
-        df_storage = df_storage.rename(columns={"technology_type": "storage_type"})
-        df_generator = df_generator.drop_duplicates(subset="name")
-        df_storage = df_storage.drop_duplicates(subset="name")
-        return df_generator, df_storage
-
-    @staticmethod
-    def create_generator_emission_fee_df(df_data: pd.DataFrame) -> pd.DataFrame:
-        df = df_data.copy()
-        df = df.dropna(subset=["emission_fee_id"])
-        df = df[["gen_name", "emission_fee_id"]]
-        df = df.rename(
-            columns={"gen_name": "generator", "emission_fee_id": "emission_fee"}
-        )
-        return df
-
-    @staticmethod
-    def create_technology_to_bus_df(df_data: pd.DataFrame) -> pd.DataFrame:
-        df = df_data.copy()
-        df = df[["gen_name", "technology_class", "bus_name"]]
-        df = df.rename(
-            columns={
-                "gen_name": "technology",
-                "technology_class": "type",
-                "bus_name": "bus",
-            }
-        )
-        return df
-
-    @staticmethod
-    def _handle_capacity(df: pd.DataFrame, aggr_name: str) -> pd.DataFrame:
-        filtered_columns = [
-            col
-            for col in df.columns
-            if (col.startswith("MIN") or col.startswith("MAX"))
-            and col.endswith(aggr_name)
-        ]
-        filtered_df = df[filtered_columns]
-        for col in filtered_df.columns:
-            if col.startswith("MIN"):
-                col_name = "min_device_nom_power"
-            elif col.startswith("MAX"):
-                col_name = "max_device_nom_power"
-            else:
-                col_name = col
-            filtered_df = filtered_df.rename(columns={col: col_name})
-        return filtered_df
-
-    @staticmethod
-    def _create_tag_df(df: pd.DataFrame) -> pd.DataFrame:
-        dummies = pd.get_dummies(df["tag"])
-        dummies[dummies == 1] = "YES"
-        dummies[dummies == 0] = np.nan
-        return dummies
-
-
-class BusStructureCreator:
-    @staticmethod
-    def create_bus_df(df_data: pd.DataFrame) -> pd.DataFrame:
-        df = df_data.copy()
-        df = df[["bus_name", "energy_type"]]
-        df = df.drop_duplicates(subset="bus_name")
-        df = df.rename(columns={"bus_name": "name"})
-        df["dsr_type"] = np.nan
-        return df
-
-    @staticmethod
-    def create_technologystack_bus_df(df_data: pd.DataFrame) -> pd.DataFrame:
-        df = df_data.copy()
-        df = df[["lbs", "bus_name"]]
-        df = df.rename(columns={"bus_name": "bus", "lbs": "technology_stack"})
-        df = df.drop_duplicates()
-        return df
-
-    @staticmethod
-    def create_technologystack_bout_df(df_data: pd.DataFrame) -> pd.DataFrame:
-        df = df_data.copy()
-        df = df[df["bus_type"] == "OUTPUT"].drop(columns=["bus_type"])
-        df = df[["lbs", "energy_type", "bus_name"]].drop_duplicates()
-        pivot_df = df.pivot(
-            index="lbs", columns="energy_type", values="bus_name"
-        ).reset_index()
-        pivot_df = pivot_df.rename(columns={"lbs": "name"})
-        return pivot_df
-
-
-class InitStateCreator:
-    @staticmethod
-    def create_global_technology_df(
-        df_data: pd.DataFrame, aggr_name: str | None = None
-    ) -> pd.DataFrame:
-        df = df_data.copy()
-        df = df.rename(columns={"gen_name": "technology"})
-        if aggr_name is not None:
-            df = df.rename(columns={f"BASE_CAP_{aggr_name}": "base_capacity"})
-        df = df[["technology", "base_capacity"]]
-        return df
-
-    @staticmethod
-    def create_local_technology_df(
-        df_data: pd.DataFrame, df_base_fraction: pd.DataFrame, aggr_name: str
-    ) -> pd.DataFrame:
-        df = df_data.copy()
-        aggr_frac_row = df_base_fraction.loc[aggr_name]
-        df = df.rename(
-            columns={
-                f"BASE_CAP_{aggr_name}": "base_capacity_row",
-                "gen_name": "technology",
-            }
-        )
-        aggr_frac_mapped = df["lbs_type"].map(aggr_frac_row)
-        df["base_capacity"] = (
-            df["base_capacity_row"] * aggr_frac_mapped * aggr_frac_row["n_buildings"]
-        )
-        df = df[["technology", "base_capacity"]]
-        return df
-
-    @staticmethod
-    def create_technology_stack_df(df_data: pd.DataFrame) -> pd.DataFrame:
-        df = df_data.copy()
-        df = pd.melt(
-            df,
-            id_vars=["aggregate_id"],
-            var_name="technology_stack",
-            value_name="base_fraction",
-        )
-        df = df.dropna(subset=["base_fraction"])
-        df["technology_stack"] = df["aggregate_id"] + "_" + df["technology_stack"]
-        df = df.rename(columns={"aggregate_id": "aggregate"})
-        df = df[["technology_stack", "aggregate", "base_fraction"]]
-        return df
-
-
-class StaticStructureCreator:
-    @staticmethod
-    def create_aggregate_df(df_data: pd.DataFrame) -> pd.DataFrame:
-        df = df_data.copy()
-        df = df.rename(
-            columns={
-                "aggregate_id": "name",
-                "usable_area_per_building": "average_area",
-                "n_buildings": "n_consumers_base",
-                "demand_profile_type": "demand_type",
-            }
-        )
-        df = df[["name", "demand_type", "n_consumers_base", "average_area"]]
-        return df
-
-    @staticmethod
-    def create_emission_type_df(df_data: pd.DataFrame) -> pd.DataFrame:
-        df = df_data.copy()
-        df = df.rename(
-            columns={
-                "emission_type_id": "name",
-                "base_emission": "base_total_emission",
-            }
-        )
-        return df
-
-    @staticmethod
-    def create_emission_fees_emission_type_df(df_data: pd.DataFrame) -> pd.DataFrame:
-        df = df_data.copy()
-        df = df.rename(
-            columns={
-                "emission_type_id": "emission_type",
-                "emission_fee_id": "emission_fee",
-            }
-        )
-        df = df[["emission_type", "emission_fee"]]
-        return df
-
-    @staticmethod
-    def create_energy_types_df(
-        local_et: pd.Series, global_et: pd.Series
-    ) -> pd.DataFrame:
-        df = pd.concat([local_et, global_et]).drop_duplicates().to_frame()
-        df = df.rename(columns={"energy_type": "name"})
-        return df
+# PyZefir
+# Copyright (C) 2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+import numpy as np
+import pandas as pd
+
+from pyzefir.structure_creator.structure_and_initial_state.utils import (
+    join_energy_types,
+)
+
+
+class LineStructureCreator:
+    @staticmethod
+    def _create_lines_dataframe(
+        first_df: pd.DataFrame, second_df: pd.DataFrame, energy_type: str
+    ) -> pd.DataFrame:
+        return (
+            pd.merge(
+                first_df.assign(key=1),
+                second_df.assign(key=1),
+                on="key",
+            )
+            .drop("key", axis=1)
+            .assign(
+                name=lambda x: x["bus_name_x"] + " > " + x["bus_name_y"],
+                energy_type=energy_type,
+                bus_from=lambda x: x["bus_name_x"],
+                bus_to=lambda x: x["bus_name_y"],
+                transmission_loss=lambda x: (
+                    x["transmission_loss"] if "transmission_loss" in x.columns else 0.0
+                ),
+                max_capacity=np.nan,
+                transmission_fee=lambda x: (
+                    x["transmission_fee"] if "transmission_fee" in x.columns else np.nan
+                ),
+            )[
+                [
+                    "name",
+                    "energy_type",
+                    "bus_from",
+                    "bus_to",
+                    "transmission_loss",
+                    "max_capacity",
+                    "transmission_fee",
+                ]
+            ]
+        )
+
+    @staticmethod
+    def create_lines(
+        df_data: pd.DataFrame,
+        global_subsystem_config: pd.DataFrame,
+        lbs_connection_df: pd.DataFrame,
+        aggr_name: str,
+    ) -> pd.DataFrame:
+        dfs: list[pd.DataFrame] = []
+        global_subsystem_config = global_subsystem_config.rename(
+            columns={f"TF_{aggr_name}": "transmission_fee"}
+        )
+        subsystems = global_subsystem_config["bus_name"].unique()
+        energy_types_dict = (
+            global_subsystem_config.groupby("bus_name")["energy_type"]
+            .agg(join_energy_types)
+            .to_dict()
+        )
+        for subsystem in subsystems:
+            et: str = energy_types_dict[subsystem]
+            filtered_df = df_data[
+                df_data[subsystem] & (df_data["energy_type"] == et)
+            ].drop_duplicates(subset="bus_name")
+            global_bus = global_subsystem_config[
+                global_subsystem_config["bus_name"] == subsystem
+            ].drop_duplicates(subset="bus_name")
+            result_df = LineStructureCreator._create_lines_dataframe(
+                global_bus, filtered_df, et
+            )
+            if not lbs_connection_df.empty:
+                lbs_to_global_tech_df = lbs_connection_df.set_index("lbs").eq(1)
+                lbs_subsystems_lines_df = (
+                    LineStructureCreator._create_lbs_to_subsystems_lines_dataframe(
+                        lbs_to_global_tech_df[subsystem], global_bus, filtered_df, et
+                    )
+                )
+                dfs.append(lbs_subsystems_lines_df)
+            dfs.append(result_df)
+        df = pd.concat(dfs)
+        return df
+
+    @staticmethod
+    def _create_lbs_to_subsystems_lines_dataframe(
+        connection_df: pd.Series,
+        global_bus: pd.DataFrame,
+        filtered_df: pd.DataFrame,
+        energy_type: str,
+    ) -> pd.DataFrame:
+        filtered_df = filtered_df[
+            filtered_df["lbs_type"].isin(connection_df.index[connection_df])
+        ]
+        result_df = LineStructureCreator._create_lines_dataframe(
+            filtered_df, global_bus, energy_type=energy_type
+        )
+        return result_df
+
+    @staticmethod
+    def create_local_lbs_lines(
+        df_data: pd.DataFrame,
+    ) -> pd.DataFrame:
+        if (
+            "bus_from_id" not in df_data.columns
+            or df_data["bus_from_id"].isnull().all()
+        ):
+            return pd.DataFrame()
+        df = df_data.copy()
+        local_lines_df = (
+            df[["bus_from_id", "bus_to_id", "line_energy_type"]]
+            .dropna()
+            .drop_duplicates()
+        )
+        dfs: list[pd.DataFrame] = []
+        for _, group_df in df.groupby("lbs"):
+            for bus_fr, bus_to, et in local_lines_df.itertuples(index=False):
+                bus_fr_df_filtered = (
+                    group_df[
+                        (group_df["bus_id"] == bus_fr) & (group_df["energy_type"] == et)
+                    ]
+                    .dropna(subset=["bus_from_id", "bus_to_id", "line_energy_type"])
+                    .drop_duplicates(subset=["bus_name"])
+                    .rename(
+                        columns={
+                            "local_transmission_loss": "transmission_loss",
+                            "local_transmission_fee": "transmission_fee",
+                        }
+                    )
+                )
+                bus_to_df_filtered = group_df[
+                    (group_df["bus_id"] == bus_to) & (group_df["energy_type"] == et)
+                ].drop_duplicates(subset="bus_name")
+                if bus_fr_df_filtered.empty or bus_to_df_filtered.empty:
+                    continue
+                result_df = LineStructureCreator._create_lines_dataframe(
+                    bus_fr_df_filtered, bus_to_df_filtered, et
+                )
+                dfs.append(result_df)
+        df = pd.concat(dfs)
+        return df
+
+
+class LbsStructureCreator:
+    @staticmethod
+    def create_technologystack_aggr_df(
+        df_data: pd.DataFrame,
+        aggr_name: str,
+    ) -> pd.DataFrame:
+        df = df_data.copy()
+        df = df[["lbs"]].drop_duplicates()
+        df["aggregate"] = aggr_name
+        df = df.rename(columns={"lbs": "technology_stack"})
+        return df
+
+
+class GeneratorStructureCreator:
+    @staticmethod
+    def create_generator_storage_df(
+        df_data: pd.DataFrame,
+        aggr_name: str | None = None,
+    ) -> tuple[pd.DataFrame, pd.DataFrame]:
+        df = df_data.copy()
+        tags_df = GeneratorStructureCreator._create_tag_df(df)
+        if aggr_name is not None:
+            capa_df = GeneratorStructureCreator._handle_capacity(df, aggr_name)
+        else:
+            capa_df = pd.DataFrame()
+        df = df[["gen_name", "technology_type", "technology_class"]]
+        df = df.rename(columns={"gen_name": "name"})
+        df = pd.concat([df, capa_df], axis=1)
+
+        df_generator = df[df["technology_class"] == "GENERATOR"].drop(
+            columns=["technology_class"]
+        )
+        if "GENERATOR" in tags_df.index:
+            df_tags_generator = tags_df.loc["GENERATOR", tags_df.loc["GENERATOR"].any()]
+            df_generator = pd.concat([df_generator, df_tags_generator], axis=1)
+        df_generator = df_generator.rename(
+            columns={"technology_type": "generator_type"}
+        )
+
+        df_storage = df[df["technology_class"] == "STORAGE"].drop(
+            columns=["technology_class"]
+        )
+        if "STORAGE" in tags_df.index:
+            df_tags_storage = tags_df.loc["STORAGE", tags_df.loc["STORAGE"].any()]
+            df_storage = pd.concat([df_storage, df_tags_storage], axis=1)
+        df_storage = df_storage.rename(columns={"technology_type": "storage_type"})
+        df_generator = df_generator.drop_duplicates(subset="name")
+        df_storage = df_storage.drop_duplicates(subset="name")
+        return df_generator, df_storage
+
+    @staticmethod
+    def create_generator_emission_fee_df(df_data: pd.DataFrame) -> pd.DataFrame:
+        df = df_data.copy()
+        df = df.dropna(subset=["emission_fee_id"])
+        df = df[["gen_name", "emission_fee_id"]]
+        df = df.rename(
+            columns={"gen_name": "generator", "emission_fee_id": "emission_fee"}
+        )
+        return df
+
+    @staticmethod
+    def create_technology_to_bus_df(df_data: pd.DataFrame) -> pd.DataFrame:
+        df = df_data.copy()
+        df = df[["gen_name", "technology_class", "bus_name"]]
+        df = df.rename(
+            columns={
+                "gen_name": "technology",
+                "technology_class": "type",
+                "bus_name": "bus",
+            }
+        )
+        return df
+
+    @staticmethod
+    def _handle_capacity(df: pd.DataFrame, aggr_name: str) -> pd.DataFrame:
+        filtered_columns = [
+            col
+            for col in df.columns
+            if (col.startswith("MIN") or col.startswith("MAX"))
+            and col.endswith(aggr_name)
+        ]
+        filtered_df = df[filtered_columns]
+        for col in filtered_df.columns:
+            if col.startswith("MIN"):
+                col_name = "min_device_nom_power"
+            elif col.startswith("MAX"):
+                col_name = "max_device_nom_power"
+            else:
+                col_name = col
+            filtered_df = filtered_df.rename(columns={col: col_name})
+        return filtered_df
+
+    @staticmethod
+    def _create_tag_df(df: pd.DataFrame) -> pd.DataFrame:
+        tags_df = pd.concat([df["technology_class"], df.filter(regex="^TAG_")], axis=1)
+        tags_df = tags_df.rename(columns=lambda x: x.replace("TAG_", ""))
+        tags_df = tags_df.set_index(["technology_class", df.index])
+        return tags_df
+
+    @staticmethod
+    def create_generator_binding_df(df: pd.DataFrame) -> pd.DataFrame:
+        df = df.loc[:, ["gen_name", "binding_name"]].dropna().drop_duplicates()
+        df = df.rename(columns={"gen_name": "generator"})
+        return df
+
+
+class BusStructureCreator:
+    @staticmethod
+    def create_bus_df(df_data: pd.DataFrame) -> pd.DataFrame:
+        df = df_data.copy()
+        df = df[["bus_name", "energy_type"]]
+        df = df.drop_duplicates(subset="bus_name")
+        df = df.rename(columns={"bus_name": "name"})
+        df["dsr_type"] = np.nan
+        return df
+
+    @staticmethod
+    def create_technologystack_bus_df(df_data: pd.DataFrame) -> pd.DataFrame:
+        df = df_data.copy()
+        df = df[["lbs", "bus_name"]]
+        df = df.rename(columns={"bus_name": "bus", "lbs": "technology_stack"})
+        df = df.drop_duplicates()
+        return df
+
+    @staticmethod
+    def create_technologystack_bout_df(df_data: pd.DataFrame) -> pd.DataFrame:
+        df = df_data.copy()
+        df = df[df["bus_type"] == "OUTPUT"].drop(columns=["bus_type"])
+        df = df[["lbs", "energy_type", "bus_name"]].drop_duplicates()
+        pivot_df = df.pivot(
+            index="lbs", columns="energy_type", values="bus_name"
+        ).reset_index()
+        pivot_df = pivot_df.rename(columns={"lbs": "name"})
+        return pivot_df
+
+
+class InitStateCreator:
+    @staticmethod
+    def create_global_technology_df(
+        df_data: pd.DataFrame, aggr_name: str | None = None
+    ) -> pd.DataFrame:
+        df = df_data.copy()
+        df = df.rename(columns={"gen_name": "technology"})
+        if aggr_name is not None:
+            df = df.rename(columns={f"BASE_CAP_{aggr_name}": "base_capacity"})
+        df = df[["technology", "base_capacity"]]
+        return df
+
+    @staticmethod
+    def create_local_technology_df(
+        df_data: pd.DataFrame, df_base_fraction: pd.DataFrame, aggr_name: str
+    ) -> pd.DataFrame:
+        df = df_data.copy()
+        aggr_frac_row = df_base_fraction.loc[aggr_name]
+        df = df.rename(
+            columns={
+                f"BASE_CAP_{aggr_name}": "base_capacity_row",
+                "gen_name": "technology",
+            }
+        )
+        aggr_frac_mapped = df["lbs_type"].map(aggr_frac_row)
+        df["base_capacity"] = (
+            df["base_capacity_row"] * aggr_frac_mapped * aggr_frac_row["n_buildings"]
+        )
+        df = df[["technology", "base_capacity"]]
+        return df
+
+    @staticmethod
+    def create_technology_stack_df(df_data: pd.DataFrame) -> pd.DataFrame:
+        df = df_data.copy()
+        df = pd.melt(
+            df,
+            id_vars=["aggregate_id"],
+            var_name="technology_stack",
+            value_name="base_fraction",
+        )
+        df = df.dropna(subset=["base_fraction"])
+        df["technology_stack"] = df["aggregate_id"] + "__" + df["technology_stack"]
+        df = df.rename(columns={"aggregate_id": "aggregate"})
+        df = df[["technology_stack", "aggregate", "base_fraction"]]
+        return df
+
+
+class StaticStructureCreator:
+    @staticmethod
+    def create_aggregate_df(df_data: pd.DataFrame) -> pd.DataFrame:
+        df = df_data.copy()
+        df = df.rename(
+            columns={
+                "aggregate_id": "name",
+                "usable_area_per_building": "average_area",
+                "n_buildings": "n_consumers_base",
+                "demand_profile_type": "demand_type",
+            }
+        )
+        df = df[["name", "demand_type", "n_consumers_base", "average_area"]]
+        return df
+
+    @staticmethod
+    def create_emission_type_df(df_data: pd.DataFrame) -> pd.DataFrame:
+        df = df_data.copy()
+        df = df.rename(
+            columns={
+                "emission_type_id": "name",
+                "base_emission": "base_total_emission",
+            }
+        )
+        return df
+
+    @staticmethod
+    def create_emission_fees_emission_type_df(df_data: pd.DataFrame) -> pd.DataFrame:
+        df = df_data.copy()
+        df = df.rename(
+            columns={
+                "emission_type_id": "emission_type",
+                "emission_fee_id": "emission_fee",
+            }
+        )
+        df = df[["emission_type", "emission_fee"]]
+        return df
+
+    @staticmethod
+    def create_energy_types_df(
+        local_et: pd.Series, global_et: pd.Series
+    ) -> pd.DataFrame:
+        df = pd.concat([local_et, global_et]).drop_duplicates().to_frame()
+        df = df.rename(columns={"energy_type": "name"})
+        return df
```

### Comparing `pyzefir-0.4.1/pyzefir/utils/__init__.py` & `pyzefir-0.4.22/pyzefir/utils/__init__.py`

 * *Ordering differences only*

 * *Files 23% similar despite different names*

```diff
@@ -1,15 +1,15 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
```

### Comparing `pyzefir-0.4.1/pyzefir/utils/config_parser.py` & `pyzefir-0.4.22/pyzefir/utils/config_parser.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,376 +1,415 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-import configparser
-from dataclasses import dataclass
-from pathlib import Path
-from typing import Any, overload
-
-import linopy
-import numpy as np
-import pandas as pd
-
-from pyzefir.cli.logger import DEFAULT_LOG_LEVEL, LOG_LEVEL_MAPPING
-
-
-class ConfigException(Exception):
-    pass
-
-
-@dataclass(frozen=True, kw_only=True)
-class ConfigParams:
-    """Class to hold configuration parameters."""
-
-    input_path: Path
-    """path to the model input data (either *.csv or *.xlsx files)"""
-    scenario: str
-    """name of the scenario"""
-    input_format: str
-    """csv or xlsx"""
-    output_path: Path
-    """path to the folder, where model results will be dumped"""
-    csv_dump_path: Path | None
-    """path to the folder, where converted (xlsx -> csv) files will be stored [default = output_path/model-csv-input]"""
-    sol_dump_path: Path
-    """path where linopy *.sol file will be dumped [default = output_path/results.sol]"""
-    opt_logs_path: Path
-    """path where linopy log file will be dumped [default = output_path/linopy.log]"""
-    year_sample: np.ndarray | None
-    """indices of years forming year sample [if not provided, full year index will be used]"""
-    hour_sample: np.ndarray | None
-    """indices of hours forming hour sample [if not provided, full hour index will be used]"""
-    discount_rate: np.ndarray | None
-    """vector containing discount year for consecutive years [if not provided, zero discount rate is assumed]"""
-    network_config: dict[str, Any] | None = None
-    """network configuration"""
-    money_scale: float = 1.0
-    """ numeric scale parameter """
-    ens: bool = True
-    """ use ens associated with buses if not balanced """
-    use_hourly_scale: bool = True
-    """ use ratio of the total number of hours to the total number of hours in given sample """
-    n_years: int | None
-    """ number of years in which the simulation will be calculated (used for structure creator) """
-    n_hours: int | None
-    """ number of hours in which the simulation will be calculated (used for structure creator) """
-    solver: str | None = None
-    structure_creator_input_path: Path | None = None
-    """ path to the creator input files """
-    format_exceptions: bool = True
-    """ whether to format exceptions or not handle them at all """
-    log_level: int
-    """ logging level """
-
-    def __post_init__(self) -> None:
-        """Validate parameters."""
-        validate_dir_path(self.input_path, "input_path")
-        validate_dir_path(self.output_path, "output_path", create=True)
-        validate_1D_array(self.year_sample, "year_sample")
-        validate_1D_array(self.discount_rate, "discount_rate")
-        validate_1D_array(self.hour_sample, "hour_sample")
-        validate_input_format(self.input_format)
-        validate_csv_dump_path(self.csv_dump_path, self.input_format)
-        validate_sol_dump_path(self.sol_dump_path)
-        validate_dir_path(self.opt_logs_path.parent, "opt_logs_path parent")
-        validate_solver_name(self.solver)
-        validate_structure_create(
-            self.n_hours, self.n_years, self.structure_creator_input_path
-        )
-
-
-def validate_structure_create(
-    n_hours: int | None,
-    n_years: int | None,
-    input_path: Path | None,
-) -> None:
-    """Validate if are the same type and if both are int check if input_path exists"""
-    if (n_hours is None) != (n_years is None):
-        raise ConfigException(
-            "Both parameters must have the same int or None value,"
-            f"and they do n_hours: {type(n_hours)} and n_years: {type(n_years)}"
-        )
-    if n_hours is not None and n_years is not None and input_path is not None:
-        validate_dir_path(input_path, "structure creator")
-
-
-def validate_file_path(file_path: Path, param_name: str) -> None:
-    """Validate if the specified path points to an existing file."""
-    if not file_path.exists():
-        raise ConfigException(
-            f"Path specified as {param_name} does not exist: {file_path}"
-        )
-    if not file_path.is_file():
-        raise ConfigException(
-            f"Path specified as {param_name} does not point to a file: {file_path}"
-        )
-
-
-def validate_dir_path(dir_path: Path, param_name: str, create: bool = False) -> None:
-    """Validate if the specified path points to an existing folder."""
-    if not dir_path.exists():
-        if not create:
-            raise ConfigException(
-                f"Path specified as {param_name} should exist: {dir_path}"
-            )
-        dir_path.mkdir(parents=True)
-    if not dir_path.is_dir():
-        raise ConfigException(
-            f"Path specified as {param_name} should point to a folder: {dir_path}"
-        )
-
-
-def validate_suffix(path: Path, suffix: str, param_name: str) -> None:
-    """Validate if path is pointing to a file / directory with given suffix."""
-    if not path.suffix == suffix:
-        raise ConfigException(
-            f"Path specified as {param_name} has incorrect suffix: {path.name} (expected {suffix})"
-        )
-
-
-def validate_config_path(config_ini_path: Path) -> None:
-    """Validate if the specified path is a valid .ini configuration file."""
-    validate_file_path(config_ini_path, "config_file_path")
-    validate_suffix(config_ini_path, ".ini", "config_file_path")
-
-
-def validate_sol_dump_path(path: Path) -> None:
-    """Validate specified path to *.sol file."""
-    validate_dir_path(path.parent, "sol_dump_path directory")
-    validate_suffix(path, ".sol", "sol_dump_path")
-
-
-def validate_1D_array(data: np.ndarray | None, param_name: str) -> None:
-    """Validate if hour_sample, year_sample or discount_rate is 1D NumPy array."""
-    if data is not None and not data.ndim == 1:
-        raise ConfigException(
-            f"provided {param_name} is {data.ndim} dimensional dataset, one dimensional data is required"
-        )
-
-
-def validate_input_format(input_format: str) -> None:
-    """Validate if provided input_file parameter is correct."""
-    if input_format not in ["csv", "xlsx"]:
-        raise ConfigException(
-            f"provided input_format {input_format} is different than valid formats: csv, xlsx"
-        )
-
-
-def validate_csv_dump_path(csv_dump_path: Path | None, input_format: str) -> None:
-    """Validate if csv_dump_path is provided only for xlsx input_format and, if it is provided - it exists."""
-    if input_format == "csv" and csv_dump_path is not None:
-        raise ConfigException(
-            "csv_dump_path should not be specified for csv input_format"
-        )
-    if input_format == "xlsx" and csv_dump_path is None:
-        raise ConfigException("csv_dump_path should be specified for xlsx input_format")
-    if csv_dump_path is not None:
-        validate_dir_path(csv_dump_path, param_name="csv_dump_path", create=True)
-
-
-def validate_solver_name(solver_name: str | None) -> None:
-    """Validate if solver_name is correct."""
-    if solver_name is not None and solver_name not in linopy.available_solvers:
-        raise ConfigException(
-            f"provided solver_name {solver_name} is different than valid solvers: {linopy.available_solvers}"
-        )
-
-
-def load_vector_from_csv(path: Path, param_name: str) -> np.ndarray:
-    """Load 1 dimensional dataset (as 1D NumPy array) from given path."""
-    validate_file_path(path, param_name)
-    validate_suffix(path, ".csv", param_name)
-    return pd.read_csv(path, header=None, sep=";").values.squeeze()
-
-
-class ConfigLoader:
-    _req, _opt = "required", "optional"
-    _mandatory_sections = {
-        "input": {"input_path": _req, "scenario": _req, "input_format": _req},
-        "output": {
-            "output_path": _req,
-            "sol_dump_path": _opt,
-            "opt_logs_path": _opt,
-            "csv_dump_path": _opt,
-        },
-    }
-    _optional_sections = {
-        "parameters": {"year_sample": _opt, "discount_rate": _opt, "hour_sample": _opt},
-        "optimization": {
-            "binary_fraction": _opt,
-            "money_scale": _opt,
-            "ens": _opt,
-            "use_hourly_scale": _opt,
-            "solver": _opt,
-            "numeric_tolerance": _opt,
-        },
-        "create": {"n_years": _opt, "n_hours": _opt, "input_path": _opt},
-        "debug": {
-            "format_network_exceptions": _opt,
-            "log_level": _opt,
-        },
-    }
-    _sections = _mandatory_sections | _optional_sections
-
-    _default_csv_dump_path_name = "model-csv-input"
-    _default_opt_log = "opt.log"
-    _default_sol = "results.sol"
-
-    def __init__(self, config_ini_path: Path) -> None:
-        validate_config_path(config_ini_path)
-        self.config = configparser.ConfigParser()
-        self.config.read(config_ini_path)
-        self._validate_config_file_structure()
-
-    def _validate_config_file_structure(self) -> None:
-        """Validate sections and parameters in loaded *.ini file."""
-        if set(self._mandatory_sections) - set(self.config.sections()) or not set(
-            self.config.sections()
-        ).issubset(self._sections):
-            raise ConfigException(
-                f"incorrect *.ini file: required sections: {set(self._sections)}, given: {set(self.config.sections())}"
-            )
-        if "create" in self.config.sections():
-            if (
-                input_format_value := self.config.get("input", "input_format")
-            ) != "xlsx":
-                raise ConfigException(
-                    "Invalid input format: If you want to use structure creator,"
-                    f" input format must be xlsx but given :{input_format_value}"
-                )
-
-        for section in self.config.sections():
-            given_keys, allowed_keys = (
-                set(self.config[section]),
-                set(self._sections[section]),
-            )
-            required_keys = set(
-                [
-                    key
-                    for key in self._sections[section]
-                    if self._sections[section] == self._req
-                ]
-            )
-            if not required_keys.issubset(given_keys):
-                raise ConfigException(
-                    f"incorrect *.ini file: required parameters in section {section} are: {required_keys}, but given: "
-                    f"{given_keys}"
-                )
-            if not given_keys.issubset(allowed_keys):
-                raise ConfigException(
-                    f"incorrect *.ini file: allowed parameters in section {section} are: {allowed_keys}, but given: "
-                    f"{given_keys}"
-                )
-
-    def load(self) -> ConfigParams:
-        """Create ConfigParams obj from given *.ini file."""
-        output_path = Path(self.config.get("output", "output_path"))
-        return ConfigParams(
-            input_path=Path(self.config.get("input", "input_path")),
-            scenario=self.config.get("input", "scenario"),
-            input_format=self.config.get("input", "input_format"),
-            output_path=output_path,
-            csv_dump_path=self._get_path("output", "csv_dump_path"),
-            sol_dump_path=self._get_path(
-                "output", "sol_dump_path", output_path / self._default_sol
-            ),
-            opt_logs_path=self._get_path(
-                "output", "opt_logs_path", output_path / self._default_opt_log
-            ),
-            year_sample=self._load_parameter_from_csv("year_sample"),
-            hour_sample=self._load_parameter_from_csv("hour_sample"),
-            discount_rate=self._load_parameter_from_csv("discount_rate"),
-            money_scale=self.config.getfloat(
-                "optimization", "money_scale", fallback=1.0
-            ),
-            network_config=self._load_network_config(),
-            ens=self.config.getboolean("optimization", "ens", fallback=True),
-            use_hourly_scale=self.config.getboolean(
-                "optimization", "use_hourly_scale", fallback=True
-            ),
-            n_years=(
-                int(n_years_raw)
-                if (n_years_raw := self.config.get("create", "n_years", fallback=None))
-                is not None
-                else None
-            ),
-            n_hours=(
-                int(n_hours_raw)
-                if (n_hours_raw := self.config.get("create", "n_hours", fallback=None))
-                is not None
-                else None
-            ),
-            solver=self.config.get("optimization", "solver", fallback=None),
-            structure_creator_input_path=(
-                Path(creator_input)
-                if (
-                    creator_input := self.config.get(
-                        "create", "input_path", fallback=None
-                    )
-                )
-                is not None
-                else None
-            ),
-            format_exceptions=self.config.getboolean(
-                "debug", "format_network_exceptions", fallback=True
-            ),
-            log_level=self._get_log_level(),
-        )
-
-    def _get_log_level(self) -> int:
-        config_log_level = self.config.get("debug", "log_level", fallback="")
-        if (log_level := LOG_LEVEL_MAPPING.get(config_log_level.lower())) is not None:
-            return log_level
-        return DEFAULT_LOG_LEVEL
-
-    def _load_network_config(self) -> dict[str, Any]:
-        network_config: dict[str, Any] = {}
-        if "optimization" not in self.config.sections():
-            return network_config
-        optimization_section = self.config["optimization"]
-        network_config["binary_fraction"] = (
-            optimization_section.getboolean("binary_fraction")
-            if "binary_fraction" in optimization_section
-            else False
-        )
-        if (
-            numeric_tolerance := optimization_section.getfloat(
-                "numeric_tolerance", fallback=None
-            )
-        ) is not None:
-            network_config["numeric_tolerance"] = numeric_tolerance
-        return network_config
-
-    def _load_parameter_from_csv(self, parameter: str) -> np.ndarray | None:
-        path = self._get_path("parameters", parameter)
-        return (
-            load_vector_from_csv(path, param_name=parameter)
-            if path is not None
-            else None
-        )
-
-    @overload
-    def _get_path(self, section: str, key: str, default: Path) -> Path:
-        pass
-
-    @overload
-    def _get_path(self, section: str, key: str, default: None = None) -> Path | None:
-        pass
-
-    def _get_path(
-        self, section: str, key: str, default: Path | None = None
-    ) -> Path | None:
-        path_str = self.config[section].get(key, "")
-        return Path(path_str) if path_str.strip() else default
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+import configparser
+from dataclasses import dataclass, field
+from itertools import repeat
+from pathlib import Path
+from typing import Any, overload
+
+import linopy
+import numpy as np
+import pandas as pd
+
+from pyzefir.cli.logger import DEFAULT_LOG_LEVEL, LOG_LEVEL_MAPPING
+
+
+class ConfigException(Exception):
+    pass
+
+
+@dataclass(frozen=True, kw_only=True)
+class ConfigParams:
+    """Class to hold configuration parameters."""
+
+    input_path: Path
+    """path to the model input data (either *.csv or *.xlsx files)"""
+    scenario: str
+    """name of the scenario"""
+    input_format: str
+    """csv or xlsx"""
+    output_path: Path
+    """path to the folder, where model results will be dumped"""
+    csv_dump_path: Path | None
+    """path to the folder, where converted (xlsx -> csv) files will be stored [default = output_path/model-csv-input]"""
+    sol_dump_path: Path
+    """path where linopy *.sol file will be dumped [default = output_path/results.sol]"""
+    opt_logs_path: Path
+    """path where linopy log file will be dumped [default = output_path/linopy.log]"""
+    year_sample: np.ndarray | None
+    """indices of years forming year sample [if not provided, full year index will be used]"""
+    hour_sample: np.ndarray | None
+    """indices of hours forming hour sample [if not provided, full hour index will be used]"""
+    discount_rate: np.ndarray | None
+    """vector containing discount year for consecutive years [if not provided, zero discount rate is assumed]"""
+    network_config: dict[str, Any] | None = None
+    """network configuration"""
+    money_scale: float = 1.0
+    """ numeric scale parameter """
+    use_hourly_scale: bool = True
+    """ use ratio of the total number of hours to the total number of hours in given sample """
+    n_years: int | None
+    """ number of years in which the simulation will be calculated (used for structure creator) """
+    n_hours: int | None
+    """ number of hours in which the simulation will be calculated (used for structure creator) """
+    solver: str | None = None
+    structure_creator_input_path: Path | None = None
+    """ path to the creator input files """
+    format_exceptions: bool = True
+    """ whether to format exceptions or not handle them at all """
+    log_level: int
+    """ logging level """
+    solver_settings: dict[str, dict[str, Any]] = field(default_factory=dict)
+    """ additional settings that can be passed to the solver """
+    xlsx_results: bool = False
+    """ dump results into additional xlsx files (outside the default CSV files)"""
+
+    def __post_init__(self) -> None:
+        """Validate parameters."""
+        validate_dir_path(self.input_path, "input_path")
+        validate_dir_path(self.output_path, "output_path", create=True)
+        validate_1D_array(self.year_sample, "year_sample")
+        validate_1D_array(self.discount_rate, "discount_rate")
+        validate_1D_array(self.hour_sample, "hour_sample")
+        validate_input_format(self.input_format)
+        validate_csv_dump_path(self.csv_dump_path, self.input_format)
+        validate_sol_dump_path(self.sol_dump_path)
+        validate_dir_path(self.opt_logs_path.parent, "opt_logs_path parent")
+        validate_solver_name(self.solver)
+        validate_structure_create(
+            self.n_hours, self.n_years, self.structure_creator_input_path
+        )
+
+
+def validate_structure_create(
+    n_hours: int | None,
+    n_years: int | None,
+    input_path: Path | None,
+) -> None:
+    """Validate if are the same type and if both are int check if input_path exists"""
+    if (n_hours is None) != (n_years is None):
+        raise ConfigException(
+            "Both parameters must have the same int or None value,"
+            f"and they do n_hours: {type(n_hours)} and n_years: {type(n_years)}"
+        )
+    if n_hours is not None and n_years is not None and input_path is not None:
+        validate_dir_path(input_path, "structure creator")
+
+
+def validate_file_path(file_path: Path, param_name: str) -> None:
+    """Validate if the specified path points to an existing file."""
+    if not file_path.exists():
+        raise ConfigException(
+            f"Path specified as {param_name} does not exist: {file_path}"
+        )
+    if not file_path.is_file():
+        raise ConfigException(
+            f"Path specified as {param_name} does not point to a file: {file_path}"
+        )
+
+
+def validate_dir_path(dir_path: Path, param_name: str, create: bool = False) -> None:
+    """Validate if the specified path points to an existing folder."""
+    if not dir_path.exists():
+        if not create:
+            raise ConfigException(
+                f"Path specified as {param_name} should exist: {dir_path}"
+            )
+        dir_path.mkdir(parents=True)
+    if not dir_path.is_dir():
+        raise ConfigException(
+            f"Path specified as {param_name} should point to a folder: {dir_path}"
+        )
+
+
+def validate_suffix(path: Path, suffix: str, param_name: str) -> None:
+    """Validate if path is pointing to a file / directory with given suffix."""
+    if not path.suffix == suffix:
+        raise ConfigException(
+            f"Path specified as {param_name} has incorrect suffix: {path.name} (expected {suffix})"
+        )
+
+
+def validate_config_path(config_ini_path: Path) -> None:
+    """Validate if the specified path is a valid .ini configuration file."""
+    validate_file_path(config_ini_path, "config_file_path")
+    validate_suffix(config_ini_path, ".ini", "config_file_path")
+
+
+def validate_sol_dump_path(path: Path) -> None:
+    """Validate specified path to *.sol file."""
+    validate_dir_path(path.parent, "sol_dump_path directory")
+    validate_suffix(path, ".sol", "sol_dump_path")
+
+
+def validate_1D_array(data: np.ndarray | None, param_name: str) -> None:
+    """Validate if hour_sample, year_sample or discount_rate is 1D NumPy array."""
+    if data is not None and not data.ndim == 1:
+        raise ConfigException(
+            f"provided {param_name} is {data.ndim} dimensional dataset, one dimensional data is required"
+        )
+
+
+def validate_input_format(input_format: str) -> None:
+    """Validate if provided input_file parameter is correct."""
+    if input_format not in ["csv", "xlsx"]:
+        raise ConfigException(
+            f"provided input_format {input_format} is different than valid formats: csv, xlsx"
+        )
+
+
+def validate_csv_dump_path(csv_dump_path: Path | None, input_format: str) -> None:
+    """Validate if csv_dump_path is provided only for xlsx input_format and, if it is provided - it exists."""
+    if input_format == "csv" and csv_dump_path is not None:
+        raise ConfigException(
+            "csv_dump_path should not be specified for csv input_format"
+        )
+    if input_format == "xlsx" and csv_dump_path is None:
+        raise ConfigException("csv_dump_path should be specified for xlsx input_format")
+    if csv_dump_path is not None:
+        validate_dir_path(csv_dump_path, param_name="csv_dump_path", create=True)
+
+
+def validate_solver_name(solver_name: str | None) -> None:
+    """Validate if solver_name is correct."""
+    if solver_name is not None and solver_name not in linopy.available_solvers:
+        raise ConfigException(
+            f"provided solver_name {solver_name} is different than valid solvers: {linopy.available_solvers}"
+        )
+
+
+def load_vector_from_csv(path: Path, param_name: str) -> np.ndarray:
+    """Load 1 dimensional dataset (as 1D NumPy array) from given path."""
+    validate_file_path(path, param_name)
+    validate_suffix(path, ".csv", param_name)
+    return pd.read_csv(path, header=None, sep=";").values.squeeze()
+
+
+class ConfigLoader:
+    _req, _opt, _any = "required", "optional", {"any"}
+    _configurable_solvers = {"gurobi", "cplex", "highs", "glpk"}
+    _mandatory_sections = {
+        "input": {"input_path": _req, "scenario": _req, "input_format": _req},
+        "output": {
+            "output_path": _req,
+            "sol_dump_path": _opt,
+            "opt_logs_path": _opt,
+            "csv_dump_path": _opt,
+            "xlsx_results": _opt,
+        },
+    }
+    _optional_sections = {
+        "parameters": {"year_sample": _opt, "discount_rate": _opt, "hour_sample": _opt},
+        "optimization": {
+            "binary_fraction": _opt,
+            "money_scale": _opt,
+            "use_hourly_scale": _opt,
+            "solver": _opt,
+            "ens_penalty_cost": _opt,
+        },
+        "create": {"n_years": _opt, "n_hours": _opt, "input_path": _opt},
+        "debug": {
+            "format_network_exceptions": _opt,
+            "log_level": _opt,
+        },
+        **{solver: val for solver, val in zip(_configurable_solvers, repeat(_any))},
+    }
+
+    _sections = _mandatory_sections | _optional_sections
+
+    _default_csv_dump_path_name = "model-csv-input"
+    _default_opt_log = "opt.log"
+    _default_sol = "results.sol"
+
+    def __init__(self, config_ini_path: Path) -> None:
+        validate_config_path(config_ini_path)
+        self.config = configparser.ConfigParser()
+        self.config.optionxform = str  # type: ignore
+        self.config.read(config_ini_path)
+        self._validate_config_file_structure()
+
+    def _validate_config_file_structure(self) -> None:
+        """Validate sections and parameters in loaded *.ini file."""
+        if set(self._mandatory_sections) - set(self.config.sections()) or not set(
+            self.config.sections()
+        ).issubset(self._sections):
+            raise ConfigException(
+                f"incorrect *.ini file: required sections: {set(self._sections)}, given: {set(self.config.sections())}"
+            )
+        if "create" in self.config.sections():
+            if (
+                input_format_value := self.config.get("input", "input_format")
+            ) != "xlsx":
+                raise ConfigException(
+                    "Invalid input format: If you want to use structure creator,"
+                    f" input format must be xlsx but given :{input_format_value}"
+                )
+
+        self._validate_section_structure()
+
+    def _validate_section_structure(self) -> None:
+        for section in self.config.sections():
+            given_keys, allowed_keys = (
+                set(self.config[section]),
+                set(self._sections[section]),
+            )
+            required_keys = set(
+                [
+                    key
+                    for key in self._sections[section]
+                    if self._sections[section] == self._req
+                ]
+            )
+            if not required_keys.issubset(given_keys):
+                raise ConfigException(
+                    f"incorrect *.ini file: required parameters in section {section} are: {required_keys}, but given: "
+                    f"{given_keys}"
+                )
+            if not allowed_keys == self._any and not given_keys.issubset(allowed_keys):
+                raise ConfigException(
+                    f"incorrect *.ini file: allowed parameters in section {section} are: {allowed_keys}, but given: "
+                    f"{given_keys}"
+                )
+
+    @staticmethod
+    def try_parse_config_option(string: str) -> float | int | bool | str:
+        if string.lower() == "true":
+            return True
+        if string.lower() == "false":
+            return False
+        try:
+            number = float(string)
+            if number.is_integer():
+                return int(number)
+            return number
+        except ValueError:
+            pass
+
+        return string
+
+    def load(self) -> ConfigParams:
+        """Create ConfigParams obj from given *.ini file."""
+        output_path = Path(self.config.get("output", "output_path"))
+        return ConfigParams(
+            input_path=Path(self.config.get("input", "input_path")),
+            scenario=self.config.get("input", "scenario"),
+            input_format=self.config.get("input", "input_format"),
+            output_path=output_path,
+            csv_dump_path=self._get_path("output", "csv_dump_path"),
+            sol_dump_path=self._get_path(
+                "output", "sol_dump_path", output_path / self._default_sol
+            ),
+            opt_logs_path=self._get_path(
+                "output", "opt_logs_path", output_path / self._default_opt_log
+            ),
+            year_sample=self._load_parameter_from_csv("year_sample"),
+            hour_sample=self._load_parameter_from_csv("hour_sample"),
+            discount_rate=self._load_parameter_from_csv("discount_rate"),
+            money_scale=self.config.getfloat(
+                "optimization", "money_scale", fallback=1.0
+            ),
+            network_config=self._load_network_config(),
+            use_hourly_scale=self.config.getboolean(
+                "optimization", "use_hourly_scale", fallback=True
+            ),
+            n_years=(
+                int(n_years_raw)
+                if (n_years_raw := self.config.get("create", "n_years", fallback=None))
+                is not None
+                else None
+            ),
+            n_hours=(
+                int(n_hours_raw)
+                if (n_hours_raw := self.config.get("create", "n_hours", fallback=None))
+                is not None
+                else None
+            ),
+            solver=self.config.get("optimization", "solver", fallback=None),
+            structure_creator_input_path=(
+                Path(creator_input)
+                if (
+                    creator_input := self.config.get(
+                        "create", "input_path", fallback=None
+                    )
+                )
+                is not None
+                else None
+            ),
+            format_exceptions=self.config.getboolean(
+                "debug", "format_network_exceptions", fallback=True
+            ),
+            log_level=self._get_log_level(),
+            solver_settings={
+                section: {
+                    key: self.try_parse_config_option(value)
+                    for key, value in self.config.items(section)
+                }
+                for section in self._configurable_solvers
+                if section in self.config.sections()
+            },
+            xlsx_results=self.config.getboolean(
+                "output", "xlsx_results", fallback=False
+            ),
+        )
+
+    def _get_log_level(self) -> int:
+        config_log_level = self.config.get("debug", "log_level", fallback="")
+        if (log_level := LOG_LEVEL_MAPPING.get(config_log_level.lower())) is not None:
+            return log_level
+        return DEFAULT_LOG_LEVEL
+
+    def _load_network_config(self) -> dict[str, Any]:
+        network_config: dict[str, Any] = {}
+        if "optimization" not in self.config.sections():
+            return network_config
+        optimization_section = self.config["optimization"]
+        network_config["binary_fraction"] = (
+            optimization_section.getboolean("binary_fraction")
+            if "binary_fraction" in optimization_section
+            else False
+        )
+        if (
+            numeric_tolerance := optimization_section.getfloat(
+                "numeric_tolerance", fallback=None
+            )
+        ) is not None:
+            network_config["numeric_tolerance"] = numeric_tolerance
+        network_config["ens_penalty_cost"] = optimization_section.getfloat(
+            "ens_penalty_cost", fallback=np.nan
+        )
+        return network_config
+
+    def _load_parameter_from_csv(self, parameter: str) -> np.ndarray | None:
+        path = self._get_path("parameters", parameter)
+        return (
+            load_vector_from_csv(path, param_name=parameter)
+            if path is not None
+            else None
+        )
+
+    @overload
+    def _get_path(self, section: str, key: str, default: Path) -> Path:
+        pass
+
+    @overload
+    def _get_path(self, section: str, key: str, default: None = None) -> Path | None:
+        pass
+
+    def _get_path(
+        self, section: str, key: str, default: Path | None = None
+    ) -> Path | None:
+        path_str = self.config[section].get(key, "")
+        return Path(path_str) if path_str.strip() else default
```

### Comparing `pyzefir-0.4.1/pyzefir/utils/converters/__init__.py` & `pyzefir-0.4.22/pyzefir/utils/converters/__init__.py`

 * *Ordering differences only*

 * *Files 23% similar despite different names*

```diff
@@ -1,15 +1,15 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
```

### Comparing `pyzefir-0.4.1/pyzefir/utils/converters/converter.py` & `pyzefir-0.4.22/pyzefir/utils/converters/converter.py`

 * *Ordering differences only*

 * *Files 25% similar despite different names*

```diff
@@ -1,33 +1,33 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-import logging
-from abc import ABC, abstractmethod
-from pathlib import Path
-
-logger = logging.getLogger(__name__)
-
-
-class AbstractConverter(ABC):
-    @abstractmethod
-    def convert(self) -> None:
-        pass
-
-    @staticmethod
-    def manage_existence_path(path: Path) -> None:
-        if not path.parent.exists():
-            path.parent.mkdir(parents=True, exist_ok=True)
-            logger.debug(f"Created directories: {path.parent}")
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+import logging
+from abc import ABC, abstractmethod
+from pathlib import Path
+
+logger = logging.getLogger(__name__)
+
+
+class AbstractConverter(ABC):
+    @abstractmethod
+    def convert(self) -> None:
+        pass
+
+    @staticmethod
+    def manage_existence_path(path: Path) -> None:
+        if not path.parent.exists():
+            path.parent.mkdir(parents=True, exist_ok=True)
+            logger.debug(f"Created directories: {path.parent}")
```

### Comparing `pyzefir-0.4.1/pyzefir/utils/converters/xlsx_to_csv_converter.py` & `pyzefir-0.4.22/pyzefir/utils/converters/xlsx_to_csv_converter.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,173 +1,179 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-import logging
-import os.path
-from pathlib import Path
-
-import pandas as pd
-
-from pyzefir.parser.utils import TRUE_VALUES, sanitize_dataset_name
-from pyzefir.parser.validator.dataframe_validator import DataFrameValidator
-from pyzefir.parser.validator.valid_structure import (
-    DatasetConfig,
-    get_dataset_config_from_categories,
-    get_dataset_reference,
-)
-from pyzefir.utils.converters.converter import AbstractConverter
-from pyzefir.utils.path_manager import (
-    DataCategories,
-    XlsxPathManager,
-    get_datasets_from_categories,
-)
-
-logger = logging.getLogger(__name__)
-
-
-class ExcelToCsvConverterException(Exception):
-    pass
-
-
-class ExcelToCsvConverter(AbstractConverter):
-    def __init__(
-        self,
-        input_files_path: Path,
-        output_files_path: Path,
-        scenario_path: Path | None = None,
-    ) -> None:
-        self.path_manager = XlsxPathManager(
-            input_path=input_files_path,
-            output_path=output_files_path,
-            scenario_name=scenario_path.stem if scenario_path else None,
-        )
-        self._scenario_path = scenario_path
-
-    def convert(self) -> None:
-        for category in DataCategories.get_main_categories():
-            if category == DataCategories.SCENARIO and not self._scenario_path:
-                logger.debug(
-                    f"Scenario file is not passed {self._scenario_path=}, skipped"
-                )
-                continue
-            xlsx_path = (
-                self._scenario_path
-                if category == DataCategories.SCENARIO
-                else self.path_manager.get_input_file_path(category)
-            )
-            if not os.path.isfile(str(xlsx_path)):
-                logger.error(f"Cannot find file in dir {xlsx_path}")
-                raise ExcelToCsvConverterException(
-                    f"File cannot be found in given path: {xlsx_path}"
-                )
-
-            xlsx_df_dict = pd.read_excel(
-                xlsx_path, sheet_name=None, true_values=TRUE_VALUES
-            )
-            logger.debug(f"File {xlsx_path} found in given path")
-
-            sanitized_df_dict = self._sanitize_spreadsheets_names(xlsx_df_dict)
-            self._validate(category=category, xlsx_df_dict=sanitized_df_dict)
-            self._convert_xlsx_to_csv(category, xlsx_df_dict=sanitized_df_dict)
-
-    def _validate(self, category: str, xlsx_df_dict: dict[str, pd.DataFrame]) -> None:
-        if category not in DataCategories.get_dynamic_categories():
-            self._validate_xlsx_structure(
-                xlsx_sheets_names=list(xlsx_df_dict.keys()), category=category
-            )
-        self._validate_dataframes_structure(
-            xlsx_df_dict=xlsx_df_dict, category=category
-        )
-
-    @staticmethod
-    def _validate_dataframes_structure(
-        xlsx_df_dict: dict[str, pd.DataFrame], category: str
-    ) -> None:
-        for sheet_name, df in xlsx_df_dict.items():
-            if df.empty:
-                continue
-            valid_structure = get_dataset_config_from_categories(
-                data_category=category, dataset_name=sheet_name
-            )
-            dataframe_structure: dict[str, str] = (
-                ExcelToCsvConverter._get_dataframe_structure(df, valid_structure)
-            )
-            dataset_reference = get_dataset_reference(
-                category, valid_structure.dataset_name
-            )
-            DataFrameValidator(
-                df=df,
-                dataframe_structure=dataframe_structure,
-                valid_structure=valid_structure,
-                dataset_reference=dataset_reference,
-            ).validate()
-
-    @staticmethod
-    def _get_dataframe_structure(
-        df: pd.DataFrame, valid_structure: DatasetConfig
-    ) -> dict[str, str]:
-        structure = {}
-        for col, dtype in df.dtypes.items():
-            if valid_structure.columns.get(col) is bool:
-                df.loc[:, col] = df.loc[:, col].fillna(False)
-                structure[str(col)] = "bool"
-            elif (
-                col not in valid_structure.columns
-                and valid_structure.default_type is not None
-                and bool in valid_structure.default_type
-            ):
-                df.loc[:, col] = df.loc[:, col].fillna(False)
-                structure[str(col)] = "bool"
-            else:
-                structure[str(col)] = dtype.name
-        return structure
-
-    @staticmethod
-    def _validate_xlsx_structure(xlsx_sheets_names: list[str], category: str) -> None:
-        valid_sheets_names: list[str] = get_datasets_from_categories(category)
-        missing_spreadsheets = set(valid_sheets_names).difference(xlsx_sheets_names)
-        if missing_spreadsheets:
-            logger.error("Required spreadsheets not in xlsx file")
-            raise ExcelToCsvConverterException(
-                f"Not all required spreadsheets {missing_spreadsheets} found in xlsx file spreadsheets"
-                f" {xlsx_sheets_names}"
-            )
-        logger.debug("All required spreadsheets are in xlsx file")
-
-    def _convert_xlsx_to_csv(
-        self, category: str, xlsx_df_dict: dict[str, pd.DataFrame]
-    ) -> None:
-        for sheet_name, df in xlsx_df_dict.items():
-            csv_path = (
-                self.path_manager.concatenate_path_for_dynamic_dataset_name(
-                    category, sheet_name
-                )
-                if category in DataCategories.get_dynamic_categories()
-                else self.path_manager.get_path(category, sheet_name)
-            )
-            self.manage_existence_path(csv_path)
-            logger.debug(f"Saving dataframe: {csv_path}")
-            df.to_csv(csv_path, index=False)
-
-    @staticmethod
-    def _sanitize_spreadsheets_names(
-        xlsx_df_dict: dict[str | int, pd.DataFrame]
-    ) -> dict[str, pd.DataFrame]:
-        new_xlsx_df_dict = {}
-        for sheet_name in list(xlsx_df_dict.keys()):
-            sheet_name_refactored = sanitize_dataset_name(str(sheet_name))
-            new_xlsx_df_dict[sheet_name_refactored] = xlsx_df_dict.pop(sheet_name)
-            logger.debug(f"Replace name: {sheet_name} into {sheet_name_refactored}")
-        return new_xlsx_df_dict
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+import logging
+import os.path
+from pathlib import Path
+
+import pandas as pd
+
+from pyzefir.parser.utils import TRUE_VALUES, sanitize_dataset_name
+from pyzefir.parser.validator.dataframe_validator import DataFrameValidator
+from pyzefir.parser.validator.valid_structure import (
+    DatasetConfig,
+    get_dataset_config_from_categories,
+    get_dataset_reference,
+)
+from pyzefir.utils.converters.converter import AbstractConverter
+from pyzefir.utils.path_manager import (
+    DataCategories,
+    XlsxPathManager,
+    get_datasets_from_categories,
+    get_optional_datasets_from_categories,
+)
+
+logger = logging.getLogger(__name__)
+
+
+class ExcelToCsvConverterException(Exception):
+    pass
+
+
+class ExcelToCsvConverter(AbstractConverter):
+    def __init__(
+        self,
+        input_files_path: Path,
+        output_files_path: Path,
+        scenario_path: Path | None = None,
+    ) -> None:
+        self.path_manager = XlsxPathManager(
+            input_path=input_files_path,
+            output_path=output_files_path,
+            scenario_name=scenario_path.stem if scenario_path else None,
+        )
+        self._scenario_path = scenario_path
+
+    def convert(self) -> None:
+        for category in DataCategories.get_main_categories():
+            if category == DataCategories.SCENARIO and not self._scenario_path:
+                logger.debug(
+                    f"Scenario file is not passed {self._scenario_path=}, skipped"
+                )
+                continue
+            xlsx_path = (
+                self._scenario_path
+                if category == DataCategories.SCENARIO
+                else self.path_manager.get_input_file_path(category)
+            )
+            if not os.path.isfile(str(xlsx_path)):
+                if category in DataCategories.get_optional_categories():
+                    continue
+                logger.error(f"Cannot find file in dir {xlsx_path}")
+                raise ExcelToCsvConverterException(
+                    f"File cannot be found in given path: {xlsx_path}"
+                )
+
+            xlsx_df_dict = pd.read_excel(
+                xlsx_path, sheet_name=None, true_values=TRUE_VALUES
+            )
+            logger.debug(f"File {xlsx_path} found in given path")
+
+            sanitized_df_dict = self._sanitize_spreadsheets_names(xlsx_df_dict)
+            self._validate(category=category, xlsx_df_dict=sanitized_df_dict)
+            self._convert_xlsx_to_csv(category, xlsx_df_dict=sanitized_df_dict)
+
+    def _validate(self, category: str, xlsx_df_dict: dict[str, pd.DataFrame]) -> None:
+        if category not in DataCategories.get_dynamic_categories():
+            self._validate_xlsx_structure(
+                xlsx_sheets_names=list(xlsx_df_dict.keys()), category=category
+            )
+        self._validate_dataframes_structure(
+            xlsx_df_dict=xlsx_df_dict, category=category
+        )
+
+    @staticmethod
+    def _validate_dataframes_structure(
+        xlsx_df_dict: dict[str, pd.DataFrame], category: str
+    ) -> None:
+        for sheet_name, df in xlsx_df_dict.items():
+            if df.empty:
+                continue
+            valid_structure = get_dataset_config_from_categories(
+                data_category=category, dataset_name=sheet_name
+            )
+            dataframe_structure: dict[str, str] = (
+                ExcelToCsvConverter._get_dataframe_structure(df, valid_structure)
+            )
+            dataset_reference = get_dataset_reference(
+                category, valid_structure.dataset_name
+            )
+            DataFrameValidator(
+                df=df,
+                dataframe_structure=dataframe_structure,
+                valid_structure=valid_structure,
+                dataset_reference=dataset_reference,
+            ).validate()
+
+    @staticmethod
+    def _get_dataframe_structure(
+        df: pd.DataFrame, valid_structure: DatasetConfig
+    ) -> dict[str, str]:
+        structure = {}
+        for col, dtype in df.dtypes.items():
+            if valid_structure.columns.get(col) is bool:
+                df.loc[:, col] = df.loc[:, col].fillna(False)
+                structure[str(col)] = "bool"
+            elif (
+                col not in valid_structure.columns
+                and valid_structure.default_type is not None
+                and bool in valid_structure.default_type
+            ):
+                df.loc[:, col] = df.loc[:, col].fillna(False)
+                structure[str(col)] = "bool"
+            else:
+                structure[str(col)] = dtype.name
+        return structure
+
+    @staticmethod
+    def _validate_xlsx_structure(xlsx_sheets_names: list[str], category: str) -> None:
+        valid_sheets_names: list[str] = get_datasets_from_categories(category)
+        missing_spreadsheets = set(valid_sheets_names).difference(xlsx_sheets_names)
+        optional_spreadsheets = set(get_optional_datasets_from_categories(category))
+        if missing_spreadsheets and not missing_spreadsheets.issubset(
+            optional_spreadsheets
+        ):
+            logger.error("Required spreadsheets not in xlsx file")
+            raise ExcelToCsvConverterException(
+                f"Not all required spreadsheets {missing_spreadsheets} found in xlsx file spreadsheets"
+                f" {xlsx_sheets_names}"
+            )
+        logger.debug("All required spreadsheets are in xlsx file")
+
+    def _convert_xlsx_to_csv(
+        self, category: str, xlsx_df_dict: dict[str, pd.DataFrame]
+    ) -> None:
+        for sheet_name, df in xlsx_df_dict.items():
+            csv_path = (
+                self.path_manager.concatenate_path_for_dynamic_dataset_name(
+                    category, sheet_name
+                )
+                if category in DataCategories.get_dynamic_categories()
+                else self.path_manager.get_path(category, sheet_name)
+            )
+            self.manage_existence_path(csv_path)
+            logger.debug(f"Saving dataframe: {csv_path}")
+            df.to_csv(csv_path, index=False)
+
+    @staticmethod
+    def _sanitize_spreadsheets_names(
+        xlsx_df_dict: dict[str | int, pd.DataFrame]
+    ) -> dict[str, pd.DataFrame]:
+        new_xlsx_df_dict = {}
+        for sheet_name in list(xlsx_df_dict.keys()):
+            sheet_name_refactored = sanitize_dataset_name(str(sheet_name))
+            new_xlsx_df_dict[sheet_name_refactored] = xlsx_df_dict.pop(sheet_name)
+            logger.debug(f"Replace name: {sheet_name} into {sheet_name_refactored}")
+        return new_xlsx_df_dict
```

### Comparing `pyzefir-0.4.1/pyzefir/utils/functions.py` & `pyzefir-0.4.22/pyzefir/utils/functions.py`

 * *Ordering differences only*

 * *Files 21% similar despite different names*

```diff
@@ -1,97 +1,97 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-from collections import defaultdict
-from typing import TypeVar
-
-import numpy as np
-
-
-def get_dict_vals(used_dict: dict[int, set] | None) -> set:
-    """get all values of dictionary"""
-    if used_dict is None:
-        return set()
-    return {element for value_set in used_dict.values() for element in value_set}
-
-
-def demand_chunk_unit_indices(
-    demand_chunk_idx: int,
-    demand_chunk_tags: dict[int, int],
-    unit_tags: dict[int, set[int]],
-) -> set[int]:
-    """unit idx of the corresponding demand chunk id"""
-    """dem_ch_tag: demand chunks idx to tag idx """
-    """unit _tags: unit idx to tag idx"""
-    return {
-        unit_idx
-        for unit_idx, tag_set in unit_tags.items()
-        if demand_chunk_tags[demand_chunk_idx] in tag_set
-    }
-
-
-T = TypeVar("T")
-Y = TypeVar("Y")
-
-
-def invert_dict_of_sets(dict_: dict[T, set[Y]]) -> dict[Y, set[T]]:
-    result_dict = defaultdict(set)
-    for key, value_set in dict_.items():
-        for value in value_set:
-            result_dict[value].add(key)
-    return dict(result_dict)
-
-
-def tag_str_to_idx(
-    min_max_gen_frac: dict[str, dict[tuple[int, int], float]] | None,
-    tag_str_to_idx_arg: dict[int, int],
-) -> dict[str, dict[tuple[int, int], float]] | None:
-    """for opt_parameters: reading min/max generation fractions replace tags str by idxs
-    using tag_str_to_idx map"""
-    if min_max_gen_frac is None:
-        return None
-    return {
-        k: {
-            (tag_str_to_idx_arg[t[0]], tag_str_to_idx_arg[t[1]]): p
-            for t, p in v.items()
-        }
-        for k, v in min_max_gen_frac.items()
-    }
-
-
-def is_flow_int(num: float | int | str | None) -> bool:
-    """check if general float number allowing int type"""
-    if (
-        num is not None
-        and isinstance(num, float | int | np.integer)
-        and not np.isnan(num)
-    ):
-        return True
-    return False
-
-
-def is_none_general(arg: dict | None) -> bool:
-    """returns True if None or empty dict"""
-    res = False
-    if isinstance(arg, dict):
-        if len(arg) == 0:
-            res = True
-    elif arg is None:
-        res = True
-    return res
-
-
-def flatten_list(list_of_lists: list[tuple[int]] | list[list[int]]) -> list[int]:
-    return [elem for list_elem in list_of_lists for elem in list_elem]
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+from collections import defaultdict
+from typing import TypeVar
+
+import numpy as np
+
+
+def get_dict_vals(used_dict: dict[int, set] | None) -> set:
+    """get all values of dictionary"""
+    if used_dict is None:
+        return set()
+    return {element for value_set in used_dict.values() for element in value_set}
+
+
+def demand_chunk_unit_indices(
+    demand_chunk_idx: int,
+    demand_chunk_tags: dict[int, int],
+    unit_tags: dict[int, set[int]],
+) -> set[int]:
+    """unit idx of the corresponding demand chunk id"""
+    """dem_ch_tag: demand chunks idx to tag idx """
+    """unit _tags: unit idx to tag idx"""
+    return {
+        unit_idx
+        for unit_idx, tag_set in unit_tags.items()
+        if demand_chunk_tags[demand_chunk_idx] in tag_set
+    }
+
+
+T = TypeVar("T")
+Y = TypeVar("Y")
+
+
+def invert_dict_of_sets(dict_: dict[T, set[Y]]) -> dict[Y, set[T]]:
+    result_dict = defaultdict(set)
+    for key, value_set in dict_.items():
+        for value in value_set:
+            result_dict[value].add(key)
+    return dict(result_dict)
+
+
+def tag_str_to_idx(
+    min_max_gen_frac: dict[str, dict[tuple[int, int], float]] | None,
+    tag_str_to_idx_arg: dict[int, int],
+) -> dict[str, dict[tuple[int, int], float]] | None:
+    """for opt_parameters: reading min/max generation fractions replace tags str by idxs
+    using tag_str_to_idx map"""
+    if min_max_gen_frac is None:
+        return None
+    return {
+        k: {
+            (tag_str_to_idx_arg[t[0]], tag_str_to_idx_arg[t[1]]): p
+            for t, p in v.items()
+        }
+        for k, v in min_max_gen_frac.items()
+    }
+
+
+def is_flow_int(num: float | int | str | None) -> bool:
+    """check if general float number allowing int type"""
+    if (
+        num is not None
+        and isinstance(num, float | int | np.integer)
+        and not np.isnan(num)
+    ):
+        return True
+    return False
+
+
+def is_none_general(arg: dict | None) -> bool:
+    """returns True if None or empty dict"""
+    res = False
+    if isinstance(arg, dict):
+        if len(arg) == 0:
+            res = True
+    elif arg is None:
+        res = True
+    return res
+
+
+def flatten_list(list_of_lists: list[tuple[int]] | list[list[int]]) -> list[int]:
+    return [elem for list_elem in list_of_lists for elem in list_elem]
```

### Comparing `pyzefir-0.4.1/pyzefir/utils/path_manager.py` & `pyzefir-0.4.22/pyzefir/utils/path_manager.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,272 +1,299 @@
-# PyZefir
-# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
-#
-# This program is free software: you can redistribute it and/or modify
-# it under the terms of the GNU Affero General Public License as published by
-# the Free Software Foundation, either version 3 of the License, or
-# (at your option) any later version.
-#
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU Affero General Public License for more details.
-#
-# You should have received a copy of the GNU Affero General Public License
-# along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-import logging
-from dataclasses import dataclass, fields
-from pathlib import Path
-
-logger = logging.getLogger(__name__)
-
-
-class DataCategoriesException(Exception):
-    pass
-
-
-class CsvPathManagerException(Exception):
-    pass
-
-
-@dataclass(frozen=True)
-class DataCategories:
-    INITIAL_STATE: str = "initial_state"
-    STRUCTURE: str = "structure"
-    CAPACITY_FACTORS: str = "capacity_factors"
-    FUELS: str = "fuels"
-    GENERATOR: str = "generator_types"
-    STORAGE: str = "storage_types"
-    DEMAND: str = "demand_types"
-    SCENARIO: str = "scenarios"
-    DEMAND_CHUNKS: str = "demand_chunks"
-    CONVERSION_RATE: str = "conversion_rate"
-
-    @classmethod
-    def check_directory_name(cls, value: str) -> None:
-        if not any(getattr(cls, f.name) == value for f in fields(cls)):
-            logger.warning(f"Incorrect {cls.__name__} field: {value}")
-            raise DataCategoriesException(
-                f"{cls.__name__} does not contain a field {value}"
-            )
-
-    @staticmethod
-    def get_main_categories() -> list[str]:
-        return [
-            DataCategories.INITIAL_STATE,
-            DataCategories.STRUCTURE,
-            DataCategories.CAPACITY_FACTORS,
-            DataCategories.FUELS,
-            DataCategories.GENERATOR,
-            DataCategories.STORAGE,
-            DataCategories.DEMAND,
-            DataCategories.SCENARIO,
-            DataCategories.CONVERSION_RATE,
-            DataCategories.DEMAND_CHUNKS,
-        ]
-
-    @staticmethod
-    def get_dynamic_categories() -> list[str]:
-        return [
-            DataCategories.DEMAND,
-            DataCategories.CONVERSION_RATE,
-            DataCategories.DEMAND_CHUNKS,
-        ]
-
-
-@dataclass(frozen=True)
-class DataSubCategories:
-    EMISSION_PER_UNIT: str = "Emission_Per_Unit"
-    ENERGY_PER_UNIT: str = "Energy_Per_Unit"
-    PROFILES: str = "Profiles"
-    GENERATOR_TYPES: str = "Generator_Types"
-    EFFICIENCY: str = "Efficiency"
-    EMISSION_REDUCTION: str = "Emission_Reduction"
-    GENERATOR_TYPE_ENERGY_CARRIER: str = "Generator_Type_Energy_Carrier"
-    GENERATOR_TYPE_ENERGY_TYPE: str = "Generator_Type_Energy_Type"
-    PARAMETERS: str = "Parameters"
-    TECHNOLOGY: str = "Technology"
-    TECHNOLOGYSTACK: str = "TechnologyStack"
-    ENERGY_TYPES: str = "Energy_Types"
-    EMISSION_TYPES: str = "Emission_Types"
-    AGGREGATES: str = "Aggregates"
-    LINES: str = "Lines"
-    BUSES: str = "Buses"
-    GENERATORS: str = "Generators"
-    STORAGES: str = "Storages"
-    TECHNOLOGYSTACKS_BUSES_OUT: str = "TechnologyStack_Buses_out"
-    TECHNOLOGY_BUS: str = "Technology_Bus"
-    TECHNOLOGYSTACK_BUSES: str = "TechnologyStack_Buses"
-    TECHNOLOGYSTACK_AGGREGATE: str = "TechnologyStack_Aggregate"
-    ENERGY_SOURCE_EVOLUTION_LIMITS: str = "Energy_Source_Evolution_Limits"
-    ELEMENT_ENERGY_EVOLUTION_LIMITS: str = "Element_Energy_Evolution_Limits"
-    COST_PARAMETERS: str = "Cost_Parameters"
-    FUEL_AVAILABILITY: str = "Fuel_Availability"
-    RELATIVE_EMISSION_LIMITS: str = "Relative_Emission_Limits"
-    FUEL_PRICES: str = "Fuel_Prices"
-    CONSTANTS: str = "Constants"
-    YEARLY_ENERGY_USAGE: str = "Yearly_Demand"
-    TRANSMISSION_FEES: str = "Transmission_Fees"
-    FRACTIONS: str = "Fractions"
-    N_CONSUMERS: str = "N_Consumers"
-    EMISSION_FEES_EMISSION_TYPES: str = "Emission_Fees_Emission_Types"
-    GENERATOR_EMISSION_FEES: str = "Generator_Emission_Fees"
-    EMISSION_FEES: str = "Emission_Fees"
-    DEMAND_CHUNKS: str = "Demand_Chunks"
-    GENERATION_FRACTION: str = "Generation_Fraction"
-    CURTAILMENT_COST: str = "Curtailment_Cost"
-    DSR: str = "DSR"
-    POWER_RESERVE: str = "Power_Reserve"
-    POWER_UTILIZATION: str = "Power_Utilization"
-
-    @classmethod
-    def check_directory_name(cls, value: str) -> None:
-        if not any(getattr(cls, f.name) == value for f in fields(cls)):
-            logger.warning(f"Incorrect {cls.__name__} field: {value}")
-            raise DataCategoriesException(
-                f"{cls.__name__} does not contain a field {value} "
-            )
-
-
-def get_datasets_from_categories(data_category: str) -> list[str]:
-    datasets_in_categories = {
-        DataCategories.FUELS: [
-            DataSubCategories.EMISSION_PER_UNIT,
-            DataSubCategories.ENERGY_PER_UNIT,
-        ],
-        DataCategories.CAPACITY_FACTORS: [
-            DataSubCategories.PROFILES,
-        ],
-        DataCategories.GENERATOR: [
-            DataSubCategories.GENERATOR_TYPES,
-            DataSubCategories.EFFICIENCY,
-            DataSubCategories.EMISSION_REDUCTION,
-            DataSubCategories.GENERATOR_TYPE_ENERGY_CARRIER,
-            DataSubCategories.GENERATOR_TYPE_ENERGY_TYPE,
-            DataSubCategories.POWER_UTILIZATION,
-        ],
-        DataCategories.STORAGE: [DataSubCategories.PARAMETERS],
-        DataCategories.INITIAL_STATE: [
-            DataSubCategories.TECHNOLOGY,
-            DataSubCategories.TECHNOLOGYSTACK,
-        ],
-        DataCategories.STRUCTURE: [
-            DataSubCategories.ENERGY_TYPES,
-            DataSubCategories.EMISSION_TYPES,
-            DataSubCategories.AGGREGATES,
-            DataSubCategories.LINES,
-            DataSubCategories.BUSES,
-            DataSubCategories.GENERATORS,
-            DataSubCategories.STORAGES,
-            DataSubCategories.TECHNOLOGYSTACKS_BUSES_OUT,
-            DataSubCategories.TECHNOLOGY_BUS,
-            DataSubCategories.TECHNOLOGYSTACK_BUSES,
-            DataSubCategories.TECHNOLOGYSTACK_AGGREGATE,
-            DataSubCategories.TRANSMISSION_FEES,
-            DataSubCategories.EMISSION_FEES_EMISSION_TYPES,
-            DataSubCategories.GENERATOR_EMISSION_FEES,
-            DataSubCategories.DSR,
-            DataSubCategories.POWER_RESERVE,
-        ],
-        DataCategories.SCENARIO: [
-            DataSubCategories.ELEMENT_ENERGY_EVOLUTION_LIMITS,
-            DataSubCategories.ENERGY_SOURCE_EVOLUTION_LIMITS,
-            DataSubCategories.COST_PARAMETERS,
-            DataSubCategories.FUEL_AVAILABILITY,
-            DataSubCategories.RELATIVE_EMISSION_LIMITS,
-            DataSubCategories.FUEL_PRICES,
-            DataSubCategories.CONSTANTS,
-            DataSubCategories.YEARLY_ENERGY_USAGE,
-            DataSubCategories.FRACTIONS,
-            DataSubCategories.N_CONSUMERS,
-            DataSubCategories.EMISSION_FEES,
-            DataSubCategories.GENERATION_FRACTION,
-            DataSubCategories.CURTAILMENT_COST,
-        ],
-        DataCategories.DEMAND_CHUNKS: [DataSubCategories.DEMAND_CHUNKS],
-    }
-
-    try:
-        return datasets_in_categories[data_category]
-    except KeyError:
-        logger.warning(f"{data_category=} not in datasets_in_categories keys")
-        raise
-
-
-class CsvPathManager:
-    def __init__(self, dir_path: Path, scenario_name: str | None = None) -> None:
-        self._dir_path = dir_path
-        self._scenario_name = scenario_name
-
-    def __repr__(self) -> str:
-        return f"CsvPathManager({self._dir_path=})"
-
-    @property
-    def dir_path(self) -> Path:
-        logger.debug(f"Csv root dir path is {self._dir_path}")
-        return self._dir_path
-
-    def get_path(self, data_category: str, dataset_name: str | None = None) -> Path:
-        DataCategories.check_directory_name(data_category)
-        if dataset_name:
-            if data_category == DataCategories.SCENARIO and self._scenario_name:
-                target_path = self._dir_path.joinpath(
-                    data_category,
-                    f"{self._scenario_name}/{self._get_file_name_from_dict(data_category, dataset_name)}",
-                )
-            else:
-                target_path = self._dir_path.joinpath(
-                    data_category,
-                    self._get_file_name_from_dict(data_category, dataset_name),
-                )
-            logger.debug(f"File {dataset_name} is at the path: {target_path}")
-        else:
-            target_path = self._dir_path.joinpath(data_category)
-            logger.debug(f"Given folder is at the path: {target_path}")
-        return target_path
-
-    def concatenate_path_for_dynamic_dataset_name(
-        self, category: str, dataset_name: str
-    ) -> Path:
-        root_path = self.get_path(data_category=category)
-        return root_path.joinpath(f"{dataset_name}.csv")
-
-    @staticmethod
-    def _get_file_name_from_dict(data_category: str, dataset_name: str) -> str:
-        try:
-            DataSubCategories.check_directory_name(dataset_name)
-            return f"{dataset_name}.csv"
-        except DataCategoriesException as e:
-            logger.warning(f"Exception was raised: {e}")
-            raise CsvPathManagerException(
-                f"File {dataset_name} in category {data_category} is not part of given structure"
-            )
-
-
-class XlsxPathManager(CsvPathManager):
-    def __init__(
-        self, input_path: Path, output_path: Path, scenario_name: str | None = None
-    ) -> None:
-        super().__init__(output_path)
-        self._input_path = input_path
-        self._scenario_name = scenario_name
-
-    def __repr__(self) -> str:
-        return f"XlsxPathManager({self.input_path=}, {self.output_path=})"
-
-    @property
-    def input_path(self) -> Path:
-        logger.debug(f"Input path is {self._input_path}")
-        return self._input_path
-
-    @property
-    def output_path(self) -> Path:
-        logger.debug(f"Output path is {self._dir_path}")
-        return self._dir_path
-
-    def get_input_file_path(self, data_category: str) -> Path:
-        DataCategories.check_directory_name(data_category)
-        target_path = self._input_path.joinpath(f"{data_category}.xlsx")
-
-        logger.debug(f"Path for file {data_category}: {target_path}")
-        return target_path
+# PyZefir
+# Copyright (C) 2023-2024 Narodowe Centrum Bada Jdrowych
+#
+# This program is free software: you can redistribute it and/or modify
+# it under the terms of the GNU Affero General Public License as published by
+# the Free Software Foundation, either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU Affero General Public License for more details.
+#
+# You should have received a copy of the GNU Affero General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+import logging
+from dataclasses import dataclass, fields
+from pathlib import Path
+
+logger = logging.getLogger(__name__)
+
+
+class DataCategoriesException(Exception):
+    pass
+
+
+class CsvPathManagerException(Exception):
+    pass
+
+
+@dataclass(frozen=True)
+class DataCategories:
+    INITIAL_STATE: str = "initial_state"
+    STRUCTURE: str = "structure"
+    CAPACITY_FACTORS: str = "capacity_factors"
+    FUELS: str = "fuels"
+    GENERATOR: str = "generator_types"
+    STORAGE: str = "storage_types"
+    DEMAND: str = "demand_types"
+    SCENARIO: str = "scenarios"
+    DEMAND_CHUNKS: str = "demand_chunks"
+    CONVERSION_RATE: str = "conversion_rate"
+    GENERATOR_TYPE_EFFICIENCY: str = "generator_type_efficiency"
+
+    @classmethod
+    def check_directory_name(cls, value: str) -> None:
+        if not any(getattr(cls, f.name) == value for f in fields(cls)):
+            logger.warning(f"Incorrect {cls.__name__} field: {value}")
+            raise DataCategoriesException(
+                f"{cls.__name__} does not contain a field {value}"
+            )
+
+    @staticmethod
+    def get_main_categories() -> list[str]:
+        return [
+            DataCategories.INITIAL_STATE,
+            DataCategories.STRUCTURE,
+            DataCategories.CAPACITY_FACTORS,
+            DataCategories.FUELS,
+            DataCategories.GENERATOR,
+            DataCategories.STORAGE,
+            DataCategories.DEMAND,
+            DataCategories.SCENARIO,
+            DataCategories.CONVERSION_RATE,
+            DataCategories.DEMAND_CHUNKS,
+            DataCategories.GENERATOR_TYPE_EFFICIENCY,
+        ]
+
+    @staticmethod
+    def get_dynamic_categories() -> list[str]:
+        return [
+            DataCategories.DEMAND,
+            DataCategories.CONVERSION_RATE,
+            DataCategories.DEMAND_CHUNKS,
+            DataCategories.GENERATOR_TYPE_EFFICIENCY,
+        ]
+
+    @staticmethod
+    def get_optional_categories() -> list[str]:
+        return [
+            DataCategories.STORAGE,
+            DataCategories.GENERATOR_TYPE_EFFICIENCY,
+        ]
+
+
+@dataclass(frozen=True)
+class DataSubCategories:
+    EMISSION_PER_UNIT: str = "Emission_Per_Unit"
+    ENERGY_PER_UNIT: str = "Energy_Per_Unit"
+    PROFILES: str = "Profiles"
+    GENERATOR_TYPES: str = "Generator_Types"
+    EFFICIENCY: str = "Efficiency"
+    EMISSION_REDUCTION: str = "Emission_Reduction"
+    GENERATOR_TYPE_ENERGY_CARRIER: str = "Generator_Type_Energy_Carrier"
+    GENERATOR_TYPE_ENERGY_TYPE: str = "Generator_Type_Energy_Type"
+    PARAMETERS: str = "Parameters"
+    TECHNOLOGY: str = "Technology"
+    TECHNOLOGYSTACK: str = "TechnologyStack"
+    ENERGY_TYPES: str = "Energy_Types"
+    EMISSION_TYPES: str = "Emission_Types"
+    AGGREGATES: str = "Aggregates"
+    LINES: str = "Lines"
+    BUSES: str = "Buses"
+    GENERATORS: str = "Generators"
+    STORAGES: str = "Storages"
+    TECHNOLOGYSTACKS_BUSES_OUT: str = "TechnologyStack_Buses_out"
+    TECHNOLOGY_BUS: str = "Technology_Bus"
+    TECHNOLOGYSTACK_BUSES: str = "TechnologyStack_Buses"
+    TECHNOLOGYSTACK_AGGREGATE: str = "TechnologyStack_Aggregate"
+    ENERGY_SOURCE_EVOLUTION_LIMITS: str = "Energy_Source_Evolution_Limits"
+    ELEMENT_ENERGY_EVOLUTION_LIMITS: str = "Element_Energy_Evolution_Limits"
+    COST_PARAMETERS: str = "Cost_Parameters"
+    FUEL_AVAILABILITY: str = "Fuel_Availability"
+    RELATIVE_EMISSION_LIMITS: str = "Relative_Emission_Limits"
+    FUEL_PRICES: str = "Fuel_Prices"
+    CONSTANTS: str = "Constants"
+    YEARLY_ENERGY_USAGE: str = "Yearly_Demand"
+    TRANSMISSION_FEES: str = "Transmission_Fees"
+    FRACTIONS: str = "Fractions"
+    N_CONSUMERS: str = "N_Consumers"
+    EMISSION_FEES_EMISSION_TYPES: str = "Emission_Fees_Emission_Types"
+    GENERATOR_EMISSION_FEES: str = "Generator_Emission_Fees"
+    EMISSION_FEES: str = "Emission_Fees"
+    DEMAND_CHUNKS: str = "Demand_Chunks"
+    GENERATION_FRACTION: str = "Generation_Fraction"
+    CURTAILMENT_COST: str = "Curtailment_Cost"
+    DSR: str = "DSR"
+    POWER_RESERVE: str = "Power_Reserve"
+    POWER_UTILIZATION: str = "Power_Utilization"
+    GENERATOR_BINDING: str = "Generator_Binding"
+    GENERATION_COMPENSATION: str = "Generation_Compensation"
+
+    @classmethod
+    def check_directory_name(cls, value: str) -> None:
+        if not any(getattr(cls, f.name) == value for f in fields(cls)):
+            logger.warning(f"Incorrect {cls.__name__} field: {value}")
+            raise DataCategoriesException(
+                f"{cls.__name__} does not contain a field {value} "
+            )
+
+
+def get_datasets_from_categories(data_category: str) -> list[str]:
+    datasets_in_categories = {
+        DataCategories.FUELS: [
+            DataSubCategories.EMISSION_PER_UNIT,
+            DataSubCategories.ENERGY_PER_UNIT,
+        ],
+        DataCategories.CAPACITY_FACTORS: [
+            DataSubCategories.PROFILES,
+        ],
+        DataCategories.GENERATOR: [
+            DataSubCategories.GENERATOR_TYPES,
+            DataSubCategories.EFFICIENCY,
+            DataSubCategories.EMISSION_REDUCTION,
+            DataSubCategories.GENERATOR_TYPE_ENERGY_CARRIER,
+            DataSubCategories.GENERATOR_TYPE_ENERGY_TYPE,
+            DataSubCategories.POWER_UTILIZATION,
+        ],
+        DataCategories.STORAGE: [DataSubCategories.PARAMETERS],
+        DataCategories.INITIAL_STATE: [
+            DataSubCategories.TECHNOLOGY,
+            DataSubCategories.TECHNOLOGYSTACK,
+        ],
+        DataCategories.STRUCTURE: [
+            DataSubCategories.ENERGY_TYPES,
+            DataSubCategories.EMISSION_TYPES,
+            DataSubCategories.AGGREGATES,
+            DataSubCategories.LINES,
+            DataSubCategories.BUSES,
+            DataSubCategories.GENERATORS,
+            DataSubCategories.STORAGES,
+            DataSubCategories.TECHNOLOGYSTACKS_BUSES_OUT,
+            DataSubCategories.TECHNOLOGY_BUS,
+            DataSubCategories.TECHNOLOGYSTACK_BUSES,
+            DataSubCategories.TECHNOLOGYSTACK_AGGREGATE,
+            DataSubCategories.TRANSMISSION_FEES,
+            DataSubCategories.EMISSION_FEES_EMISSION_TYPES,
+            DataSubCategories.GENERATOR_EMISSION_FEES,
+            DataSubCategories.DSR,
+            DataSubCategories.POWER_RESERVE,
+            DataSubCategories.GENERATOR_BINDING,
+        ],
+        DataCategories.SCENARIO: [
+            DataSubCategories.ELEMENT_ENERGY_EVOLUTION_LIMITS,
+            DataSubCategories.ENERGY_SOURCE_EVOLUTION_LIMITS,
+            DataSubCategories.COST_PARAMETERS,
+            DataSubCategories.FUEL_AVAILABILITY,
+            DataSubCategories.RELATIVE_EMISSION_LIMITS,
+            DataSubCategories.FUEL_PRICES,
+            DataSubCategories.CONSTANTS,
+            DataSubCategories.YEARLY_ENERGY_USAGE,
+            DataSubCategories.FRACTIONS,
+            DataSubCategories.N_CONSUMERS,
+            DataSubCategories.EMISSION_FEES,
+            DataSubCategories.GENERATION_FRACTION,
+            DataSubCategories.CURTAILMENT_COST,
+            DataSubCategories.GENERATION_COMPENSATION,
+        ],
+        DataCategories.DEMAND_CHUNKS: [DataSubCategories.DEMAND_CHUNKS],
+    }
+
+    try:
+        return datasets_in_categories[data_category]
+    except KeyError:
+        logger.warning(f"{data_category=} not in datasets_in_categories keys")
+        raise
+
+
+def get_optional_datasets_from_categories(data_category: str) -> list[str]:
+    datasets_in_categories = {
+        DataCategories.STORAGE: [
+            DataSubCategories.PARAMETERS,
+        ],
+        DataCategories.STRUCTURE: [
+            DataSubCategories.STORAGES,
+        ],
+    }
+
+    return datasets_in_categories.get(data_category, [])
+
+
+class CsvPathManager:
+    def __init__(self, dir_path: Path, scenario_name: str | None = None) -> None:
+        self._dir_path = dir_path
+        self._scenario_name = scenario_name
+
+    def __repr__(self) -> str:
+        return f"CsvPathManager({self._dir_path=})"
+
+    @property
+    def dir_path(self) -> Path:
+        logger.debug(f"Csv root dir path is {self._dir_path}")
+        return self._dir_path
+
+    def get_path(self, data_category: str, dataset_name: str | None = None) -> Path:
+        DataCategories.check_directory_name(data_category)
+        if dataset_name:
+            if data_category == DataCategories.SCENARIO and self._scenario_name:
+                target_path = self._dir_path.joinpath(
+                    data_category,
+                    f"{self._scenario_name}/{self._get_file_name_from_dict(data_category, dataset_name)}",
+                )
+            else:
+                target_path = self._dir_path.joinpath(
+                    data_category,
+                    self._get_file_name_from_dict(data_category, dataset_name),
+                )
+            logger.debug(f"File {dataset_name} is at the path: {target_path}")
+        else:
+            target_path = self._dir_path.joinpath(data_category)
+            logger.debug(f"Given folder is at the path: {target_path}")
+        return target_path
+
+    def concatenate_path_for_dynamic_dataset_name(
+        self, category: str, dataset_name: str
+    ) -> Path:
+        root_path = self.get_path(data_category=category)
+        return root_path.joinpath(f"{dataset_name}.csv")
+
+    @staticmethod
+    def _get_file_name_from_dict(data_category: str, dataset_name: str) -> str:
+        try:
+            DataSubCategories.check_directory_name(dataset_name)
+            return f"{dataset_name}.csv"
+        except DataCategoriesException as e:
+            logger.warning(f"Exception was raised: {e}")
+            raise CsvPathManagerException(
+                f"File {dataset_name} in category {data_category} is not part of given structure"
+            )
+
+
+class XlsxPathManager(CsvPathManager):
+    def __init__(
+        self, input_path: Path, output_path: Path, scenario_name: str | None = None
+    ) -> None:
+        super().__init__(output_path)
+        self._input_path = input_path
+        self._scenario_name = scenario_name
+
+    def __repr__(self) -> str:
+        return f"XlsxPathManager({self.input_path=}, {self.output_path=})"
+
+    @property
+    def input_path(self) -> Path:
+        logger.debug(f"Input path is {self._input_path}")
+        return self._input_path
+
+    @property
+    def output_path(self) -> Path:
+        logger.debug(f"Output path is {self._dir_path}")
+        return self._dir_path
+
+    def get_input_file_path(self, data_category: str) -> Path:
+        DataCategories.check_directory_name(data_category)
+        target_path = self._input_path.joinpath(f"{data_category}.xlsx")
+
+        logger.debug(f"Path for file {data_category}: {target_path}")
+        return target_path
```

### Comparing `pyzefir-0.4.1/pyzefir.egg-info/PKG-INFO` & `pyzefir-0.4.22/pyzefir.egg-info/PKG-INFO`

 * *Files 11% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: pyzefir
-Version: 0.4.1
+Version: 0.4.22
 Author-email: Narodowe Centrum Bada Jdrowych <office@idea.edu.pl>
 License:                     GNU AFFERO GENERAL PUBLIC LICENSE
                                Version 3, 19 November 2007
         
          Copyright (C) 2007 Free Software Foundation, Inc. <https://fsf.org/>
          Everyone is permitted to copy and distribute verbatim copies
          of this license document, but changing it is not allowed.
@@ -742,14 +742,22 @@
 
 ## Make stages
 
 Install virtual environment and all dependencies
 ```bash
 make install
 ```
+If you are developing pyZefir it is recommended to use editable mode.
+```bash
+make install EDITABLE=yes
+```
+which  allows you to install a package in such a way that any changes made to
+the source code are immediately reflected in the installed package without the
+need to reinstall it.
+
 Run linters check (black, pylama)
 ```bash
 make lint
 ```
 Run unit and fast integration tests (runs lint stage before)
 ```bash
 Make unit
@@ -805,42 +813,37 @@
 structure-creator -i pyzefir\resources\structure_creator_resources -o pyzefir\results -s base_scenario -h 8760 -y 20
 ```
 
 ### How structure creator resources directory must look like:
 ```markdown
 .
  structure_creator_resources/
-     cap_range/
-        cap_base.xlsx
-        cap_max.xlsx
-        cap_min.xlsx
      lbs/
-        boiler_coal_new_lkt.json
-        boiler_gas_lkt.json
+        boiler_coal_new_lkt.xlsx
+        boiler_gas_lkt.xlsx
         ...
      scenarios/
         base_scenario/
             fractions/
                boiler_coal_new_lkt.xlsx
                boiler_gas_lkt.xlsx
                ...
             cost_parameters.xlsx
             fuel_parameters.xlsx
+            generation_fraction.xlsx
             n_consumers.xlsx
             relative_emission_limits.xlsx
             technology_cap_limits.xlsx
             technology_type_cap_limits.xlsx
             yearly_demand.xlsx
-     subsystems/
-        heating_subsystem.json
-        kse_subsystem.json
-     aggr_types.json
+     aggregates.xlsx
      configuration.xlsx
-     emission_fees.json
-     global_techs.json
+     emissions.xlsx
+     subsystems.xlsx
+     transmission_fees.xlsx
 ```
 
 ## Simulation run
 
 1. Prepare `config.ini` file (look at `config_example.ini` file in project directory)
 
 :information_source: The section `create` of `config.ini` file is used for `structure creator` only, so if you're not going
@@ -857,7 +860,96 @@
 ```
 #### E.g.
 
 ```bash
 pyzefir -c pyzefir/config_basic.ini
 ```
 
+### How pyzefir resources directory must look like:
+```markdown
+
+XLSX input
+.
+ /pyzefir resources/
+     /scenarios/
+        scenario_1.xlsx
+        scenario_2.xlsx
+        ...
+     capacity_factors.xlsx
+     conversion_rate.xlsx
+     demand_chunks.xlsx
+     fuels.xlsx
+     generator_types.xlsx
+     initial_state.xlsx
+     storage_types.xlsx
+     structure.xlsx
+
+CSV input
+
+.
+ /pyzefir resources/
+     /capacity_factors/
+        Profiles.csv
+     /conversion_rate/
+        HEAT_PUMP.csv
+        BOILER_COAL.csv
+        ...
+     /demand_chunks/
+        Demand_Chunks.csv
+        chunk_period_1.csv
+        chunk_period_2.csv
+        ...
+     /demand_types/
+        family.csv
+        multifamily.csv
+        ...
+     /fuels/
+        Emission_Per_Unit.csv
+        Energy_Per_Unit.csv
+     /generator_types/
+        Efficiency.csv
+        Emission_Reduction.csv
+        Generator_Type_Energy_Carrier.csv
+        Generator_Type_Energy_Type.csv
+        Generator_Types.csv
+        Power_Utilization.csv
+     /initial_state/
+        Technology.csv
+        TechnologyStack.csv
+     /storage_types/
+        Parameters.csv
+     /structure/
+        Aggregates.csv
+        Buses.csv
+        DSR.csv
+        Emission_Fees_Emission_Types.csv
+        Emission_Types.csv
+        Energy_Types.csv
+        Generator_Binding.csv
+        Generator_Emission_Fees.csv
+        Generators.csv
+        Lines.csv
+        Power_Reserve.csv
+        Storages.csv
+        Technology_Bus.csv
+        TechnologyStack_Aggregate.csv
+        TechnologyStack_Buses_out.csv
+        TechnologyStack_Buses.csv
+        Transmission_Fees.csv
+     /scenario/
+         /scenario_name/
+            Constants.csv
+            Cost_Parameters.csv
+            Curtailment_Cost.csv
+            Element_Energy_Evolution_Limits.csv
+            Emission_Fees.csv
+            Energy_Source_Evolution_Limits.csv
+            Fractions.csv
+            Fuel_Availability.csv
+            Fuel_Prices.csv
+            Generation_Fraction.csv
+            N_Consumers.csv
+            Relative_Emission_Limits.csv
+            Yearly_Demand.csv
+         /another_scenario_name/
+             ....
+```
```

### Comparing `pyzefir-0.4.1/pyzefir.egg-info/SOURCES.txt` & `pyzefir-0.4.22/pyzefir.egg-info/SOURCES.txt`

 * *Files 4% similar despite different names*

```diff
@@ -51,27 +51,29 @@
 pyzefir/optimization/results.py
 pyzefir/optimization/linopy/__init__.py
 pyzefir/optimization/linopy/expression_handler.py
 pyzefir/optimization/linopy/model.py
 pyzefir/optimization/linopy/constraints_builder/__init__.py
 pyzefir/optimization/linopy/constraints_builder/balancing_constraints_builder.py
 pyzefir/optimization/linopy/constraints_builder/builder.py
+pyzefir/optimization/linopy/constraints_builder/capacity_binding_builder.py
 pyzefir/optimization/linopy/constraints_builder/capacity_evolution_constraints_builder.py
 pyzefir/optimization/linopy/constraints_builder/fraction_constraints_builder.py
 pyzefir/optimization/linopy/constraints_builder/generation_constraints_builder.py
 pyzefir/optimization/linopy/constraints_builder/generation_ramp.py
 pyzefir/optimization/linopy/constraints_builder/line_flow_constraints_builder.py
 pyzefir/optimization/linopy/constraints_builder/scenario_constraints_builder.py
 pyzefir/optimization/linopy/constraints_builder/storage_constraints_builder.py
 pyzefir/optimization/linopy/objective_builder/__init__.py
 pyzefir/optimization/linopy/objective_builder/capex_objective_builder.py
 pyzefir/optimization/linopy/objective_builder/curtailed_energy_cost.py
 pyzefir/optimization/linopy/objective_builder/dsr_penalty_objective_builder.py
 pyzefir/optimization/linopy/objective_builder/emission_fee_objective_builder.py
 pyzefir/optimization/linopy/objective_builder/ens_penalty_builder.py
+pyzefir/optimization/linopy/objective_builder/generation_compensation_objective_builder.py
 pyzefir/optimization/linopy/objective_builder/opex_objective_builder.py
 pyzefir/optimization/linopy/objective_builder/transmission_fee_objective_builder.py
 pyzefir/optimization/linopy/objective_builder/var_cost_objective_builder.py
 pyzefir/optimization/linopy/preprocessing/__init__.py
 pyzefir/optimization/linopy/preprocessing/indices.py
 pyzefir/optimization/linopy/preprocessing/opt_parameters.py
 pyzefir/optimization/linopy/preprocessing/opt_variables.py
@@ -124,34 +126,27 @@
 pyzefir/parser/validator/dataframe_validator.py
 pyzefir/parser/validator/valid_structure.py
 pyzefir/postprocessing/__init__.py
 pyzefir/postprocessing/results_exporters.py
 pyzefir/postprocessing/results_handler.py
 pyzefir/structure_creator/__init__.py
 pyzefir/structure_creator/__main__.py
-pyzefir/structure_creator/constants_enums.py
 pyzefir/structure_creator/excel_writer.py
-pyzefir/structure_creator/input_data.py
-pyzefir/structure_creator/utils.py
 pyzefir/structure_creator/cli/__init__.py
 pyzefir/structure_creator/cli/cli_wrapper.py
 pyzefir/structure_creator/data_loader/__init__.py
 pyzefir/structure_creator/data_loader/constants_enums.py
 pyzefir/structure_creator/data_loader/input_data.py
 pyzefir/structure_creator/scenario/__init__.py
 pyzefir/structure_creator/scenario/constants_enums.py
 pyzefir/structure_creator/scenario/main.py
 pyzefir/structure_creator/scenario/utils.py
 pyzefir/structure_creator/structure_and_initial_state/__init__.py
-pyzefir/structure_creator/structure_and_initial_state/constants_enums.py
-pyzefir/structure_creator/structure_and_initial_state/create_initial_state_data.py
-pyzefir/structure_creator/structure_and_initial_state/create_structure_data.py
 pyzefir/structure_creator/structure_and_initial_state/create_structures.py
 pyzefir/structure_creator/structure_and_initial_state/dataclasses.py
-pyzefir/structure_creator/structure_and_initial_state/main.py
 pyzefir/structure_creator/structure_and_initial_state/preprocess_handlers.py
 pyzefir/structure_creator/structure_and_initial_state/structure_element_creators.py
 pyzefir/structure_creator/structure_and_initial_state/utils.py
 pyzefir/utils/__init__.py
 pyzefir/utils/config_parser.py
 pyzefir/utils/functions.py
 pyzefir/utils/path_manager.py
```

